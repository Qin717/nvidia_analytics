patent_id,patent_abstract
10001996,"Embodiments related to selecting a runahead poison policy from a plurality of runahead poison policies during microprocessor operation are provided. The example method includes causing the microprocessor to enter runahead upon detection of a runahead event and implementing a first runahead poison policy selected from a plurality of runahead poison policies operative to manage runahead poison injection during runahead. The example method also includes during microprocessor operation, selecting a second runahead poison policy operative to manage runahead poison injection differently from the first runahead poison policy."
10002031,"A first thread is placed into a blocked state by causing the thread to perform a blocking pop operation on a hardware-accelerated, single-entry queue. When a synchronization event completes, a second thread may release the first thread from the blocked state pushing a data value onto the hardware accelerated, single-entry queue. The push operation satisfies the blocking pop operation, and the first thread is released."
10002586,"Display data used in display frame generation are compressed for efficient storage in a local memory within a graphics processing unit. The compression technique used is difference encoding and before performing difference encoding, display data in RGB format are converted into YCbCr format. Since the component values of adjacent pixels in YCbCr format typically vary less than the component values of the same adjacent pixels in RGB format, converting the display data to YCbCr format before performing difference encoding improves the compression efficiency."
10003362,"A transmitter for a serial communications link, a serial communications link and an electronic system are disclosed herein. In one embodiment, the transmitter includes: (1) a communications interface connected to a transmission medium and (2) a safe mode circuit coupled to the communications interface and configured to send data over the transmission medium in a safe mode."
10007527,"One embodiment of the present invention sets forth a technique for processing load instructions for parallel threads of a thread group when a sub-set of the parallel threads request the same memory address. The load/store unit determines if the memory addresses for each sub-set of parallel threads match based on one or more uniform patterns. When a match is achieved for at least one of the uniform patterns, the load/store unit transmits a read request to retrieve data for the sub-set of parallel threads. The number of read requests transmitted is reduced compared with performing a separate read request for each thread in the sub-set. A variety of uniform patterns may be defined based on common access patterns present in program instructions. A variety of uniform patterns may also be defined based on interconnect constraints between the load/store unit and the memory when a full crossbar interconnect is not available."
10008029,"Updating depth related graphics data is described. Geometric primitives are processed. Pixels are generated from the primitives based on the processing, each of which has at least one corresponding depth value. Culling is performed on a first group of the pixels, based on a representation of the at least one depth related value corresponding to each. Pixels may be discarded based on the culling and upon which a second group of pixels remain. A depth related raster operations function is performed, in which data is transacted with a depth buffer. The culling function is updated in relation to the transacting. The updating is performed on the basis of a granularity, which characterizes the culling function."
10008033,"A method, system, and computer program product for performing a lighting simulation are disclosed. The method includes the steps of receiving a three-dimensional (3D) model, receiving a set of probes, where each probe specifies a location within the 3D model and an orientation of the probe, and performing, via a processor, a lighting simulation based on the 3D model, the set of probes, and one or more light path expressions. The light path expressions are regular expressions that represent a series of events, each event representing an interaction of a ray at a location in the 3D model."
10008034,"A system, method, and computer program product are provided for computing indirect lighting in a cloud network. In operation, one or more scenes for rendering are identified. Further, indirect lighting associated with the one or more scenes is identified. Additionally, computation associated with the indirect lighting is performed in a cloud network utilizing at least one of a voxel-based algorithm, a photon-based algorithm, or an irradiance-map-based algorithm."
10008043,"In embodiments of the invention, an apparatus may include a display comprising a plurality of pixels and a computer system coupled with the display and operable to instruct the display to display images. The apparatus may further include an SLM array located adjacent to the display and comprising a plurality of SLMs, wherein the SLM array is operable to produce a light field by altering light emitted by the display to simulate an object that is in focus to an observer while the display and the SLM array are located within a near-eye range of the observer."
10009027,"Three state latch. In accordance with a first embodiment, an electronic circuit includes n pairs of cascaded logical gates. Each of the n pairs of cascaded logical gates includes a first logical gate including n−1 first gate inputs and one first gate output, and a second logical gate including two second gate inputs and one second gate output. One of the second gate inputs is coupled to the first gate output. The second gate output is cross coupled to one of the first gate inputs of all other the pairs of cascaded logical gates, and n is greater than 2."
10009606,A technique for decoding data within a context-based adaptive binary arithmetic coding (CABAC) stream processes one or more bins of compressed data based on video format parameters associated with the stream. A configurable CABAC decoder circuit cascades one or more instances of CABAC bin decoder logic to operate properly within a timing constrain established by a decoder clock frequency. The decoder may advantageously select among different combinations of decoder clock frequency and decoded bins per clock cycle to minimize power consumption associated with decompressing and playing the compressed data.
10013290,"A system and method are provided for synchronizing threads in a divergent region of code within a multi-threaded parallel processing system. The method includes, prior to any thread entering a divergent region, generating a count that represents a number of threads that will enter the divergent region. The method also includes using the count within the divergent region to synchronize the threads in the divergent region."
10013940,"A method for refreshing a display. The method includes refreshing even and odd columns of a display panel at a first frame refresh rate where for each frame, even and odd columns are refreshed. Upon entering a display idle period, a low power display refresh is performed. The low power display refresh includes: refreshing the even columns of the display during even frames while circuitry driving odd columns are not used, and refreshing the odd columns of the display during odd frames while circuitry driving the even columns are not used. Refreshing the even columns and refreshing the odd columns are performed at a second frame refresh rate that is slower than the first frame refresh rate."
10019381,"In one embodiment, a microprocessor is provided. The microprocessor includes a cache that is controlled by a cache controller. The cache controller is configured to replace cachelines in the cache based on a replacement scheme that prioritizes the replacement of cachelines that are less likely to cause roll back of a transaction of the microprocessor."
10019776,"A tile coalescer within a graphics processing pipeline coalesces coverage data into tiles. The coverage data indicates, for a set of XY positions, whether a graphics primitive covers those XY positions. The tile indicates, for a larger set of XY positions, whether one or more graphics primitives cover those XY positions. The tile coalescer includes coverage data in the tile only once for each XY position, thereby allowing the API ordering of the graphics primitives covering each XY position to be preserved. The tile is then distributed to a set of streaming multiprocessors for shading and blending operations. The different streaming multiprocessors execute thread groups to process the tile. In doing so, those thread groups may perform read-modify-write operations with data stored in memory. Each such thread group is scheduled to execute via atomic operations, and according to the API order of the associated graphics primitives."
10019787,"A solution is proposed that allows power savings via enhancement of pixel data to compensate for reducing backlight intensity levels. According to one embodiment, each pixel of a display is sorted according to the brightness (intensity) of the pixel. Regional pixel gains are calculated and applied on a per pixel basis so as not to exceed a quality threshold. The intensity of the backlight corresponding to each region may be decreased by an equivalent amount, thereby reducing (potentially significantly) the power consumed to operate the backlight while maintaining the color intensity in the image due to the applied pixel gains."
10020036,"One embodiment of the present invention sets forth a method for accessing non-contiguous locations within a DRAM memory page by sending a first column address command to a first DRAM device using a first subset of pins and sending a second column address command to a second DRAM device using a second subset of repurposed pins. The technique requires minimal additional pins, space, and power consumption. Further, sending multiple column address commands allows for increased granularity of DRAM accesses and therefore more efficient use of pins. The technique for accessing non-contiguous locations within a DRAM memory page."
10020871,"A wireless communications system is described which comprises a base station, a relay device, and a terminal device. The terminal device is operable to transmit a message to the base station via the relay device. The relay device is operable to add a relay header to the message received from the terminal device, the relay header comprising control information for controlling the transmission of subsequent messages from the terminal device to the relay device. The relay device is also operable to relay the message having the relay header added to the base station. By adding such control information to messages being relayed from the terminal device to the base station on the uplink, subsequent downlink communications from the base station to the terminal device can include the control information generated at the relay device (or transmission parameters derived from the control information)."
10025643,"A system and method for compiling source code (e.g., with a compiler). The method includes accessing a portion of device source code and determining whether the portion of the device source code comprises a piece of work to be launched on a device from the device. The method further includes determining a plurality of application programming interface (API) calls based on the piece of work to be launched on the device and generating compiled code based on the plurality of API calls. The compiled code comprises a first portion operable to execute on a central processing unit (CPU) and a second portion operable to execute on the device (e.g., GPU)."
10025879,"A system, computer readable medium, and method are disclosed for performing a tree traversal operation. The method includes the steps of executing, via a processor, a tree traversal operation for a tree data structure, receiving a transformation node that includes transformation data during the tree traversal operation, and transforming spatial data included in a query data structure based on the transformation data. Each node in the tree data structure is classified according to one of a plurality of nodesets, the plurality of nodesets corresponding to a plurality of local coordinate systems. The processor may be a parallel processing unit that includes one or more tree traversal units, which implement the tree traversal operation in hardware, software, or a combination of hardware and software."
10026140,A graphics system is disclosed. The graphics system includes at least one GPU (graphics processing unit) for processing a compute workload. The graphics system uses a multi-user manager for allocating the compute workload capability for each one of a plurality of users. Each user will use an access terminal.
10026223,"Systems and methods of extracting an isosurface wherein points on the isosurface have a constant value. The method includes dividing a volume into a grid of voxels The method includes identifying intersecting edges in the voxels, wherein the intersecting edges intersect the isosurface. The method includes generating patches for the intersecting edges and tessellating the patches and generating a grid of tessellated vertices. The method includes determining intersection points of the tessellated vertices with the isosurface and moving the intersected vertices to form a finer approximation of the isosurface."
10026468,"This description is directed to a dynamic random access memory (DRAM) array having a plurality of rows and a plurality of columns. The array further includes a plurality of cells, each of which are associated with one of the columns and one of the rows. Each cell includes a capacitor that is selectively coupled to a bit line of its associate column so as to share charge with the bit line when the cell is selected. There is a segmented word line circuit for each row, which is controllable to cause selection of only a portion of the cells in the row."
10027401,"A wireless communications system is described which comprises a base station, a relay device, and a terminal device. The terminal device is operable to transmit a message to the base station via the relay device. The relay device is operable to add a relay header to the message received from the terminal device, the relay header comprising control information for controlling the transmission of subsequent messages from the terminal device to the relay device. The relay device is also operable to relay the message having the relay header added to the base station. By adding such control information to messages being relayed from the terminal device to the base station on the uplink, subsequent downlink communications from the base station to the terminal device can include the control information generated at the relay device (or transmission parameters derived from the control information)."
10027893,"Real-time video stabilization for mobile devices based on on-board motion sensing. In accordance with a method embodiment of the present invention, a first image frame from a camera at a first time is accessed. A second image frame from the camera at a subsequent time is accessed. A crop polygon around scene content common to the first image frame and the second image frame is identified. Movement information describing movement of the camera in an interval between the first time and the second time is accessed. The crop polygon is warped to remove motion distortions of the second image frame is warped using the movement information. The warping may include defining a virtual camera that remains static when the movement of the camera is below a movement threshold. The movement information may describe the movement of the camera at each scan line of the second image frame."
10031856,A system for managing virtual memory. The system includes a first processing unit configured to execute a first operation that references a first virtual memory address. The system also includes a first memory management unit (MMU) associated with the first processing unit and configured to generate a first page fault upon determining that a first page table that is stored in a first memory unit associated with the first processing unit does not include a mapping corresponding to the first virtual memory address. The system further includes a first copy engine associated with the first processing unit. The first copy engine is configured to read a first command queue to determine a first mapping that corresponds to the first virtual memory address and is included in a first page state directory. The first copy engine is also configured to update the first page table to include the first mapping.
10032242,"A method for managing bind-render-target commands in a tile-based architecture. The method includes receiving a requested set of bound render targets and a draw command. The method also includes, upon receiving the draw command, determining whether a current set of bound render targets includes each of the render targets identified in the requested set. The method further includes, if the current set does not include each render target identified in the requested set, then issuing a flush-tiling-unit-command to a parallel processing subsystem, modifying the current set to include each render target identified in the requested set, and issuing bind-render-target commands identifying the requested set to the tile-based architecture for processing. The method further includes, if the current set of render targets includes each render target identified in the requested set, then not issuing the flush-tiling-unit-command."
10032243,"One embodiment of the present invention sets forth a graphics subsystem configured to implement distributed cache tiling. The graphics subsystem includes one or more world-space pipelines, one or more screen-space pipelines, one or more tiling units, and a crossbar unit. Each world-space pipeline is implemented in a different processing entity and is coupled to a different tiling unit. Each screen-space pipeline is implemented in a different processing entity and is coupled to the crossbar unit. The tiling units are configured to receive primitives from the world-space pipelines, generate cache tile batches based on the primitives, and transmit the primitives to the screen-space pipelines. One advantage of the disclosed approach is that primitives are processed in application-programming-interface order in a highly parallel tiling architecture. Another advantage is that primitives are processed in cache tile order, which reduces memory bandwidth consumption and improves cache memory utilization."
10032245,"A tile coalescer within a graphics processing pipeline coalesces coverage data into tiles. The coverage data indicates, for a set of XY positions, whether a graphics primitive covers those XY positions. The tile indicates, for a larger set of XY positions, whether one or more graphics primitives cover those XY positions. The tile coalescer includes coverage data in the tile only once for each XY position, thereby allowing the API ordering of the graphics primitives covering each XY position to be preserved. The tile is then distributed to a set of streaming multiprocessors for shading and blending operations. The different streaming multiprocessors execute thread groups to process the tile. In doing so, those thread groups may perform read-modify-write operations with data stored in memory. Each such thread group is scheduled to execute via atomic operations, and according to the API order of the associated graphics primitives."
10032246,"A texture processing pipeline is configured to store decoded texture data within a cache unit in order to expedite the processing of texture requests. When a texture request is processed, the texture processing pipeline queries the cache unit to determine whether the requested data is resident in the cache. If the data is not resident in the cache unit, a cache miss occurs. The texture processing pipeline then reads encoded texture data from global memory, decodes that data, and writes different portions of the decoded memory into the cache unit at specific locations according to a caching map. If the data is, in fact, resident in the cache unit, a cache hit occurs, and the texture processing pipeline then reads decoded portions of the requested texture data from the cache unit and combines those portions according to the caching map."
10032289,"A system, method, and computer program product for implementing a tree traversal operation for a tree data structure is disclosed. The method includes the steps of receiving at least a portion of a tree data structure that represents a tree having a plurality of nodes and processing, via a tree traversal operation algorithm executed by a processor, one or more nodes of the tree data structure by intersecting the one or more nodes of the tree data structure with a query data structure. A first node of the tree data structure is associated with a first local coordinate system and a second node of the tree data structure is associated with a second local coordinate system, the first node being an ancestor of the second node, and the first local coordinate system and the second local coordinate system are both specified relative to a global coordinate system."
10032692,"Various embodiments relating to semiconductor package structures having reduced thickness while maintaining rigidity are provided. In one embodiment, a semiconductor package structure includes a substrate including a surface, a semiconductor die including a first interface surface connected to the surface of the substrate and a second interface surface opposing the first interface surface, a mold compound applied to the substrate surrounding the semiconductor die. The second interface surface of the semiconductor die is exposed from the mold compound. The semiconductor package structure includes a heat dissipation cover attached to the second interface surface of the semiconductor die and the mold compound."
10032696,"A microelectronic package includes an interposer with through-silicon vias that is formed from a semiconductor substrate and one or more semiconductor dies coupled to the interposer. A first signal redistribution layer formed on the first side of the interposer electrically couples the one or more semiconductor dies to the through-silicon vias. A second redistribution layer is formed on a second side of the interposer, and is electrically coupled to the through-silicon vias. In some embodiments, a mold compound is connected to an edge surface of the interposer and is configured to stiffen the microelectronic package."
10032710,"An integrated circuit (IC) system includes an IC coupled to a package. The package, in turn, is coupled to a ball grid array. The integrated circuit is electrically coupled to the ball grid array by a plurality of package through-hole (PTH) vias that penetrate through the package. Each PTH via includes a conductive element associated with a differential signaling pair. The conductive elements within a given differential signaling pair are disposed in the package at specific locations, relative to other conductive elements in other differential signaling pairs, to reduce crosstalk between those differential signaling pairs. At least one advantage of technique described herein is that the conductive elements within the package can be densely packed together without inducing excessive crosstalk. Therefore, the package can support a large number of differential signaling pairs, allowing high-throughput data communication."
10034007,"Techniques for non-subsampled video encoding of R′G′B′ data using Y′, Cb and Cr data to generate compressed data wherein the Y′-plane comprises three separate color frames that are not interleaved, and recovering the data therefrom."
10037228,"A technique for simultaneously executing multiple tasks, each having an independent virtual address space, involves assigning an address space identifier (ASID) to each task and constructing each virtual memory access request to include both a virtual address and the ASID. During virtual to physical address translation, the ASID selects a corresponding page table, which includes virtual to physical address mappings for the ASID and associated task. Entries for a translation look-aside buffer (TLB) include both the virtual address and ASID to complete each mapping to a physical address. Deep scheduling of tasks sharing a virtual address space may be implemented to improve cache affinity for both TLB and data caches."
10037620,"One embodiment of the present invention includes a method for rendering a geometry object in a computer-generated scene. A screen space associated with a display screen is divided into a set of regions. For each region; a first sampling factor in a horizontal dimension is computed that represents a horizontal sampling factor for pixels located in the region, a second sampling factor in a vertical dimension is computed that represents a vertical sampling factor for the pixels located in the region, a first offset in the horizontal dimension is computed that represents a horizontal position associated with the region, and a second offset in the vertical dimension is computed that represent a vertical position associated with the region. When the geometry object is determined to intersect more than one region, an instance of the geometry object is generated each region that the geometry object intersects."
10038430,"A system for controlling gatings of a multi-core processor, the system includes a pulse width modulation generator for generating a control square wave; and a phase shifter for shifting a phase of the control square wave to generate control square waves with different phases, and respectively inputting the control square waves with the different phases to a gating of each of multiple processing engines in the multi-core processor. A multi-core processor is provided that includes multiple processing engines. Each processing engine includes a gating, and a system for controlling the gating. Accordingly, in the multi-core processor, the load to be processed in a certain period of a working cycle can be averaged to be processed in a longer period of the working cycle. Consequently, current noise and voltage noise and temperature growth due to the load change can be reduced."
10042469,"A method for reducing line display latency on a touchpad device is disclosed. The method comprises storing information regarding a plurality of prior touch events on a touch screen of the touchpad device into an event buffer. It further comprises determining an average speed and a predicted direction of motion of a user interaction with the touch screen using the plurality of prior touch events. Next, it comprises calculating a first prediction point using the average speed, the predicted direction, and a last known touch event on the touch screen. Subsequently, it comprises applying weighted filtering on the first prediction point using a measured line curvature to determine a second prediction point. Finally, it comprises rendering a prediction line between the last known touch event on the touch screen and the second prediction point."
10043230,"Computer and graphics processing elements, connected generally in series, form a pipeline. Circuit elements known as di/dt throttles are inserted within the pipeline at strategic locations where the potential exists for data flow to transition from an idle state to a maximum data processing rate. The di/dt throttles gently ramp the rate of data flow from idle to a typical level. Disproportionate current draw and the consequent voltage droop are thus avoided, allowing an increased frequency of operation to be realized."
10043234,"A system and method for decompressing compressed data (e.g., in a frame buffer) and optionally recompressing the data. The method includes determining a portion of an image to be accessed from a memory and sending a conditional read corresponding to the portion of the image. In response to the conditional read, an indicator operable to indicate that the portion of the image is uncompressed may be received. If the portion of the image is compressed, in response to the conditional read, compressed data corresponding to the portion of the image is received. In response to receiving the compressed data, the compressed data is uncompressed into uncompressed data. The uncompressed data may then be written to the memory corresponding to the portion of the image. The uncompressed data may then be in-place compressed for or during subsequent processing."
10043457,"A display for a computer system, such as an LCD, is configured to consume less power when compared to conventional designs. The display includes a screen and at least one backlight configured to illuminate the screen. An input to the at least one backlight is adjustable to produce a desired level of brightness. The input may be computed based on a generated source image and a defined constraint. An input to the display is computed based on the input to the at least one backlight and the source image. The input to the display modifies the level of brightness provided by the at least one backlight to produce a viewable image."
10049006,"A method for updating a DRAM memory array is disclosed. The method comprises: a) transitioning the DRAM memory array from an idle state to a refresh state in accordance with a command from a memory controller; b) initiating a refresh on the DRAM memory array using DRAM internal control circuitry by activating a row of data into an associated sense amplifier buffer; and c) during the refresh, performing an ERR Correction Code (ECC) scrub operation of selected bits in the activated row of the DRAM memory array."
10049646,"A method for switching, including initializing an instantiation of an application and performing graphics rendering to generate a plurality of rendered frames through execution of the application in order to generate a first video stream comprising the plurality of rendered frames. The method includes sequentially loading the plurality of rendered frames into one or more frame buffers, and determining when a first bitmap of a frame that is loaded into a corresponding frame buffer matches an application signature comprising a derivative of a master bitmap associated with a keyframe of the first video stream."
10055806,"A tile coalescer within a graphics processing pipeline coalesces coverage data into tiles. The coverage data indicates, for a set of XY positions, whether a graphics primitive covers those XY positions. The tile indicates, for a larger set of XY positions, whether one or more graphics primitives cover those XY positions. The tile coalescer includes coverage data in the tile only once for each XY position, thereby allowing the API ordering of the graphics primitives covering each XY position to be preserved. The tile is then distributed to a set of streaming multiprocessors for shading and blending operations. The different streaming multiprocessors execute thread groups to process the tile. In doing so, those thread groups may perform read-modify-write operations with data stored in memory. Each such thread group is scheduled to execute via atomic operations, and according to the API order of the associated graphics primitives."
10055875,"One embodiment of the present invention sets forth an Eulerian fluid simulation technique which enables real-time simulations of large scale three dimensional fluid volumes that include free surface water. A hybrid grid representation composed of regular cubic cells on top of a layer of tall cells is used to reduce computation time. Water above an arbitrary terrain can be represented without consuming an excessive amount of memory and compute power, while focusing simulation effort on the area near the surface of the water to produce accurate results. Additionally, the grid representation may be optimized for a graphics processor implementation of the fluid solver."
10055883,"A method, computer readable medium, and system are disclosed for rendering shadows. A frustum projected from a grid cell corresponding to a light source in light-space is defined and a graphics primitive is determined to intersect the frustum. A light-space visibility buffer is accessed to obtain a set of pixel fragment footprints corresponding to the frustum and it is identified whether each pixel fragment footprint of the pixel fragment footprints is shadowed by the graphics primitive."
10057849,"A system for, and method of, reducing power consumed obtaining system information from a cell, the system information contained in at least a master information block, a scheduling information block and a system information block. In one embodiment, the system includes: (1) a broadcast control channel (BCCH) frame cache configured to buffer received BCCH frames bearing portions of the system information and (2) a system information verifier associated with the BCCH frame cache and configured to determine version consistency in the master information block and the scheduling information block by employing the check numbers associated therewith."
10061526,"One embodiment of the present invention is a memory subsystem that includes a sliding window tracker that tracks memory accesses associated with a sliding window of memory page groups. When the sliding window tracker detects an access operation associated with a memory page group within the sliding window, the sliding window tracker sets a reference bit that is associated with the memory page group and is included in a reference vector that represents accesses to the memory page groups within the sliding window. Based on the values of the reference bits, the sliding window tracker causes the selection a memory page in a memory page group that has fallen into disuse from a first memory to a second memory. Because the sliding window tracker tunes the memory pages that are resident in the first memory to reflect memory access patterns, the overall performance of the memory subsystem is improved."
10062142,"Data transfer techniques include transferring display surface data from a memory subsystem into a stutter buffer at a first rate until the stutter buffer is substantially full. The memory interface and/or memory of the memory subsystem may then be placed into a suspend state until the stutter buffer is substantially empty. The display surface data is transferred from the stutter buffer to display logic at a second rate even when the memory subsystem is in a suspend state. The second rate, which is typically the rendering rate of the display, is substantially slower than the rate at which data is transferred into the stutter buffer."
10067768,"A method, system, and computer program product for executing divergent threads using a convergence barrier are disclosed. A first instruction in a program is executed by a plurality of threads, where the first instruction, when executed by a particular thread, indicates to a scheduler unit that the thread participates in a convergence barrier. A first path through the program is executed by a first divergent portion of the participating threads and a second path through the program is executed by a second divergent portion of the participating threads. The first divergent portion of the participating threads executes a second instruction in the program and transitions to a blocked state at the convergence barrier. The scheduler unit determines that all of the participating threads are synchronized at the convergence barrier and the convergence barrier is cleared."
10068366,"A method, computer readable medium, and system are disclosed for generating multi-view image data. The method includes the steps of processing primitive data of a model to generate processed primitive data that includes multiple position vectors for each vertex in the primitive data, the number of position vectors associated with each vertex being equal to the number of views in at least two views being generated. The method further includes storing the processed primitive data in a buffer. Finally, the processed primitive data may be read from the buffer for each view in the at least two views and transmitted to a raster pipeline to generate image data corresponding to a particular view."
10068549,"A method, computer program product, and system for cursor handling in a variable refresh rate environment are disclosed. The method includes the steps of receiving a first image, combining a cursor at a first position with the first image to produce a first combined image, and displaying the combined image on a variable refresh rate display device. The method also includes the steps of determining that a refresh timeout associated with the variable refresh rate display device has occurred, and then, after determining that a second image has not been generated, combining the cursor at a second position with the first image to produce a second combined image for display. The logic for implementing the method may be included in a graphics processing unit or within the variable refresh rate display device itself."
10074212,"A method and renderer for a progressive computation of a light transport simulation are provided. The method includes the steps of employing a low discrepancy sequence of samples; and scrambling an index of the low discrepancy sequence independently per region using a hash value based on coordinates of a respective region, wherein for each set of a power-of-two number of the samples, the scrambling is a permutation."
10074411,"A memory driver, a method of driving a command bus for a synchronous dual data rate (sDDR) memory and a memory controller for controlling dynamic random-access memory (DRAM). In one embodiment, the memory driver includes: (1) pull-up and pull-down transistors couplable to a command bus of a memory controller and operable in 1N and 2N timing modes and (2) gear down offset circuitry coupled to the pull-up transistor and operable to offset the command bus when transitioning out of the 1N timing mode and increase an extent and duration of 1-0-1 transitions on the command bus."
10078911,"A system, method, and computer program product are provided for executing processes involving at least one primitive in a graphics processor, utilizing a data structure. In operation, a data structure is associated with at least one primitive. Additionally, a plurality of processes involving the at least one primitive are executed in a graphics processor, utilizing the data structure. Moreover, the plurality of processes include at least one of selecting at least one surface or portion thereof to which to render, or selecting at least one of a plurality of viewports."
10079746,"A system and method for testing a data channel are provided. In one embodiment, the method includes: (1) transmitting groups of increasing numbers of probing packets of a uniform load over successive time periods over the data channel and (2) determining a bandwidth of the data channel based on receive times and loads of at least some of successfully received ones of the groups."
10080161,"A method, a transmitter and a computer program product for processing data units at the transmitter are disclosed. In one embodiment, data units are transmitted to a receiver according to a protocol and with respective sequence numbers. The protocol indicates that the receiver is to use a reordering window to determine whether a data unit which is newly received from the transmitter is a new or repeated data unit the data stream by comparing the sequence numbers of the newly received data unit and a previously received data unit. A status report is received and based thereon, the sequence number of a next data unit to be transmitted in a new cell following a handover is selectively adjusted such that the next data unit will be determined to be a new data unit. The next data unit is transmitted with the adjusted sequence number to the receiver."
10083036,"One embodiment of the present invention sets forth a technique for managing graphics processing resources in a tile-based architecture. The technique includes storing a release packet associated with a graphics processing resource in a buffer and initiating a replay of graphics primitives stored in the buffer and associated with the graphics processing resource. The technique further includes, for each tile included in a plurality of tiles and processed during the replay, reading the release packet and determining whether the tile is a last tile processed during the replay. The technique further includes determining not to transmit the release packet to a screen-space pipeline and continuing to read graphics data stored in the buffer if the tile is not the last tile to be processed during the replay, or transmitting the release packet to the screen-space pipeline if the tile is the last tile to be processed during the replay."
10083514,"One embodiment of the present invention includes techniques for rasterizing primitives that include edges shared between paths. For each edge, a rasterizer unit selects and applies a sample rule from multiple sample rules. If the edge is shared, then the selected sample rule causes each group of coverage samples associated with a single color sample to be considered as either fully inside or fully outside the edge. Consequently, conflation artifacts caused when the number of coverage samples per pixel exceeds the number of color samples per pixel may be reduced. In prior-art techniques, reducing such conflation artifacts typically involves increasing the number of color samples per pixel to equal the number of coverage samples per pixel. Advantageously, the disclosed techniques enable rendering using algorithms that reduce the ratio of color to coverage samples, thereby decreasing memory consumption and memory bandwidth use, without causing conflation artifacts associated with shared edges."
10083932,"A method of forming a package on package, semiconductor package arrangement is described. In one aspect, solder bumps on a lower surface of a first grid array package substrate are fused to corresponding unencapsulated solder bumps on an upper surface of a second grid array package substrate. The fused solder bumps form solder joints that electrically connect the first and second packages. The height of the resulting solder joints is greater than a height of a die that is flip chip mounted to the second substrate such that the first substrate does not contact any portion of the second package and an air gap is formed that separates the second die from the first package. Corresponding PoP packages structures are also described."
10089707,"A server and methods for performing an ultra-high resolution pan-scan on displays connected across multiple client GPUs are provided. In one embodiment, one of the methods includes: 1) rendering a surface that exceeds resolutions of displays connected to multiple client GPUs; 2) receiving viewport coordinates of one of the displays that is connected to one of the multiple client GPUs; 3) encoding only a portion of the surface that corresponds to the viewport coordinates; 4) sending the portion to the one of the multiple client GPUs."
10091251,In one aspect there is provided a host device having: a modem interface arranged to transmit transmission units between the host device and a modem; a communication function configured to generate primitives to establish a communication event between the host device and a remote device; a client agent connected to receive control primitives from the communication function and operable to convert the control primitives to data transmission units; a host routing interface operable to route data transmission units from the client agent according to a predetermined route option which is set based on whether a communication event control function for processing the data transmission units is located on the host device or the modem.
10095526,"A multi-threaded processing unit includes a hardware pre-processor coupled to one or more processing engines (e.g., copy engines, GPCs, etc.) that implement pre-emption techniques by dividing tasks into smaller subtasks and scheduling subtasks on the processing engines based on the priority of the tasks. By limiting the size of the subtasks, higher priority tasks may be executed quickly without switching the context state of the processing engine. Tasks may be subdivided based on a threshold size or by taking into account other consideration such as physical boundaries of the memory system."
10095542,"Techniques are provided for restoring threads within a processing core. The techniques include, for a first thread group included in a plurality of thread groups, executing a context restore routine to restore from a memory a first portion of a context associated with the first thread group, determining whether the first thread group completed an assigned function, and, if the first thread group completed the assigned function, then exiting the context restore routine, or if the first thread group did not complete the assigned function, then executing one or more operations associated with a trap handler routine."
10095548,"One embodiment of the present disclosure sets forth an effective way to maintain fairness and order in the scheduling of common resource access requests related to replay operations. Specifically, a streaming multiprocessor (SM) includes a total order queue (TOQ) configured to schedule the access requests over one or more execution cycles. Access requests are allowed to make forward progress when needed common resources have been allocated to the request. Where multiple access requests require the same common resource, priority is given to the older access request. Access requests may be placed in a sleep state pending availability of certain common resources. Deadlock may be avoided by allowing an older access request to steal resources from a younger resource request. One advantage of the disclosed technique is that older common resource access requests are not repeatedly blocked from making forward progress by newer access requests."
10096078,A graphics processing subsystem includes one or more memory devices and two or more graphics processing units (GPU). The graphics processing units each include a memory interface. A first sub-set of the memory interface of the first graphics processing unit communicatively couples the first graphics processing unit to the first memory device. A first sub-set of the memory interface of the second graphics processing unit is connected to a second sub-set of the memory interface of the first graphics processing unit.
10096086,"A raster unit is configured to generate different sample patterns for adjacent pixels within a given frame. In addition, the raster unit may adjust the sample patterns between frames. The raster unit includes an index unit that selects a sample pattern table for use with a current frame. For a given pixel, the index unit extracts a sample pattern from the selected sample pattern table. The extracted sample pattern is used to generate coverage information for the pixel. The coverage information for all pixels is then used to generate an image. The resultant image may then be filtered to reduce or remove artifacts induced by the changing of sample locations."
10096134,"A method, computer program product, and system for sparse convolutional neural networks that improves efficiency is described. Multi-bit data for input to a processing element is received at a compaction engine. The multi-bit data is determined to equal zero and a single bit signal is transmitted from the memory interface to the processing element in lieu of the multi-bit data, where the single bit signal indicates that the multi-bit data equals zero. A compacted data sequence for input to a processing element is received by a memory interface. The compacted data sequence is transmitted from the memory interface to an expansion engine. Non-zero values are extracted from the compacted data sequence and zeros are inserted between the non-zero values by the expansion engine to generate an expanded data sequence that is output to the processing element."
10096534,"Embodiments of the invention provides an IC system in which low-power chips can be positioned vertically proximate high-power chips without suffering the effects of overheating. In one embodiment, the IC system includes a first substrate, a high-power chip disposed on a first side of the first substrate, a thermal conductive pad disposed on a second side of the first substrate, one or more thermal conductive features formed in the first substrate, wherein the thermal conductive features thermally connect the high-power chip and the thermal conductive pad, and a heat sink attached to a surface of the thermal conductive pad, wherein the heat sink is in thermal communication with the thermal conductive pad. By having thermal conductive features formed through the first substrate to thermally connect the high-power chip and the thermal conductive pad, heat generated by the high-power chip can be effectively dissipated into the heat sink."
10097203,"A CRC generator, a method for computing a CRC of a data packet, and an electronic system, such as a circuit board, are disclosed herein. In one embodiment the method is for computing the CRC of a data packet to be transmitted on a serial communications link having multiple lanes. In one embodiment, the CRC generator includes: (1) a CRC calculator configured to define a CRC calculation of a data packet in sequential order and perform parallelized computations, according to the sequential order and the multiple lanes, to generate sub-CRC values and (2) combination circuitry configured to combine the sub-CRC values to provide the CRC value for the packet."
10102142,"A method for detecting an instruction ordering violation in a CPU. The method includes receiving a reordered stream of instructions and detecting whether an ordering violation has occurred by using virtual addresses. The method further includes transferring results of the reordered stream of instructions from a load store buffer into a cache and detecting whether an ordering violation has occurred by using physical addresses. Subsequently, a recovery is initiated upon detection of an ordering violation."
10102668,"A system, method, and computer program product are provided for rendering at variable sampling rates. Vertex coordinates for 3D primitive are received from a shader execution unit, and an arithmetic operation is performed on the vertex coordinates by fixed operation circuitry to produce modified vertex coordinates in homogeneous coordinate space. The modified vertex coordinates are transformed from homogeneous coordinate space into screen-space to produce screen-space vertex coordinates of a transformed 3D primitive and the transformed 3D primitive is rasterized in screen-space using the screen-space vertex coordinates to produce an image for display."
10103719,"A method for regulating voltage for a processor is disclosed. The method comprises requesting a target frequency value, wherein the target frequency value determines a target clock frequency for clocking the processor. The method also comprises comparing the target clock frequency to a first signal to generate an error signal. Further, the method comprises using the error signal to generate a duty cycle control signal, wherein the duty cycle control signal is operable to generate a periodic waveform. Finally, the method comprises generating an output regulator voltage using the periodic waveform, wherein the output voltage is operable to provide power to the processor."
10104618,"Saving power in a mobile terminal includes determining alignment processing moments after the mobile terminal enters a standby mode. Alignable wakeup events, which occur during alignment processing periods corresponding to each alignment processing moment, are thus controlled to commence related processing at each of the alignment processing moments. Power consumption caused by various wakeup events in a standby mode may thus be reduced and battery life of the mobile terminal may thus be improved."
10108424,"The disclosure provides a micro-processing system operable in a hardware decoder mode and in a translation mode. In the hardware decoder mode, the hardware decoder receives and decodes non-native ISA instructions into native instructions for execution in a processing pipeline. In the translation mode, native translations of non-native ISA instructions are executed in the processing pipeline without using the hardware decoder. The system includes a code portion profile stored in hardware that changes dynamically in response to use of the hardware decoder to execute portions of non-native ISA code. The code portion profile is then used to dynamically form new native translations executable in the translation mode."
10112115,"One embodiment of the present invention sets forth a technique for broadcasting composited game content. The technique includes executing an application program to generate a first video frame of game content, and causing the first video frame to be displayed on a primary display device. The technique further includes compositing at least one graphical user interface (GUI) element with the first video frame to generate a composited frame. The technique further includes causing the composited frame to be displayed on an external display device by transmitting the composited frame to the external display device via a local display interface."
10114755,"A system, method, and computer program product for warming a cache for a task launch is described. The method includes the steps of receiving a task data structure that defines a processing task, extracting information stored in a cache warming field of the task data structure, and, prior to executing the processing task, generating a cache warming instruction that is configured to load one or more entries of a cache storage with data fetched from a memory."
10114758,"One embodiment of the present invention includes techniques to support demand paging across a processing unit. Before a host unit transmits a command to an engine that does not tolerate page faults, the host unit ensures that the virtual memory addresses associated with the command are appropriately mapped to physical memory addresses. In particular, if the virtual memory addresses are not appropriately mapped, then the processing unit performs actions to map the virtual memory address to appropriate locations in physical memory. Further, the processing unit ensures that the access permissions required for successful execution of the command are established. Because the virtual memory address mappings associated with the command are valid when the engine receives the command, the engine does not encounter page faults upon executing the command. Consequently, in contrast to prior-art techniques, the engine supports demand paging regardless of whether the engine is involved in remedying page faults."
10114760,"A system and method are provided for implementing multi-stage translation of virtual addresses. The method includes the steps of receiving, at a first memory management unit, a memory request including a virtual address in a first address space, translating the virtual address to generate a second virtual address in a second address space, and transmitting a modified memory request including the second virtual address to a second memory management unit. The second memory management unit is configured to translate the second virtual address to generate a physical address in a third address space. The physical address is associated with a location in a memory."
10115229,"A method for light transport includes steps of initializing a data structure that is configured to provide an importance value for each incident sample in a three-dimensional (3D) scene and tracing, in a direction from an origin, a ray of a plurality of rays through the 3D scene to intersect an object at a hitpoint. Additional steps include selecting a next direction of the ray according to a distribution of the importance values at the hitpoint, tracing the ray in the next direction to find a next hitpoint, updating a first importance value corresponding to the hitpoint using a second importance value corresponding to the next hitpoint, and setting the hitpoint of the ray to the next hitpoint. The additional steps are repeated until the next hitpoint is an endpoint. A contribution, based on each hitpoint and the endpoint, to a pixel that is intersected by the ray is recorded."
10116314,"A frequency divider includes first circuitry, second circuitry, and third circuitry. The first circuitry includes divide-by-two (div2) frequency divider circuitry, and the second circuitry includes additional circuitry for a divide-by-three (div3) frequency divider. The second circuitry is selectively enabled using a control signal and can receive signals from the first circuitry when enabled. Specifically, the second circuitry is enabled in the div3 mode but is not enabled in the div2 mode. The third circuitry receives signals from the first circuitry and also receives signals from the second circuitry when the second circuitry is enabled. The first circuitry and the third circuitry function as a div2 frequency divider when the second circuitry is not enabled. The first circuitry, the second circuitry, and the third circuitry function as a div3 frequency divider when the second circuitry is enabled."
10116916,"A method, computer readable medium, and system are disclosed for image processing to reduce aliasing using a temporal anti-aliasing algorithm modified to implement variance clipping. The method includes the step of generating a current frame of image data in a memory. Then, each pixel in the current frame of image data is processed by: sampling a resolved pixel color for a corresponding pixel in a previous frame of image data stored in the memory, adjusting the resolved pixel color based on a statistical distribution of color values for a plurality of samples in the neighborhood of the pixel in the current frame of image data to generate an adjusted pixel color, and blending a color value for the pixel in the current frame of image data with the adjusted pixel color to generate a resolved pixel color for the pixel in the current frame of image data."
10116943,"One embodiment of the present invention sets forth a technique for adaptively compressing video frames. The technique includes encoding a first plurality of video frames based on a first video compression algorithm to generate first encoded video frames and transmitting the first encoded video frames to a client device. The technique further includes receiving a user input event, switching from the first video compression algorithm to a second video compression algorithm in response to the user input event, encoding a second plurality of video frames based on the second video compression algorithm to generate second encoded video frames, and transmitting the second encoded video frames to the client device."
10118095,"One embodiment of the invention sets forth a method that includes receiving a request from a client device to launch an application program for execution on a server device, where the application program is configured to operate in a full-screen display mode, and, in response, creating an execution environment for the application program that disables the full-screen display mode. Within the execution environment, the application program is configured to generate the rendered image data for display on the client device. With the disclosed approach, application programs that are configured to execute on an application server computer system in a full-screen display mode can be executed through an execution environment that includes a shim layer configured to disable the full-screen display mode and transmit the render image data to a client device for display."
10120028,"Systems and methods for latches are presented. In one embodiment a system includes scan in propagation component, data propagation component, and control component. The scan in propagation component is operable to select between a scan in value and a recirculation value. The data propagation component is operable to select between a data value and results forwarded from the scan in propagation component, wherein results of the data propagation component are forwarded as the recirculation value to the scan in propagation component. The control component is operable to control an indication of a selection by the scan in propagation component and the data propagation component."
10120187,"A system, computer readable medium, and method for sub-frame scan-out are disclosed. The method includes the steps of dividing a frame into a plurality of slices. For each slice in the plurality of slices, the steps further include sampling a sensor associated with a head mounted display to generate sample data corresponding to the slice; adjusting one or more parameters associated with rendering operations for the slice based on the sample data; and rendering primitive data associated with a model according to the rendering operations to generate image data for the slice. Each slice is a portion of the frame and corresponds to different sample data from the sensor. Thus, adjusting of the parameters is different for each slice of the frame."
10121220,"A parallel processor and a method of reducing texture cache invalidation are disclosed. In one embodiment, the parallel processor includes a cache configured to receive lines of data; and a parallel execution unit associated with the cache and configured to execute parallel counterparts of an operation. The parallel counterparts, when executed, are configured to create, in the cache, corresponding aliases of a line of data pertaining to the operation such that the parallel counterparts are operable to invalidate only the corresponding aliases."
10121276,"A method, computer readable medium, and system are disclosed for generating and utilizing infinite resolution texture acceleration data structures. The method for generating an infinite resolution texture acceleration data structure includes the steps of receiving an image; generating an infinite resolution texture acceleration data structure associated with the image that includes a texture map, a curve index map, and a curve data map; and storing the infinite resolution texture acceleration data structure in a memory. The texture map is a two-dimensional array of texels, each texel encoding a color value based on the image. The curve data map encodes parameters for at least one curve segment associated with the image. The curve index map associates each texel in the texture map with zero or more curve segments corresponding with the texel."
10123408,A circuit board includes a substrate and a conductive trace. An electronic element is electrically coupled with the conductive trace. A pair of holes pass through the substrate and are disposed respectively at two opposite sides of the conductive trace and adjacent to the conductive trace. A current-measuring device may be adapted for passing through the holes and surrounding the conductive trace.
10128904,A repeater circuit is disclosed. The repeater circuit is coupled to a transmission line driven by a first transmitter circuit and configured to detect a signal transition from a first voltage level to a second voltage level at a first position on the transmission line. The repeater circuit then reinforces the signal transition from the second voltage level to a third voltage level at the first position on the transmission line without interrupting a current through the transmission line.
10133677,"Techniques are disclosed for transitioning a memory page between memories in a virtual memory subsystem. A unified virtual memory (UVM) driver detects a page fault in response to a memory access request associated with a first memory page, where a local page table does not include an entry corresponding to a virtual memory address included in the memory access request. The UVM driver, in response to the page fault, executes a page fault sequence. The page fault sequence includes modifying the ownership state associated with the first memory page to be central-processing-unit-shared. The page fault sequence further includes scheduling the first memory page for migration from a system memory associated with a central processing unit (CPU) to a local memory associated with a parallel processing unit (PPU). One advantage of the disclosed approach is that the PPU accesses memory pages with greater efficiency."
10134169,"One embodiment of the present invention sets forth a method for accessing texture objects stored within a texture memory. The method comprises the steps of receiving a texture bind request from an application program, wherein the texture bind request includes an object identifier that identifies a first texture object stored in the texture memory and an image identifier that identifies a first image unit, binding the first texture object to the first image unit based on the texture bind request, receiving, within a shader engine, a first shading program command from the application program for performing a first memory access operation on the first texture object, wherein the memory access operation is a store operation or atomic operation to an arbitrary location in the image, and performing, within the shader engine, the first memory access operation on the first texture object via the first image unit."
10139926,"A peripheral device for a computing device comprises a body configured for insertion into a storage cavity in the computing device, a first magnet, and a second magnet. The first magnet is disposed within the body proximate a first external surface of the body and having a first pole of a first polarity and a second pole of a second polarity, wherein the first pole is oriented toward the first external surface. The second magnet is disposed within the body between a second external surface and the first magnet and having a first pole of the first polarity and a second pole of the second polarity, wherein the first pole of the second magnet is oriented toward the second external surface."
10141930,"Three state latch. In accordance with a first embodiment, an electronic circuit includes a single latch having three stable states. The electronic circuit may be configured so that all three outputs reflect a change at any one input in not more than three gate delays. The electronic circuit may further be configured so that when all inputs are set to one, a previous state of the latch is retained and output on the outputs."
10146545,"Embodiments related to fetching instructions and alternate versions achieving the same functionality as the instructions from an instruction cache included in a microprocessor are provided. In one example, a method is provided, comprising, at an example microprocessor, fetching an instruction from an instruction cache. The example method also includes hashing an address for the instruction to determine whether an alternate version of the instruction which achieves the same functionality as the instruction exists. The example method further includes, if hashing results in a determination that such an alternate version exists, aborting fetching of the instruction and retrieving and executing the alternate version."
10147203,"A raster unit is configured to generate different sample patterns for adjacent pixels within a given frame. In addition, the raster unit may adjust the sample patterns between frames. The raster unit includes an index unit that selects a sample pattern table for use with a current frame. For a given pixel, the index unit extracts a sample pattern from the selected sample pattern table. The extracted sample pattern is used to generate coverage information for the pixel. The coverage information for all pixels is then used to generate an image. The resultant image may then be filtered to reduce or remove artifacts induced by the changing of sample locations."
10147222,"A multi-pass unit interoperates with a device driver to configure a screen space pipeline to perform multiple processing passes with buffered graphics primitives. The multi-pass unit receives primitive data and state bundles from the device driver. The primitive data includes a graphics primitive and a primitive mask. The primitive mask indicates the specific passes when the graphics primitive should be processed. The state bundles include one or more state settings and a state mask. The state mask indicates the specific passes where the state settings should be applied. The primitives and state settings are interleaved. For a given pass, the multi-pass unit extracts the interleaved state settings for that pass and configures the screen space pipeline according to those state settings. The multi-pass unit also extracts the interleaved graphics primitives to be processed in that pass. Then, the multi-pass unit causes the screen space pipeline to process those graphics primitives."
10147370,"A method, computer program product, and system perform gamma correction for a variable refresh rate display panel. An image is received for display on a screen of a display device. The image is adjusted based on gamma correction factors that are dependent on a variable refresh rate of the display device and the adjusted image is output for display on the screen of the display device."
10151924,"A display method and system are disclosed for virtual/augmented reality. The method includes the steps of generating an image by a projection engine and projecting light rays defining the image onto a diffuser holographic optical element (DHOE) located between an observer and a concave mirror element, where a concave surface of the concave mirror element faces the observer. The light rays are projected onto the DHOE at a reference angle that causes the light rays to be diffused to the concave surface of the concave mirror element and the diffused light rays are reflected back to the observer such that the observer perceives a virtual image that appears to the observer at a position behind the concave mirror element and further from the observer than the concave mirror element."
10152310,"A compiler and a method of compiling code that reduces memory bandwidth when processing code on a computer are provided herein. In one embodiment, the method includes: (1) automatically identifying a sequence of operations for fusing, wherein the sequence of operations correspond to instructions from a source code, (2) determining subdivisions of a final output of the sequence of operations, (3) determining input data and intermediate operations needed to obtain a final subdivision output for each of the subdivisions and (4) automatically generating code to fuse the sequence of operations employing the subdivisions, wherein the automatically identifying and the automatically generating are performed by a processor."
10152312,Compiler techniques for inline parallelism and re-targetable parallel runtime execution of logic iterators enables selection thereof from the source code or dynamically during the object code execution.
10152328,"One embodiment of the present invention sets forth a technique for efficiently performing voting operations within a multi-threaded parallel-processing system. A group of related parallel program threads executes within a processor core together in parallel. A new instruction, called a “vote” instruction, is introduced that enables a parallel program thread to post an individual vote within the context of the group of related threads and to receive the result of the vote. In this fashion, the vote instruction advantageously reduces overhead associated with inter-thread communication, thereby improving overall system performance."
10152329,"One embodiment of the present disclosure sets forth an optimized way to execute pre-scheduled replay operations for divergent operations in a parallel processing subsystem. Specifically, a streaming multiprocessor (SM) includes a multi-stage pipeline configured to insert pre-scheduled replay operations into a multi-stage pipeline. A pre-scheduled replay unit detects whether the operation associated with the current instruction is accessing a common resource. If the threads are accessing data which are distributed across multiple cache lines, then the pre-scheduled replay unit inserts pre-scheduled replay operations behind the current instruction. The multi-stage pipeline executes the instruction and the associated pre-scheduled replay operations sequentially. If additional threads remain unserviced after execution of the instruction and the pre-scheduled replay operations, then additional replay operations are inserted via the replay loop, until all threads are serviced. One advantage of the disclosed technique is that divergent operations requiring one or more replay operations execute with reduced latency."
10154265,"A graphics server and method for streaming rendered content via a remote graphics rendering service. One embodiment of the graphics server includes: (1) a frame capturer configured to capture frames of rendered content at a frame rate, (2) an encoder configured to encode captured frames at the frame rate, and (3) a processor configured to cause encoded frames to be transmitted if the rendered content is at least partially changed, and cause a skip-frame message to be transmitted, the skip-frame message configured to cause the frame capturer to forgo capturing and the encoder to forgo encoding if the rendered content is unchanged."
10157309,"A method, computer readable medium, and system are disclosed for detecting and classifying hand gestures. The method includes the steps of receiving an unsegmented stream of data associated with a hand gesture, extracting spatio-temporal features from the unsegmented stream by a three-dimensional convolutional neural network (3DCNN), and producing a class label for the hand gesture based on the spatio-temporal features."
10157492,"One embodiment of the present invention sets forth a method for pre-computing Z-values using an IGPU and, subsequently, conveying these Z-values to a DGPU. The graphics driver partitions the display into rectangular M-by-N tiles of pixels. For each tile, the graphics driver generates a quad geometry that encompasses the corresponding pixels. For each image frame, the graphics driver configures the IGPU to generate and down-sample a Z-buffer, creating a coarse Z-texture that contains a Z-value for each tile. The graphics driver transfers the coarse Z-texture to the system memory and configures the DGPU to apply the coarse Z-texture to the quad geometries, thereby generating a coarse Z-buffer in which the M-by-N pixels included in each tile are assigned the Z-value for the particular tile. Among other things, this technique enables the IGPU to pre-compute Z-values for the DGPU without straining the system memory bandwidth or defeating the Z-buffer compression techniques used by the DGPU."
10158858,"A method for performing index compression. The method includes identifying a tile in an image, wherein the image comprises a plurality of tiles, wherein each tile includes color associated with a plurality of pixels. Furthermore, the method includes generating a plurality of indices located throughout the tile, and storing the plurality of indices. Additionally, the method includes offsetting zero or more locations of an index of the plurality of indices from a pixel location."
10158868,"Novel solutions are described herein for providing a consistent quality of service, latency-wise, for remote processing by managing the process queues in a processing server and temporarily pausing frame production and delivery to limit the lag experienced by a user in a client device. The claimed embodiments limit the latency (lag) experienced by a user by preventing the production rate of rendered frames at the server from significantly outperforming the decoding and display of the received frames in the client device and avoiding the resultant lag."
10164638,"A balanced, charge-recycling repeater link is disclosed. The link includes a first set of segments operating in a first voltage domain and a second set of segments operating in a second voltage domain. The link is configured to transmit a first signal over at least one segment in the first set of segments and at least one other segment in the second set of segments. Each segment of the link includes at least one active circuit element configured to charge or discharge one or more corresponding interconnects within the link and a level shifter configured to shift the level of a signal on a last interconnect of the segment from the first voltage domain to the second voltage domain or the second voltage domain to the first voltage domain."
10168785,"An apparatus and method for gesture detection and recognition. The apparatus includes a processing element, a radar sensor, a depth sensor, and an optical sensor. The radar sensor, the depth sensor, and the optical sensor are coupled to the processing element, and the radar sensor, the depth sensor, and the optical sensor are configured for short range gesture detection and recognition. The processing element is further configured to detect and recognize a hand gesture based on data acquired with the radar sensor, the depth sensor, and the optical sensor."
10169072,"A method for providing state inheritance across command lists in a multi-threaded processing environment. The method includes receiving an application program that includes a plurality of parallel threads; generating a command list for each thread of the plurality of parallel threads; causing a first command list associated with a first thread of the plurality of parallel threads to be executed by a processing unit; and causing a second command list associated with a second thread of the plurality of parallel threads to be executed by the processing unit, where the second command list inherits from the first command list state associated with the processing unit."
10169091,"A technique for simultaneously executing multiple tasks, each having an independent virtual address space, involves assigning an address space identifier (ASID) to each task and constructing each virtual memory access request to include both a virtual address and the ASID. During virtual to physical address translation, the ASID selects a corresponding page table, which includes virtual to physical address mappings for the ASID and associated task. Entries for a translation look-aside buffer (TLB) include both the virtual address and ASID to complete each mapping to a physical address. Deep scheduling of tasks sharing a virtual address space may be implemented to improve cache affinity for both TLB and data caches."
10176739,"An aspect of the present invention proposes a method for performing partial refresh on display panels. According to one or more embodiments of the present invention, the display panels may be implemented as self-refreshing display panels communicatively coupled with a computing device that generates graphical data for display in the display panel. To perform partial refresh, consecutive frames are compared to identify the portions of the frames with updated material. In one or more embodiments, only the pixels corresponding to the updated portion(s) are refreshed in the display panel."
10180916,"A copy subsystem within a processor includes a set of logical copy engines and a set of physical copy engines. Each logical copy engine corresponds to a different command stream implemented by a device driver, and each logical copy engine is configured to receive copy commands via the corresponding command stream. When a logical copy engine receives a copy command, the logical copy engine distributes the command, or one or more subcommands derived from the command, to one or more of the physical copy engines. The physical copy engines can perform multiple copy operations in parallel with one another, thereby allowing the bandwidth of the communication link(s) to be saturated."
10181842,"A flip-flop element is configured to include FinFET technology transistors with a mix of threshold voltage levels. The data input path includes FinFET transistors configured with high voltage thresholds (HVT). The clock input path includes transistors configured with standard voltage thresholds (SVT). By including FinFET transistors with SVT thresholds in the clock signal path, the Miller capacitance of the clock signal path is reduced relative to HVT FinFET transistors, leading to lower rise time and correspondingly lower hold time. By including HVT threshold devices in the data input path, the flip-flop element attains high speed and low power operation. By including SVT threshold devices in the clock signal path, the flip-flop element achieves faster switching times in the clock signal path."
10187094,"A single-ended signal transmission system recovers a noise signal associated with a data input signal and uses the recovered noise signal to compensate for noise on the data input signal. The noise signal may be recovered from a noise reference signal line, or clock signal line, or a data signal line associated with a DC-balanced data input signal. The recovered noise signal may be represented as an analog signal or a digital signal. The recovered noise signal may be processed to compensate for DC offset and nonlinearities associated with one or more different input buffers. In one embodiment, the recovered noise signal includes frequency content substantially below a fundamental frequency for data transmission through the data input signal."
10187663,"A subsystem configured to encode an RGBA8 data stream assembles sequences of four-byte groups from the data stream. The subsystem decorrelates the red and blue channels, and computes a difference between each four-byte group and an anchor value. The anchor is encoded at full value. The subsystem then assigns each group a five-bit header based on the number and location of non-zero bytes and on the data content of the non-zero bytes within the group. The subsystem favors zero valued bytes. Thus, when a group includes only zero valued bytes, the header is sufficient to encode the group; no data bits are necessary. Further, two successive groups of zero-valued bytes may be encoded as a single header with no data bits, achieving further data reduction. Finally, the subsystem concatenates all the headers with associated data to yield the source data stream compressed to some ratio, e.g. four-to-one."
10192525,"A system, method and computer program product are provided for generating one or more values for a signal patch using neighboring patches collected based on a distance dynamically computed from a noise distribution of the signal patch. In use, a reference patch is identified from a signal, and a reference distance is computed based on a noise distribution in the reference patch. Neighbor patches are then collected from the signal based on the computed reference distance from the reference patch. Further, the collected neighbor patches are processed with the reference patch to generate one or more values for the reference patch."
10200022,"A method for regulating voltage for a processor is disclosed. The method comprises requesting a target frequency value, wherein the target frequency value determines a target clock frequency for clocking the processor. The method also comprises comparing the target clock frequency to a first signal to generate an error signal. Further, the method comprises using the error signal to generate a duty cycle control signal, wherein the duty cycle control signal is operable to generate a periodic waveform. Finally, the method comprises generating an output regulator voltage using the periodic waveform, wherein the output voltage is operable to provide power to the processor."
10200154,"A receiver, transmitter and method for early packet header verification are provided. In one embodiment, the method includes: (1) receiving a payload flit of a preceding packet and a header flit of a current packet; and (2) using a Cyclic Redundancy Check (CRC) in the header flit to verify the payload flit of the preceding packet and the header flit of the current packet."
10200508,"A special-purpose processing system, a method of carrying out sharing special-purpose processing resources and a graphics processing system. In one embodiment, the special-purpose processing system includes: (1) a special-purpose processing resource and (2) a Representational State Transfer (ReST) application programming interface operable to process data using the special-purpose processing resource in response to stateless commands based on a standard protocol selected from the group consisting of: (2a) a standard network protocol and (2b) a standard database query protocol."
10200571,"An image of an object under a first illuminant is captured. The color of the ambient light at a device on which the image is to be displayed is identified. The image data is adjusted to compensate for the color of the ambient light as well as for the color of the first illuminant. An image based on the adjusted image data can then be displayed on the device. As such, the desired perception of the colors in the displayed image can be managed so that image quality is maintained even if the image is displayed under different ambient lighting conditions."
10212406,"A system and method for computational zoom generates a resulting image having two or more effective focal lengths. A first surface within a three-dimensional (3D) scene including a first and second set of 3D objects defined by 3D information is identified. The first and second sets of 3D objects are located within first and second depth ranges of the 3D scene, respectively. The first set of 3D objects is projected onto the first surface according to a first projection mapping to produce a first portion of image components. The second set of 3D objects is projected onto the first surface according to a second projection mapping to produce a second portion of image components. The resulting image comprising the first portion of image components and the second portion of image components is generated based on a camera projection from the first surface to a camera view plane."
10216413,"Techniques are provided by which memory pages may be migrated among PPU memories in a multi-PPU system. According to the techniques, a UVM driver determines that a particular memory page should change ownership state and/or be migrated between one PPU memory and another PPU memory. In response to this determination, the UVM driver initiates a peer transition sequence to cause the ownership state and/or location of the memory page to change. Various peer transition sequences involve modifying mappings for one or more PPU, and copying a memory page from one PPU memory to another PPU memory. Several steps in peer transition sequences may be performed in parallel for increased processing speed."
10216521,"A method, computer readable medium, and system are disclosed for error coping. The method includes the steps of receiving, by a processing unit, a set of program instructions including a first program instruction that is responsive to error detection, detecting an error in a value of a first operand of the first program instruction, and determining that error coping execution is selectively enabled for the first instruction. The value for the first operand is replaced with a substitute value and the first program instruction is executed by the processing unit."
10217183,"A system, method, and computer program product are provided for allocating processor resources to process compute workloads and graphics workloads substantially simultaneously. The method includes the steps of allocating a plurality of processing units to process tasks associated with a graphics pipeline, receiving a request to allocate at least one processing unit in the plurality of processing units to process tasks associated with a compute pipeline, and reallocating the at least one processing unit to process tasks associated with the compute pipeline."
10217184,"A processing unit includes multiple execution pipelines, each of which is coupled to a first input section for receiving input data for pixel processing and a second input section for receiving input data for vertex processing and to a first output section for storing processed pixel data and a second output section for storing processed vertex data. The processed vertex data is rasterized and scan converted into pixel data that is used as the input data for pixel processing. The processed pixel data is output to a raster analyzer."
10217444,"A method for network cloud resource generation, including creating a template virtual machine. The method includes creating an instantiation of a virtual machine for an end user by cloning the template, and loading an application executed by the virtual machine. The method includes accessing first information associated with the end user, and loading the first information in an instantiation of the application."
10218988,"A method for performing image decompression. The method includes identifying a pixel in an image, wherein the image comprises a plurality of tiles including color data that is displayed by a plurality of pixels, wherein each tile is associated with a base value, a delta value, and a plurality of indices. One or more tiles associated with the pixel are identified. An interpolated base is determined by interpolating decompressed bases of the one or more tiles. An interpolated delta is determined by interpolating deltas of the one or more tiles. An index is determined for the pixel. A color value is determined for the pixel based on the interpolated base, interpolated delta, and the index."
10219387,"A process for manufacturing a printed circuit board having high-density microvias formed in a thick substrate is disclosed. The method includes the steps of forming one or more holes in a thick substrate using a laser drilling technique, electroplating the one or more holes with a conductive material, wherein the conductive material does not completely fill the one or more holes, and filling the one or more plated holes with a non-conductive material."
10223122,"One embodiment of the present invention sets forth a graphics processing system configured to track event counts in a tile-based architecture. The graphics processing system includes a screen-space pipeline and a tiling unit. The screen-space pipeline includes a first unit, a count memory associated with the first unit, and an accumulating memory associated with the first unit. The first unit is configured to detect an event type and increment the count memory. The tiling unit is configured to cause the screen-space pipeline to update an external memory address to reflect a first value stored in the count memory when the first unit completes processing of a first set of primitives. The tiling unit is also configured to cause the screen-space pipeline to update the accumulating memory to reflect a second value stored in the count memory when the first unit completes processing of a second set of primitives."
10223333,"In one embodiment of the present invention a convolution engine configures a parallel processing pipeline to perform multi-convolution operations. More specifically, the convolution engine configures the parallel processing pipeline to independently generate and process individual image tiles. In operation, for each image tile, the pipeline calculates source locations included in an input image batch. Notably, the source locations reflect the contribution of the image tile to an output tile of an output matrix—the result of the multi-convolution operation. Subsequently, the pipeline copies data from the source locations to the image tile. Similarly, the pipeline copies data from a filter stack to a filter tile. The pipeline then performs matrix multiplication operations between the image tile and the filter tile to generate data included in the corresponding output tile. To optimize both on-chip memory usage and execution time, the pipeline creates each image tile in on-chip memory as-needed."
10223987,"A method, computer program product, and system perform DC balancing for a variable refresh rate display panel based on regions. A first portion of a first image is displayed on a first region of a screen of a display device using a spatial inversion pattern and a first polarity of a temporal polarity pattern for the first region of the screen of the display device. A second polarity of a second temporal polarity pattern for a second region of the screen of the display device is determined and a second portion of the first image is displayed on the second region of the screen of the display device using the spatial inversion pattern and the second polarity of the second temporal polarity pattern."
10224813,A system and method are provided for controlling a modified buck converter circuit. A pull-up switching mechanism that is coupled to an upstream terminal of an inductor within a modified buck converter circuit is enabled. A load current at the output of the modified buck regulator circuit is measured. A capacitor current associated with a capacitor that is coupled to a downstream terminal of the inductor is continuously sensed and the pull-up switching mechanism is disabled when the capacitor current is greater than a sum of the load current and an enabling current value.
10228919,"One embodiment of the present invention sets forth a technique for reducing sign-extension instructions (SEIs) included in a computer program, the technique involves receiving intermediate code that is associated with the computer program and includes a first SEI that is included in a loop structure within the computer program, determining that the first SEI is eligible to be moved outside of the loop structure, inserting into a preheader of the loop a second SEI that, when executed by a processor, promotes an original value targeted by the first SEI from a smaller type to a larger type, and replacing the first SEI with one or more intermediate instructions that are eligible for additional compiler optimizations."
10229529,"A system, method, and computer program product are provided for implementing anti-aliasing operations using a programmable sample pattern table. The method includes the steps of receiving an instruction that causes one or more values to be stored in one or more corresponding entries of the programmable sample pattern table and performing an anti-aliasing operation based on at least one value stored in the programmable sample pattern table. At least one value is selected from the programmable sample pattern table based on, at least in part, a location of one or more corresponding pixels."
10229651,"A method for rendering and displaying video. The method includes executing an application at a processor. As instructed by the processor when executing the application, the method includes rendering a plurality of image frames at a plurality of graphics processing units (GPUs). The method includes determining information related to relative timing between renderings of the plurality of image frames. The method includes encoding the plurality of image frames into a video file. The method includes encoding the information into the video file."
10230405,"A receiver, transmitter, and method for a dynamic forward error correction (FEC) are provided. In one embodiment, the method includes: 1) transmitting frames of data during a streaming session according to a FEC repair rate, each frame being contained in a plurality of source packets and having at least one repair packet; and 2) changing the FEC repair rate at least once during the streaming session based on at least one of a number of unrecovered source packets and a number of unused repair packets."
10232274,"A system for multi-client control of an avatar. In one embodiment, the system includes: (1) a game engine configured to execute game code configured to create a game in a game space and accept a response stream to allow said avatar to be controlled and (2) a cooperative play engine associated with said game engine for communication therewith and having a stereoscopic device driver configured to render left-eye and right-eye views of said game space, said cooperative play engine configured to: (2a) transmit said left-eye view toward a first client associated with a first player and (2b) transmit said right-eye view toward a second client associated with a second player."
10234893,"A dual-domain dynamic multiplexer and a method of transitioning between asynchronous voltage and frequency domains. One embodiment of the dual-domain dynamic multiplexer includes: (1) a first domain having a first voltage and a first clock, and a second domain having a second voltage and a second clock, (2) a plurality of data and data select input pairs wherein a data input of an input pair is in the first domain and a data select input of an input pair is in the second domain, and (3) a pre-charge stage in the second domain that is energized upon an edge of the second clock, whereby one data and data input pair is enabled and data latched in the second domain upon another edge of the second clock."
10235208,"A streaming multiprocessor (SM) included within a parallel processing unit (PPU) is configured to suspend a thread group executing on the SM and to save the operating state of the suspended thread group. A load-store unit (LSU) within the SM re-maps local memory associated with the thread group to a location in global memory. Subsequently, the SM may re-launch the suspended thread group. The LSU may then perform local memory access operations on behalf of the re-launched thread group with the re-mapped local memory that resides in global memory."
10235338,"A system, computer readable medium, and method are disclosed for performing a tree traversal operation utilizing a short stack data structure. The method includes the steps of executing, via a processor, a tree traversal operation for a tree data structure utilizing a short stack data structure, determining that the short stack data structure is empty after testing a current node in the tree traversal operation, and executing, via the processor, a back-tracking operation for the current node to identify a new node in the tree data structure to continue the tree traversal operation. The processor may be a parallel processing unit that includes one or more tree traversal units, which implement the tree traversal operation in hardware, software, or a combination of hardware and software."
10237563,"A system and method are provided for a 3D modeling system with which an encoded video stream is produced. The system includes a content engine, an encoder, and a fixed function engine. The fixed function engine receives content information from the content engine. The fixed function engine produces encoder information from the content information. The encoder uses the encoder information to produce an encoded video stream having at least one of a higher quality and a lower bandwidth than a video stream encoded without the encoder information."
10241148,"One embodiment of the present invention sets forth an integrated circuit that includes multiple input/output (I/O) pad groups. Each I/O pad group includes an on-chip star network, multiple I/O pads, multiple test multiplexers, a digital-to-analog converter (DAC), and a wide-range comparator. Each test multiplexer is configured to couple a different I/O pad to the on-chip star network. The DAC is configured to supply at least one of a source current, a sink current, and a first reference voltage to the on-chip star network. The wide-range comparator is configured to compare a voltage present on a first I/O pad included in the plurality of I/O pads with a second reference voltage. Advantageously, IO leakage and DC parametric testing may be performed on integrated circuits with high I/O pad counts using an ATE system with a significantly lower quantity of ATE test channels relative to prior approaches."
10241761,"A system and method for processing source code for compilation. The method includes accessing a portion of host source code and determining whether the portion of the host source code comprises a device lambda expression. The method further includes in response to the portion of host code comprising the device lambda expression, determining a unique placeholder type instantiation based on the device lambda expression and modifying the device lambda expression based on the unique placeholder type instantiation to produce modified host source code. The method further includes sending the modified host source code to a host compiler."
10241798,"An issue control unit is configured to control the rate at which an instruction issue unit issues instructions to an execution pipeline in order to avoid spikes in power drawn by that execution pipeline. The issue control unit maintains a history buffer that reflects, for N previous cycles, the number of instructions issued during each of those N cycles. If the total number of instructions issued during the N previous cycles exceeds a threshold value, then the issue control unit throttles the instruction issue unit from issuing instructions during a subsequent cycle. In addition, the issue control unit increases the threshold value in proportion to the number of previously issued instructions and based on a variety of configurable parameters. Accordingly, the issue control unit maintains granular control over the rate with which the instruction issue unit “ramps up” to a maximum instruction issue rate."
10241810,"A processing system comprising a microprocessor core and a translator. Within the microprocessor core is arranged a hardware decoder configured to selectively decode instructions for execution in the microprocessor core, and, a logic structure configured to track usage of the hardware decoder. The translator is operatively coupled to the logic structure and configured to selectively translate the instructions for execution in the microprocessor core, based on the usage of the hardware decoder as determined by the logic structure."
10242462,"A video encoder, a method of encoding a frame of video data, and a three-dimensional modeling system producing an encoded video stream are disclosed herein. In one embodiment, the method includes: (1) receiving from an application a frame of video data to be encoded, (2) determining a gamer's attention area for the frame of video data and (3) changing an encoding of the frame of video data by allocating bits for the frame based upon the gamer's attention area."
10242485,"An apparatus, computer readable medium, and method are disclosed for performing an intersection query between a query beam and a target bounding volume. The target bounding volume may comprise an axis-aligned bounding box (AABB) associated with a bounding volume hierarchy (BVH) tree. An intersection query comprising beam information associated with the query beam and slab boundary information for a first dimension of a target bounding volume is received. Intersection parameter values are calculated for the first dimension based on the beam information and the slab boundary information and a slab intersection case is determined for the first dimension based on the beam information. A parametric variable range for the first dimension is assigned based on the slab intersection case and the intersection parameter values and it is determined whether the query beam intersects the target bounding volume based on at least the parametric variable range for the first dimension."
10249018,"A graphics processor and a method of scaling user interface (UI) elements for smaller displays. One embodiment of the graphics processor includes: (1) a scene renderer configured to render a scene from scene data generated by a graphics application, (2) a user interface (UI) renderer configured to render a UI from UI data generated by the graphics application, (3) a UI scaler configured to scale the UI based on properties of a remote display, and (4) a compositor operable to combine the scene and the UI into a composite image."
10249083,"A strain based dynamic technique, for rendering special effects, includes simulation as a function of a Green-St. Venant strain tensor constraint. The behavior of a soft body may be controlled independent of a mesh structure by assigning different stiffness values to each constraint of the Green-St. Venant strain tensor."
10249361,"A subsystem configured to write data to a static random access memory cell employs a single N-channel MOS device connected to ground in each leg of the bi-stable memory cell to overdrive the stored data. The subsystem implements the dual control required to effect matrix operation of the SRAM cell in the gate circuit of the single N-channel MOS device in the drive path. Specifically, the column select signal controls a semiconductor junction that interrupts the data connection to the gate. In this manner, the column select control is removed from the drive path, thus increasing drive strength. Further, a second semiconductor junction connects the gate of the single NMOS device in the drive path when the gate signal is interrupted."
10250892,"A subsystem configured to upsample a video data stream encoded in YCrCb format 4:2:0 (also termed YUV 4:2:0) performs an algorithm upon a two-by-two group of subsampled pixels. The subsystem computes an inside probability that the chrominance of a target pixel is a close match to the chrominance inside the group of four pixels. The subsystem further computes three weighting factors relating the chrominance of the target pixel to each of three adjacent pixels in an upsampled four-by-four pixel group. The subsystem then computes an outside estimate of the chrominance based on the weighting factors. Finally, the subsystem computes the chrominance of the target pixel based on the inside probability, the outside estimate, and the subsampled chrominance. The subsystem performs the algorithm upon all two-by-two groups of four pixels within a subsampled YUV 4:2:0 video data stream and generates an upsampled YUV 4:4:4 video data stream."
10252171,"A system for cooperative game control. In one embodiment, the system includes: (1) a cloud game engine for executing game code configured to create a game, generate a video stream corresponding to a particular player and accept a response stream from the particular player to allow the particular player to play the game and (2) a cooperative play engine associated with the cloud game engine for communication therewith and configured to multicast the video stream from the cloud game engine to the particular player and at least one other player, combine separate response streams from the particular player and the at least one other player into a joint response stream and provide the joint response stream to the cloud game engine."
10255075,"A method, system and computer program product embodied on a computer-readable medium are provided for managing the execution of out-of-order instructions. The method includes the steps of receiving a plurality of instructions and identifying a subset of instructions in the plurality of instructions to be executed out-of-order."
10255228,"One embodiment of the present invention sets forth a technique that provides an efficient way to retrieve operands from a register file. Specifically, the instruction dispatch unit receives one or more instructions, each of which includes one or more operands. Collectively, the operands are organized into one or more operand groups from which a shaped access may be formed. The operands are retrieved from the register file and stored in a collector. Once all operands are read and collected in the collector, the instruction dispatch unit transmits the instructions and corresponding operands to functional units within the streaming multiprocessor for execution. One advantage of the present invention is that multiple operands are retrieved from the register file in a single register access operation without resource conflict. Performance in retrieving operands from the register file is improved by forming shaped accesses that efficiently retrieve operands exhibiting recognized memory access patterns."
10255547,"In one embodiment of the present invention, a convolution engine configures a parallel processing pipeline to perform multi-convolution operations. More specifically, the convolution engine configures the parallel processing pipeline to independently generate and process individual image tiles. In operation, for each image tile, the pipeline calculates source locations included in an input image batch based on one or more start addresses and one or more offsets. Subsequently, the pipeline copies data from the source locations to the image tile. The pipeline then performs matrix multiplication operations between the image tile and a filter tile to generate a contribution of the image tile to an output matrix. To optimize the amount of memory used, the pipeline creates each image tile in shared memory as needed. Further, to optimize the throughput of the matrix multiplication operations, the values of the offsets are precomputed by a convolution preprocessor."
10255717,"Embodiments of the present invention are directed to techniques for improving the efficiency of shadow mapping by using highly optimized hardware-accelerated rasterizers. Embodiments of the present invention use a shader (such as a fragment or compute shader) to construct advanced shadow maps which store a list of polygons that intersect each pixel, and synchronizing read/write operations (e.g., with atomics) to ensure consistency of the texture accesses when managing the per-texel triangle lists during creation. By using these hardware-accelerated and optimized techniques, high quality hard shadows can be produced during real-time rendering, as performed in graphics processing engines, for example. Moreover, this technique can be synchronized with other pre-fragment features that are becoming increasingly prevalent and efficient in the latest processing architectures."
10257449,"Embodiments of the present invention are directed to methods and systems for performing automatic noise reduction in video. According to one aspect of the invention, a video noise-reducing system is provided consisting of a noise estimator, a motion classifier, two stages of filters, each including a spatial and temporal filter, and a combiner. The system adapts to noise level and to scene content to find at each location in the image a balance of noise reduction and detail preservation. Temporal Infinite Impulse Response (IIR) filtering provides a high level of detail-preserving noise reduction where motion allows, while non linear spatial filtering provides edge-preserving noise reduction in areas where the temporal filter would introduce motion artifacts. A spatial-temporal combiner provides smooth transition and balance between the two filtering modes; this block also enables use of external cues to produce a visually pleasing output based on ambient conditions."
10258886,An electronic computing system for dynamically controlling user interface device settings for an electronic game playable by multiple players over a computer network.
10261807,"Embodiments of the present invention provide a novel solution to generate multiple linked device code portions within a final executable file. Embodiments of the present invention are operable to extract device code from their respective host object filesets and then link them together to form multiple linked device code portions. Also, using the identification process described by embodiments of the present invention, device code embedded within host objects may also be uniquely identified and linked in accordance with the protocols of conventional programming languages. Furthermore, these multiple linked device code portions may be then converted into distinct executable forms of code that may be encapsulated within a single executable file."
10269090,"One embodiment of the present invention includes techniques for processing a multi-resolution hierarchy, where an application configures a ROP unit to render all the levels included in the multi-resolution hierarchy to a single composite render target. The ROP unit renders memory pages to the composite render target in pitch order. In contrast, the texture unit accesses the composite render target with memory pages in pitch order for each level of the hierarchy. The application configures the MMU to ensure that the composite render target is correctly interpreted by the texture unit. Notably, the MMU translates ROP unit virtual addresses and texture unit virtual addresses using different mapping strategies to the same physical address space. One advantage of the disclosed embodiments is that rendering to the multi-resolution hierarchy does not require the CPU to execute the state parameter changes that are associated with rendering the different hierarchical levels using prior-art techniques."
10269166,"A method, a computer program, and a production renderer for accelerating a rendering process of an image are provided. In one embodiment, the method includes intercepting a first invocation of a function from a custom shader during a rendering process of an image, computing a result of the function employing a processor, and returning the result to the custom shader in response to a second invocation of the function during the rendering process."
10275049,"Signaling touch screen enabled devices is disclosed. A capacitive stylus has a body suitable for being hand held as a writing instrument. The body has a tip for interfacing with a capacitive touch screen display panel of a computer system. The stylus has an insulator disposed near its tip, which insulates capacitance of the stylus body. A switch selectively couples the tip to the remaining parts of the stylus body. A controller controls the switch. A mode selector on the body is responsive to being pressed to signal the controller for selecting one of multiple modes. The controller is configured to enter the selected mode responsive to the mode selector and is configured to control the switch unit to switch according to different signal patterns depending on a mode entered by the controller."
10275275,"A copy subsystem within a processor includes a set of logical copy engines and a set of physical copy engines. Each logical copy engine corresponds to a different command stream implemented by a device driver, and each logical copy engine is configured to receive copy commands via the corresponding command stream. When a logical copy engine receives a copy command, the logical copy engine distributes the command, or one or more subcommands derived from the command, to one or more of the physical copy engines. The physical copy engines can perform multiple copy operations in parallel with one another, thereby allowing the bandwidth of the communication link(s) to be saturated."
10276156,A sound-activated control system includes an audio receiver and a command discriminator. The receiver is configured to receive an audio waveform and to produce a digital audio waveform therefrom. The command discriminator is configured to detect a temporally and/or spectrally compact nonphonetic audio command within the digital audio waveform and to control a voice-activated system an action in response to the nonphonetic command.
10277921,"Decoder techniques in accordance with embodiment of the present technology include partially decoding a compressed file on a serial based processing unit to find offsets of each of a plurality of entropy data blocks. The compressed file and offset for each of the plurality of entropy encoded data blocks are transferred to a parallel based processing unit. Thereafter, the compressed file is at least partially decoded on the parallel based processing unit using the offset for each of the plurality of entropy encoded data blocks."
10281524,"In one embodiment, a test system comprises: a test partition configured to perform test operations; a centralized test controller for controlling testing by the test partition; and a test link interface controller configured to communicate between the centralized test controller and the test partition, wherein the test link interface controller controls dynamic changes to external pads associated with the test operations. The test link interface controller dynamically selects between an input direction and output direction for the external pads. The test link interface includes a pin direction controller that generates direction control signals based on the state of local test controller and communicates the desired direction to a boundary scan cell associated with the pin. The boundary scan cell programs the pad to either input or output direction depending on direction control signals. The input direction corresponds to driving test data and the output direction corresponds to observing test data."
10282803,"One embodiment of the present invention includes a graphics subsystem that includes a tiling unit, a crossbar unit, and a screen-space pipeline. The crossbar unit is configured to transmit primitives interleaved with state change commands to the tiling unit. The tiling unit is configured to record an initial state associated with the primitives and to transmit to the screen-space pipeline one or more primitives in the primitives that overlap a first cache tile. The tiling unit is further configured to transmit the initial state to the screen-space pipeline and to transmit to the screen-space pipeline one or more primitives in the primitives that overlap a second cache tile. The tiling unit includes a state filter block configured to determine that a first state change in the state change commands is followed by a second state change, without an intervening primitive, and to forego transmitting the first state change in response."
10284269,"A communications system has a cellular structure including a base station that is located within a cell of the cellular structure and provides an elevation beamforming transmission based on a set of elevation precoding matrix indicator offsets in an elevation codebook. The communications system also includes user equipment that is located within the cell and coupled to the base station to receive the set of elevation precoding matrix indicator offsets and a set of reference signals to provide channel quality and inter-cell interference measurements, wherein a selected channel quality indicator is based on an increase in channel quality with respect to inter-cell interference at the user equipment and corresponds to one of the set of elevation precoding matrix indicator offsets. A method of operating a communications system having a cellular structure is also provided."
10289418,"Techniques are provided for handling a trap encountered in a thread that is part of a thread array that is being executed in a plurality of execution units. In these techniques, a data structure with an identifier associated with the thread is updated to indicate that the trap occurred during the execution of the thread array. Also in these techniques, the execution units execute a trap handling routine that includes a context switch. The execution units perform this context switch for at least one of the execution units as part of the trap handling routine while allowing the remaining execution units to exit the trap handling routine before the context switch. One advantage of the disclosed techniques is that the trap handling routine operates efficiently in parallel processors."
10289469,"Systems and methods for enhancing reliability are presented. In one embodiment, a system comprises a processor configured to execute program instructions and contemporaneously perform reliability enhancement operations (e.g., fault checking, error mitigation, etc.) incident to executing the program instructions. The fault checking can include: identifying functionality of a particular portion of the program instructions; speculatively executing multiple sets of operations contemporaneously; and comparing execution results from the multiple sets of operations. The multiple sets of operations are functional duplicates of the particular portion of the program instructions. If the execution results have a matching value, then the value can be made architecturally visible. If the execution results do not have a matching value, the system can be put in a safe mode. An error mitigation operation can be performed can include a corrective procedure. The corrective procedure can include rollback to a known valid state."
10296345,"Embodiments of the present invention are operable to communicate a list of important shaders and their current best-known compilations to remote client devices over a communications network. Client devices are allowed to produce modified shader compilations by varying optimizations. If a client device produces a modified compilation that beats an important shader's current best-known compilation, embodiments of the present invention can communicate this new best-known shader compilation back to a host computer system. Furthermore, embodiments of the present invention may periodically broadcast the new best-known shader compilation back to client devices for possible further optimization or for efficient rendering operations using the best-known shader compilation."
10298422,"A multi-stage amplifier circuit equalizes an input signal through multiple signal amplification paths. DC gain is kept substantially constant over frequency, while adjustable high-frequency gain provides equalization (e.g., peaking). Various embodiments include a common source topology, a common gate topology, differential signaling topologies, and a topology suitable for stabilizing a voltage supply against high-frequency transient loads. A system may include one or more integrated circuits that may each include one or more instances of the multi-stage amplifier."
10298475,"A receiver and method for estimating an available bandwidth of a data channel streaming video data are provided. In one embodiment, the receiver includes: (1) a physical interface configured to receive the video data from a network, (2) a packet memory configured to store frames of the video data, (3) a dispersed packet time calculator configured to calculate a total time for one of the frames to go through the data channel, and (4) a bandwidth estimator configured to determine the available bandwidth of the data channel based on a number of data units received for the one frame and the total time."
10298645,"A computer application streaming system includes an optimization unit coupled to a streaming device to determine streaming optimal playable settings for a remote user device corresponding to a selected computer application and a sending unit coupled to the optimization unit to manage streaming of the streaming optimal playable settings over a network connected to the remote user device. A receiving unit is coupled to the network to recover the streaming optimal playable settings for application to the remote user device when employing the selected computer application. An optional feedback unit is coupled to the remote user device to provide remote information over the network for modifying the streaming optimal playable settings, and an optional update unit is coupled to the streaming device to manage modification of the streaming optimal playable settings as directed by the remote information. A method of streaming a computer application is also provided."
10303616,A system for managing virtual memory. The system includes a first processing unit configured to execute a first operation that references a first virtual memory address. The system also includes a first memory management unit (MMU) associated with the first processing unit and configured to generate a first page fault upon determining that a first page table that is stored in a first memory unit associated with the first processing unit does not include a mapping corresponding to the first virtual memory address. The system further includes a first copy engine associated with the first processing unit. The first copy engine is configured to read a first command queue to determine a first mapping that corresponds to the first virtual memory address and is included in a first page state directory. The first copy engine is also configured to update the first page table to include the first mapping.
10310879,"An embodiment of the invention sets forth a primary processing unit, a secondary processing unit coupled to the primary processing unit and accessible via a plurality of channels and a plurality of guest virtual machines executing on the primary processing unit. Each guest virtual machine includes a driver associated with the secondary processing unit, and a privileged virtual machine executing on the primary processing unit and configured to allocate a different set of channels of the plurality of channels to each of the drivers included in the guest virtual machines, where a first set of channels allocated to a first driver enables the first driver to access the secondary processing unit without conflicting with any of the other and with minimal performance overhead by directly accessing the secondary processing unit channels."
10310973,"A technique for simultaneously executing multiple tasks, each having an independent virtual address space, involves assigning an address space identifier (ASID) to each task and constructing each virtual memory access request to include both a virtual address and the ASID. During virtual to physical address translation, the ASID selects a corresponding page table, which includes virtual to physical address mappings for the ASID and associated task. Entries for a translation look-aside buffer (TLB) include both the virtual address and ASID to complete each mapping to a physical address. Deep scheduling of tasks sharing a virtual address space may be implemented to improve cache affinity for both TLB and data caches."
10311589,One embodiment of the present invention sets forth a technique for estimating a head pose of a user. The technique includes acquiring depth data associated with a head of the user and initializing each particle included in a set of particles with a different candidate head pose. The technique further includes performing one or more optimization passes that include performing at least one iterative closest point (ICP) iteration for each particle and performing at least one particle swarm optimization (PSO) iteration. Each ICP iteration includes rendering the three-dimensional reference model based on the candidate head pose associated with the particle and comparing the three-dimensional reference model to the depth data. Each PSO iteration comprises updating a global best head pose associated with the set of particles and modifying at least one candidate head pose. The technique further includes modifying a shape of the three-dimensional reference model based on depth data.
10311628,"One embodiment of the present invention includes a method for rendering a geometry object in a computer-generated scene. A screen space associated with a display screen is divided into a set of regions. For each region; a first sampling factor in a horizontal dimension is computed that represents a horizontal sampling factor for pixels located in the region, a second sampling factor in a vertical dimension is computed that represents a vertical sampling factor for the pixels located in the region, a first offset in the horizontal dimension is computed that represents a horizontal position associated with the region, and a second offset in the vertical dimension is computed that represent a vertical position associated with the region. When the geometry object is determined to intersect more than one region, an instance of the geometry object is generated each region that the geometry object intersects."
10312967,"A method for transmitting data advantageously reduces cross-talk in high-speed data transmission. The method comprises receiving an input data word, encoding the input data word into a code word, and driving the code word on to an interconnect for transmission. The code word is generating using a balanced coding scheme, and the interconnect is a single-ended, twisted-wire on-chip fly-over interconnect. A receiver circuit decodes the code word to generate an output data word."
10317459,"A microelectronic package has an IC chip that includes logical circuitry for routing certain I/O signals to debug ports disposed on an outer surface of the microelectronic package. The I/O signals include data and command signals that are transmitted between semiconductor chips in the microelectronic package via conductive traces that are not physically accessible via with conventional debugging techniques. The logical circuitry may be configured to programmably select I/O signals based on a software input, and may be connected to the various I/O signals transmitted between the IC chip and another IC chip in the microelectronic package when a debugging of the I/O signals is enabled. Circuitry employed in conventional operation of the IC chip may also be employed to connect the logical circuitry to the various I/O signals."
10317463,A method for testing. The method includes sending a single instruction over a JTAG interface to a JTAG controller to select a first internal test data register of a plurality of data registers. The method includes programming the first internal test data register using the JTAG interface to configure mode control access and state control access for a test controller implementing a sequential scan architecture to test a chip at a system level.
10317678,"A method and system for operating a catadioptric glasses system is presented. The method includes the steps of generating an image via a light engine included in a glasses system and projecting the image onto a display that includes a diffusion layer positioned between a curved mirror and a user's retina. Light emitted from a surface of the diffusion layer is reflected off the curved mirror to the user's retina through the diffusion layer, and the diffusion layer is located between a focal point of the curved mirror and a surface of the curved mirror. The diffusion layer may be mechanically moved relative to the user's eye to enable light to pass through transparent regions in the diffusion layer in a time multiplexed fashion. The glasses system may also include a mirror stack to enable different virtual images to be formed at different depths."
10319005,"To establish a target (e.g., billing) address, a device receives a first physical address determined by geolocating the device (e.g., based on an Internet Protocol (IP) address associated with the device). A street-level map that includes an indicator that is rendered at a first location in the map corresponding to the first physical address is displayed. The indicator can be moved from the first location to one or more other locations in the map. The device receives a selection of a physical address corresponding to the location in the map of the indicator when the selection is made. The device records the selected physical address as the target address."
10319060,"The present invention facilitates efficient and effective utilization of unified virtual addresses across multiple components. In one embodiment, the presented new approach or solution uses Operating System (OS) allocation on the central processing unit (CPU) combined with graphics processing unit (GPU) driver mappings to provide a unified virtual address (VA) across both GPU and CPU. The new approach helps ensure that a GPU VA pointer does not collide with a CPU pointer provided by OS CPU allocation (e.g., like one returned by “malloc” C runtime API, etc.)."
10319132,A method and system of representing and simulating an object by representing using with velocity-dependent particles.
10324693,"A system and method for optimizing multiple invocations of a graphics processing unit (GPU) program in Java. In one embodiment, the system includes: (1) a frontend component in a computer system and configured to compile Java bytecode associated with the a class object that implements a functional interface into Intermediate Representation (IR) code and store the IR code with the associated jogArray and (2) a collector/composer component in the computer system, associated with the frontend and configured to traverse a tree containing the multiple invocations from the result to collect the IR code and compose the IR code collected in the traversing into aggregate IR code when a result of the GPU program is explicitly requested to be transferred to a host."
10324725,"The disclosure provides a method and a system for identifying and replacing code translations that generate spurious fault events. In one embodiment the method includes executing a first set and a second set of native instructions, performing a third translation of a target instruction to form a third set of native instructions in response to a determination that a fault occurrence is attributed to a first translation, wherein the third set of native instructions is not the same as the second set of native instructions, and the third set of native instructions is not the same as the first set of native instructions, and executing the third set of native instructions."
10326625,"A single-ended signal transmission system recovers a noise signal associated with a data input signal and uses the recovered noise signal to compensate for noise on the data input signal. The noise signal may be recovered from a noise reference signal line, or clock signal line, or a data signal line associated with a DC-balanced data input signal. The recovered noise signal may be represented as an analog signal or a digital signal. The recovered noise signal may be processed to compensate for DC offset and nonlinearities associated with one or more different input buffers. In one embodiment, the recovered noise signal includes frequency content substantially below a fundamental frequency for data transmission through the data input signal."
10331603,"Techniques are disclosed for tracking memory page accesses in a unified virtual memory system. An access tracking unit detects a memory page access generated by a first processor for accessing a memory page in a memory system of a second processor. The access tracking unit determines whether a cache memory includes an entry for the memory page. If so, then the access tracking unit increments an associated access counter. Otherwise, the access tracking unit attempts to find an unused entry in the cache memory that is available for allocation. If so, then the access tracking unit associates the second entry with the memory page, and sets an access counter associated with the second entry to an initial value. Otherwise, the access tracking unit selects a valid entry in the cache memory; clears an associated valid bit; associates the entry with the memory page; and initializes an associated access counter."
10331632,"A system, method, and computer program product are provided for modifying a hierarchical tree data structure. An initial hierarchical tree data structure is received and treelets of node neighborhoods in the initial hierarchical tree data structure are formed. Each treelet includes n leaf nodes and n−1 internal nodes. The treelets are restructured, by a processor, to produce an optimized hierarchical tree data structure."
10332310,"One embodiment of the present invention includes a technique for distributing work slices associated with a graphics processing unit for processing. A primitive distribution system receives a draw command related to a graphics object associated with a plurality of indices. The primitive distribution system creates a plurality of work slices, where each work slice is associated with a different subset of the indices included in the plurality of indices. The primitive distribution system scans a first subset of indices to identify a first set of characteristics that is needed to process a second subset of indices. The primitive distribution system processes the second subset of indices based at least in part on the one or more characteristics. Advantageously, because multiple work slices are analyzed in parallel for duplicate indices, the time required to analyze work slices is more in balance with the time required to process the work slices, leading to greater utilization of GPU resources and improved overall performance."
10333565,"A transmitter for a high speed serial communications link, a serial communications link, and a receiver for a high speed serial communications link are disclosed herein. In one embodiment, the transmitter includes: (1) a communications interface connected to a transmission medium having multiple lanes, and (2) a safe mode circuit coupled to the communications interface and configured to send data over the transmission medium in a safe mode, wherein in the safe mode at least one of the lanes is dedicated to transmitting a link detect signal for link detection."
10338820,"A system architecture conserves memory bandwidth by including compression utility to process data transfers from the cache into external memory. The cache decompresses transfers from external memory and transfers full format data to naive clients that lack decompression capability and directly transfers compressed data to savvy clients that include decompression capability. An improved compression algorithm includes software that computes the difference between the current data word and each of a number of prior data words. Software selects the prior data word with the smallest difference as the nearest match and encodes the bit width of the difference to this data word. Software then encodes the difference between the current stride and the closest previous stride. Software combines the stride, bit width, and difference to yield final encoded data word. Software may encode the stride of one data word as a value relative to the stride of a previous data word."
10338919,"A method, computer readable medium, and processor are disclosed for performing matrix multiply and accumulate (MMA) operations. The processor includes a datapath configured to execute the MMA operation to generate a plurality of elements of a result matrix at an output of the datapath. Each element of the result matrix is generated by calculating at least one dot product of corresponding pairs of vectors associated with matrix operands specified in an instruction for the MMA operation. A dot product operation includes the steps of: generating a plurality of partial products by multiplying each element of a first vector with a corresponding element of a second vector; aligning the plurality of partial products based on the exponents associated with each element of the first vector and each element of the second vector; and accumulating the plurality of aligned partial products into a result queue utilizing at least one adder."
10339850,"A method, computer readable medium, and system generate a low-latency image for display. The method includes the steps of receiving a portion of an image for display, selecting a pulse-width value for displaying the portion of the image, and driving a display device to present the portion of the image using a pulse-width value and pulse density modulation value. Logic circuits for implementing the method may be included in a graphics processing unit or within a display device. The portion of the image for display may be rendered based on real-time position information associated with a head-mounted display."
10346212,"A streaming multiprocessor (SM) in a parallel processing subsystem schedules priority among a plurality of threads. The SM retrieves a priority descriptor associated with a thread group, and determines whether the thread group and a second thread group are both operating in the same phase. If so, then the method determines whether the priority descriptor of the thread group indicates a higher priority than the priority descriptor of the second thread group. If so, the SM skews the thread group relative to the second thread group such that the thread groups operate in different phases, otherwise the SM increases the priority of the thread group. f the thread groups are not operating in the same phase, then the SM increases the priority of the thread group. One advantage of the disclosed techniques is that thread groups execute with increased efficiency, resulting in improved processor performance."
10346507,"Embodiments of the present invention are directed to methods and systems for performing block sparse matrix-vector multiplications with improved efficiency through the use of a specific re-ordering the matrix data such that matrix symmetry can be exploited while simultaneously avoiding atomic memory operations or the need for inefficient memory operations in general. One disclosed method includes reordering the matrix data such that, for any column of non-transpose data, and for any row of transpose data simultaneously processed within a single thread-block on a GPU, all matrix elements update independent elements of the output vector. Using the method, the amount of data required to represent the sparse matrix can be reduced by as much as 50%, thereby doubling the effective performance on the GPU, and doubling the size of the matrix that can be accelerated by the GPU."
10350489,"Aspects of the present invention are directed to techniques for improving the manufacturing control mechanisms—specifically game controllers—for computerized electronic devices. According to one aspect of the present invention, a button assembly is provided that eliminates the need for dampers or gaskets for shock absorption by implementing the hammer and pad using novel and advantageous geometries. According to one embodiment, the bottom or striking surface of the hammer in a button assembly is implemented at an angle, which, when pressed, strikes a similarly angled surface of the landing pad. The slope of the corresponding angles cause the hammer to slide along the angled surface, and for the kinetic force of the impact to be redirected as shearing force away from the button assembly (and the corresponding user appendage)."
10360039,"A mechanism for predicated execution of instructions within a parallel processor executing multiple threads or data lanes is disclosed. Each thread or data lane executing within the parallel processor is associated with a predicate register that stores a set of 1-bit predicates. Each of these predicates can be set using different types of predicate-setting instructions, where each predicate setting instruction specifies one or more source operands, at least one operation to be performed on the source operands, and one or more destination predicates for storing the result of the operation. An instruction can be guarded by a predicate that may influence whether the instruction is executed for a particular thread or data lane or how the instruction is executed for a particular thread or data lane."
10361023,"A magnetic power supply coupling system is disclosed. An integrated circuit module includes an integrated circuit die and a secondary winding that is configured to generate an induced, alternating current based on a magnetic flux. A primary winding is external to the integrated circuit module, proximate to the integrated circuit module, and coupled to a main power supply corresponding to an alternating current that generates the magnetic flux. The induced, alternating current is converted into a direct current at a voltage level to supply power to the integrated circuit die."
10362289,"A method, computer readable medium, and system are disclosed for image processing to reduce aliasing using a temporal anti-aliasing algorithm modified to implement variance clipping. The method includes the step of generating a current frame of image data in a memory. Then, each pixel in the current frame of image data is processed by: sampling a resolved pixel color for a corresponding pixel in a previous frame of image data stored in the memory, adjusting the resolved pixel color based on a statistical distribution of color values for a plurality of samples in the neighborhood of the pixel in the current frame of image data to generate an adjusted pixel color, and blending a color value for the pixel in the current frame of image data with the adjusted pixel color to generate a resolved pixel color for the pixel in the current frame of image data."
10365930,"A technique for managing a parallel cache hierarchy that includes receiving an instruction from a scheduler unit, where the instruction comprises a load instruction or a store instruction; determining that the instruction includes a cache operations modifier that identifies a policy for caching data associated with the instruction at one or more levels of the parallel cache hierarchy; and executing the instruction and caching the data associated with the instruction based on the cache operations modifier."
10369461,"A gaming cloud gaming system and a method of initiating a gaming session. One embodiment of the gaming cloud gaming system includes a computing system having: (1) an entry point operable to receive a game session request and generate instructions for establishing a connection between a client and a game server, and (2) a dynamically configurable reverse proxy operable to proxy for the game server and configured to employ the instructions to create a route to a randomly selected port on the game server through which the connection is makeable."
10373332,"A method, computer readable medium, and system are disclosed for dynamic facial analysis. The method includes the steps of receiving video data representing a sequence of image frames including at least one head and extracting, by a neural network, spatial features comprising pitch, yaw, and roll angles of the at least one head from the video data. The method also includes the step of processing, by a recurrent neural network, the spatial features for two or more image frames in the sequence of image frames to produce head pose estimates for the at least one head."
10386916,"One embodiment provides a method for reducing leakage current in device logic having an operational supply-voltage threshold, a nonzero data-retention supply voltage threshold, and two or more on-die transistor switches to switchably connect a voltage source to the device logic. After the logic enters an idle period, one or more of the switches are opened to lower a supply voltage of the logic below the operational supply-voltage threshold but above the data-retention supply-voltage threshold. When the logic exits the idle period, one or more of the switches are closed to raise the supply voltage of the logic above the operational supply-voltage threshold."
10387653,"One embodiment of the present invention includes a boot read only memory (ROM) with an embedded, private key provision key (KPK) set that enables secure provisioning of chips. As part of taping-out a chip, the chip provider establishes the KPK set and provides the boot ROM exclusive access to the KPK. For each Original Equipment Manufacturer (OEM), the chip provider assigns and discloses an OEM-specific KPK that is included in the KPK set at a particular KPK index. Upon receiving a secured provisioning image and the associated KPK index, the boot ROM accesses the KPK set to reconstruct the KPK and then decrypts and executes the secured provisioning image. Advantageously, this enables the manufacturing factory to provision the chip without the security risks attributable to conventional provisioning approaches that require disclosing security keys to the manufacturing factory."
10388059,"A method, computer readable medium, and system are disclosed for performing stable ray tracing. The method includes the steps of identifying a plurality of old hit points used in a previously rendered frame, re-projecting the plurality of old hit points within a current frame to create a plurality of samples within a screen space of the current frame, adjusting the plurality of samples within the screen space of the current frame, based on one or more criteria, for each of the plurality of samples, tracing a ray from the sample toward a corresponding old hit point for the sample to determine a current hit point corresponding to the sample for the current frame, where the current hit point may include the corresponding old hit point for the sample or an updated hit point for the sample, shading at least a portion of the plurality of current hit points to obtain a color for each of the plurality of samples within the screen space of the current frame, and reconstructing a final color for a plurality of pixels in the screen space of the current frame, utilizing the color for each of the plurality of samples within the screen space of the current frame."
10395432,"In embodiments of the invention, a method may include displaying an array of slits using a first light-attenuating spatial light modulator, displaying a pre-filtered image using a second light-attenuating SLM by attenuating rays of light originating from a surrounding environment to synthesis a near-eye light field, where the rays of light pass through the first and second light-attenuating SLMs, and selectively blocking the rays of light originating from the surrounding environment using the array of slits to generate a virtual image in said near-eye light field."
10395624,"A method, computer readable medium, and system are disclosed for adjusting an angular sampling rate during rendering. The method includes the steps of determining a location of a gaze within a displayed scene, and adjusting, during a rendering of the scene, an angular sampling rate used to render at least a portion of the scene, based on the location of the gaze within the displayed scene."
10401623,"A display method and system are disclosed for virtual/augmented reality. The method includes the steps of generating an image by a projection engine and projecting light rays defining the image onto a diffuser holographic optical element (DHOE) located between an observer and a concave mirror element, where a concave surface of the concave mirror element faces the observer. The light rays are projected onto the DHOE at a reference angle that causes the light rays to be diffused to the concave surface of the concave mirror element and the diffused light rays are reflected back to the observer such that the observer perceives a virtual image that appears to the observer at a position behind the concave mirror element and further from the observer than the concave mirror element."
10402323,"In one embodiment of the present invention a cache unit organizes data stored in an attached memory to optimize accesses to compressed data. In operation, the cache unit introduces a layer of indirection between a physical address associated with a memory access request and groups of blocks in the attached memory. The layer of indirection—virtual tiles—enables the cache unit to selectively store compressed data that would conventionally be stored in separate physical tiles included in a group of blocks in a single physical tile. Because the cache unit stores compressed data associated with multiple physical tiles in a single physical tile and, more specifically, in adjacent locations within the single physical tile, the cache unit coalesces the compressed data into contiguous blocks. Subsequently, upon performing a read operation, the cache unit may retrieve the compressed data conventionally associated with separate physical tiles in a single read operation."
10402697,"A method, computer readable medium, and system are disclosed for classifying video image data. The method includes the steps of processing training video image data by at least a first layer of a convolutional neural network (CNN) to extract a first set of feature maps and generate classification output data for the training video image data. Spatial classification accuracy data is computed based on the classification output data and target classification output data and spatial discrimination factors for the first layer are computed based on the spatial classification accuracies and the first set of feature maps."
10402937,"A method for rendering graphics frames allocates rendering work to multiple graphics processing units (GPUs) that are configured to allow access to pages of data stored in locally attached memory of a peer GPU. The method includes the steps of generating, by a first GPU coupled to a first memory circuit, one or more first memory access requests to render a first primitive for a first frame, where at least one of the first memory access requests targets a first page of data that physically resides within a second memory circuit coupled to a second GPU. The first GPU requests the first page of data through a first data link coupling the first GPU to the second GPU and a register circuit within the first GPU accumulates an access request count for the first page of data. The first GPU notifies a driver that the access request count has reached a specified threshold."
10404505,A system comprising a PAM-4 transmitter coupled data lanes includes a least significant bit section and a most significant bit section for the symbols generated on each lane. A controller to determine a state of the PAM-4 transmitter and selectively inverts a polarity of the symbol bits on the lanes based on the state.
10409730,"One embodiment of the present invention includes a microcontroller coupled to a memory management unit (MMU). The MMU is coupled to a page table included in a physical memory, and the microcontroller is configured to perform one or more virtual memory operations associated with the physical memory and the page table. In operation, the microcontroller receives a page fault generated by the MMU in response to an invalid memory access via a virtual memory address. To remedy such a page fault, the microcontroller performs actions to map the virtual memory address to an appropriate location in the physical memory. By contrast, in prior-art systems, a fault handler would typically remedy the page fault. Advantageously, because the microcontroller executes these tasks locally with respect to the MMU and the physical memory, latency associated with remedying page faults may be decreased. Consequently, overall system performance may be increased."
10410431,"Embodiments of the present invention provide a method for simulating deformable solids undergoing large plastic deformation and topological changes using shape matching. Positional information for particles and orientation information from clusters is used to simulate deformable solids represented by particles. Each visual vertex stores references to particles that influence the vertex, and stores the local position of the particles. A two-step method interpolates orientation from clusters to particles, and uses the orientation and position of particles to skin the visual mesh vertices. This results in a fast method that can reproduce rotation and does not require the visual mesh vertex to be located within a convex hull of particles."
10412361,"The disclosure is directed to a method to generate a generated stereoscopic video image stream of a zenith or nadir view perspective of a scene utilizing a blending of stereoscopic and monoscopic view perspectives. In another aspect, a system is disclosed for generating a zenith or nadir view perspective utilizing a relative user view orientation. In another aspect, an apparatus is disclosed capable to generate a zenith or nadir view perspective utilizing a detected user view orientation, and display a generated stereoscopic video image stream of the view perspective."
10412529,"A virtual reality (VR) audio rendering system and method using pre-computed impulse responses (IRs) to generate audio frames in a VR setting for rendering. Based on a current position of a user or a VR object, a set of possible motions are predicted and a set of IRs are pre-computed by using a Geometric Acoustic (GA) model of a virtual scene. Once a position change is actually detected, one of the pre-computed IRs is selected and convolved with a set of audio frames to generate modified audio frames for rendering. As the modified audio frames are generated by using pre-computed IR without requiring intensive ray tracing computations, the audio latency can be significantly reduced."
10417813,"A method for generating temporally stable hash values reduces visual artifacts associated with stochastic sampling of data for graphics applications. A given hash value can be generated from a scaled and discretized object-space for a geometric object within a scene. Through appropriate scaling, the hash value can be discretized and remain constant within a threshold distance from a pixel center. As the geometric object moves within the scene, a hash value associated with a given feature of the geometric object remains constant because the hash value is generated using an object-space coordinate anchored to the feature. In one embodiment, alpha testing threshold values are assigned random, but temporally stable hash output values generated using object-space coordinate positions for primitive fragments undergoing alpha testing. Alpha tested fragments are temporally stable, beneficially improving image quality."
10417817,"A method, computer readable medium, and system are disclosed for supersampling a large-scale and disjoined data set. The data set may include point cloud, voxel, or polygonal mesh data. The data set may be rendered using a distributed, sort-last rendering system that includes a plurality of rendering nodes and one or more compositing nodes. The method includes the steps of receiving graphics data at a plurality of rendering nodes, rendering at least a portion of the graphics data by one or more rendering nodes to produce multi-sample image data, encoding the multi-sample image data using a difference encoding technique, and transmitting the encoded multi-sample image data to a compositing node. The multi-sample image data comprises a plurality of values per pixel of a target image corresponding to a plurality of sample locations defined for each pixel of the target image."
10417989,"Disclosed herein is a GPU for improved multitasking by a user, a GPU computing system including the GPU and a method of manufacturing a GPU system. In one embodiment, the GPU includes: (1) a video overlayer configured to create an operating area over a portion of a video image generated by the graphical processing unit and (2) an overlay interface configured to provide a virtual space input to the video overlayer to operate a virtual machine within the operating area."
10417990,"A method of binding graphics resources is provided that includes: (1) identifying graphics resources for binding, (2) generating a bind group for the graphics resources, (3) organizing the bind group into a bind group memory using a bind group layout and (4) providing bind group control for processing of the bind group. A method of organizing graphics resources and a resource organizing unit are also provided."
10423424,"Techniques are disclosed for performing an auxiliary operation via a compute engine associated with a host computing device. The method includes determining that the auxiliary operation is directed to the compute engine, and determining that the auxiliary operation is associated with a first context comprising a first set of state parameters. The method further includes determining a first subset of state parameters related to the auxiliary operation based on the first set of state parameters. The method further includes transmitting the first subset of state parameters to the compute engine, and transmitting the auxiliary operation to the compute engine. One advantage of the disclosed technique is that surface area and power consumption are reduced within the processor by utilizing copy engines that have no context switching capability."
10424069,"A method, computer readable medium, and system are disclosed for estimating optical flow between two images. A first pyramidal set of features is generated for a first image and a partial cost volume for a level of the first pyramidal set of features is computed, by a neural network, using features at the level of the first pyramidal set of features and warped features extracted from a second image, where the partial cost volume is computed across a limited range of pixels that is less than a full resolution of the first image, in pixels, at the level. The neural network processes the features and the partial cost volume to produce a refined optical flow estimate for the first image and the second image."
10424074,"Methods and apparatuses are disclosed for reporting texture footprint information. A texture footprint identifies the portion of a texture that will be utilized in rendering a pixel in a scene. The disclosed methods and apparatuses advantageously improve system efficiency in decoupled shading systems by first identifying which texels in a given texture map are needed for subsequently rendering a scene. Therefore, the number of texels that are generated and stored may be reduced to include the identified texels. Texels that are not identified need not be rendered and/or stored."
10430356,"Embodiments of the present invention set forth techniques for resolving page faults associated with a copy engine. A copy engine within a parallel processor receives a copy operation that includes a set of copy commands. The copy engine executes a first copy command included in the set of copy commands that results in a page fault. The copy engine stores the set of copy commands to the memory. At least one advantage of the disclosed techniques is that the copy engine can perform copy operations that involve source and destination memory pages that are not pinned, leading to reduced memory demand and greater flexibility."
10430915,One or more copy commands are scheduled for locating one or more pages of data in a local memory of a graphics processing unit (GPU) for more efficient access to the pages of data during rendering. A first processing unit that is coupled to a first GPU receives a notification that an access request count has reached a specified threshold. The first processing unit schedules a copy command to copy the first page of data to a first memory circuit of the first GPU from a second memory circuit of the second GPU. The copy command is included within a GPU command stream.
10430989,"A multi-pass unit interoperates with a device driver to configure a screen space pipeline to perform multiple processing passes with buffered graphics primitives. The multi-pass unit receives primitive data and state bundles from the device driver. The primitive data includes a graphics primitive and a primitive mask. The primitive mask indicates the specific passes when the graphics primitive should be processed. The state bundles include one or more state settings and a state mask. The state mask indicates the specific passes where the state settings should be applied. The primitives and state settings are interleaved. For a given pass, the multi-pass unit extracts the interleaved state settings for that pass and configures the screen space pipeline according to those state settings. The multi-pass unit also extracts the interleaved graphics primitives to be processed in that pass. Then, the multi-pass unit causes the screen space pipeline to process those graphics primitives."
10432954,"The present disclosure discloses a video encoder, a video encoding system and a video encoding method. The video encoder comprises a logic control module and an encoding module. Wherein, the logic control module is configured to receive a control command sent from an external controller for encoding a specified portion of each frame of image, and send the control command to the encoding module; and the encoding module is configured to receive the control command from the logic control module, and encode the specified portion of each frame of image according to the control command, so as to cooperate with a plurality of other video encoders to complete encoding each frame of image. By employing the video encoder, video encoding system and video encoding method according to the present disclosure, each frame of image can be accomplished jointly by a plurality of video encoders, thus significantly reducing the encoding time, diminishing the encoding latency, and achieving real-time encoding of high-definition video sources, in particular, video sources with a resolution ratio of 4 k or above."
10436840,"A distributed test circuit includes partitions arranged in series to form a scan path, each partition including a scan multiplexer, a test data register, and a segment insertion bit component. The scan multiplexer of each partition provides inputs to the corresponding test data register of the each partition. Broadcast control logic generates a select signal to the scan multiplexer of each partition to place the test circuit in a broadcast mode when the select signal is asserted, and to switch the test circuit to a daisy mode when select signal is de-asserted. The segment insertion bit is operable to include or bypass each partition from the scan path."
10437593,"A synchronization instruction causes a processor to ensure that specified threads included within a warp concurrently execute a single subsequent instruction. The specified threads include at least a first thread and a second thread. In operation, the first thread arrives at the synchronization instruction. The processor determines that the second thread has not yet arrived at the synchronization instruction and configures the first thread to stop executing instructions. After issuing at least one instruction for the second thread, the processor determines that all the specified threads have arrived at the synchronization instruction. The processor then causes all the specified threads to execute the subsequent instruction. Advantageously, unlike conventional approaches to synchronizing threads, the synchronization instruction enables the processor to reliably and properly execute code that includes complex control flows and/or instructions that presuppose that threads are converged."
10438314,"One embodiment of the present invention sets forth a graphics processing system. The graphics processing system includes a screen-space pipeline and a tiling unit. The screen-space pipeline is configured to perform visibility testing and fragment shading. The tiling unit is configured to determine that a first set of primitives overlaps a first cache tile. The tiling unit is also configured to first transmit the first set of primitives to the screen-space pipeline with a command configured to cause the screen-space pipeline to process the first set of primitives in a z-only mode, and then transmit the first set of primitives to the screen-space pipeline with a command configured to cause the screen-space pipeline to process the first set of primitives in a normal mode. In the z-only mode, at least some fragment shading operations are disabled in the screen-space pipeline. In the normal mode, fragment shading operations are enabled."
10438400,"A method, computer readable medium, and system are disclosed for rendering images utilizing a foveated rendering algorithm with post-process filtering to enhance a contrast of the foveated image. The method includes the step of receiving a three-dimensional scene, rendering the 3D scene according to a foveated rendering algorithm to generate a foveated image, and filtering the foveated image using a contrast-enhancing filter to generate a filtered foveated image. The foveated rendering algorithm may incorporate aspects of coarse pixel shading, mipmapped texture maps, linear efficient anti-aliased normal maps, exponential variance shadow maps, and specular anti-aliasing techniques. The foveated rendering algorithm may also be combined with temporal anti-aliasing techniques to further reduce artifacts in the foveated image."
10444280,"Granular dynamic test systems and methods facilitate efficient and effective timing of test operations. In one embodiment, a chip test system comprises: a first test partition operable to perform test operations based upon a first local test clock signal; a second test partition operable to perform test operations based upon a second local test clock signal; and a centralized controller configured to coordinate testing between the plurality of test partitions, wherein the coordination includes managing communication of test information between the plurality of test partitions and external pins. In one exemplary implementation, a trigger edge of the first local test clock signal is staggered with respect to a trigger edge of the second local test clock signal, wherein the stagger is coordinated to mitigate power consumption by test operations in the first test partition and test operations in the second test partition."
10445177,"A method for updating a DRAM memory array is disclosed. The method comprises: a) transitioning the DRAM memory array from an idle state to a refresh state in accordance with a command from a memory controller; b) initiating a refresh on the DRAM memory array using DRAM internal control circuitry by activating a row of data into an associated sense amplifier buffer; and c) during the refresh, performing an ERR Correction Code (ECC) scrub operation of selected bits in the activated row of the DRAM memory array."
10445243,A system for managing virtual memory. The system includes a first processing unit configured to execute a first operation that references a first virtual memory address. The system also includes a first memory management unit (MMU) associated with the first processing unit and configured to generate a first page fault upon determining that a first page table that is stored in a first memory unit associated with the first processing unit does not include a mapping corresponding to the first virtual memory address. The system further includes a first copy engine associated with the first processing unit. The first copy engine is configured to read a first command queue to determine a first mapping that corresponds to the first virtual memory address and is included in a first page state directory. The first copy engine is also configured to update the first page table to include the first mapping.
10451676,"A method for testing. An external clock frequency is generated. Test data is supplied over a plurality of SSI connections clocked at the external clock frequency, wherein the test data is designed for testing a logic block. A DSTA module is configured for the logic block that is integrated within a chip to a bandwidth ratio, wherein the bandwidth ratio defines the plurality of SSI connections and a plurality of PSI connections of the chip. The external clock frequency is divided down using the bandwidth ratio to generate an internal clock frequency, wherein the bandwidth ratio defines the external clock frequency and the internal clock frequency. The test data is scanned over the plurality of PSI connections clocked at the internal clock frequency according to the bandwidth ratio, wherein the plurality of PSI connections is configured for inputting the test data to the plurality of scan chains."
10452566,"One embodiment of the present invention includes a memory management unit (MMU) that is configured to efficiently process requests to access memory that includes protected regions. Upon receiving an initial request via a virtual address (VA), the MMU translates the VA to a physical address (PA) based on page table entries (PTEs) and gates the response based on page-specific secure state information. To thwart software-based attempts to illicitly access the protected regions, the secure state information is not stored in page tables. However, to expedite subsequent requests, after the MMU identifies the PTE and the corresponding secure state information, the MMU stores both the PTE and the secure state information as a cache line in a translation lookaside buffer. Advantageously, the disclosed embodiments protect data in the protected regions from security risks associated with software-based protection schemes without incurring the performance degradation associated with hardware-based “carve-out” memory protection schemes."
10453168,"A tile coalescer within a graphics processing pipeline coalesces coverage data into tiles. The coverage data indicates, for a set of XY positions, whether a graphics primitive covers those XY positions. The tile indicates, for a larger set of XY positions, whether one or more graphics primitives cover those XY positions. The tile coalescer includes coverage data in the tile only once for each XY position, thereby allowing the API ordering of the graphics primitives covering each XY position to be preserved. The tile is then distributed to a set of streaming multiprocessors for shading and blending operations. The different streaming multiprocessors execute thread groups to process the tile. In doing so, those thread groups may perform read-modify-write operations with data stored in memory. Each such thread group is scheduled to execute via atomic operations, and according to the API order of the associated graphics primitives."
10459861,"A unified cache subsystem includes a data memory configured as both a shared memory and a local cache memory. The unified cache subsystem processes different types of memory transactions using different data pathways. To process memory transactions that target shared memory, the unified cache subsystem includes a direct pathway to the data memory. To process memory transactions that do not target shared memory, the unified cache subsystem includes a tag processing pipeline configured to identify cache hits and cache misses. When the tag processing pipeline identifies a cache hit for a given memory transaction, the transaction is rerouted to the direct pathway to data memory. When the tag processing pipeline identifies a cache miss for a given memory transaction, the transaction is pushed into a first-in first-out (FIFO) until miss data is returned from external memory. The tag processing pipeline is also configured to process texture-oriented memory transactions."
10459873,"The invention provides a method for adaptively adjusting a framerate of a graphic processing unit (GPU). For example, when the GPU workload is high and the temperature of the GPU is close to high temperature, the framerate can be decreased to reduce the workload; when the GPU workload is low, the framerate can be permitted to increase to raise the workload. By the present invention, the GPU is permitted to operate at maximum temperature. The method comprises the steps of: (a) receiving an execution parameter associated with at least one GPU; (b) comparing if the execution parameter is greater than a first reference value; and (c) in the event the execution parameter is greater than the first reference value, increasing a sleep time and power-gating the at least one GPU based on the sleep time to adjust the framerate."
10460504,"A method, computer readable medium, and system are disclosed for performing a texture level-of-detail approximation. The method includes the steps of identifying a scene to be rendered, projecting a ray passing through a pixel of a screen space, resulting in a first hit point at a geometry element within the scene, determining a footprint angle of the pixel, determining a curvature measure for the geometry element at the first hit point within the scene, computing a texture level of detail (LOD) approximation for a component of the scene, utilizing the footprint angle of the pixel and the curvature measure for the geometry element, and performing, utilizing a hardware processor, one or more rendering operations for the scene, utilizing the texture LOD approximation."
10466763,"A clocked electronic device includes first and second control systems. The first control system is configured to decrease clock frequency in the device in response to decreasing supply voltage. The second control system is responsive to clock lag in the device and to an amount of current drawn through the device. It is configured to increase the supply voltage in response to increasing clock lag, but to decrease the supply voltage when the current drawn through the device exceeds an operational threshold."
10466968,"A system including a series of partial product select encoders and partial product muxes, each of the partial product select encoders receiving a multiplier, receiving a carry input from a multiplier tree, and outputting a select signal to an associated partial product mux based on the multiplier and carry input, and each of the partial product muxes outputting a partial product based on the select signal and a multiplicand received."
10467763,"A method, computer readable medium, and system are disclosed for estimating optical flow between two images. A first pyramidal set of features is generated for a first image and a partial cost volume for a level of the first pyramidal set of features is computed, by a neural network, using features at the level of the first pyramidal set of features and warped features extracted from a second image, where the partial cost volume is computed across a limited range of pixels that is less than a full resolution of the first image, in pixels, at the level. The neural network processes the features and the partial cost volume to produce a refined optical flow estimate for the first image and the second image."
10468093,"A method and system for a DRAM having a first bank that includes a first sub-array (SA) and a second SA. The first SA includes a first storage unit coupled to a first row-buffer in a first sub-channel (FSC) and a second storage unit in a second sub-channel (SSC). The second SA includes a third storage unit and a fourth storage unit coupled to a second row-buffer. The first SA is associated with a first row address (RA) and the FSC is associated with a first column address (CA) stored in the FSC. The second SA is associated with a second RA and the SSC is associated with a second CA stored in the SSC. The first and second CAs are used to select portions of data from the first and second row-buffers, respectively, for output to a data bus."
10473720,"In one embodiment, a test system comprises: a plurality of test partitions and a centralized controller configured to coordinate testing between the plurality of test partitions. At least one of the plurality of test partitions comprises: a partition test interface controller configured to control testing within at least one test partition in accordance with dynamic selection of a test mode, and at least one test chain configured to perform test operations. The dynamic selection of the test mode and control of testing within a test partition can be independent of selection of a test mode and control in others of the plurality of test partitions. In one embodiment, a free running clock signal is coupled to a test partition, and the partition test mode controller transforms the free running clock signal into a local partition test clock which is controlled in accordance with the dynamic selection of the test mode."
10476537,"A single-ended signal transmission system recovers a noise signal associated with a data input signal and uses the recovered noise signal to compensate for noise on the data input signal. The noise signal may be recovered from a noise reference signal line, or clock signal line, or a data signal line associated with a DC-balanced data input signal. The recovered noise signal may be represented as an analog signal or a digital signal. The recovered noise signal may be processed to compensate for DC offset and nonlinearities associated with one or more different input buffers. In one embodiment, the recovered noise signal includes frequency content substantially below a fundamental frequency for data transmission through the data input signal."
10481203,"In one embodiment, a system comprises: a global clock input for receiving a global clock, a plurality of partitions; and a skew tolerant interface configured to compensate for clock skew differences between a global clock from outside at least one of the partitions and a balanced local clock within at least one of the partitions. The partitions can be test partitions. The skew tolerant interface can cross a mesochronous boundary. In one exemplary implementation, the skew tolerant interface includes a deskew ring buffer on communication path of the at least one partition. pointers associated with the ring buffer can be free-running and depend only on clocks being pulsed when out of reset. The scheme can be fully synchronous and deterministic. The scheme can be modeled for the ATPG tools using simple pipeline flops. The depth of the pipeline can be dependent on the pointer difference for the read/write interface. The global clock input can be part of a scan link."
10481684,"A method, computer readable medium, and system are disclosed for generating foveal images. The method includes the steps of redirecting first light rays towards an eye, where the first light rays are redirected by an optical combiner and produce a peripheral image and generating second light rays by a light engine. The second light rays are redirected towards the eye, where the second light rays intersect a first region of the optical combiner and converge at a nodal point within the eye and produce an inset foveal image positioned within at least a portion of the peripheral image. An origin of the second light rays is offset to intersect a second region of the optical combiner in response to a change in a gaze direction of the eye."
10481696,"An apparatus and method for radar based gesture detection. The apparatus includes a processing element and a transmitter configured to transmit radar signals. The transmitter is coupled to the processing element. The apparatus further includes a plurality of receivers configured to receive radar signal reflections, where the plurality of receivers is coupled to the processing element. The transmitter and plurality of receivers are configured for short range radar and the processing element is configured to detect a hand gesture based on the radar signal reflections received by the plurality of receivers."
10482196,"A method, computer readable medium, and system are disclosed for generating a Gaussian mixture model hierarchy. The method includes the steps of receiving point cloud data defining a plurality of points; defining a Gaussian Mixture Model (GMM) hierarchy that includes a number of mixels, each mixel encoding parameters for a probabilistic occupancy map; and adjusting the parameters for one or more probabilistic occupancy maps based on the point cloud data utilizing a number of iterations of an Expectation-Maximum (EM) algorithm."
10484459,"A computer streaming system includes an application hints unit that provides an advisory hint for a remote user device corresponding to a selected streaming application, and a sending unit that manages streaming of the advisory hint and the selected streaming application over a network connected to the remote user device. Additionally, the computer streaming system includes a receiving unit that recovers the advisory hint for the remote user device, and a hints processing unit that applies the advisory hint to the remote user device when employing the selected computer application. Also, the computer streaming system includes a feedback unit that provides remote user feedback information over the network directed to responding to the advisory hint, and an update unit that provides the remote user feedback information. Also provided is a method of streaming a computer application."
10489056,"A queue manager apparatus converts inbound commands of a first width into scalar format commands to be queued in a command queue. Furthermore, the queue manager converts the scalar format commands residing in the command queue into outbound commands of a second width for transmission. Converting inbound commands to scalar format commands and then converting the scalar format commands to a target width for transmission allows the queue manager to advantageously provide efficient and programmable command transmission between arbitrary processing units, regardless of potentially mismatched native command widths."
10489200,"One embodiment of the present invention is a computer-implemented method for scheduling a thread group for execution on a processing engine that includes identifying a first thread group included in a first set of thread groups that can be issued for execution on the processing engine, where the first thread group includes one or more threads. The method also includes transferring the first thread group from the first set of thread groups to a second set of thread groups, allocating hardware resources to the first thread group, and selecting the first thread group from the second set of thread groups for execution on the processing engine. One advantage of the disclosed technique is that a scheduler only allocates limited hardware resources to thread groups that are, in fact, ready to be issued for execution, thereby conserving those resources in a manner that is generally more efficient than conventional techniques."
10489521,"A simulation engine performs a mass-conserving Eulerian fluid simulation by manipulating the distribution of density between nodes associated with the fluid simulation. The simulation engine traces a velocity field upstream to identify the source of mass that currently resides at a given node. The simulation engine then adjusts (i) the density contributions to that source from adjacent nodes and (ii) the density contributions provided by that source to the given node. In doing so, the simulation engine maintains conservation of mass at a local level between nodes within a given neighborhood. As a result, mass is conserved at a global level. One advantage of the disclosed technique is that a fluid interface associated with the fluid simulation may appear physically realistic, because numerical errors typically caused by violations of conservation of mass may be eliminated."
10489542,"A neural network including an embedding layer to receive a gate function vector and an embedding width and alter a shape of the gate function vector by the embedding width, a concatenator to receive a gate feature input vector and concatenate the gate feature input vector with the gate function vector altered by the embedding width, a convolution layer to receive a window size, stride, and output feature size and generate an output convolution vector with a shape based on a length of the gate function vector, the window size of the convolution layer, and the output feature size of the convolution layer, and a fully connected layer to reduce the gate output convolution vector to a final path delay output."
10489875,"One embodiment of the present invention includes a method for tracking which cache tiles included in a plurality of cache tiles are intersected by a plurality of bounding boxes. The method includes receiving the plurality of bounding boxes, wherein each bounding box is associated with one or more graphics primitives being rendered to a render surface, and wherein the render surface is divided into the plurality of cache tiles. The method further includes, for each bounding box included in the plurality of bounding boxes, determining one or more cache tiles included in the plurality of cache tiles that are intersected by the bounding box, and storing a result in an array for each cache tile that is intersected by the bounding box. Finally, the method includes determining not to process a cache tile included in the plurality of cache tiles based on the results stored in the array."
10491238,"A PAM-4 communication process divides a full burst of raw data into two half bursts, extracts a bit from each half burst and communicating the extracted bit on a DBI line, and encodes the remaining bits of the half burst to avoid maximum transitions between PAM-4 symbols on a data line."
10491435,"Methods of operating a serial data bus divide series of data bits into sequences of one or more bits and encode the sequences as N-level symbols, which are then transmitted at multiple discrete voltage levels. These methods may be utilized to communicate over serial data lines to improve bandwidth and reduce crosstalk and other sources of noise."
10497168,"The disclosure provides a virtual view broadcaster, a virtual view broadcasting system, and a video gaming broadcaster. In one embodiment, the virtual view broadcaster includes: (1) a cloud-based renderer configured to generate virtual view images from a virtual camera positioned in a computer application, and (2) an image processor configured to generate a virtual view stream for the virtual camera employing the virtual view rendered images, wherein the virtual view images are from different viewing directions at the virtual camera."
10503456,"Techniques for rendering images on multiple tilted displays concurrently to mitigate perspective distortion are disclosed herein. According to one described approach, viewports are assigned to a center monitor and two peripheral monitors. Scene data for the viewports is calculated, and geometric primitives are generated for the viewports based on the scene data. Image transformation is performed based on a modified perspective value to modify geometry of the geometric primitives based on tilt angles of the displays, and the geometric primitives are rasterized using the modified geometry."
10503457,"Techniques for rendering images on multiple tilted displays concurrently to mitigate perspective distortion are disclosed herein. According to one described approach, viewports are assigned to a center monitor and two peripheral monitors. Scene data for the viewports is calculated, and geometric primitives are generated for the viewports based on the scene data. Image transformation is performed based on a modified perspective value to modify geometry of the geometric primitives based on tilt angles of the displays, and the geometric primitives are rasterized using the modified geometry."
10503507,"A method, computer readable medium, and system are disclosed for inline data inspection. The method includes the steps of receiving, by a load/store unit, a load instruction and obtaining, by an inspection circuit that is coupled to the load/store unit, data specified by the load instruction. Additional steps include determining that the data equals zero and transmitting the data and a predicate signal to the load/store unit, wherein the predicate signal indicates that the data equals zero. Alternative additional steps include computing a predicate value based on a comparison between the data and a threshold value and transmitting the data and the predicate value to the load/store unit, wherein the predicate value is asserted when the data is less than the threshold value and is negated when the data is not less than the threshold value."
10503513,"A subsystem is configured to support a distributed instruction set architecture with primary and secondary execution pipelines. The primary execution pipeline supports the execution of a subset of instructions in the distributed instruction set architecture that are issued frequently. The secondary execution pipeline supports the execution of another subset of instructions in the distributed instruction set architecture that are issued less frequently. Both execution pipelines also support the execution of FFMA instructions as well as a common subset of instructions in the distributed instruction set architecture. When dispatching a requested instruction, an instruction scheduling unit is configured to select between the two execution pipelines based on various criteria. Those criteria may include power efficiency with which the instruction can be executed and availability of execution units to support execution of the instruction."
10504273,"A method, computer readable medium, and system are disclosed for implementing automatic level-of-detail for physically-based materials. The method includes the steps of identifying a declarative representation of a material to be rendered, creating a reduced complexity declarative representation of the material by applying one or more term rewriting rules to the declarative representation of the material, and returning the reduced complexity declarative representation of the material."
10505451,A system and method are provided for controlling a modified buck converter circuit. A pull-up switching mechanism that is coupled to an upstream terminal of an inductor within a modified buck converter circuit is enabled. A load current at the output of the modified buck regulator circuit is measured. A capacitor current associated with a capacitor that is coupled to a downstream terminal of the inductor is continuously sensed and the pull-up switching mechanism is disabled when the capacitor current is greater than a sum of the load current and an enabling current value.
10509447,"The invention is directed to a novel solution for improving heat management in computing devices by using thermally active material integrated within a shield can disposed over an integrated circuit or printed circuit board. By integrating the thermally active material within the shield can, isothermal conditions can be maintained for a longer period of time, thereby extending the transient state of a heat-producing system for longer durations, while maintaining slim vertical profiles."
10509479,"An apparatus and method for gesture detection and recognition. The apparatus includes a processing element, a radar sensor, a depth sensor, and an optical sensor. The radar sensor, the depth sensor, and the optical sensor are coupled to the processing element, and the radar sensor, the depth sensor, and the optical sensor are configured for short range gesture detection and recognition. The processing element is further configured to detect and recognize a hand gesture based on data acquired with the radar sensor, the depth sensor, and the optical sensor."
10509658,"A system, method, and computer program product are provided for simultaneously determining settings for a plurality of parameter variations. In use, a plurality of parameter variations associated with a device is identified. Additionally, settings for each of the plurality of parameter variations are determined simultaneously."
10515011,"One embodiment of the present invention sets forth a technique for increasing available storage space within compressed blocks of memory attached to data processing chips, without requiring a proportional increase in on-chip compression status bits. A compression status bit cache provides on-chip availability of compression status bits used to determine how many bits are needed to access a potentially compressed block of memory. A backing store residing in a reserved region of attached memory provides storage for a complete set of compression status bits used to represent compression status of an arbitrarily large number of blocks residing in attached memory. Physical address remapping (“swizzling”) used to distribute memory access patterns over a plurality of physical memory devices is partially replicated by the compression status bit cache to efficiently integrate allocation and access of the backing store data with other user data."
10528423,"The present invention facilitates efficient and effective utilization of storage management features. In one embodiment, a memory device comprises a memory interface, an ECC generation component, and storage components. The memory interface is configured to receive an access request to an address at which data is stored. The memory interface can also forward responses to the request including the data and ECC information associated with the data. The ECC generation component is configured to automatically establish an address at which the ECC information is stored based upon the receipt of the access request to an address at which data is stored. In one exemplary implementation, the internal establishment of the address at which the ECC information is stored is automatic. The storage components are configured to store the information."
10528864,"A method, computer program product, and system perform computations using a sparse convolutional neural network accelerator. A first vector comprising only non-zero weight values and first associated positions of the non-zero weight values within a 3D space is received. A second vector comprising only non-zero input activation values and second associated positions of the non-zero input activation values within a 2D space is received. The non-zero weight values are multiplied with the non-zero input activation values, within a multiplier array, to produce a third vector of products. The first associated positions are combined with the second associated positions to produce a fourth vector of positions, where each position in the fourth vector is associated with a respective product in the third vector. The products in the third vector are transmitted to adders in an accumulator array, based on the position associated with each one of the products."
10535114,"In one embodiment of the present invention a driver configures a graphics pipeline implemented in a cache tiling architecture to perform dynamically-defined multi-pass rendering sequences. In operation, based on sequence-specific configuration data, the driver determines an optimized tile size and, for each pixel in each pass, the set of pixels in each previous pass that influence the processing of the pixel. The driver then configures the graphics pipeline to perform per-tile rendering operations in a region that is translated by a pass-specific offset backward—vertically and/or horizontally—along a tiled caching traversal line. Notably, the offset ensures that the required pixel data from previous passes is available. The driver further configures the graphics pipeline to store the rendered data in cache lines. Advantageously, the disclosed approach exploits the efficiencies inherent in cache tiling architecture while honoring highly configurable data dependencies between passes in multi-pass rendering sequences."
10536709,"In one embodiment, a method of prioritized compression for 3D video wireless display, the method comprising: inputting video data; abstracting scene depth of the video data; estimating foreground and background for each image of the video data; performing different kinds of compressions to the foreground and background in each image; and outputting the processed video data. Thus, the image quality is not affected by the data loss during the wireless transmission."
10545189,"In one embodiments, a system comprises: a plurality of scan test chains configured to perform test operations at a first clock speed; a central test controller for controlling testing by the scan test chains; and an interface configured to generate instructions to direct central test controller. The interface communicates with the centralized test controller at the first clock speed and an external scan input at a second clock speed. The second clock speed can be faster than the first clock speed. The instructions communicated to the central controller can be directions associated with sequential scan compression/decompression operations. In one exemplary implementation, the interface further comprise a mode state machine used to generate the mode control instructions and a test register state machine that generate test state control instructions, wherein the test mode control instructions and the test state control instructions direct operations of the centralized test controller."
10546361,"The present invention facilitates efficient and effective utilization of unified virtual addresses across multiple components. In one exemplary implementation, an address allocation process comprises: establishing space for managed pointers across a plurality of memories, including allocating one of the managed pointers with a first portion of memory associated with a first one of a plurality of processors; and performing a process of automatically managing accesses to the managed pointers across the plurality of processors and corresponding memories. The automated management can include ensuring consistent information associated with the managed pointers is copied from the first portion of memory to a second portion of memory associated with a second one of the plurality of processors based upon initiation of an accesses to the managed pointers from the second one of the plurality of processors."
10547713,A system and method for transmitting state based input over a network are presented. Embodiments of the present invention are operable to generate vector data comprising a composite of all state data associated with the state of all user input claims of a client system and transmit the vector data from the client device to a host device over a network. Embodiments of the present invention are further operable at the host device to determine a simulated input state at the client side by performing a comparison of the vector data currently received to a last known vector data and rendering output in response to the comparison.
10552201,One embodiment of the present invention sets forth a technique for instruction level execution preemption. Preempting at the instruction level does not require any draining of the processing pipeline. No new instructions are issued and the context state is unloaded from the processing pipeline. Any in-flight instructions that follow the preemption command in the processing pipeline are captured and stored in a processing task buffer to be reissued when the preempted program is resumed. The processing task buffer is designated as a high priority task to ensure the preempted instructions are reissued before any new instructions for the preempted context when execution of the preempted context is restored.
10552202,One embodiment of the present invention sets forth a technique for instruction level execution preemption. Preempting at the instruction level does not require any draining of the processing pipeline. No new instructions are issued and the context state is unloaded from the processing pipeline. Any in-flight instructions that follow the preemption command in the processing pipeline are captured and stored in a processing task buffer to be reissued when the preempted program is resumed. The processing task buffer is designated as a high priority task to ensure the preempted instructions are reissued before any new instructions for the preempted context when execution of the preempted context is restored.
10558230,"High-resolution switched digital regulators are disclosed having fast cross corner and variable temperature response, with constrained ripple. The strength of the power transistors utilized by the regulator are adjusted to control the current delivered to the load. The regulators utilize a slow control loop in parallel with a primary fast switching loop. The slow loop uses the switching signal of the primary loop to estimate the load current and set the power transistor size accordingly."
10559122,"A system for, and method of, computing reduced-resolution indirect illumination using interpolated directional incoming radiance and a graphics processing subsystem incorporating the system or the method. In one embodiment, the system includes: (1) a cone tracing shader executable in a graphics processing unit to compute directional incoming radiance cones for sparse pixels and project the directional incoming radiance cones on a basis and (2) an interpolation shader executable in the graphics processing unit to compute outgoing radiance values for untraced pixels based on directional incoming radiance values for neighboring ones of the sparse pixels."
10560698,"A graphics server and method for streaming rendered content via a remote graphics rendering service is provided. In one embodiment, the server includes a memory, a graphics renderer, a frame capturer, an encoder, and a processor. The memory is configured to store a pre-computed skip-frame message indicative to a client to re-use a previously transmitted frame of the video stream. The graphics renderer is configured to identify when rendered content has not changed. When the graphics renderer identifies that the rendered content has not changed, the processor is configured to cause: (1) the frame capturer to not capture the frames of the rendered content; (2) the encoder to not encode the frames of the rendered content; and (3) the pre-encoded skip-frame message to be transmitted without requiring any pixel processing."
10565686,"A method, computer readable medium, and system are disclosed for training a neural network. The method includes the steps of selecting an input sample from a set of training data that includes input samples and noisy target samples, where the input samples and the noisy target samples each correspond to a latent, clean target sample. The input sample is processed by a neural network model to produce an output and a noisy target sample is selected from the set of training data, where the noisy target samples have a distribution relative to the latent, clean target sample. The method also includes adjusting parameter values of the neural network model to reduce differences between the output and the noisy target sample."
10565747,"A system, method, and computer readable medium for inverse graphics rendering comprise a differentiable rendering pipeline and a gradient descent optimization engine. A given scene is described using scene parameters. Visibility functions, and other rendered functions, are constructed to be continuous and differentiable, allowing the optimization engine and the rendering pipeline to efficiently iterate through increasingly refined scene models."
10565781,"A method of adjusting a shading normal vector for a computer graphics rendering program. Calculating a normalized shading normal vector pointing outwards from an origin point on a tessellated surface modeling a target surface to be rendered. Calculating a normalized outgoing reflection vector projecting from the origin point for an incoming view vector directed towards the origin point and reflecting relative to the normalized shading normal vector. Calculating a correction vector such that when the correction vector is added to the normalized outgoing reflection vector a resulting vector sum is yielded that is equal to a maximum reflection vector, wherein the maximum reflection vector is on or above the tessellated surface. Calculating a normalized maximum reflection vector by normalizing a vector sum of the correction vector plus the maximum reflection vector. Calculating a normalized adjusted shading normal vector by normalizing a vector difference of the normalized maximum reflection vector minus the incoming view vector."
10566958,"Injection locked oscillation circuits are applied along clock distribution circuit paths to increase clock signal bandwidth, reduce duty cycle error, reduce quadrature phase error, reduce clock signal jitter, and reduce clock signal power consumption."
10571978,"A fan control module configured to control the speed of a fan receives a signal that indicates the power used by a graphics processing unit (GPU) and a signal that indicates the GPU temperature. Whenever the GPU power exceeds a power threshold level, but the GPU temperature is below a temperature threshold level, the control module turns the fan on and causes the fan to operate at a minimum speed. Whenever the GPU temperature is above the temperature threshold, the control module causes the fan speed to increase with increasing temperature, regardless of power. The control module turns the fan off only when both the GPU temperature is below the temperature threshold and the GPU power is below the power threshold. Although the algorithm is discussed in conjunction with a GPU, the algorithm can be implemented with any type of processor or subsystem that needs to be fan-cooled."
10573058,"A method, computer readable medium, and system are disclosed for performing stable ray tracing. The method includes the steps of identifying a plurality of old hit points used in a previously rendered frame, re-projecting the plurality of old hit points within a current frame to create a plurality of samples within a screen space of the current frame, adjusting the plurality of samples within the screen space of the current frame, based on one or more criteria, for each of the plurality of samples, tracing a ray from the sample toward a corresponding old hit point for the sample to determine a current hit point corresponding to the sample for the current frame, where the current hit point may include the corresponding old hit point for the sample or an updated hit point for the sample, shading at least a portion of the plurality of current hit points to obtain a color for each of the plurality of samples within the screen space of the current frame, and reconstructing a final color for a plurality of pixels in the screen space of the current frame, utilizing the color for each of the plurality of samples within the screen space of the current frame."
10573061,"A method, computer readable medium, and system are disclosed for redirecting a user's movement through a physical space while the user views a virtual environment. A temporary visual suppression event is detected when a user's eyes move relative to the user's head while viewing a virtual scene displayed on a display device, an orientation of the virtual scene relative to the user is modified to direct the user to physically move along a planned path through a virtual environment corresponding to the virtual scene, and the virtual scene is displayed on the display device according to the modified orientation."
10573071,"A method, computer readable medium, and system are disclosed for computing a path for a user to move along within a physical space while viewing a virtual environment in a virtual reality system. A path for a user to physically move along through a virtual environment is determined based on waypoints and at least one characteristic of the physical environment within which the user is positioned, position data for the user is received indicating whether and how much a current path taken by the user has deviated from the path, and an updated path is computed through the virtual environment based on the waypoints and the at least one characteristic of the physical environment."
10580196,"A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include opaque and alpha triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to determine primitives intersected by the ray, and return intersection information to a streaming multiprocessor for further processing. The hardware-based traversal coprocessor is configured to omit reporting of one or more primitives the ray is determined to intersect. The omitted primitives include primitives which are provably capable of being omitted without a functional impact on visualizing the virtual scene."
10580198,"A system and method of rendering a fluid-like object in a volume space are provided. In one embodiment, the method includes: (1) determining a list of bricks in the volume space that the fluid-like object would occupy, (2) grouping the bricks into buckets based on depth values of the bricks and (3) rendering each of the buckets separately."
10581645,"A signal transceiver includes a signal transmitter driving a first differential link between a supply voltage of the signal transmitter and a fraction of the supply voltage, and driving a second differential link between the faction of the supply voltage and a reference ground. The signal transceiver also includes a signal receiver in which the first differential link is coupled to a gate node of an NMOS transistor and to a source node of a PMOS transistor; and the second differential link is coupled to a source node of the NMOS transistor and to a gate node of the PMOS transistor."
10593020,"An image processing method extracts consecutive input blurry frames from a video, and generates sharp frames corresponding to the input blurry frames. An optical flow is determined between the sharp frames, and the optical flow is used to compute a per-pixel blur kernel. The blur kernel is used to reblur each of the sharp frames into a corresponding re-blurred frame. The re-blurred frame is used to fine-tune the deblur network by minimizing the distance between the re-blurred frame and the input blurry frame."
10594337,"A circuit includes a splitter to extract L bits from each of a plurality of N-bit transmissions on a data bus, a decoder to generate output data comprising N-L bits of each N-bit transmission, and a delay circuit to apply the L bits for a previous transmission to control the inversion of a current transmission at the decoder."
10595039,"A method, computer readable medium, and system are disclosed for action video generation. The method includes the steps of generating, by a recurrent neural network, a sequence of motion vectors from a first set of random variables and receiving, by a generator neural network, the sequence of motion vectors and a content vector sample. The sequence of motion vectors and the content vector sample are sampled by the generator neural network to produce a video clip."
10599606,"Methods of operating a serial data bus generate two-level bridge symbols to insert between four-level symbols on one or more data lanes of the serial data bus, to reduce voltage deltas on the one or more data lanes during data transmission on the serial data bus."
10600141,"Marker commands are added to a stream of commands that are executed by a graphics processing unit (GPU) in a computing system. While the GPU executes the commands, information is written to a memory location each time a marker is reached in the pipeline. The memory location is accessible to the central processing unit (CPU), and the information identifies a command executed by the GPU. If the CPU receives an indication that the GPU is in an invalid state, then the CPU responds by accessing the memory location to identify the command executed in the pipeline of the GPU. Consequently, a command that was executing when the GPU entered the invalid state can be identified. This information can be used to pinpoint the cause of the invalid state."
10600167,"A method, computer readable medium, and system are disclosed for performing spatiotemporal filtering. The method includes the steps of applying, utilizing a processor, a temporal filter of a filtering pipeline to a current image frame, using a temporal reprojection, to obtain a color and auxiliary information for each pixel within the current image frame, providing the auxiliary information for each pixel within the current image frame to one or more subsequent filters of the filtering pipeline, and creating a reconstructed image for the current image frame, utilizing the one or more subsequent filters of the filtering pipeline."
10600229,"In various embodiments, a parallel processor implements a graphics processing pipeline that generates rendered images via a shading program. In operation, the parallel processor causes a first set of execution threads to execute the shading program on a first portion of the input mesh to generate first geometry stored in an on-chip memory. The parallel processor also causes a second set of execution threads to execute the mesh shading program on a second portion of the input mesh to generate second geometry stored in the on-chip memory. Subsequently, the parallel processor reads the first geometry and the second geometry from the on-chip memory, and performs operations on the first geometry and the second geometry to generate a rendered image derived from the input mesh. Advantageously, unlike conventional graphics processing pipelines, the performance of the graphics processing pipeline is not limited by a primitive distributor."
10600232,"A texture level of detail (LOD) approximation may be performed utilizing ray differentials and a G-buffer. For example, a scene to be rendered is identified, and a G-buffer of the scene is rendered. Additionally, ray tracing is started for the scene, and during the ray tracing, a ray differential is created by accessing the G-buffer. Further, the created ray differential is appended to a current ray, and the created ray differential is traced."
10600730,"In one embodiment, a system comprises: a plurality of aggressor bus lines; and a plurality of differential pair bus lines that are located in relatively parallel close proximity to the plurality of aggressor bus lines, wherein at least two of the plurality of differential pair bus lines change location with respect to each other at a point that has a cancelling affect on cross talk from the plurality of aggressor bus lines, wherein the change includes cross over routing. The plurality of differential pair bus lines can convey differential clock signals. The routing of the plurality of differential pair bus lines is substantially parallel to one another before and after the change."
10601324,A DC-DC converter circuit includes a switched tank converter configured to output a switching waveform. The DC-DC converter circuit further includes a transformer coupled to the switched tank converter to receive the switching waveform output by the switched tank converter across a primary winding of the transformer.
10601409,"A circuit, method, and system are disclosed for sampling a signal. The system includes a sampler circuit configured to sample input signals when a clock signal is at a first level to produce sampled signals, a detection circuit that is coupled to the sampler circuit, and a feedback circuit that receives an output signal and generates the clock signal. The detection circuit pre-charges the sampled signals when the clock signal is at a second level and, using threshold adjusted inverters, detects voltage levels of each sampled signal to produce detected voltage level signals, where a threshold voltage of the threshold adjusted inverters is entirely outside of a transition voltage range of the sampler circuit. In response to one of the detected voltage level signals transitioning from the second level to the first level, the detection circuit transitions the output signal from the first level to the second level."
10601719,"A system for enforcing quality of service and methods of configuring and enforcing quality of service (QoS). In one embodiment, the system includes: (1) a host configured to process a plurality of applications and (2) a modem coupled to the host and configured to interface with data networks and having a non-access stratum configured to prioritize real time data packets and selectively to discard data packets based on a defined criteria."
10602175,"A method for using an average motion vector in a motion vector search process. The method includes accessing an input frame for processing and reading average motion vector information from memory. The method further includes performing a motion vector search by using the average motion vector and a plurality of hints, calculating a winner motion vector based on the average motion vector and the plurality of hints, and storing the winner motion vector back into memory to create a new updated average motion vector. The method further includes finishing processing the input frame using the winning motion vector."
10607390,"A device driver is configured to identify a group of compute shaders to be executed in multiple traversals of a graphics processing pipeline. Each such compute shader accesses a compute tile of data having particular dimensions. The device driver interoperates with a tiling unit to determines dimension for a cache tile so that an integer multiple of each compute tile will fit evenly within the cache tile. Thus, when executing compute shaders in different traversals of the graphics processing pipeline, the data processed by those compute shaders can be cached in the cache tile between passes."
10607552,A display controller generates a backlight illumination field (BLIF) based on a coarse point-spread function (PSF) and a correction PSF. The display controller samples the coarse PSF to accumulate light contributions from a larger neighborhood of LEDs around a given LCD pixel. The display controller samples the correction PSF to generate correction factors for a smaller neighborhood of LEDs around the given LCD pixel. The display controller interpolates samples drawn from the coarse PSF and samples drawn from the correction PSF and then combines the interpolated samples to generate a full resolution BLIF.
10614541,"A method for implementing a hybrid scalable CPU/GPU rigid body pipeline. The method includes partitioning a rigid body pipeline into a GPU portion comprising GPU components and a CPU portion comprising CPU components. The method further includes executing the GPU components on the GPU of a computer system, and executing the CPU components on the CPU of the computer system. Communication data dependencies between the CPU and the GPU are managed as the GPU components and the CPU components process through the GPU and the CPU. The method concludes by outputting a resulting processed frame for display."
10614613,"A method, computer readable medium, and system are disclosed for reducing noise during a rendering of a scene by sharing information that is spatially close through path space filtering. A vertex of a light transport path is selected, and one or more features of the selected vertex are quantized. A first hash is calculated based on the one or more quantized features of the selected vertex, and a collision resolution is performed within a hash table. A contribution of the light transport path at the selected vertex is accumulated to the hash table, and a counter is incremented in response to adding the contribution of the light transport path at the selected vertex to the hash table. An average contribution of the light transport path is then calculated, utilizing the counter."
10621022,"A family of software-hardware cooperative mechanisms to accelerate intra-thread duplication leverage the register file error detection hardware to implicitly check the data from duplicate instructions, avoiding the overheads of instruction checking and enforcing low-latency error detection with strict error containment guarantees."
10623200,"An encoding process for bus data utilizes data from multiple data line groups on a multi-byte wide bus where each group has an associated DBI line. The process leverages the expanded encoding space for the multiple groups and associated multiple DBI bits. This process may be expanded to four bytes, eight bytes, etc."
10623217,"A PAM signaling system utilizes multiple equalizers on each data lane of a serial data bus, each of the equalizers associated with a different signal eye of the serial data bus."
10628160,"Embodiments related to selecting a runahead poison policy from a plurality of runahead poison policies during microprocessor operation are provided. The example method includes causing the microprocessor to enter runahead upon detection of a runahead event and implementing a first runahead poison policy selected from a plurality of runahead poison policies operative to manage runahead poison injection during runahead. The example method also includes during microprocessor operation, selecting a second runahead poison policy operative to manage runahead poison injection differently from the first runahead poison policy."
10630773,"Embodiments of the claimed subject matter provide systems and methods for configuring and connecting a controller to a game streaming service. The system includes a plurality of input controls and a network controller configured for communicating with a game streaming service. The system further includes a processor coupled to the plurality of input controls and the network controller. The processor is configured communicate with the game streaming service to login to a game streaming service account and communicate input from the plurality of controls to the game streaming service. The system further includes a power source configured to provide power to the plurality of input controls, the network controller, and the processor."
10635357,"Improved methods and systems for accessing a memory in a computer are disclosed. In one embodiment, the true and complement portions of a differential write clock signal are employed as two single ended clock signals for independently controlling different memory chips in a memory system. For example, in a memory system having two memory chips, one memory chip is configured to use the true write clock signal and the other memory chip is configured to use the complement write clock signal. Employing the differential write clock signal as two single ended clock signals allows overlapping of write and read operations across multiple memory chips, reducing the time needed for accessing memory. Accordingly, the disclosed methods and systems provide a more efficient memory system that can be used to improve the operation of a computer."
10636336,"A method, computer readable medium, and system are disclosed for generating mixed-primary data for display. The method includes the steps of receiving a source image that includes a plurality of pixels, dividing the source image into a plurality of blocks, analyzing the source image based on an image decomposition algorithm, encoding chroma information and modulation information to generate a video signal, and transmitting the video signal to a mixed-primary display. The chroma information and modulation information correspond with two or more mixed-primary color components and are generated by the image decomposition algorithm to minimize error between a reproduced image and the source image. The two or more mixed-primary colors selected for each block of the source image are not limited to any particular set of colors and each mixed-primary color component may be selected from any color capable of being reproduced by the mixed-primary display."
10642311,"A method for displaying a near-eye light field display (NELD) image is disclosed. The method comprises determining a pre-filtered image to be displayed, wherein the pre-filtered image corresponds to a target image. It further comprises displaying the pre-filtered image on a display. Subsequently, it comprises producing a near-eye light field after the pre-filtered image travels through a microlens array adjacent to the display, wherein the near-eye light field is operable to simulate a light field corresponding to the target image. Finally, it comprises altering the near-eye light field using at least one converging lens, wherein the altering allows a user to focus on the target image at an increased depth of field at an increased distance from an eye of the user and wherein the altering increases spatial resolution of said target image."
10642744,"An improved architectural means to address processor cache attacks based on speculative execution defines a new memory type that is both cacheable and inaccessible by speculation. Speculative execution cannot access and expose a memory location that is speculatively inaccessible. Such mechanisms can disqualify certain sensitive data from being exposed through speculative execution. Data which must be protected at a performance cost may be specifically marked. If the processor is told where secrets are stored in memory and is forbidden from speculating on those memory locations, then the processor will ensure the process trying to access those memory locations is privileged to access those locations before reading and caching them. Such countermeasure is effective against attacks that use speculative execution to leak secrets from a processor cache."
10643106,"A system and method for procedurally synthesizing a training dataset for training a machine-learning model. In one embodiment, the system includes: (1) a training designer configured to describe variations in content of training images to be included in the training dataset and (2) an image definer coupled to the training designer, configured to generate training image definitions in accordance with the variations and transmit the training image definitions: to a 3D graphics engine for rendering into corresponding training images, and further to a ground truth generator for generating associated ground truth corresponding to the training images, the training images and the associated ground truth comprising the training dataset."
10644686,"A circuit, method, and system are disclosed for sampling a signal. The system includes a sampler circuit configured to sample input signals when a clock signal is at a first voltage level to produce sampled signals, a detection circuit that is coupled to the sampler circuit, and a feedback circuit that receives an output signal and generates the clock signal. The detection circuit pre-charges the sampled signals when the clock signal is at a second voltage level and, using threshold adjusted inverters, detects voltage levels of each sampled signal to produce detected voltage levels, where a threshold voltage of the threshold adjusted inverters is entirely outside of a transition voltage range of the sampler circuit. In response to one of the detected voltage levels transitioning from the second level to the first level, the detection circuit transitions the output signal from the first voltage level to the second voltage level."
10657094,"Methods of operating a serial data bus divide series of data bits into sequences of one or more bits and encode the sequences as N-level symbols, which are then transmitted at multiple discrete voltage levels. These methods may be utilized to communicate over serial data lines to improve bandwidth and reduce crosstalk and other sources of noise."
10657306,"Techniques to improve the accuracy and speed for detection and remediation of difficult to test nodes in a circuit design netlist. The techniques utilize improved netlist representations, test point insertion, and trained neural networks."
10659063,"Aspects of the present invention are directed to techniques for improving the efficiency of power supply schemes by continuously and adaptively scaling voltage and frequency levels in an integrated circuit based on measured conditions in real-time, without resorting to a reliance on excessive pre-computed margins typical of conventional schemes. Embodiments of the present invention employ a self-tuning dynamic voltage control oscillator (or other similar clock signal generator) that sets the frequency for components in the integrated circuit. When a requested frequency exceeds a maximum allowed frequency for a given voltage level (accounting for other age and temperature related conditions), a look-up table is dynamically referenced to determine a new voltage level that is sufficient to safely and efficiently generate the requested frequency. The look-up table continuously receives updates on the operating conditions, and new voltage requests can be generated dynamically as necessary based on the system's current needs."
10663515,"A hardware controller of a device under test (DUT) communicates with a PCIe controller to fetch test data and control test execution. The hardware controller also communicates with a JTAG/IEEE 1500 component to set up the DUT into various test configurations and to trigger test execution. For SCAN tests, the hardware controller provides a high throughput direct access to the on-chip compressors/decompressors to load the scan data and to collect the test results."
10664049,"A method, computer readable medium, and system are disclosed for gaze tracking. The method includes the steps of receiving reflected light rays at an optical sensor, where all of the reflected light rays converge towards a rotational center of an eye and generating pattern data based on intersections of the reflected light rays at a surface of the optical sensor. A processor computes an estimated gaze direction of the eye based on the pattern data."
10668386,"A system, method, and computer program product are provided for simultaneously determining settings for a plurality of parameter variations. In use, a plurality of parameter variations associated with a device is identified, where the plurality of parameter variations are organized into a plurality of segments. Additionally, settings for each of the plurality of parameter variations are determined and consistency of the settings across the plurality of segments is ensured."
10671763,"Computing devices are now used for various purposes ranging from monitoring a refrigerator to driving automobiles. Protecting the data and logic within the chips of the computing devices is essential to ensure reliable operation. When a particular partition of a chip is powered-up but the logic of the partition is not reset, the logic will be in an unpredictable random state. To operate in a secure environment, it is necessary to start the operation of the logic from a known state and not a random state. To ensure the logic is operating in a secure environment, a digital reset detector circuit (DRDC) is provided that indicates if the logic was reset after power-up. The DRDC can ensure chips are secure from attacks involving reset deprivation upon power-up and help protect various secure and secret assets in a chip, including customer keys."
10672185,"One aspect of the disclosure provides a method for rendering an image. The method includes: placing primitives of the image in a screen space; binning the primitives into tiles of the screen space that the primitives touch; and rasterizing the tiles at one tile of the tiles at a time. The aforementioned rasterizing includes shading a subset of the primitives binned to the one tile at a first shading rate during a first pass and shading the subset of primitives binned to the one tile at a second shading rate during a second pass, the second shading rate is different from the first shading rate, and the aforementioned placing is performed once while the image is rendered."
10672461,"A negative bit line write assist system includes an array voltage supply and a static random access memory (SRAM) cell that is coupled to the array voltage supply and controlled by bit lines during a write operation. Additionally, the negative bit line write assist system includes a bit line voltage unit that is coupled to the SRAM cell, wherein a distributed capacitance is controlled by a write assist command to provide generation of a negative bit line voltage during the write operation. A negative bit line write assist method is also provided."
10681321,"The present disclosure is directed to a process to partially or fully suppress, or limit, pixel coloration errors. These pixel coloration errors, represented by small noise values, can be introduced during signal processing of high dynamic range (HDR) video signals. Converting visual content to a half precision floating point representation, for example, FP16, can introduce small amounts of signal noise due to value rounding. The noise can be multiplied and accumulated during HDR signal processing resulting in visual artifacts and degraded image quality. The disclosure can detect these noise amounts in pixel color component values, and suppress, or partially suppress, the noise to prevent the noise from accumulating during subsequent HDR signal processing."
10684824,"A method, computer readable medium, and system are disclosed for rounding numerical values. A set of bits from an input value is identified as a rounding value. A second set of bits representing a second value is extracted from the input value and added with the rounding value to produce a sum. The sum is truncated to produce the rounded output value. Thus, the present invention provides a stochastic rounding technique that rounds up an input value as a function of a second value and a rounding value, both of which were obtained from the input value. When the second value and rounding value are obtained from consistent bit locations of the input value, the resulting output value is deterministic. Stochastic rounding, which is deterministic, is advantageously applicable in deep learning applications."
10685925,"Systems and methods that facilitate resistance and capacitance balancing are presented. In one embodiment, a system comprises: a plurality of ground lines configured to ground components; and a plurality of signal bus lines interleaved with the plurality of ground lines, wherein the interleaving is configured so that plurality of signal bus lines and plurality of ground lines are substantially evenly spaced and the plurality of signal bus lines convey a respective plurality of signals have similar resistance and capacitance constants that are balanced. The plurality of signals can see a substantially equal amount ground surface and have similar amounts of capacitance. The plurality of signal bus lines can have similar cross sections and lengths with similar resistances. The plurality of signal bus lines interleaved with the plurality of ground lines can be included in a two copper layer interposer design with one redistribution layer (RDL)."
10691572,"Memory, used by a computer to store data, is generally prone to faults, including permanent faults (i.e. relating to a lifetime of the memory hardware), and also transient faults (i.e. relating to some external cause) which are otherwise known as soft errors. Since soft errors can change the state of the data in the memory and thus cause errors in applications reading and processing the data, there is a desire to characterize the degree of vulnerability of the memory to soft errors. In particular, once the vulnerability for a particular memory to soft errors has been characterized, cost/reliability trade-offs can be determined, or soft error detection mechanisms (e.g. parity) may be selectively employed for the memory. A method, computer readable medium, and system are provided for using liveness as a factor to evaluate memory vulnerability to soft errors."
10692244,"A deep neural network (DNN) system learns a map representation for estimating a camera position and orientation (pose). The DNN is trained to learn a map representation corresponding to the environment, defining positions and attributes of structures, trees, walls, vehicles, etc. The DNN system learns a map representation that is versatile and performs well for many different environments (indoor, outdoor, natural, synthetic, etc.). The DNN system receives images of an environment captured by a camera (observations) and outputs an estimated camera pose within the environment. The estimated camera pose is used to perform camera localization, i.e., recover the three-dimensional (3D) position and orientation of a moving camera, which is a fundamental task in computer vision with a wide variety of applications in robot navigation, car localization for autonomous driving, device localization for mobile navigation, and augmented/virtual reality."
10694164,"The disclosure is directed to a method to generate a stereoscopic video image stream of a zenith or nadir view perspective of a scene. In another aspect, a system is disclosed for generating a zenith or nadir view perspective utilizing a relative user view orientation. In yet another aspect, a video processing computer is disclosed operable to generate a zenith or nadir view perspective utilizing a user view orientation."
10699383,"Methods are disclosed herein to blur an image to be displayed on a stereo display (such as virtual or augmented reality displays) based on the focus and convergence of the user. The methods approximate the complex effect of chromatic aberration on focus, utilizing three (R/G/B) simple Gaussian blurs. For transparency the methods utilize buffers for levels of blur rather than depth. The methods enable real-time chromatic-based blurring effects for VR/AR displays."
10699427,"Methods and apparatuses are disclosed for reporting texture footprint information. A texture footprint identifies the portion of a texture that will be utilized in rendering a pixel in a scene. The disclosed methods and apparatuses advantageously improve system efficiency in decoupled shading systems by first identifying which texels in a given texture map are needed for subsequently rendering a scene. Therefore, the number of texels that are generated and stored may be reduced to include the identified texels. Texels that are not identified need not be rendered and/or stored."
10699447,"A plurality of processors with logic units to train one or more neural networks for image construction, at least in part, using established one or more levels of compression for image data from a region of interest (ROI)."
10700846,"A system for data and clock recovery includes a timing error detector, a phase detector, and a phase increment injector. The phase increment injector may be used to determine an increment to affect an output of the phase detector or a clocking element. A sign of the increment is determined from a sign or direction of an accumulated version of a clock and data recovery gradient value."
10705525,"A method, computer readable medium, and system are disclosed for performing autonomous path navigation using deep neural networks. The method includes the steps of receiving image data at a deep neural network (DNN), determining, by the DNN, both an orientation of a vehicle with respect to a path and a lateral position of the vehicle with respect to the path, utilizing the image data, and controlling a location of the vehicle, utilizing the orientation of the vehicle with respect to the path and the lateral position of the vehicle with respect to the path."
10705790,"A virtual reality (VR) audio rendering system and method include spatializing microphone-captured real-world sounds according to a VR setting. In a game streaming system, when a player speaks through a microphone, the voice is processed by geometrical acoustic (GA) simulation configured for a virtual scene, and thereby spatialized audio effects specific to the scene are added. The GA simulation may include generating an impulse response using sound propagation simulation and dynamic HRTF-based listener directivity. When the GA-processed voice of the player is played, the local player or other fellow players can hear it as if the sound travels in the scenery and according to the geometries in the virtual scene. This mechanism can advantageously place the players' chatting in the same virtual world like built-in game audio, thereby advantageously providing enhanced immersive VR experience to users."
10705994,"A unified cache subsystem includes a data memory configured as both a shared memory and a local cache memory. The unified cache subsystem processes different types of memory transactions using different data pathways. To process memory transactions that target shared memory, the unified cache subsystem includes a direct pathway to the data memory. To process memory transactions that do not target shared memory, the unified cache subsystem includes a tag processing pipeline configured to identify cache hits and cache misses. When the tag processing pipeline identifies a cache hit for a given memory transaction, the transaction is rerouted to the direct pathway to data memory. When the tag processing pipeline identifies a cache miss for a given memory transaction, the transaction is pushed into a first-in first-out (FIFO) until miss data is returned from external memory. The tag processing pipeline is also configured to process texture-oriented memory transactions."
10706608,"A method, computer readable medium, and system are disclosed for performing tree traversal with backtracking in constant time. The method includes the steps of traversing a tree, maintaining a bit trail variable and a current key variable during the traversing, where the bit trail variable includes a first plurality of bits indicating tree levels on which a node has been postponed along a path from the root of the tree during the traversing, and the current key variable includes a second plurality of bits indicating a number of a current node within the tree, and performing backtracking within the tree during the traversing, utilizing the bit trail variable and the current key variable."
10709991,"A system for cooperative application control. In one embodiment, the system includes: (1) a cloud application engine for executing application code configured to allow interaction with an application, generate a video stream corresponding to a particular user and accept a response stream from the particular user to allow the particular user to interact with the application and (2) a cooperative interaction engine associated with the cloud application engine for communication therewith and configured to multicast the video stream from the cloud application engine to the particular user and at least one other user, combine separate response streams from the particular user and the at least one other user into a joint response stream and provide the joint response stream to the cloud application engine."
10713756,"One aspect of the current disclosure provides a method of upscaling an image. The method includes: rendering an image, wherein the rendering includes generating color samples of the image at a first resolution and depth samples of the image at a second resolution, which is higher than the first resolution; and upscaling the image to an upscaled image at a third resolution, which is higher than the first resolution, using the color samples and the depth samples."
10713838,"The present invention facilitates efficient and effective image processing. A network can comprise: a first system configured to perform a first portion of lighting calculations for an image and combing results of the first portion of lighting calculations for the image with results of a second portion of lighting calculations; and a second system configured to perform the second portion of lighting calculations and forward the results of the second portion of the lighting calculations to the first system. The first and second portion of lighting calculations can be associated with indirect lighting calculations and direct lighting calculations respectively. The first system can be a client in a local location and the second system can be a server in a remote location (e.g., a cloud computing environment). The first system and second system can be in a cloud and a video is transmitted to a local system."
10715817,A method and apparatus for enhancing motion estimation based on user input are provided. The motion estimation apparatus used for video encoding comprises a receiver operable to receive a user based input and an input analysis module operable to analyzed the user based input. The apparatus also comprises an encoder that is operable to compute displacement coordinates from the analyzed user based input for a current block in a target frame of a video stream and operable to determine a search area in a reference frame to search for a best match for the current block using the displacement coordinates. The encoder can also comprise a block match module operable to find a best match block for the current block in the search area of the reference frame using a block matching procedure.
10725837,"Techniques are disclosed for sharing of data exchange among kernels (each a set of instructions) executing on a system having multiple processing units. In an embodiment, each processing unit includes an on-chip scratchpad memory that can be accessed by the kernels executing on the processing unit. All or a portion of the scratchpad memory can be allocated and configured, for example, such that the scratchpad is accessible to multiple kernels in parallel, to one or more kernels in serial, or a combination of both."
10726797,"A display controller within a display device includes a serial peripheral interface (SPI) that coordinates the updating of current settings for groups of light-emitting diodes (LEDs). The SPI controller operates in synchrony with a liquid-crystal display (LCD) vertical scan position in order to update the current settings for rows of LEDs in parallel with the updating of nearby rows of LCD pixels. When updating a row of LEDs, the SPI controller executes one or more SPI transactions included in an SPI program to write current settings for multiple LEDs nearly simultaneously. A compiler generates the SPI program based on the topology of LEDs included in the display device."
10728062,"In a computing system, various components/devices communicate with each other. For example, a microprocessor may communicate with memory or may communicate with another microprocessor over a link. Various factors such as the frequency and transmission speed of a signal can distort what is being communicated over a link. The problem becomes more pronounced as the transmission speed increases. To address this problem, devices on both ends of a link can cooperate to equalize the link. Equalization involves configuring the transmitting device to alter the signal being transmitted so that certain distortions introduced during transmission are negated by the time the signal arrives at the receiving device. Given that each link can have slightly different characteristics, appropriate equalization parameters need to be ascertained for each link. Introduced herein are improved techniques for performing equalization that are quick yet provide equalization parameters that are stable even in a noisy high-speed link."
10733794,"One embodiment of the present invention includes a parallel processing unit (PPU) that performs pixel shading at variable granularities. For effects that vary at a low frequency across a pixel block, a coarse shading unit performs the associated shading operations on a subset of the pixels in the pixel block. By contrast, for effects that vary at a high frequency across the pixel block, fine shading units perform the associated shading operations on each pixel in the pixel block. Because the PPU implements coarse shading units and fine shading units, the PPU may tune the shading rate per-effect based on the frequency of variation across each pixel group. By contrast, conventional PPUs typically compute all effects per-pixel, performing redundant shading operations for low frequency effects. Consequently, to produce similar image quality, the PPU consumes less power and increases the rendering frame rate compared to a conventional PPU."
10740254,"Embodiments of the present invention may be directed to a graphics system of a computer system. The system may include a frame buffer having a number of partitions respectively mapped to a number of discrete memory devices and a dedicated copy buffer operable to store new image frames, mapped to a first memory device. The first memory device corresponds to a first partition of the number of partitions. The system may also include a loader circuit coupled between the frame buffer and the dedicated copy buffer, operable to copy new image frames from the frame buffer to the dedicated copy buffer. The system may also include a clocked output coupled to receive an image frame from the dedicated copy buffer and operable to drive a display device therewith. The system may enter a low power state wherein a number of the discrete memory devices are powered off."
10740901,"A segmentation model is trained with an image reconstruction model that shares an encoding. During application of the segmentation model, the segmentation model may use the encoding and network layers trained for the segmentation without the image reconstruction model. The image reconstruction model may include a probabilistic representation of the image that represents the image based on a probability distribution. When training the model, the encoding layers of the model use a loss function including an error term from the segmentation model and from the autoencoder model. The image reconstruction model thus regularizes the encoding layers and improves modeling results and prevents overfitting, particularly for small training sizes."
10740952,"A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include opaque and alpha triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to determine primitives intersected by the ray, and return intersection information to a streaming multiprocessor for further processing. The hardware-based traversal coprocessor is configured to provide a deterministic result of intersected triangles regardless of the order that the memory subsystem returns triangle range blocks for processing, while opportunistically eliminating alpha intersections that lie further along the length of the ray than closer opaque intersections."
10740954,"In various examples, the actual spatial properties of a virtual environment are used to produce, for a pixel, an anisotropic filter kernel for a filter having dimensions and weights that accurately reflect the spatial characteristics of the virtual environment. Geometry of the virtual environment may be computed based at least in part on a projection of a light source onto a surface through an occluder, in order to determine a footprint that reflects a contribution of the light source to lighting conditions of the pixel associated with a point on the surface. The footprint may define a size, orientation, and/or shape of the anisotropic filter kernel and corresponding filter weights. The anisotropic filter kernel may be applied to the pixel to produce a graphically-rendered image of the virtual environment."
10741143,"Systems and techniques for streaming video with dynamic jitter tolerance are described. In one example, a system includes a server executing an application and generating image frames associated with the application at a frame rate, and a client which displays the image frames on a display that has a predetermined refresh rate and which monitors arrival times of the image frames in relation to the predetermined refresh rate. The server is further configured to dynamically change the frame rate based on the monitoring so that the frame rate more closely corresponds to the predetermined refresh rate of the client's display."
10741215,"In various examples, recordings of gameplay sessions are enhanced by the application of special effects to relatively high(er) and/or low(er) interest durations of the gameplay sessions. Durations of relatively high(er) or low(er) predicted interest in a gameplay session are identified, for instance, based upon level of activity engaged in by a gamer during a particular gameplay session duration. Once identified, different variations of video characteristic(s) are applied to at least a portion of the identified durations for implementation during playback. The recordings may be generated and/or played back in real-time with a live gameplay session, or after completion of the gameplay session. Further, video data of the recordings themselves may be modified to include the special effects and/or indications of the durations and/or variations may be included in metadata and used for playback."
10742224,"A circuit includes a first ring oscillator with a plurality of stages, each coupled via a voltage follower cross-coupling to a plurality of stages of a second ring oscillator. Further ring oscillators may be coupled to the first ring oscillator and the second ring oscillator. Additionally, the voltage follower cross-coupling for each of the stages may include one or more first voltage follower having a first strength, and one or more second voltage follower having a second strength different than the first strength."
10742950,"An apparatus for capturing digital stereoscopic images of a scene. The apparatus comprises a first pair of separated camera lens oriented such that a first imaginary line between the first pair of lens is substantially parallel with a horizon line a scene, wherein digital image data is capturable through the first pair of camera lens and storable in two separate digital image data bases corresponding to a left-eye horizontal view and a right-eye horizontal view respectively. The apparatus comprises a second pair of separated camera lens oriented such that a second imaginary line between the second pair of lens is substantially non-parallel with the horizon line, wherein digital image data is capturable through the second pair of camera lens and storable in two separate digital image data bases corresponding to a left-eye off-horizontal view and a right-eye off-horizontal view respectively."
10746798,"A system for testing complex integrated circuits in the field using updated tests, test sequences, models, and test conditions such as voltage and clock frequencies, over the life cycle of the circuit."
10748036,"Segmentation is the identification of separate objects within an image. An example is identification of a pedestrian passing in front of a car, where the pedestrian is a first object and the car is a second object. Superpixel segmentation is the identification of regions of pixels within an object that have similar properties An example is identification of pixel regions having a similar color, such as different articles of clothing worn by the pedestrian and different components of the car. A pixel affinity neural network (PAN) model is trained to generate pixel affinity maps for superpixel segmentation. The pixel affinity map defines the similarity of two points in space. In an embodiment, the pixel affinity map indicates a horizontal affinity and vertical affinity for each pixel in the image. The pixel affinity map is processed to identify the superpixels."
10748332,"Systems and methods that facilitate efficient and effective shadow image generation are presented. In one embodiment, a hard shadow generation system comprises a compute shader, pixel shader and graphics shader. The compute shader is configured to retrieve pixel depth information and generate projection matrix information, wherein the generating includes performing dynamic re-projection from eye-space to light space utilizing the pixel depth information. The pixel shader is configured to create light space visibility information. The graphics shader is configured to perform frustum trace operations to produce hard shadow information, wherein the frustum trace operations utilize the light space visibility information. The light space visibility information can be considered irregular z information stored in an irregular z-buffer."
10748333,"In various embodiments, a finite aperture omni-directional camera is modeled by aligning a finite aperture lens and focal point with the omni-directional part of the projection. For example, each point on an image plane maps to a direction in camera space. For a spherical projection, the lens can be orientated along this direction and the focal point is picked along this direction at focal distance from the lens. For a cylindrical projection, the lens can be oriented along the projected direction on the two dimensional (2D) xz-plane, as the projection is not omni-directional in the y direction. The focal point is picked along the (unprojected) direction so its projection on the xz-plane is at focal distance from the lens. The final outgoing ray can be constructed by sampling of point on this oriented lens and shooting a ray from there through the focal point."
10749720,"A receiver receives communications over a communication channel, which may distort an incoming communication signal. In order to counter this distortion, the frequency response of the receiver is manipulated by adjusting several frequency response parameters. Each frequency response parameter controls at least a portion of the frequency response of the receiver. The optimal values for the frequency response parameters are determined by modifying an initial set of values for the frequency response parameters through one or more of stochastic hill climbing operations until a performance metric associated with the receiver reaches a local maximum. The modified values are displaced through one or more mutation operations. The stochastic hill climbing operations may subsequently be performed on the mutated values to generate the final values for the frequency response parameters."
10754775,"A memory management unit responds to an invalidate by class command by identifying a marker for a class of cache entries that the invalidate by class command is meant to invalidate. The memory management unit stores the active marker as a retired marker and then sets the active marker to the next available marker. Thereafter, the memory management sends an acknowledgement signal (e.g., to the operating system) while invalidating the cache entries having the class and the retired marker in the background. By correlating markers with classes of cache entries, the memory management can more quickly respond to class invalidation requests."
10757812,"The present invention provides a printed circuit board and a layout method thereof and an electronic equipment. On the printed circuit board is arranged a first processor chip and a second processor chip, wherein the first processor chip is arranged on a first surface of the printed circuit board; the second processor chip is arranged on a second surface of the printed circuit board; and a first through-hole is disposed on the printed circuit board, part of pins of the first processor chip being connected to part of pins of the second processor chip via the first through-hole. The printed circuit board, the layout method thereof and the electronic equipment provided in the present invention arrange two processor chips on different surfaces of the printed circuit board and enable the respective parts of pins of the two processor chips to pass through the printed circuit board to be connected with each other by providing a through-hole on the printed circuit board, which not only greatly saves the space on the printed circuit board and is beneficial to product miniaturization, but also reduces transmission loss of high speed circuit and component costs."
10761582,"A computer system comprising: a graphics processor, a display controller comprising a display-local frame buffer, a display device, and a memory. The memory stores instructions, that when executed by the computer system, perform a method of entering a power management state. The method comprises detecting that the computer system is idle and optional proximity detector for determining if a user is present in front of the system. With the computer system idle, and the user in proximity of the system, the display-local frame buffer is activated. Display information transmitted by the graphics processor is stored in the display-local frame buffer. Initially a power reduction state is initiated for the graphics subsystem including the graphics processor, and the display device is placed in a self-refresh state with the display self-refreshing from information stored in the local frame buffer."
10762425,"A spatial linear propagation network (SLPN) system learns the affinity matrix for vision tasks. An affinity matrix is a generic matrix that defines the similarity of two points in space. The SLPN system is trained for a particular computer vision task and refines an input map (i.e., affinity matrix) that indicates pixels the share a particular property (e.g., color, object, texture, shape, etc.). Inputs to the SLPN system are input data (e.g., pixel values for an image) and the input map corresponding to the input data to be propagated. The input data is processed to produce task-specific affinity values (guidance data). The task-specific affinity values are applied to values in the input map, with at least two weighted values from each column contributing to a value in the refined map data for the adjacent column."
10762593,"The present invention facilitates efficient and effective utilization of unified virtual addresses across multiple components. In one exemplary implementation, an address allocation process comprises: establishing space for managed pointers across a plurality of memories, including allocating one of the managed pointers with a first portion of memory associated with a first one of a plurality of processors; and performing a process of automatically managing accesses to the managed pointers across the plurality of processors and corresponding memories. The automated management can include ensuring consistent information associated with the managed pointers is copied from the first portion of memory to a second portion of memory associated with a second one of the plurality of processors based upon initiation of an accesses to the managed pointers from the second one of the plurality of processors."
10762620,"When a computer image is generated from a real-world scene having a semi-reflective surface (e.g. window), the computer image will create, at the semi-reflective surface from the viewpoint of the camera, both a reflection of a scene in front of the semi-reflective surface and a transmission of a scene located behind the semi-reflective surface. Similar to a person viewing the real-world scene from different locations, angles, etc., the reflection and transmission may change, and also move relative to each other, as the viewpoint of the camera changes. Unfortunately, the dynamic nature of the reflection and transmission negatively impacts the performance of many computer applications, but performance can generally be improved if the reflection and transmission are separated. The present disclosure uses deep learning to separate reflection and transmission at a semi-reflective surface of a computer image generated from a real-world scene."
10769076,"Multiprocessor clusters in a virtualized environment conventionally fail to provide memory access security, which is frequently a requirement for efficient utilization in multi-client settings. Without adequate access security, a malicious process may access what might be confidential data that belongs to a different client sharing the multiprocessor cluster. Furthermore, an inadvertent programming error in the code for one client process may accidentally corrupt data that belongs to the different client. Neither scenario is acceptable. Embodiments of the present disclosure provide access security by enabling each processing node within a multiprocessor cluster to virtualize and manage local memory access and only process access requests possessing proper access credentials. In this way, different applications executing on a multiprocessor cluster may be isolated from each other while advantageously sharing the hardware resources of the multiprocessor cluster."
10769454,"System and methods for detecting blockages in images are described. A method may include receiving a plurality of images captured by a camera installed on a vehicle. The method may include identifying one or more candidate blocked regions in the plurality of images. Each of the candidate blocked regions may contain image data caused by blockages in the camera's field-of-view. The method may further include assigning blockage scores to the one or more candidate blocked regions based on region-associations among the one or more candidate blocked regions in the plurality of images. In response to a determination that one of the blockage scores is above a predetermined blockage threshold, the method may include transmitting a blockage alarm signal to the vehicle."
10769840,"Various types of systems or technologies can be used to collect data in a 3D space. For example, LiDAR (light detection and ranging) and RADAR (radio detection and ranging) systems are commonly used to generate point cloud data for 3D space around vehicles, for such functions as localization, mapping, and tracking. This disclosure provides improvements for processing the point cloud data that has been collected. The processing improvements include using a three dimensional polar depth map to assist in performing nearest neighbor analysis on point cloud data for object detection, trajectory detection, freespace detection, obstacle detection, landmark detection, and providing other geometric space parameters."
10776532,"A system and method for solving linear complementarity problems for rigid body simulation is disclosed. The method includes determining a plurality of modified effective masses for a plurality of contacts between a plurality of bodies, wherein each modified effective mass term is based on a corresponding number of contacts. A plurality of relative velocities is determined based on the plurality of body velocities determined from a last iteration. A plurality of impulse corrections is determined based on the plurality of modified effective masses and the plurality of relative velocities. A plurality of updated impulses is determined based on the impulse corrections. The plurality of updated impulses is applied to the plurality of bodies based on a plurality of original masses of the bodies, body velocities determined from the last iteration, to determine a plurality of updated velocities of the plurality of bodies."
10776688,Video interpolation is used to predict one or more intermediate frames at timesteps defined between two consecutive frames. A first neural network model approximates optical flow data defining motion between the two consecutive frames. A second neural network model refines the optical flow data and predicts visibility maps for each timestep. The two consecutive frames are warped according to the refined optical flow data for each timestep to produce pairs of warped frames for each timestep. The second neural network model then fuses the pair of warped frames based on the visibility maps to produce the intermediate frame for each timestep. Artifacts caused by motion boundaries and occlusions are reduced in the predicted intermediate frames.
10776983,"Various types of systems or technologies can be used to collect data in a 3D space. For example, LiDAR (light detection and ranging) and RADAR (radio detection and ranging) systems are commonly used to generate point cloud data for 3D space around vehicles, for such functions as localization, mapping, and tracking. This disclosure provides improvements for processing the point cloud data that has been collected. The processing improvements include analyzing point cloud data using trajectory equations, depth maps, and texture maps. The processing improvements also include representing the point cloud data by a two dimensional depth map or a texture map and using the depth map or texture map to provide object motion, obstacle detection, freespace detection, and landmark detection for an area surrounding a vehicle."
10776985,"Disclosed approaches may leverage the actual spatial and reflective properties of a virtual environment—such as the size, shape, and orientation of a bidirectional reflectance distribution function (BRDF) lobe of a light path and its position relative to a reflection surface, a virtual screen, and a virtual camera—to produce, for a pixel, an anisotropic kernel filter having dimensions and weights that accurately reflect the spatial characteristics of the virtual environment as well as the reflective properties of the surface. In order to accomplish this, geometry may be computed that corresponds to a projection of a reflection of the BRDF lobe below the surface along a view vector to the pixel. Using this approach, the dimensions of the anisotropic filter kernel may correspond to the BRDF lobe to accurately reflect the spatial characteristics of the virtual environment as well as the reflective properties of the surface."
10776995,"The introduced method and system use a 4-dimensional (4D) light field as a background of a scene, instead of 2D background image. Realizing computing a light field takes tremendous amounts of processing power, data storage and time (even with the currently available hardware), the introduced method and system compute and store the light field before rendering a scene. To reduce the time storing and accessing the light field during the rendering process, the introduced method and system also uses a modified video codec to compress and decompress the light field as 2D images."
10783393,"A method, computer readable medium, and system are disclosed for sequential multi-tasking to generate coordinates of landmarks within images. The landmark locations may be identified on an image of a human face and used for emotion recognition, face identity verification, eye gaze tracking, pose estimation, etc. A neural network model processes input image data to generate pixel-level likelihood estimates for landmarks in the input image data and a soft-argmax function computes predicted coordinates of each landmark based on the pixel-level likelihood estimates."
10783394,"A method, computer readable medium, and system are disclosed to generate coordinates of landmarks within images. The landmark locations may be identified on an image of a human face and used for emotion recognition, face identity verification, eye gaze tracking, pose estimation, etc. A transform is applied to input image data to produce transformed input image data. The transform is also applied to predicted coordinates for landmarks of the input image data to produce transformed predicted coordinates. A neural network model processes the transformed input image data to generate additional landmarks of the transformed input image data and additional predicted coordinates for each one of the additional landmarks. Parameters of the neural network model are updated to reduce differences between the transformed predicted coordinates and the additional predicted coordinates."
10783950,"The present invention facilitates efficient and effective utilization of storage management features. In one embodiment, a system comprises: a storage component, a memory controller, and a communication link. The storage component stores information. The memory controller controls the storage component. The communication link communicatively couples the storage component and the memory controller. In one embodiment, the communication link communicates storage system management information between the memory storage component and memory controller, and communication of the storage system management information does not interfere with command/address information communication and data information communication. In one exemplary implementation, the communication link comprises: a data bus that communicates data; a command/address bus that communicates commands and addresses, wherein the command and the addresses are related to the storage of the data; and a management communication bus that communicates storage system management information."
10789194,"Systems and techniques for synchronizing transactions between processing devices on an interconnection network are provided. Upon receiving a stream of posted transactions followed by a flush transaction from a source processing device connected to the interconnection network, the flush transaction is trapped before it enters the interconnecting network. Subsequently, based on monitoring for responses received from a destination processing device for transactions corresponding to the posted transactions, a flush response is generated and returned to the source processing device. The described techniques enable efficient synchronizing posted writes, posted atomics and the like over complex interconnection fabrics such that a first GPU can write data to a second GPU so that a third GPU can safely consume the data written to the second GPU."
10789678,A superpixel sampling network utilizes a neural network coupled to a differentiable simple linear iterative clustering component to determine pixel-superpixel associations from a set of pixel features output by the neural network. The superpixel sampling network computes updated superpixel centers and final pixel-superpixel associations over a number of iterations.
10790628,"A power adapter has a solenoid actuated retaining latch controlled by an electronic circuit that detects the presence or absence of AC mains voltage. When the assembled AC-DC adapter and plug assembly are removed from the wall, the latch detects removal and unlocks the plug assembly for easy removal without undue force required by the user. The circuit is designed for minimal power consumption, and the solenoid only consumes power when it is engaging or disengaging the latch."
10795691,"A system, method, and computer program product are provided for simultaneously determining settings for a plurality of parameter variations. In use, a plurality of parameter variations associated with a device is identified. Additionally, settings for each of the plurality of parameter variations are determined simultaneously."
10795722,"One embodiment of the present invention sets forth a technique for encapsulating compute task state that enables out-of-order scheduling and execution of the compute tasks. The scheduling circuitry organizes the compute tasks into groups based on priority levels. The compute tasks may then be selected for execution using different scheduling schemes. Each group is maintained as a linked list of pointers to compute tasks that are encoded as task metadata (TMD) stored in memory. A TMD encapsulates the state and parameters needed to initialize, schedule, and execute a compute task."
10798457,"A gaming system includes a network server and a gaming manager communicatively coupled to the network server. The gaming manager having a video control unit that starts a video game running remotely with a static video portion and a user interactive video portion and a video receiving unit, coupled to the video control unit, that receives the static video portion for local display while the user interactive video portion is being initialized remotely for subsequent local game play. The gaming system further includes a local user device, coupled to the gaming manager, that initially displays the static video portion and provides a user interface for the subsequent local game play following completion of remote initialization of the user interactive video portion. A method of managing a remote game is also provided."
10810455,"An image processing method transforms image sequences into luminances, filters the luminances, determines the temporal differences between the luminances, performs a frequency domain transformation on the temporal differences, and applies a temporal contrast sensitivity function envelope integral to the frequency transform output to generate a temporal image metric. The temporal image metric may be applied for example to train a neural network or to configure a display device to depict a visual indication of the temporal image metric."
10810784,"Systems and methods for improved texture mapping and graphics processing are described. According to an example implementation, whole or parts of texture blocks are prefetched to an intermediate cache by a processing unit so that the same processing unit or another processing unit can subsequently obtain the prefetched texture block from the intermediate cache. Moreover, in some example implementations, control circuitry associated with the intermediate cache may throttle prefetch requests in order to avoid the memory system and/or the interconnect system receiving excessive amounts of prefetch requests. Additionally, in some implementations, deduplication of prefetch requests can be performed at the intermediate cache and/or the processing unit. Some implementations also include an efficient technique for calculating the address of the next texture block to be prefetched."
10810785,"In a ray tracer, to prevent any long-running query from hanging the graphics processing unit, a traversal coprocessor provides a preemption mechanism that will allow rays to stop processing or time out early. The example non-limiting implementations described herein provide such a preemption mechanism, including a forward progress guarantee, and additional programmable timeout options that can be time or cycle based. Those programmable options provide a means for quality of service timing guarantees for applications such as virtual reality (VR) that have strict timing requirements."
10817043,A technique is disclosed for a graphics processing unit (GPU) to enter and exit a power saving deep sleep mode. The technique involves preserving processing state within local memory by configuring the local memory to operate in a self-refresh mode while the GPU is powered off for deep sleep. An interface circuit coupled to the local memory is configured to prevent spurious GPU signals from disrupting proper self-refresh of the local memory. Spurious GPU signals may result from GPU power down and GPU power up events associated with the GPU entering and exiting the deep sleep mode.
10817289,Software-only and software-hardware optimizations to reduce the overhead of intra-thread instruction duplication on a GPU or other instruction processor are disclosed. The optimizations trade off error containment for performance and include ISA extensions with limited hardware changes and area costs.
10817295,"A streaming multiprocessor (SM) includes a nanosleep (NS) unit configured to cause individual threads executing on the SM to sleep for a programmer-specified interval of time. For a given thread, the NS unit parses a NANOSLEEP instruction and extracts a sleep time. The NS unit then maps the sleep time to a single bit of a timer and causes the thread to sleep. When the timer bit changes, the sleep time expires, and the NS unit awakens the thread. The thread may then continue executing. The SM also includes a nanotrap (NT) unit configured to issue traps using a similar timing mechanism to that described above. For a given thread, the NT unit parses a NANOTRAP instruction and extracts a trap time. The NT unit then maps the trap time to a single bit of a timer. When the timer bit changes, the NT unit issues a trap."
10817338,"Embodiments of the present invention set forth techniques for allocating execution resources to groups of threads within a graphics processing unit. A compute work distributor included in the graphics processing unit receives an indication from a process that a first group of threads is to be launched. The compute work distributor determines that a first subcontext associated with the process has at least one processor credit. In some embodiments, CTAs may be launched even when there are no processor credits, if one of the TPCs that was already acquired has sufficient space. The compute work distributor identifies a first processor included in a plurality of processors that has a processing load that is less than or equal to the processor loads associated with all other processors included in the plurality of processors. The compute work distributor launches the first group of threads to execute on the first processor."
10817609,A secure reconfigurable operating mode system includes a hardware device having multiple operating modes and an operating mode selector that is coupled to the hardware device. The operating mode selector has a virtual fusing register that selects an operating mode for the hardware device and a security processor that enables a secure virtual fusing based on documented security files authorizing selection of the operating mode. A method of secure hardware device operating mode reconfiguration is also provided.
10820057,"A communication method between a source device and a target device utilizes speculative connection setup between the source device and the target device, target-device-side packet ordering, and fine-grained ordering to remove packet dependencies."
10825230,A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to properly handle numerically challenging computations at or near edges and/or vertices of primitives and/or ensure that a single intersection is reported when a ray intersects a surface formed by primitives at or near edges and/or vertices of the primitives.
10825232,"A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include opaque and alpha triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to determine primitives intersected by the ray, and return intersection information to a streaming multiprocessor for further processing. The hardware-based traversal coprocessor is configured to omit reporting of one or more primitives the ray is determined to intersect. The omitted primitives include primitives which are provably capable of being omitted without a functional impact on visualizing the virtual scene."
10826786,"Point cloud registration sits at the core of many important and challenging 3D perception problems including autonomous navigation, object/scene recognition, and augmented reality (AR). A new registration algorithm is presented that achieves speed and accuracy by registering a point cloud to a representation of a reference point cloud. A target point cloud is registered to the reference point cloud by iterating through a number of cycles of an EM algorithm where, during an Expectation step, each point in the target point cloud is associated with a node of a hierarchical tree data structure and, during a Maximization step, an estimated transformation is determined based on the association of the points with corresponding nodes of the hierarchical tree data structure. The estimated transformation is determined by solving a minimization problem associated with a sum, over a number of mixture components, over terms related to a Mahalanobis distance."
10833681,This disclosure relates to a receiver comprising a clock and data recovery loop and a phase offset loop. The clock and data recovery loop may be controlled by a sum of gradients for a plurality of data interleaves. The phase offset loop may be controlled by an accumulated differential gradient for each of the data interleaves.
10838459,"A method for displaying a near-eye light field display (NELD) image is disclosed. The method comprises determining a pre-filtered image to be displayed, wherein the pre-filtered image corresponds to a target image. It further comprises displaying the pre-filtered image on a display. Subsequently, it comprises producing a near-eye light field after the pre-filtered image travels through a microlens array adjacent to the display, wherein the near-eye light field is operable to simulate a light field corresponding to the target image. Finally, it comprises altering the near-eye light field using at least one converging lens, wherein the altering allows a user to focus on the target image at an increased depth of field at an increased distance from an eye of the user and wherein the altering increases spatial resolution of said target image."
10838492,"A gaze tracking system for use in head mounted displays includes an eyepiece having an opaque frame circumferentially enclosing a transparent field of view, light emitting diodes coupled to the opaque frame for emitting infrared light onto various regions of an eye gazing through the transparent field of view, and diodes for sensing intensity of infrared light reflected off of various regions of the eye."
10839591,"The disclosure provides a virtual view broadcaster, a cloud-based renderer, and a method of providing stereoscopic images. In one embodiment, the method includes (1) generating a monoscopic set of rendered images and (2) converting the set of rendered images into a stereoscopic pair of images employing depth information from the monoscopic set of rendered images and raymarching."
10843084,"Embodiments of the present invention provide a novel solution which can be used to detect and analyze instances of micro stutter within a given game, GPU and/or driver version. Embodiments of the present invention may be operable to divide an application session into a set of sub-sessions and perform multiple derivative calculations on time-varying application parameters (e.g., frame rates) measured during each sub-session. Embodiments of the present invention may also be operable to generate separate histograms for each derivative calculation performed. As such, based on calculations performed, embodiments of the present invention may synchronously increment histogram bins representing a corresponding range of performance in real-time. Upon the completion of the application session, sub-session histograms may be compressed and then saved into a log which can be fetched and uploaded to a host computer system for aggregation and storage into a database for server-side optimization analysis."
10845834,A linear regulator for applications with low area constraint resulting in limited load decoupling capacitance that introduces a compensating zero in the regulator loop to counteract the loss of phase margin and further introduces a feed-forward noise cancellation path operating over a wide frequency range covering a first package resonance frequency. The feed-forward path has low power consumption and improves the power-supply rejection ratio.
10852775,"In various examples, a portable computing device is provided that has a bottom shell and a top shell pivotally coupled to the bottom shell for movement between a closed position and at least one open position. A display fits within a perimeter rim of the top shell, the display being obscured from view when the top shell is in the closed position and being viewable when the top shell is in the at least one open position. A coupling linkage couples the display, the top shell, and the bottom shell, to move the display between at least a first position with the display closer to the top shell when the top shell is in the closed position and a second position with at least a portion of the display farther from the top shell when the top shell is in the open position."
10852811,"An integrated circuit such as, for example a graphics processing unit (GPU), having an on-chip analog to digital converter (ADC) for use in overcurrent protection of the chip is described, where the overcurrent protection response times are substantially faster than techniques with external ADC. A system-on-chip (SoC) includes the integrated circuit and a multiplexer arranged externally to the chip having the ADC, where the multiplexer provides the ADC with a data stream of sampling information from a plurality of power sources. Methods for overcurrent protection using an on-chip ADC are also described."
10853044,"System and method of compiling a program having a mixture of host code and device code to enable Profile Guided Optimization (PGO) for device code execution. An exemplary integrated compiler can compile source code programmed to be executed by a host processor (e.g., CPU) and a co-processor (e.g., a GPU) concurrently. The compilation can generate an instrumented executable code which includes: profile instrumentation counters for the device functions; and instructions for the host processor to allocate and initialize device memory for the counters and to retrieve collected profile information from the device memory to generate instrumentation output. The output is fed back to the compiler for compiling the source code a second time to generate optimized executable code for the device functions defined in the source code."
10853994,The disclosure is directed to methods and processes of rendering a complex scene using a combination of raytracing and rasterization. The methods and processes can be implemented in a video driver or software library. A developer of an application can provide information to an application programming interface (API) call as if a conventional raytrace API is being called. The method and processes can analyze the scene using a variety of parameters to determine a grouping of objects within the scene. The rasterization algorithm can use as input primitive cluster data retrieved from raytracing acceleration structures. Each group of objects can be rendered using its own balance of raytracing and rasterization to improve rendering performance while maintaining a visual quality target level.
10860293,"Many computing systems process data organized in a matrix format. For example, artificial neural networks (ANNs) perform numerous computations on data organized into matrices using conventional matrix arithmetic operations. One such operation, which is commonly performed, is the transpose operation. Additionally, many such systems need to process many matrices and/or matrices that are large in size. For sparse matrices that hold few significant values and many values that can be ignored, transmitting and processing all the values in such matrices is wasteful. Thus, techniques are introduced for storing a sparse matrix in a compressed format that allows for a matrix transpose operation to be performed on the compressed matrix without having to first decompress the compressed matrix. By utilizing the introduced techniques, more matrix operations can be performed than conventional systems."
10860859,"Detection of activity in video content, and more particularly detecting in video start and end frames inclusive of an activity and a classification for the activity, is fundamental for video analytics including categorizing, searching, indexing, segmentation, and retrieval of videos. Existing activity detection processes rely on a large set of features and classifiers that exhaustively run over every time step of a video at multiple temporal scales, or as a small improvement computationally propose segments of the video on which to perform classification. These existing activity detection processes, however, are computationally expensive, particularly when trying to achieve activity detection accuracy, and moreover are not configurable for any particular time or computation budget. The present disclosure provides a time and/or computation budget-aware method for detecting activity in video that relies on a recurrent neural network implementing a learned policy."
10860922,"A method, computer program product, and system perform computations using a sparse convolutional neural network accelerator. A first vector comprising only non-zero weight values and first associated positions of the non-zero weight values within a 3D space is received. A second vector comprising only non-zero input activation values and second associated positions of the non-zero input activation values within a 2D space is received. The non-zero weight values are multiplied with the non-zero input activation values, within a multiplier array, to produce a third vector of products. The first associated positions are combined with the second associated positions to produce a fourth vector of positions, where each position in the fourth vector is associated with a respective product in the third vector. The products in the third vector are transmitted to adders in an accumulator array, based on the position associated with each one of the products."
10861230,A graphics processing pipeline includes three architectural features that allow a fragment shader to efficiently calculate per-sample attribute values using barycentric coordinates and per-vertex attributes. The first feature is barycentric coordinate injection to provide barycentric coordinates to the fragment shader. The second feature is an attribute qualifier that allows an attribute of a graphics primitive to be processed without conventional fixed-function interpolation. The third feature is a direct access path from the fragment shader to triangle data storage hardware resources where vertex attribute data and/or plane equation coefficients are stored. Allowing the fragment shader to calculate per-sample attribute values in this way advantageously increases system flexibility while reducing workload associated with triangle plane equation setup.
10866806,"A compiler parses a multithreaded application into cohesive blocks of instructions. Cohesive blocks include instructions that do not diverge or converge. Each cohesive block is associated with one or more uniform registers. When a set of threads executes the instructions in a given cohesive block, each thread in the set may access the uniform register independently of the other threads in the set. Accordingly, the uniform register may store a single copy of data on behalf of all threads in the set of threads, thereby conserving resources."
10866990,"An apparatus, computer readable medium, and method are disclosed for decompressing compressed geometric data stored in a lossless compression format. The compressed geometric data resides within a compression block sized according to a system cache line. An indirection technique maps a global identifier value in a linear identifier space to corresponding variable rate compressed data. The apparatus may include decompression circuitry within a graphics processing unit configured to perform ray-tracing."
10867008,"Embodiments of the present invention provide a hierarchical, multi-layer Jacobi method for implementing a dense symmetric eigenvalue solver using multiple processors. Each layer of the hierarchical method is configured to process problems of different sizes, and the division between the layers is defined according to the configuration of the underlying computer system, such as memory capacity and processing power, as well as the communication overhead between device and host. In general, the higher-level Jacobi kernel methods call the lower level Jacobi kernel methods, and the results are passed up the hierarchy. This process is iteratively performed until a convergence condition is reached. Embodiments of the hierarchical Jacobi method disclosed herein offers controllability of Schur decomposition, robust tolerance for passing data throughout the hierarchy, and significant cost reduction on row update compared to existing methods."
10867214,"Training deep neural networks requires a large amount of labeled training data. Conventionally, labeled training data is generated by gathering real images that are manually labelled which is very time-consuming. Instead of manually labelling a training dataset, domain randomization technique is used generate training data that is automatically labeled. The generated training data may be used to train neural networks for object detection and segmentation (labelling) tasks. In an embodiment, the generated training data includes synthetic input images generated by rendering three-dimensional (3D) objects of interest in a 3D scene. In an embodiment, the generated training data includes synthetic input images generated by rendering 3D objects of interest on a 2D background image. The 3D objects of interest are objects that a neural network is trained to detect and/or label."
10867429,"Methods and systems are described in some examples for changing the traversal of an acceleration data structure in a highly dynamic query-specific manner, with each query specifying test parameters, a test opcode and a mapping of test results to actions. In an example ray tracing implementation, traversal of a bounding volume hierarchy by a ray is performed with the default behavior of the traversal being changed in accordance with results of a test performed using the test opcode and test parameters specified in the ray data structure and another test parameter specified in a node of the bounding volume hierarchy. In an example implementation a traversal coprocessor is configured to perform the traversal of the bounding volume hierarchy."
10871939,"A virtual reality (VR) audio rendering system and method of using HRTF functions to quickly capture new positional cues to pre-computed audio frames responsive to changes in user position relative to sound systems. In a client-server VR system, when a user position change is detected, the client determines an appropriate HRTF based on the new position and convolves them with a set of audio frames that have been generated by the server based on a prior position, resulting in modified frames for rendering. Meanwhile, the client propagates the new position to the server to generate subsequent audio frames for the corrected position. As HRTF convolution is computationally inexpensive, the latency between user position change and the resultant sound change as perceived by the user can be significantly reduced. As a result, an immersive VR experience of the user can be preserved."
10872399,"Photorealistic image stylization concerns transferring style of a reference photo to a content photo with the constraint that the stylized photo should remain photorealistic. Examples of styles include seasons (summer, winter, etc.), weather (sunny, rainy, foggy, etc.), lighting (daytime, nighttime, etc.). A photorealistic image stylization process includes a stylization step and a smoothing step. The stylization step transfers the style of the reference photo to the content photo. A photo style transfer neural network model receives a photorealistic content image and a photorealistic style image and generates an intermediate stylized photorealistic image that includes the content of the content image modified according to the style image. A smoothing function receives the intermediate stylized photorealistic image and pixel similarity data and generates the stylized photorealistic image, ensuring spatially consistent stylizations."
10877757,"A just-in-time (JIT) compiler binds constants to specific memory locations at runtime. The JIT compiler parses program code derived from a multithreaded application and identifies an instruction that references a uniform constant. The JIT compiler then determines a chain of pointers that originates within a root table specified in the multithreaded application and terminates at the uniform constant. The JIT compiler generates additional instructions for traversing the chain of pointers and inserts these instructions into the program code. A parallel processor executes this compiled code and, in doing so, causes a thread to traverse the chain of pointers and bind the uniform constant to a uniform register at runtime. Each thread in a group of threads executing on the parallel processor may then access the uniform constant."
10878611,"In various embodiments, a deduplication application pre-processes index buffers for a graphics processing pipeline that generates rendered images via a shading program. In operation, the deduplication application causes execution threads to identify a set of unique vertices specified in an index buffer based on an instruction. The deduplication application then generates a vertex buffer and an indirect index buffer based on the set of unique vertices. The vertex buffer and the indirect index buffer are associated with a portion of an input mesh. The graphics processing pipeline then renders a first frame and a second frame based on the vertex buffer, the indirect index buffer, and the shading program. Advantageously, the graphics processing pipeline may re-use the vertex buffer and indirect index buffer until the topology of the input mesh changes."
10878770,"Embodiments of the present invention provide a novel solution that uses subjective end-user input to generate optimal image quality settings for an application. Embodiments of the present invention enable end-users to rank and/or select various adjustable application parameter settings in a manner that allows them to specify which application parameters and/or settings are most desirable to them for a given application. Based on the feedback received from end-users, embodiments of the present invention may generate optimal settings for whatever performance level the end-user desires. Furthermore, embodiments of the present invention may generate optimal settings that may be benchmarked either on a server farm or on an end-user's client device."
10880531,"The disclosure is directed to transforming signals from one signal format to another signal format. For example, the format of a digital signal can change from storing video information in 12 bits of data to storing the video information in 32 bits of data. Other storage values and combinations can also be used. Since the number of bits available to store a portion of the video information can change when changing formats, a process is needed to translate or transform the video information appropriately. A transfer function utilizing a lookup table is used for the transforming. The lookup table utilizes a variable step size segmentation scheme that decreases the amount of lookup table storage space required and also decreases the number of estimation errors, i.e., interpolation errors. Estimation errors can occur when looking up a value not stored in the lookup table, and using neighboring values that are stored to estimate the value requested. In some applications, the log2 step size or total size values can be stored in the lookup table to further reduce the amount of storage space required. A video parameter, such as the type of video content and the display room ambiance, can also be used to select the balance between further decreasing the size of the lookup table and further decreasing the estimation errors."
10884734,"A method, computer readable medium, and processor are disclosed for performing matrix multiply and accumulate (MMA) operations. The processor includes a datapath configured to execute the MMA operation to generate a plurality of elements of a result matrix at an output of the datapath. Each element of the result matrix is generated by calculating at least one dot product of corresponding pairs of vectors associated with matrix operands specified in an instruction for the MMA operation. A dot product operation includes the steps of: generating a plurality of partial products by multiplying each element of a first vector with a corresponding element of a second vector; aligning the plurality of partial products based on the exponents associated with each element of the first vector and each element of the second vector; and accumulating the plurality of aligned partial products into a result queue utilizing at least one adder."
10885698,"In a ray tracer, to prevent any long-running query from hanging the graphics processing unit, a traversal coprocessor provides a preemption mechanism that will allow rays to stop processing or time out early. The example non-limiting implementations described herein provide such a preemption mechanism, including a forward progress guarantee, and additional programmable timeout options that can be time or cycle based. Those programmable options provide a means for quality of service timing guarantees for applications such as virtual reality (VR) that have strict timing requirements."
10890620,"Systems and methods enable the updating of tests, test sequences, fault models, and test conditions such as voltage and clock frequencies, over the life cycle of a safety critical application for complex integrated circuits and systems."
10891538,"A method, computer program product, and system perform computations using a processor. A first instruction including a first index vector operand and a second index vector operand is received and the first index vector operand is decoded to produce first coordinate sets for a first array, each first coordinate set including at least a first coordinate and a second coordinate of a position of a non-zero element in the first array. The second index vector operand is decoded to produce second coordinate sets for a second array, each second coordinate set including at least a third coordinate and a fourth coordinate of a position of a non-zero element in the second array. The first coordinate sets are summed with the second coordinate sets to produce output coordinate sets and the output coordinate sets are converted into a set of linear indices."
10891775,"A method, computer readable medium, and system are disclosed for implementing automatic level-of-detail for physically-based materials. The method includes the steps of identifying a declarative representation of a material to be rendered, creating a reduced complexity declarative representation of the material by applying one or more term rewriting rules to the declarative representation of the material, and returning the reduced complexity declarative representation of the material."
10891783,"Determining the occlusions or shadows for an area light within a scene is difficult, especially realistic shadowing in large and dynamic scenes. The disclosure provides an adaptive occlusion sampling process that uses voxel cone tracing to distribute the voxel tracing cones on the surface of area lights to obtain samples for shadowing in computer generated images or scenes. A method of adaptive occlusion sampling from a rectangular area light is disclosed that can be used to provide realistic shadowing in a computer generated scene. A process to compute a shadow of an area light within a scene is also disclosed herein that includes obtaining samples, employing voxel cone tracing, from a light surface of the area light based on sample points of a sampling grid created from sample patterns that are based on a determined number of cones."
10896021,"The disclosure is directed to a process that can predict an audio glitch, and then attempt to preempt the audio glitch. The process can monitor the systems, processes, and execution threads on a larger system or device, such as a mobile device or an in-vehicle device. Using a learning algorithm, such as deep neural network (DNN), the information collected can generate a prediction of whether an audio glitch is likely to occur. An audio glitch can be an audio underrun condition. The process can use a second learning algorithm, which also can be a DNN, to generate recommended system adjustments that can attempt to prevent the audio glitch from occurring. The recommendations can be for various systems and components on the device, such as changing the processing system frequency, the memory frequency, and the audio buffer size. After the audio underrun condition has abated, the system adjustments can be reversed fully or in steps to return the system to its state prior to the system adjustments."
10901017,"Embodiments of the present invention reconstruct a waveform at a receiver-end of a channel from an observed waveform physically measured at a probe point near the middle of the channel, where the channel is corrupted by reflections. The channel may be a memory channel of a high-speed I/O interface, for example. Equations to derive the waveform may be created using linear network analysis and/or signal processing, for example. S-parameters may be derived from simulated models representing components from the probe point to the load. The s-parameters together with the load impedance are used to recreate the desired waveform free from corruption due to reflections."
10902556,"The disclosure is directed to a method to compensate for visual distortion when viewing video image streams from a multiple camera capture of a scene where the method determines the disparity difference utilizing the user view orientation and then compresses and/or stretches the left and/or right eye video image streams to compensate for the visual distortion. In another aspect, the method describes additional adjustments and corrections to the video image streams including rotating, tilting, shifting, and scaling the video image streams, and correcting for gapping and clipping visual image artifacts. In another aspect, a visual compensation system is described to implement the method. Additionally, a visual compensation apparatus is disclosed to perform the method operations."
10902616,"Navigation instructions are determined using visual data or other sensory information. Individual frames can be extracted from video data, captured from passes through an environment, to generate a sequence of image frames. The frames are processed using a feature extractor to generate frame-specific feature vectors. Image triplets are generated, including a representative image frame (or corresponding feature vector), a similar image frame adjacent in the sequence, and a disparate image frame that is separated by a number of frames in the sequence. The embedding network is trained using the triplets. Image data for a current position and a target destination can then be provided as input to the trained embedding model, which outputs a navigation vector indicating a direction and distance over which the vehicle is to be navigated in the physical environment."
10902933,"In various examples, a test system is provided for executing built-in-self-test (BIST) according to JTAG and IEEE 1500 on chips deployed in-field. Hardware and software selectively connect onto the IEEE 1500 serial interface for running BIST while the chip is being used in deployment—such as in an autonomous vehicle. In addition to providing a mechanism to connect onto the serial interface, the hardware and software may reduce memory requirements and runtime associated with running the test sequences, thereby making BIST possible in deployment. Furthermore, some embodiments include components configured to store functional states of clocks, power, and input/output prior to running BIST, which permits restoration of the functional states after the BIST."
10908878,"A method, computer readable medium, and system are disclosed for rounding floating point values. Dynamic directional rounding is a rounding technique for floating point operations. A floating point operation (addition, subtraction, multiplication, etc.) is performed on an operand to compute a floating point result. A sign (positive or negative) of the operand is identified. In one embodiment, the sign determines a direction in which the floating point result is rounded (towards negative or positive infinity). When used for updating parameters of a neural network during backpropagation, dynamic directional rounding ensures that rounding is performed in the direction of the gradient."
10908995,"In general, data is susceptible to errors caused by faults in hardware (i.e. permanent faults), such as faults in the functioning of memory and/or communication channels. To detect errors in data caused by hardware faults, the error correcting code (ECC) was introduced, which essentially provides a sort of redundancy to the data that can be used to validate that the data is free from errors caused by hardware faults. In some cases, the ECC can also be used to correct errors in the data caused by hardware faults. However, the ECC itself is also susceptible to errors, including specifically errors caused by faults in the ECC logic. A method, computer readable medium, and system are thus provided for securing against errors in an ECC."
10909033,"Techniques are disclosed for allocating a global memory space defined within physical memory devices into strided memory space(s) (SMS) and partition memory space(s) (PMS). In an embodiment, a SMS is mapped across all of the devices, and a PMS is mapped to a subset of the devices to ensure resource isolation between separate PMSs. Typically, a memory space is allocated in unit sizes. When the locations mapped to most of the SMS align to an integer number of the unit size, a common boundary can be formed between the SMS and the one or more PMSs in each of the devices. Such a boundary can advantageously minimize a region of locations that are not available for allocation in the global memory spaces. In an embodiment, when a strided allocation is not an integer number of the unit size, a remainder is mapped to locations for one or more PMSs."
10909738,"Graphics processing unit (GPU) performance and power efficiency is improved using machine learning to tune operating parameters based on performance monitor values and application information. Performance monitor values are processed using machine learning techniques to generate model parameters, which are used by a control unit within the GPU to provide real-time updates to the operating parameters. In one embodiment, a neural network processes the performance monitor values to generate operating parameters in real-time."
10909739,"In various embodiments, a parallel processor implements a graphics processing pipeline that generates rendered images. In operation, the parallel processor causes execution threads to execute a task shading program on an input mesh to generate a task shader output specifying a mesh shader count. The parallel processor then generates mesh shader identifiers, where the total number of the mesh shader identifiers equals the mesh shader count. For each mesh shader identifier, the parallel processor invokes a mesh shader based on the mesh shader identifier and the task shader output to generate geometry associated with the mesh shader identifier. Subsequently, the parallel processor performs operations on the geometries associated with the mesh shader identifiers to generate a rendered image. Advantageously, unlike conventional graphics processing pipelines, the performance of the graphics processing pipeline is not limited by a primitive distributor."
10909903,A display device includes a display controller that performs a high-throughput dithering operation. The display controller performs a quantization operation with pixel values generated by a graphics processor to generate quantized pixel values and residual error values. The display controller distributes the residual error values associated with a first group of quantized pixel values to a second group of quantized pixel values based on a set of distribution weights. A given distribution weight defines what fraction of a given residual error value is distributed to a given quantized pixel value included in the second group of quantized pixel values. The distribution weights are calibrated to permit the display controller to compute different fractions of residual error values using bit shifting logic instead of complex combinatorial logic.
10915115,"A semi-public blockchain maintained on one or more nodes in a map cloud platform comprises data for maintaining a global map of a predetermined geographic area. The blockchain also comprises a plurality of data records, where each data record is associated with an update to a global map. When a message associated with a map update to the global map is received, the nodes of the blockchain determine a consensus by evaluating the map update, where the evaluating comprises performing a plurality of proofs including a proof of location, a proof of iterations, a proof of physical delivery and a proof of safety. When consensus is attained and the map update is validated, a data record associated with the map update is generated and added to the blockchain with a timestamp and a link to prior data records in the blockchain."
10915364,"Apparatuses, systems, and techniques for performing nested kernel execution within a parallel processing subsystem. In at least one embodiment, a parent thread launches a nested child grid on the parallel processing subsystem, and enables the parent thread to perform a thread synchronization barrier on the child grid for proper execution semantics between the parent thread and the child grid."
10915445,"A method, computer readable medium, and system are disclosed for a distributed cache that provides multiple processing units with fast access to a portion of data, which is stored in local memory. The distributed cache is composed of multiple smaller caches, and each of the smaller caches is associated with at least one processing unit. In addition to a shared crossbar network through which data is transferred between processing units and the smaller caches, a dedicated connection is provided between two or more smaller caches that form a partner cache set. Transferring data through the dedicated connections reduces congestion on the shared crossbar network. Reducing congestion on the shared crossbar network increases the available bandwidth and allows the number of processing units to increase. A coherence protocol is defined for accessing data stored in the distributed cache and for transferring data between the smaller caches of a partner cache set."
10916252,"Systems and methods relying on recognition of a pattern in a data stream, such as detecting a hotword in an audio data stream are sensitive to latency (e.g., response time). To reduce power consumption, a low power processor may be used in combination with a higher power speech recognition device. When the hotword is detected by the low power signal processor, the primary speech recognition device is signaled to wake up and begin emptying a buffer storing the hotword and subsequent audio data. Latency is the delay incurred to recognize the hotword and begin emptying the buffer. To catch-up and reduce the latency, the buffer is drained at a faster rate than the buffer is filled until a latency reduction trigger is received. The latency reduction trigger is generated when the latency has been reduced to a predetermined level."
10916841,"Techniques for providing multi-antenna devices with increased antenna-to-antenna isolation as well as methods of operating and manufacturing the same are disclosed. A multi-antenna device may include a support structure, one or more radio devices coupled to a first antenna that is coupled to the support structure at a first location, a second antenna coupled to the support structure at a second location and communicatively coupled to the one or more radio devices, and a conductive structure coupled to the support structure so that it shifts an electric field null of the first antenna from an original location toward the second location during communications using the first antenna, thereby increasing isolation between the first antenna and the second antenna. The conductive structure may have a length of approximately one half of the wavelength (e.g., of 2.4 gigahertz or 5 gigahertz) of a frequency band used for the communications."
10922203,"Unavoidable physical phenomena, such as an alpha particle strikes, can cause soft errors in integrated circuits. Materials that emit alpha particles are ubiquitous, and higher energy cosmic particles penetrate the atmosphere and also cause soft errors. Some soft errors have no consequence, but others can cause an integrated circuit to malfunction. In some applications (e.g. driverless cars), proper operation of integrated circuits is critical to human life and safety. To minimize or eliminate the likelihood of a soft error becoming a serious malfunction, detailed assessment of individual potential soft errors and subsequent processor behavior is necessary. Embodiments of the present disclosure facilitate emulating a plurality of different, specific soft errors. Resilience may be assessed over the plurality of soft errors and application code may be advantageously engineered to improve resilience. Normal processor execution is halted to inject a given state error through a scan chain, and execution is subsequently resumed."
10922793,"Missing image content is generated using a neural network. In an embodiment, a high resolution image and associated high resolution semantic label map are generated from a low resolution image and associated low resolution semantic label map. The input image/map pair (low resolution image and associated low resolution semantic label map) lacks detail and is therefore missing content. Rather than simply enhancing the input image/map pair, data missing in the input image/map pair is improvised or hallucinated by a neural network, creating plausible content while maintaining spatio-temporal consistency. Missing content is hallucinated to generate a detailed zoomed in portion of an image. Missing content is hallucinated to generate different variations of an image, such as different seasons or weather conditions for a driving video."
10922876,"A method, computer readable medium, and system are disclosed for redirecting a user's movement through a physical space while the user views a virtual environment. A temporary visual suppression event is detected when a user's eyes move relative to the user's head while viewing a virtual scene displayed on a display device, an orientation of the virtual scene relative to the user is modified to direct the user to physically move along a planned path through a virtual environment corresponding to the virtual scene, and the virtual scene is displayed on the display device according to the modified orientation."
10929591,Various embodiments of the disclosure disclosed herein provide techniques for pre-silicon testing of a design for an integrated circuit. A pre-silicon testing system identifies one or more critical paths included in the integrated circuit. The pre-silicon testing system performs a based noise simulation to generate one or more voltage waveforms at each gate associated with the one or more critical paths. The pre-silicon testing system applies the one or more voltage waveforms to one or more netlists corresponding to the one or more critical paths to generate one or more modified netlists. The pre-silicon testing system performs a timing analysis on the one or more modified netlists to determine a set of slack times that correspond to a set of voltages applied to the integrated circuit. The pre-silicon testing system determines a first critical path that has a lowest slack time relative to all other critical paths.
10929654,"Estimating a three-dimensional (3D) pose of an object, such as a hand or body (human, animal, robot, etc.), from a 2D image is necessary for human-computer interaction. A hand pose can be represented by a set of points in 3D space, called keypoints. Two coordinates (x,y) represent spatial displacement and a third coordinate represents a depth of every point with respect to the camera. A monocular camera is used to capture an image of the 3D pose, but does not capture depth information. A neural network architecture is configured to generate a depth value for each keypoint in the captured image, even when portions of the pose are occluded, or the orientation of the object is ambiguous. Generation of the depth values enables estimation of the 3D pose of the object."
10929987,"A neural network model receives color data for a sequence of images corresponding to a dynamic scene in three-dimensional (3D) space. Motion of objects in the image sequence results from a combination of a dynamic camera orientation and motion or a change in the shape of an object in the 3D space. The neural network model generates two components that are used to produce a 3D motion field representing the dynamic (non-rigid) part of the scene. The two components are information identifying dynamic and static portions of each image and the camera orientation. The dynamic portions of each image contain motion in the 3D space that is independent of the camera orientation. In other words, the motion in the 3D space (estimated 3D scene flow data) is separated from the motion of the camera."
10930022,"Motion adaptive shading increases rendering performance for real-time animation in graphics systems while maintaining dynamic image quality. Each frame of an animation is statically displayed within a refresh interval, while a viewer's eyes move continuously relative to the image when actively tracking a moving object being displayed. As a result, a statically displayed frame is essentially smeared across the viewer's continuously moving retina over the lifetime of the frame, causing a perception of blur referred to as an eye-tracking motion blur effect. A region of an image depicting a moving object may be rendered at a lower shading rate because eye-tracking motion blur will substantially mask any blur introduced by reducing the shading rate. Reducing an average shading rate for rendering frames reduces computational effort per frame and may advantageously allow a rendering system to operate at a higher frame rate to provide a smoother, clearer visual experience."
10931266,"A flip-flop element is configured to gate the clock inversions within a master-slave flip-flop element. The flip-flop element reduces the number of circuit elements within the flip-flop element by collapsing elements with common functionality into a single circuit element. Further, by making the actions of judiciously selected circuit elements conditional upon the state of the input data, the flip-flop element circuit reduces the number of internal transitions. In this manner, by reducing the number of circuit elements as well as the number of transitions, the flip-flop element achieves substantial reduction in overall system power consumption, resulting in a more efficient system."
10935788,"A method for stereoscopically presenting visual content is disclosed. The method comprises identifying and distinguishing between a first type of content and a second type of content of a frame to be stereoscopically displayed. The method also comprises rendering the first type of content in a first left and a first right frame from a single perspective using a first stereoscopic rendering method. Further, the method comprises rendering the second type of content in a second left and a second right frame using a second, different stereoscopic method from two different perspectives. Additionally, the method comprises merging the first and second left frames and the first and second right frames to produce a resultant left frame and a resultant right frame. Finally, the method comprises displaying the resultant left frame and the resultant right frame for stereoscopic perception by a viewer."
10943387,"This disclosure presents a technique for utilizing ray tracing to produce a high quality visual scene that includes shadows while minimizing computing costs. Since the scene quality and computing cost is directly proportional to the number of rays used, this technique can lower the number of rays needed for shadow region rendering while maintaining a targeted visual quality for the scene. The process includes generating a complex pixel mask based on depth boundary testing, and generating a penumbra mask based on the shadow regions. These masks can use distance/depth data to cull certain pixels from their respective analysis to reduce processing time. A penumbra area can then be denoised using the two masks and the distance/depth data. Finally, the depth boundary pixel computations, i.e., complex pixels, can be resolved. From these processes, a final shadow mask can be generated and sent to the rendering process to complete the scene rendering."
10943882,"An IC package including an integrated circuit die having a major surface and one or more solder bumps located on the major surface in at least one corner region of the major surface and a substrate having a surface, the surface including bump pads thereon. The major surface of the integrated circuit die faces the substrate surface, the one or more solder bumps are bonded to individual ones of the bump pads to thereby form a bond joint, the major surface of the integrated circuit die has a footprint area of at least about 400 mm2. A ratio of a coefficient of thermal expansion of the substrate (CTEsub) to a coefficient of thermal expansion of the integrated circuit die (CTEdie) is at least about 3:1. A method of manufacturing an IC package is also disclosed."
10946281,"In various embodiments of the present disclosure, playstyle patterns of players are learned and used to generate virtual representations (“bots”) of users. Systems and methods are disclosed that use game session data (e.g., metadata) from a plurality of game sessions of a game to learn playstyle patterns of users, based on user inputs of the user in view of variables presented within the game sessions. The game session data is applied to one or more machine learning models to learn playstyle patterns of the user for the game, and associated with a user profile of the user. Profile data representative of the user profile is then used to control or instantiate bots of the users, or of categories of users, according to the learned playstyle patterns."
10948985,"Perceived clarity of an image presented by a display can be improved using an image stabilization technique to stabilize the image relative to a user's retina. During an illumination period, stabilization actuators are controlled to move a display panel or adjust optical components in the path of light associated with the image to shift the location of the image on the user's retina in response to head or eye movement detected by the system. In some embodiments, a display is configured to illuminate an image, and at least one stabilization actuator is configured to stabilize the image in a retina space associated with a user. Changes in the retina space can be detected by one or more sensors configured to detect a head position of the user and/or an orientation of the user's retina. The image is stabilized in retina space using the stabilization actuators."
10957020,"Embodiments of the present invention provide end-to-end frame time synchronization designed to improve smoothness for displaying images of 3D applications, such as PC gaming applications. Traditionally, an application that renders 3D graphics functions based on the assumption that the average render time will be used as the animation time for a given frame. When this condition is not met, and the render time for a frame does not match the average render time of prior frames, the frames are not captured or displayed at a consistent rate. This invention enables feedback to be provided to the rendering application for adjusting the animation times used to produce new frames, and a post-render queue is used to store completed frames for mitigating stutter and hitches. Flip control is used to sync the display of a rendered frame with the animation time used to generate the frame, thereby producing a smooth, consistent image."
10957078,"A raster unit is configured to generate different sample patterns for adjacent pixels within a given frame. In addition, the raster unit may adjust the sample patterns between frames. The raster unit includes an index unit that selects a sample pattern table for use with a current frame. For a given pixel, the index unit extracts a sample pattern from the selected sample pattern table. The extracted sample pattern is used to generate coverage information for the pixel. The coverage information for all pixels is then used to generate an image. The resultant image may then be filtered to reduce or remove artifacts induced by the changing of sample locations."
10957651,"A die package is disclosed through which power domains within the chip may be isolated by removing vias within the package substrate, rather than power gating. Multiple substrate options may be configured without specific vias. This eliminates the need to design power gating circuitry into the die, freeing up that die area for more functional logic. The solution allows the die package to retain the same pinout for use by PCB designers, regardless of which power domains are gated."
10964000,"Systems and techniques for noise reduction in video are described. Example implementations provide improved motion-adaptive temporal or spatio-temporal noise reduction that use an improved blending of the current frame with previous frames. The improved blending may be particularly effective for processing video captured in noisy environments such as low-light and/or mobile environments. In some example implementations, the improved blending is based on more accurately distinguishing between pixel difference in adjacent images that are caused by motion rather than noise."
10964034,"Due to the factors such as lens distortion and camera misalignment, stereoscopic image pairs often contain vertical disparities. Introduced herein is a method and apparatus that determine and correct vertical disparities in stereoscopic image pairs using an optical flow map. Instead of discarding vertical motion vectors of the optical flow map, the introduced concept extracts and analyzes the vertical motion vectors from the optical flow map and vertically aligns the images using the vertical disparity determined from the vertical motion vectors. The introduced concept recognizes that although not apparent, vertical motion does exist in stereoscopic images and can be used to correct the vertical disparity in stereoscopic images."
10964061,"A deep neural network (DNN) system learns a map representation for estimating a camera position and orientation (pose). The DNN is trained to learn a map representation corresponding to the environment, defining positions and attributes of structures, trees, walls, vehicles, etc. The DNN system learns a map representation that is versatile and performs well for many different environments (indoor, outdoor, natural, synthetic, etc.). The DNN system receives images of an environment captured by a camera (observations) and outputs an estimated camera pose within the environment. The estimated camera pose is used to perform camera localization, i.e., recover the three-dimensional (3D) position and orientation of a moving camera, which is a fundamental task in computer vision with a wide variety of applications in robot navigation, car localization for autonomous driving, device localization for mobile navigation, and augmented/virtual reality."
10965440,"A receiver circuit includes a clock lane propagating a clock signal. A self-sampled clock applies a delayed version of the clock signal to the clock signal and compensation logic controls an amount of delay of the delayed version of the clock, based on a reference voltage offset (difference) between the receiver and a transmitter. The delayed version of the clock is centered on one unit interval of the clock. An offset correction is computed as a global offset value based on a clock duty cycle error, combined with a local offset value for each data lane, and is applied to data receiver front ends."
10969740,"A method for rendering a light field comprises projecting rays from a viewpoint positioned at a first side of a spatial light modulator (SLM) to a clipping plane positioned at an opposing side of the SLM to form an elemental view frustum within a three-dimensional scene and rendering objects within the elemental view frustum to generate components of a first elemental image for the first elemental region. The SLM may include a tiled array of non-overlapping elemental regions and a top edge and a bottom edge of a first elemental region of the non-overlapping elemental regions are intersected by the rays to form the elemental view frustum. Furthermore, the light field may include the first elemental image and additional elemental images corresponding to the array of elemental regions and each one of the additional elemental images is rendered using an additional elemental view frustum."
10970256,"A technique is applied to eventually converge on a single data storage strategy for any set of object data which had an inconsistent data storage strategy applied during storage while there was a network partition. This state could occur in instances of a highly available distributed object storage system which can store objects according to multiple data storage strategies. Upon the healing of a network partition, the technique discovers if multiple data storage strategies were applied to the object data stored during a network partition, deterministically identifies which data storage strategy represents the correct strategy, for example based on the log of state transitions requested by the client according to the API contract, and ensures that this strategy is consistently applied to all object data in the collection."
10970816,"A neural network structure, namely a warped external recurrent neural network, is disclosed for reconstructing images with synthesized effects. The effects can include motion blur, depth of field reconstruction (e.g., simulating lens effects), and/or anti-aliasing (e.g., removing artifacts caused by sampling frequency). The warped external recurrent neural network is not recurrent at each layer inside the neural network. Instead, the external state output by the final layer of the neural network is warped and provided as a portion of the input to the neural network for the next image in a sequence of images. In contrast, in a conventional recurrent neural network, hidden state generated at each layer is provided as a feedback input to the generating layer. The neural network can be implemented, at least in part, on a processor. In an embodiment, the neural network is implemented on at least one parallel processing unit."
10972719,"Head-mounted Displays (HMDs) are commonly used for virtual reality, mixed reality, and augmented reality. HMDs are, by definition, worn on the head of a user to provide a display in the line of sight of the user. By viewing the display, the user is able to experience one of the aforementioned types of reality. Oftentimes, HMDs are configured to integrate live video captured from the user's perspective, especially in the case of the HMD providing augmented reality where a virtual environment is combined with video of the real world. The present disclosure provides a configuration for a HMD having an array of image sensors to accurately capture image data to form the live video from the user's perspective."
10977037,"In one embodiment, a synchronization instruction causes a processor to ensure that specified threads included within a warp concurrently execute a single subsequent instruction. The specified threads include at least a first thread and a second thread. In operation, the first thread arrives at the synchronization instruction. The processor determines that the second thread has not yet arrived at the synchronization instruction and configures the first thread to stop executing instructions. After issuing at least one instruction for the second thread, the processor determines that all the specified threads have arrived at the synchronization instruction. The processor then causes all the specified threads to execute the subsequent instruction. Advantageously, unlike conventional approaches to synchronizing threads, the synchronization instruction enables the processor to reliably and properly execute code that includes complex control flows and/or instructions that presuppose that threads are converged."
10979176,"Techniques for limiting the growth of errors in decoded data words that arise from bit errors incurred during transmission. The growth of 3+ bit errors in the decoded data word is limited at the expense of a higher number of two bit errors, which are correctable using practical error correcting codes."
10979744,"Embodiments of the present invention provide a low-latency approach for local or remote application streaming that reaches high FPS targets without overloading the available streaming bandwidth, for example, by limiting the bit rate to the same value that is used by traditional 60 FPS streaming solutions. A client device and server device cooperate to actively monitor and control a video stream to maintain an acceptable balance between latency and video quality by adjusting the frequency or resolution when necessary to improve the streaming experience. When the server device captures and transmits frames at a higher rate, the software stack executing on the client device is able to display frames with less delay, even on a display device limited to 60 Hz, thereby achieving additional latency reduction."
10983699,"A queue manager apparatus converts inbound commands of a first width into scalar format commands to be queued in a command queue. Furthermore, the queue manager converts the scalar format commands residing in the command queue into outbound commands of a second width for transmission. Converting inbound commands to scalar format commands and then converting the scalar format commands to a target width for transmission allows the queue manager to advantageously provide efficient and programmable command transmission between arbitrary processing units, regardless of potentially mismatched native command widths."
10983919,An addressing scheme in systems utilizing a number of operative memory slices in a last level cache that is not evenly divisible by a number of memory channels utilizes the operative slices exposes the full last level cache bandwidth and capacity to data processing logic in a high-performance graphics system.
10984049,"A method, computer readable medium, and system are disclosed for performing traversal stack compression. The method includes traversing a hierarchical data structure having more than two children per node, and during the traversing, creating at least one stack entry, utilizing a processor, where each stack entry contains a plurality of intersected nodes, and adding the at least one stack entry to a compressed traversal stack stored in a memory, utilizing the processor."
10984286,"A style transfer neural network may be used to generate stylized synthetic images, where real images provide the style (e.g., seasons, weather, lighting) for transfer to synthetic images. The stylized synthetic images may then be used to train a recognition neural network. In turn, the trained neural network may be used to predict semantic labels for the real images, providing recognition data for the real images. Finally, the real training dataset (real images and predicted recognition data) and the synthetic training dataset are used by the style transfer neural network to generate stylized synthetic images. The training of the neural network, prediction of recognition data for the real images, and stylizing of the synthetic images may be repeated for a number of iterations. The stylization operation more closely aligns a covariate of the synthetic images to the covariate of the real images, improving accuracy of the recognition neural network."
10984545,Techniques for estimating depth for a video stream captured by a monocular image sensor are disclosed. A sequence of image frames are captured by the monocular image sensor. A first neural network is configured to process at least a portion of the sequence of image frames to generate a depth probability volume. The depth probability volume includes a plurality of probability maps corresponding to a number of discrete depth candidate locations over a range of depths defined for the scene. The depth probability volume can be updated using a second neural network that is configured to generate adaptive gain parameters to integrate the DPVs over time. A third neural network is configured to refine the updated depth probability volume from a lower resolution to a higher resolution that matches the original resolution of the sequence of image frames. A depth map can be calculated based on the depth probability volume.
10984587,"Multiple snapshots of a scene are captured within an executing application (e.g., a video game). When each snapshot is captured, associated color values per pixel and a distance or depth value z per pixel are stored. The depth information from the snapshots is accessed, and a point cloud representing the depth information is constructed. A mesh structure is constructed from the point cloud. The light field(s) on the surface(s) of the mesh structure are calculated. A surface light field is represented as a texture. A renderer uses the surface light field with geometry information to reproduce the scene captured in the snapshots. The reproduced scene can be manipulated and viewed from different perspectives."
10984637,"Haptic effects have long been provided to enhance content, such as by providing vibrations, rumbles, etc. in a remote controller or other device being used by a user while watching or listening to the content. To date, haptic effects have either been provided by programming controls for the haptic effects within the content itself, or by providing an interface to audio that simply maps certain haptic effects with certain audio frequencies. The present disclosure provides a haptic control interface that intelligently induces haptic effects for content, in particular by using machine learning to detect specific features in content and then induce certain haptic effects for those features."
10986325,"Scene flow represents the three-dimensional (3D) structure and movement of objects in a video sequence in three dimensions from frame-to-frame and is used to track objects and estimate speeds for autonomous driving applications. Scene flow is recovered by a neural network system from a video sequence captured from at least two viewpoints (e.g., cameras), such as a left-eye and right-eye of a viewer. An encoder portion of the system extracts features from frames of the video sequence. The features are input to a first decoder to predict optical flow and a second decoder to predict disparity. The optical flow represents pixel movement in (x,y) and the disparity represents pixel movement in z (depth). When combined, the optical flow and disparity represent the scene flow."
10990732,Introduced herein is an improved technique of recovering system frequency margin via distributed CPMs. The introduced technique creates and distributes multiple sets of always sensitized critical path replicas across a chip and monitors them for timing failure. The introduced technique takes feedback from these critical path replicas and dynamically boosts the clock frequency of the chip to remove the margin. The introduced technique provides more accurate and more comprehensive coverage of a chip performance.
10991079,"This disclosure presents a method to denoise a ray traced scene where the ray tracing uses a minimal number of rays. The method can use temporal reprojections to compute a weighted average to the scene data. A spatial filter can be run on the scene data, using the temporal reprojection count to reduce the size of the utilized spatial filter radius. In some aspects, additional temporal filters can be applied to the scene data. In some aspects, global illumination temporal reprojection history counts can be used to modify the spatial filter radius. In some aspects, caustic photon tracing can be conducted to compute a logarithmic cost, which can then be utilized to reduce the denoising radius used by the spatial filter. The modified and adjusted scene data can be sent to a rendering process to complete the rendering to generate a final scene."
10991152,"One embodiment of the present invention includes a parallel processing unit (PPU) that performs pixel shading at variable granularities. For effects that vary at a low frequency across a pixel block, a coarse shading unit performs the associated shading operations on a subset of the pixels in the pixel block. By contrast, for effects that vary at a high frequency across the pixel block, fine shading units perform the associated shading operations on each pixel in the pixel block. Because the PPU implements coarse shading units and fine shading units, the PPU may tune the shading rate per-effect based on the frequency of variation across each pixel group. By contrast, conventional PPUs typically compute all effects per-pixel, performing redundant shading operations for low frequency effects. Consequently, to produce similar image quality, the PPU consumes less power and increases the rendering frame rate compared to a conventional PPU."
10991155,"In various examples, locations of directional landmarks, such as vertical landmarks, may be identified using 3D reconstruction. A set of observations of directional landmarks (e.g., images captured from a moving vehicle) may be reduced to 1D lookups by rectifying the observations to align directional landmarks along a particular direction of the observations. Object detection may be applied, and corresponding 1D lookups may be generated to represent the presence of a detected vertical landmark in an image."
10993110,"A method involves a headless IoT device wirelessly communicating a MAC address to a client device in response to a scan by the client device, and receiving from the client device a vendor action frame comprising access credentials for communicating via a Wi-Fi access point. The IoT device applies the credentials to authenticate to the Wi-Fi access point, forms an application layer for communicating over the Wi-Fi access point network, and communicates with the client device via the application layer."
10996725,"A method for managing power in a multiple processor computing device includes detecting a first amount of power being used by a first processor of the computing device; determining an amount of extra power available based on the first amount of power and a power budget for the first processor; and transmits a value to a driver associated with a second processor of the computing device, wherein the value indicates the amount of extra power available, wherein the driver adjusts at least one operating parameter of the second processor based on the amount of extra power available."
10996865,"One aspect of the current disclosure provides a method for utilizing a plurality of memories associated with a plurality of devices in a computer system. The method includes: 1) receiving a data set for executing an application employing the devices; 2) determining whether the data set is larger than a storage capacity of any of the memories; and 3) when the data set is larger than the storage capacity of any of the memories, replicating a portion of the data set across the memories and distributing a remaining portion of the data set across at least some of the memories."
10997433,"In various examples, sensor data representative of an image of a field of view of a vehicle sensor may be received and the sensor data may be applied to a machine learning model. The machine learning model may compute a segmentation mask representative of portions of the image corresponding to lane markings of the driving surface of the vehicle. Analysis of the segmentation mask may be performed to determine lane marking types, and lane boundaries may be generated by performing curve fitting on the lane markings corresponding to each of the lane marking types. The data representative of the lane boundaries may then be sent to a component of the vehicle for use in navigating the vehicle through the driving surface."
10997435,"In various examples, object fence corresponding to objects detected by an ego-vehicle may be used to determine overlap of the object fences with lanes on a driving surface. A lane mask may be generated corresponding to the lanes on the driving surface, and the object fences may be compared to the lanes of the lane mask to determine the overlap. Where an object fence is located in more than one lane, a boundary scoring approach may be used to determine a ratio of overlap of the boundary fence, and thus the object, with each of the lanes. The overlap with one or more lanes for each object may be used to determine lane assignments for the objects, and the lane assignments may be used by the ego-vehicle to determine a path or trajectory along the driving surface."
10997492,"Aspects of the present invention are directed to computer-implemented techniques for performing data compression and conversion between data formats of varying degrees of precision, and more particularly for improving the inferencing (application) of artificial neural networks using a reduced precision (e.g., INT8) data format. Embodiments of the present invention generate candidate conversions of data output, then employ a relative measure of quality to identify the candidate conversion with the greatest accuracy (i.e., least divergence from the original higher precision values). The representation can be then be used during inference to perform computations on the resulting output data."
10997496,"A method, computer program product, and system perform computations using a sparse convolutional neural network accelerator. Compressed-sparse data is received for input to a processing element, wherein the compressed-sparse data encodes non-zero elements and corresponding multi-dimensional positions. The non-zero elements are processed in parallel by the processing element to produce a plurality of result values. The corresponding multi-dimensional positions are processed in parallel by the processing element to produce destination addresses for each result value in the plurality of result values. Each result value is transmitted to a destination accumulator associated with the destination address for the result value."
10997884,"The present disclosure is directed to a method to correct for visual artifacts in a virtual reality (VR) video image where there is significant motion of the video image as a result of user actions. A user may request that the video image be moved, such as a through motion detected through a VR device, i.e., turning the head, or through a request to an application, i.e., joystick feedback to a gaming application. The video image motion can cause stutter and jitter visual artifacts, when the video frame buffer uses a synchronization constraint, such as vertical synchronization (VSync). When the VSync is disabled, a tearing visual artifact can be present. This disclosure presents a frame buffer handling process that operates with VSync disabled. The process allows the display refresh rates to operate at higher frequencies, while correcting for significant motion of the video image, i.e., tearing, through shifting back certain pixels within the scanout frame buffer."
10999051,"A receiver circuit includes a clock lane propagating a clock signal. A self-sampled clock applies a delayed version of the clock signal to the clock signal and compensation logic controls an amount of delay of the delayed version of the clock, based on a reference voltage offset (difference) between the receiver and a transmitter. The delayed version of the clock is centered on one unit interval of the clock. An offset correction based on a clock duty cycle error is applied to data receiver front ends."
10999174,"Novel solutions are provided for consistent Quality of Service in cloud gaming system that adaptively and dynamically compensate for poor network conditions by moderating rendered frame rates using frame rate capping to optimize for network latency savings (or surplus). In further embodiments, the encoding/sent frame rate to the client can also be managed in addition, or as an alternative to capping the rendered frame rates. The claimed embodiments not only maintain a constant Quality of Service (QoS) for the user, but may also be employed to leverage higher-performing networks to reduce operational costs."
11003238,"A hierarchy of interconnected memory retention (MR) circuits detect a clock gating mode being entered at any level of an integrated circuit. In response, the hierarchy automatically transitions memory at the clock gated level and all levels below the clock-gated level from a normal operating state to a memory retention state. When a memory transitions from a normal operating state to a memory retention state, the memory transitions from a higher power state (corresponding to the normal operating state) to a lower power state (corresponding to the memory retention state). Thus, in addition to the dynamic power savings caused by the clock gating mode, the hierarchy of MR circuits automatically transitions the memory modules at the clock gated level and all levels below the clock gated level to a lower power state. As a result, the leakage power consumption of the corresponding memory modules is reduced relative to prior approaches."
11004178,"Users often desire to capture certain images from an application. For example, gamers can capture displayed images from a game to show they obtained a skill level within the game or simply to capture a particular scene within the game. Existing methods of capturing images can result in low-resolution images due to limitations of the display device providing the images. This disclosure provides a method of capturing higher resolution images from source images. Techniques are also disclosed to reduce the storage size associated with the higher resolution images. Through capturing low-resolution versions of the same source images, image effects can be captured and applied to the higher resolution images where those image effects may be altered or missing. Frequency spectrum combination can be used to combine the low-resolution image data and the higher resolution image data. The higher resolution images can be processed using a segmentation scheme, such as tiling, without reducing or limiting the image effects."
11004254,"A ray (e.g., a traced path of light, etc.) is generated from an originating pixel within a scene being rendered. Additionally, one or more shadow map lookups are performed for the originating pixel to estimate an intersection of the ray with alpha-tested geometry within the scene. A shadow map stores the distance of geometry as seen from the point of view of the light, and alpha-tested geometry includes objects within the scene being rendered that have a determined texture and opacity. Further, the one or more shadow map lookups are performed to determine a visibility value for the pixel (e.g., that identifies whether the originating pixel is in a shadow) and a distance value for the pixel (e.g., that identifies how far the pixel is from the light). Further still, the visibility value and the distance value for the pixel are passed to a denoiser."
11010509,"Embodiments of the present invention provide a novel method and discretization for animating water waves. The approaches disclosed combine the flexibility of a numerical approach to wave simulation with the stability and visual detail provided by a spectrum-based approach to provide Eulerian methods for simulating large-scale oceans with highly detailed wave features. A graphics processing unit stores a one-dimensional texture referred to as a wave profile buffer that stores pre-computed results at a number of discrete sample points for performing wave height evaluation. The water surface is rendered according to water height values computed using the wave profile, accounting for advection, spatial diffusion, angular diffusion, boundary reflections, and dissipation."
11010516,"Techniques to improve the accuracy and speed for detection and remediation of difficult to test nodes in a circuit design netlist. The techniques utilize improved netlist representations, test point insertion, and trained neural networks."
11010963,"A water surface mesh is determined for a scene to be rendered. This water surface mesh includes a grouping of geometric shapes such as triangles that represents the surface of the water. This water surface mesh is then used to create a refracted or reflected mesh. The refracted or reflected mesh shows an effect produced by the water surface's refraction or reflection of light. The relationship between the water surface mesh and the refracted or reflected mesh is then used to determine how to illuminate elements within the scene. This eliminates some previously necessary steps during rendering, and enables an accurate depiction of caustics within a scene that can be performed in real-time."
11011249,"Testing packaged integrated circuit (IC) devices is difficult and time consuming. When multiple devices (dies) are packaged to produce a SiP (system in package) the devices should be tested for defects that may be introduced during the packaging process. With limited access to the inputs and outputs of the devices, test times increase compared with testing the devices before they are packaged. A CoWoS (chip on wafer on substrate) SiP includes a logic device and a memory device and has interfaces between the logic device and memory device that cannot be directly accessed at a package ball. Test programs are concurrently executed by the logic device and the memory device to reduce testing time. Each memory device includes a BIST (built-in self-test) module that is initialized and executes the memory test program while the one or more modules within the logic device are tested."
11012338,"Novel solutions are provided for consistent Quality of Service in cloud gaming system that adaptively and dynamically compensate for poor network conditions by moderating rendered frame rates using frame rate capping to optimize for network latency savings (or surplus). In further embodiments, the encoding/sent frame rate to the client can also be managed in addition, or as an alternative to capping the rendered frame rates. The claimed embodiments not only maintain a constant Quality of Service (QoS) for the user, but may also be employed to leverage higher-performing networks to reduce operational costs."
11012694,"The present disclosure is directed to a method to increase virtual machine density on a server system through adaptive rendering by dynamically determining when to shift video rendering tasks between the server system and a client computing device. In another embodiment, the adaptive rendering, using various parameters, can select one or more encoding and compression algorithms to use to prepare and process the video for transmission to the client computing device. In another embodiment, a video rendering system is disclosed that can adaptively alter how and where a video is rendered, encoded, and compressed."
11016802,"In various embodiments, an ordered atomic operation enables a parallel processing subsystem to executes an atomic operation associated with a memory location in a specified order relative to other ordered atomic operations associated with the memory location. A level 2 (L2) cache slice includes an atomic processing circuit and a content-addressable memory (CAM). The CAM stores an ordered atomic operation specifying at least a memory address, an atomic operation, and an ordering number. In operation, the atomic processing circuit performs a look-up operation on the CAM, where the look-up operation specifies the memory address. After the atomic processing circuit determines that the ordering number is equal to a current ordering number associated with the memory address, the atomic processing circuit executes the atomic operation and returns the result to a processor executing an algorithm. Advantageously, the ordered atomic operation enables the algorithm to achieve a deterministic result while optimizing latency."
11017556,"Iterative prediction systems and methods for the task of action detection process an inputted sequence of video frames to generate an output of both action tubes and respective action labels, wherein the action tubes comprise a sequence of bounding boxes on each video frame. An iterative predictor processes large offsets between the bounding boxes and the ground-truth."
11018909,"A receiver receives communications over a communication channel, which may distort an incoming communication signal. In order to counter this distortion, the frequency response of the receiver is manipulated by adjusting several frequency response parameters. Each frequency response parameter controls at least a portion of the frequency response of the receiver. The optimal values for the frequency response parameters are determined by modifying an initial set of values for the frequency response parameters through one or more of stochastic hill climbing operations until a performance metric associated with the receiver reaches a local maximum. The modified values are displaced through one or more mutation operations. The stochastic hill climbing operations may subsequently be performed on the mutated values to generate the final values for the frequency response parameters."
11023732,"In various examples, potentially highlight-worthy video clips are identified from a gameplay session that a gamer might then selectively share or store for later viewing. The video clips may be identified in an unsupervised manner based on analyzing game data for durations of predicted interest. A classification model may be trained in an unsupervised manner to classify those video clips without requiring manual labeling of game-specific image or audio data. The gamer can select the video clips as highlights (e.g., to share on social media, store in a highlight reel, etc.). The classification model may be updated and improved based on new video clips, such as by creating new video-clip classes."
11027199,"Embodiments of the claimed subject matter provide systems and methods for configuring and connecting a controller to a game streaming service. The system includes a plurality of input controls and a network controller configured for communicating with a game streaming service. The system further includes a processor coupled to the plurality of input controls and the network controller. The processor is configured communicate with the game streaming service to login to a game streaming service account and communicate input from the plurality of controls to the game streaming service. The system further includes a power source configured to provide power to the plurality of input controls, the network controller, and the processor."
11030968,"In various examples, images rendered by a processor—such as a graphics processing unit (GPU)—may be scanned out of memory in a middle-out scan order. Various architectures for liquid crystal displays (LCDs) may be implemented to support middle-out scanning, such as dual-panel architectures, ping-pong architectures, and architectures that support both top-down scan order and middle-out scan order. As a result, display latency within the system may be reduced, thereby increasing performance of the system—especially for high-performance applications such as gaming."
11037051,"Planar regions in three-dimensional scenes offer important geometric cues in a variety of three-dimensional perception tasks such as scene understanding, scene reconstruction, and robot navigation. Image analysis to detect planar regions can be performed by a deep learning architecture that includes a number of neural networks configured to estimate parameters for the planar regions. The neural networks process an image to detect an arbitrary number of plane objects in the image. Each plane object is associated with a number of estimated parameters including bounding box parameters, plane normal parameters, and a segmentation mask. Global parameters for the image, including a depth map, can also be estimated by one of the neural networks. Then, a segmentation refinement network jointly optimizes (i.e., refines) the segmentation masks for each instance of the plane objects and combines the refined segmentation masks to generate an aggregate segmentation mask for the image."
11037338,This disclosure introduces an approach that includes techniques for determining an optimal weighted execution sequence of available reconstruction algorithms using a multi-processor unit. The introduced approach includes executing a series of optimal weighted execution sequence candidates on a representative slice of the image data and comparing their results to select one of the candidates as the optimal weighted execution sequence.
11038800,"An endpoint in a network may make posted or non-posted write requests to another endpoint in the network. For a non-posted write request, the target endpoint provides a response to the requesting endpoint indicating that the write request has been serviced. For a posted write request, the target endpoint does not provide such an acknowledgment. Hence, posted write requests have lower overhead, but they suffer from potential synchronization and resiliency issues. While non-posted write requests do not have those issues, they cause increased load on the network because such requests require the target endpoint to acknowledge each write request. Introduced herein is a network operation technique that uses non-posted transactions while maintaining a load overhead of the network as a manageable level. The introduced technique reduces the load overhead of the non-posted write requests by collapsing and reducing a number of the responses."
11039092,"To support sparse scanout of an image sensor, an image data protocol such as the MIPI CSI protocol is extended with support for pixel coordinates in long packets. The receiver uses these to compute where in memory these pixels should be stored or where on a display they should be displayed. Truly sparse scanout is supported for any arbitrarily shaped image areas including for example elliptical readout for fisheye lenses. These techniques save MIPI and serializer/deserializer bandwidth in automotive and other applications, allowing for more cameras per vehicle or other host. Such techniques can be implemented in a way that is compatible with prior MIPI standardized approaches."
11042163,"In various examples, a trigger signal may be received that is indicative of a vehicle maneuver to be performed by a vehicle. A recommended vehicle trajectory for the vehicle maneuver may be determined in response to the trigger signal being received. To determine the recommended vehicle trajectory, sensor data may be received that represents a field of view of at least one sensor of the vehicle. A value of a control input and the sensor data may then be applied to a machine learning model(s) and the machine learning model(s) may compute output data that includes vehicle control data that represents the recommended vehicle trajectory for the vehicle through at least a portion of the vehicle maneuver. The vehicle control data may then be sent to a control component of the vehicle to cause the vehicle to be controlled according to the vehicle control data."
11043028,"A method, computer readable medium, and system are disclosed for overlaying a cell onto a polygon meshlet. The polygon meshlet may include a grouping of multiple geometric shapes such as triangles, and the cell may include a square-shaped boundary. Additionally, every polygon (e.g., a triangle or other geometric shape) within the polygon meshlet that has at least one edge fully inside the cell is removed to create an intermediate meshlet. A selected vertex is determined from all vertices (e.g., line intersections) of the intermediate meshlet that are located within the cell, based on one or more criteria, and all the vertices of the intermediate meshlet that are located within the cell are replaced with the selected vertex to create a modified meshlet. The modified meshlet is then rendered (e.g., as part of a process to generate a scene to be viewed)."
11043172,"A display controller progressively updates LEDs and LCD pixels in scanline order as portions of an image are scanned into a frame buffer. The display controller analyzes a first portion of the image that includes a first pixel value associated with a first LCD pixel. The display controller identifies a first LED that contributes luminance to the first LCD pixel and determines an LED current setting for the LED based on the first pixel value. The display controller then identifies a second LCD pixel that resides above the first LED and is associated with a second pixel value. The display controller configures the second LCD pixel based on the second pixel value and luminance contributions received at the second LCD pixel. Accordingly, the display controller need not wait for the entire image to be scanned into the frame buffer before initiating display of the image."
11048321,"Digital low-dropout micro voltage regulator configured to accept an external voltage and produce a regulated voltage. All active devices of the voltage regulator are digital devices. All signals of the voltage regulator, except the first voltage and the regulated voltage, may be characterized as digital signals. Some active devices of the voltage regulator may be physically separated from other active devices of the voltage regulator by active devices of non-voltage regulator circuitry."
11049018,"A method, computer readable medium, and system are disclosed for visual sequence learning using neural networks. The method includes the steps of replacing a non-recurrent layer within a trained convolutional neural network model with a recurrent layer to produce a visual sequence learning neural network model and transforming feedforward weights for the non-recurrent layer into input-to-hidden weights of the recurrent layer to produce a transformed recurrent layer. The method also includes the steps of setting hidden-to-hidden weights of the recurrent layer to initial values and processing video image data by the visual sequence learning neural network model to generate classification or regression output data."
11055097,"One embodiment of the present invention includes techniques to decrease power consumption by reducing the number of redundant operations performed. In operation, a streamlining multiprocessor (SM) identifies uniform groups of threads that, when executed, apply the same deterministic operation to uniform sets of input operands. Within each uniform group of threads, the SM designates one thread as the anchor thread. The SM disables execution units assigned to all of the threads except the anchor thread. The anchor execution unit, assigned to the anchor thread, executes the operation on the uniform set of input operands. Subsequently, the SM sets the outputs of the non-anchor threads included in the uniform group of threads to equal the value of the anchor execution unit output."
11055253,"This disclosure provides a method that allows connector pins of a USB-C connector to be dynamically repurposed between low bandwidth USB2 traffic and high bandwidth USB3 traffic. USB-C devices can negotiate the use of these pins for a dynamic transition to another function or functions. The pins can be the four center connector pins of a USB-C connection, pins A6, A7, B6, B7, that are originally designated as USB 2.0 differential pairs Changing the function of the pins provides flexibility for communicating using USB-C connectors. For example, the disclosed method/device/system can be used to support high-resolution cameras and sensors in high-resolution virtual reality headsets via a single USB-C connection instead of a user having to connect multiple cables."
11055381,"Sampling a function is used for many applications, such as rendering images. The challenge is how to select the best samples to minimize computations and produce accurate results. An alternative is to use a larger number of samples that may not be carefully selected in an attempt to increase accuracy. For a function that is an integral, such as functions used to render images, a sample distribution may be computed by inverting the integral. Unfortunately, for many integrals, it is neither easy nor practical to compute the inverted integral. Instead, warp functions may be combined to provide a sample distribution that accurately approximates the factors of the product being integrated. Each warp function approximates an inverted term of the product while accounting for the effects of warp functions approximating other factors in the product. The selected warp functions are customized or “fitted” to implement importance sampling for the approximated product."
11061571,"In various embodiments, a memory interface unit organizes data within a memory tile to facilitate efficient memory accesses. In an embodiment, a memory tile represents a portion of memory that holds multiple chunks of data, where each chunk is stored either in a non-compressed or in a smaller compressed data format. In an embodiment, the tile is organized to pack multiple compressed chunks together so that multiple compressed chunks can be retrieved from memory with a single read access. In another embodiment, the tile is organized to store redundant copies of compressed chunks so that a compressed chunk can be quickly decompressed within a tile without having to relocate other compressed chunks in the tile. Additional embodiments are further disclosed for allowing efficient accesses to both compressed and non-compressed data."
11061741,"Techniques are disclosed for reducing the latency associated with performing data reductions in a multithreaded processor. In response to a single instruction associated with a set of threads executing in the multithreaded processor, a warp reduction unit acquires register values stored in source registers, where each register value is associated with a different thread included in the set of threads. The warp reduction unit performs operation(s) on the register values to compute an aggregate value. The warp reduction unit stores the aggregate value in a destination register that is accessible to at least one of the threads in the set of threads. Because the data reduction is performed via a single instruction using hardware specialized for data reductions, the number of cycles required to perform the data reduction is decreased relative to prior-art techniques that are performed via multiple instructions using hardware that is not specialized for data reductions."
11062471,"Stereo matching generates a disparity map indicating pixels offsets between matched points in a stereo image pair. A neural network may be used to generate disparity maps in real time by matching image features in stereo images using only 2D convolutions. The proposed method is faster than 3D convolution-based methods, with only a slight accuracy loss and higher generalization capability. A 3D efficient cost aggregation volume is generated by combining cost maps for each disparity level. Different disparity levels correspond to different amounts of shift between pixels in the left and right image pair. In general, each disparity level is inversely proportional to a different distance from the viewpoint."
11063629,"Various embodiments include techniques for detecting a poor-quality cable associated with a wired communications channel that is causing noise that interferes with a wireless communications channel. The techniques are directed towards a test that a processor performs when the cable is installed in a user system. A wireless test application, executing on one or more processors of the system, determines a noise floor for the wireless communications channel when the wired communications channel is disabled. The wireless test application determines the noise power for the wireless communications channel when the wired communications channel is enabled, thereby causing interference in the wireless communications channel. The wireless test application compares the noise power to the noise floor in order to determine whether the cable is a high-quality cable or a low-quality cable."
11064203,"Real-time, hardware-implementable Structured Similarity (SSIM)-based rate distortion optimization (RDO) techniques for video transmission are described. The disclosed techniques provide efficient application of SSIM as a distortion metric in selecting prediction modes for encoding video for transmission. A prediction mode, at a high level, specifies which previously encoded group of pixels can be utilized to encode a subsequent block of pixels in a video frame. A less compute intensive distortion metric is first used to select a subset of candidate prediction modes. Then a more compute intensive SSIM-based selection is made on the subset. By utilizing the disclosed techniques during video encoding, tradeoffs between distortion and transmission rate can be made that are more relevant to human perception."
11067806,"An augmented reality display system includes a first beam path for a foveal inset image on a holographic optical element, a second beam path for a peripheral display image on the holographic optical element, and pupil position tracking logic that generates control signals to set a position of the foveal inset as perceived through the holographic optical element, to determine the peripheral display image, and to control a moveable stage."
11068626,"A cable driving a large system such as cable driven machines, cable cars or tendons in a human or robot is typically modeled as a large number of small segments that are connected via joints. The two main difficulties with this approach are satisfying the inextensibility constraint and handling the typically large mass ratio between the small segments and the larger objects they connect. This disclosure introduces a more effective approach to solving these problems. The introduced approach simulates the effect of a cable instead of the cable itself using a new type of distance constraint called ‘cable joint’ that changes both its attachment points and its rest length dynamically. The introduced approach models a cable connecting a series of objects as a sequence of cable joints, reducing the complexity of the simulation from the order of the number of segments in the cable to the number of connected objects."
11068781,"A method, computer readable medium, and system are disclosed for implementing a temporal ensembling model for training a deep neural network. The method for training the deep neural network includes the steps of receiving a set of training data for a deep neural network and training the deep neural network utilizing the set of training data by: analyzing the plurality of input vectors by the deep neural network to generate a plurality of prediction vectors, and, for each prediction vector in the plurality of prediction vectors corresponding to the particular input vector, computing a loss term associated with the particular input vector by combining a supervised component and an unsupervised component according to a weighting function and updating the target prediction vector associated with the particular input vector."
11069023,A technique selectively avoids memory fetches for partially uniform textures in real time graphics shader programs and instead uses program paths specialized for one or more frequently occurring values. One aspect avoids memory lookups and dependent computations for partially uniform textures through use of pre-constructed coarse-grained representations called value locality maps or dirty tilemaps (DTMs). The decision to use a specialized fast path or not is made dynamically by consulting such coarse-grained dirty tilemap representations. Thread-sharing value reuse can be implemented with or instead of the DTM mechanism.
11069095,"A sample mask is used to control which samples are used in a filtering operation such as bilinear filtering. A conventional filtering operation reads a set of samples based on a single coordinate and combines the samples to produce a filtered sample value. Such filtering operations are performed conventionally using fixed function units designed specifically to perform such filtering operations. However, for some applications, excluding one or more of the samples in producing a filtered sample value is desirable. In other applications, combining the samples using different weighting factors is also desirable. Techniques are disclosed herein for extending the capabilities of existing filtering units, for example, to exclude one or more samples in the filtering operation and for specifying different weighting rules for combining the samples."
11069129,"In various examples, shader bindings may be recorded in a shader binding table that includes shader records. Geometry of a 3D scene may be instantiated using object instances, and each may be associated with a respective set of the shader records using a location identifier of the set of shader records in memory. The set of shader records may represent shader bindings for an object instance under various predefined conditions. One or more of these predefined conditions may be implicit in the way the shader records are arranged in memory (e.g., indexed by ray type, by sub-geometry, etc.). For example, a section selector value (e.g., a section index) may be computed to locate and select a shader record based at least in part on a result of a ray tracing query (e.g., what sub-geometry was hit, what ray type was traced, etc.)."
11070205,"When a signal glitches, logic receiving the signal may change in response, thereby charging and/or discharging nodes within the logic and dissipating power. Providing a glitch-free signal may reduce the number of times the nodes are charged and/or discharged, thereby reducing the power dissipation. A technique for eliminating glitches in a signal is to insert a storage element that samples the signal after it is done changing to produce a glitch-free output signal. The storage element is enabled by a “ready” signal having a delay that matches the delay of circuitry generating the signal. The technique prevents the output signal from changing until the final value of the signal is achieved. The output signal changes only once, typically reducing the number of times nodes in the logic receiving the signal are charged and/or discharged so that power dissipation is also reduced."
11074717,"An object detection neural network receives an input image including an object and generates belief maps for vertices of a bounding volume that encloses the object. The belief maps are used, along with three-dimensional (3D) coordinates defining the bounding volume, to compute the pose of the object in 3D space during post-processing. When multiple objects are present in the image, the object detection neural network may also generate vector fields for the vertices. A vector field comprises vectors pointing from the vertex to a centroid of the object enclosed by the bounding volume defined by the vertex. The object detection neural network may be trained using images of computer-generated objects rendered in 3D scenes (e.g., photorealistic synthetic data). Automatically labelled training datasets may be easily constructed using the photorealistic synthetic data. The object detection neural network may be trained for object detection using only the photorealistic synthetic data."
11074871,A display controller generates a backlight illumination field (BLIF) based on a coarse point-spread function (PSF) and a correction PSF. The display controller samples the coarse PSF to accumulate light contributions from a larger neighborhood of LEDs around a given LCD pixel. The display controller samples the correction PSF to generate correction factors for a smaller neighborhood of LEDs around the given LCD pixel. The display controller interpolates samples drawn from the coarse PSF and samples drawn from the correction PSF and then combines the interpolated samples to generate a full resolution BLIF.
11079434,"In various examples, a test system is provided for executing built-in-self-test (BIST) on integrated circuits deployed in the field. The integrated circuits may include a first device and a second device, the first device having direct access to external memory, which stores test data, and the second device having indirect access to the external memory by way of the first device. In addition to providing a mechanism to permit the first device and the second device to run test concurrently, the hardware and software may reduce memory requirements and runtime associated with running the test sequences, thereby making real-time BIST possible in deployment. Furthermore, some embodiments permit a single external memory image to cater to different SKU configurations."
11079764,"In various examples, a current claimed set of points representative of a volume in an environment occupied by a vehicle at a time may be determined. A vehicle-occupied trajectory and at least one object-occupied trajectory may be generated at the time. An intersection between the vehicle-occupied trajectory and an object-occupied trajectory may be determined based at least in part on comparing the vehicle-occupied trajectory to the object-occupied trajectory. Based on the intersection, the vehicle may then execute the first safety procedure or an alternative procedure that, when implemented by the vehicle when the object implements the second safety procedure, is determined to have a lesser likelihood of incurring a collision between the vehicle and the object than the first safety procedure."
11080051,"A technique for block data transfer is disclosed that reduces data transfer and memory access overheads and significantly reduces multiprocessor activity and energy consumption. Threads executing on a multiprocessor needing data stored in global memory can request and store the needed data in on-chip shared memory, which can be accessed by the threads multiple times. The data can be loaded from global memory and stored in shared memory using an instruction which directs the data into the shared memory without storing the data in registers and/or cache memory of the multiprocessor during the data transfer."
11080111,"Apparatuses, systems, and techniques to execute programs in a single hardware context on a graphics processing unit (GPU). In at least one embodiment, resource management patches expressed in library or executable code are applied to one or more kernels to ensure execution in a shared context on a GPU."
11080590,"Various examples of the present disclosure include a stereoscopic deep neural network (DNN) that produces accurate and reliable results in real-time. Both LIDAR data (supervised training) and photometric error (unsupervised training) may be used to train the DNN in a semi-supervised manner. The stereoscopic DNN may use an exponential linear unit (ELU) activation function to increase processing speeds, as well as a machine learned argmax function that may include a plurality of convolutional layers having trainable parameters to account for context. The stereoscopic DNN may further include layers having an encoder/decoder architecture, where the encoder portion of the layers may include a combination of three-dimensional convolutional layers followed by two-dimensional convolutional layers."
11082347,"Multiple processors are often used in computing systems to solve very large, complex problems, such as those encountered in artificial intelligence. Such processors typically exchange data among each other via an interconnect fabric (such as, e.g., a group of network connections and switches) in solving such complex problems. The amount of data injected into the interconnect fabric by the processors can at times overwhelm the interconnect fabric preventing some of the processors from communicating with each other. To address this problem, techniques are disclosed to enable, for example, processors that are connected to an interconnect fabric to coordinate and control the amount of data injected so that the interconnect fabric does not get overwhelmed."
11082490,"A computer implemented method of executing applications in a cloud server system is presented. The method comprises receiving a file identifier from a client device. The method also comprises receiving a file associated with the file identifier from a first server. Further, the method comprises accessing an application associated with the file from memory of the cloud server. Also, the method comprises executing by the cloud server the application using the file received from the first server. Finally, the method comprises streaming results from the executing the application as a video stream destined for the client device."
11082720,"A method, computer readable medium, and system are disclosed for identifying residual video data. This data describes data that is lost during a compression of original video data. For example, the original video data may be compressed and then decompressed, and this result may be compared to the original video data to determine the residual video data. This residual video data is transformed into a smaller format by means of encoding, binarizing, and compressing, and is sent to a destination. At the destination, the residual video data is transformed back into its original format and is used during the decompression of the compressed original video data to improve a quality of the decompressed original video data."
11087162,"In various examples, frames of a video may include a first visual object that may appear relative to a second visual object within a region of the frames. Once a relationship between the first visual object and the region is known, one or more operations may be performed on the relative region. For example, optical character recognition may be performed on the relative region where the relative region is known to contain textual information. As a result, the identification of the first visual object may serve as an anchor for determining the location of the relative region including the second visual object—thereby increasing accuracy and efficiency of the system while reducing run-time."
11089320,A method dynamically selects one of a first sampling order and a second sampling order for a ray trace of pixels in a tile where the selection is based on a motion vector for the tile. The sampling order may be a bowtie pattern or an hourglass pattern.
11093323,"Techniques are disclosed for reducing the time required to read and write data to memory. Data reads and/or writes can be delayed when error correction code (ECC) bits, which are used to detect and/or correct data corruption, are written to memory. Writing ECC bits can take longer in some instances than writing data bits because an ECC write may involve a read/modify/write operation, as opposed to just simply writing the bits to memory. Some latencies associated with writing ECC bits can be hidden by interleaving ECC writes with data writes. However, if insufficient data writes are available for interleaving, hiding such latencies become difficult. Thus, various techniques are disclosed, for example, where ECC writes are deferred until a sufficient number of data writes become available for interleaving. By interleaving ECC writes, the disclosed techniques decrease the overall time required to read and write data to memory."
11095307,"Apparatuses, systems, and techniques to compute cyclic redundancy checks use a graphics processing unit (GPU) to compute cyclic redundancy checks. For example, in at least one embodiment, an input data sequence is distributed among GPU threads for parallel calculation of an overall CRC value for the input data sequence according to various novel techniques described herein."
11099558,"In various examples, at least partial control of a vehicle may be transferred to a control system remote from the vehicle. Sensor data may be received from a sensor(s) of the vehicle and the sensor data may be encoded to generate encoded sensor data. The encoded sensor data may be transmitted to the control system for display on a virtual reality headset of the control system. Control data may be received by the vehicle and from the control system that may be representative of a control input(s) from the control system, and actuation by an actuation component(s) of the vehicle may be caused based on the control input."
11099685,"Almost all mobile devices, such as cell phones, tablets, laptops, etc., have touch sensors that enable a user of the device to control various aspects of the device through a touch screen. The touch screen is comprised of a touchable surface and numerous touch sensors positioned across the surface to sense which portion of the surface has been touched by the user. With current touch sensor technology, a touch controller of the device will perform a periodic scan, at some rate, of all of the touch sensors in order to determine which touch sensors have sensed a touch by the user. The present disclosure provides selective activation of the touch sensors for portions of a graphical user interface (GUI) determined to have user-selectable input elements, for providing power savings on the mobile device."
11100643,"In at least one embodiment, a reinforcement-learning-based searching approach is used to produce a training configuration for a machine-learning model. In at least one embodiment, 3D medical image segmentation is performed using learned image preprocessing parameters."
11100830,"A patch scanning display apparatus and a technique for reconstructing a target image frame on a projection surface is disclosed. The patch scanning display apparatus includes a backlight and a spatial light modulator (SLM). An optical scanning device scans the image projected by the SLM across the projection surface in accordance with a scan trajectory. A decomposition model is used to generate a set of image patches based on the target image frame and the scan trajectory. In an embodiment, the decomposition model is a projective non-negative matrix factorization model. The set of image patches are utilized to generate a modulation signal for the SLM and a binary backlight signal is then generated for each time step of the scan trajectory within a frame period to activate or deactivate the light-emitting elements of the backlight during the frame period at a high refresh rate while the projected image is scanned."
11101836,A cover for a portable computing device includes a cover panel having a first portion of a solid silicone rubber sheet and a first stiffener panel that is fully encapsulated in the first portion of the solid silicone rubber sheet.
11102516,"A viewing device, a method of displaying streamed data frames and a client viewing device are disclosed herein. In one embodiment, the video viewing device includes: (1) a screen, (2) a decoder configured to decode a data frame received in a bitstream from a transmitter to provide a decoded data frame, and (3) an error concealer configured to either discard the decoded data frame or select the decoded data frame for display on the screen based on a complexity of the decoded data frame."
11106261,"Integrated circuits, or computer chips, typically include multiple hardware components (e.g. memory, processors, etc.) operating under a shared power (e.g. thermal) constraint that is sourced by one or more power sources for the chip. Typically, the hardware components can be individually configured to operate at certain states (e.g. to operate at a certain frequency by setting a clock speed for a clock dedicated to the hardware component). Thus, each hardware component can be configured to operate at an operating point that is determined to be optimal, usually in terms of achieving some desired goal for a specific application (e.g. frame rates for gaming, etc.). In the context of chip hardware that operates under a shared power/thermal constraint, a method, computer readable medium, and system are provided for determining the optimal operating point for the chip that takes into consideration both performance of the chip and power consumption by the chip."
11107176,"A tile-based system for processing graphics data. The tile based system includes a first screen-space pipeline, a cache unit, and a first tiling unit. The first tiling unit is configured to transmit a first set of primitives that overlap a first cache tile and a first prefetch command to the first screen-space pipeline for processing, and transmit a second set of primitives that overlap a second cache tile to the first screen-space pipeline for processing. The first prefetch command is configured to cause the cache unit to fetch data associated with the second cache tile from an external memory unit. The first tiling unit may also be configured to transmit a first flush command to the screen-space pipeline for processing with the first set of primitives. The first flush command is configured to cause the cache unit to flush data associated with the first cache tile."
11108704,"A switch architecture enables ports to stash packets in unused buffers on other ports, exploiting excess internal bandwidth that may exist, for example, in a tiled switch. This architecture leverages unused port buffer memory to improve features such as congestion handling and error recovery."
11113790,"During the rendering of an image, specific pixels in the image are identified where antialiasing would be helpful. Antialiasing is then performed on these identified pixels, where anti-aliasing is a technique used to add greater realism to a digital image by smoothing jagged edges. This reduces a cost of performing antialiasing by reducing a number of pixels within an image on which antialiasing is performed."
11113792,"Various approaches are disclosed to temporally and spatially filter noisy image data—generated using one or more ray-tracing effects—in a graphically rendered image. Rather than fully sampling data values using spatial filters, the data values may be sparsely sampled using filter taps within the spatial filters. To account for the sparse sampling, locations of filter taps may be jittered spatially and/or temporally. For filtering efficiency, a size of a spatial filter may be reduced when historical data values are used to temporally filter pixels. Further, data values filtered using a temporal filter may be clamped to avoid ghosting. For further filtering efficiency, a spatial filter may be applied as a separable filter in which the filtering for a filter direction may be performed over multiple iterations using reducing filter widths, decreasing the chance of visual artifacts when the spatial filter does not follow a true Gaussian distribution."
11113800,"A method, computer readable medium, and system are disclosed for performing spatiotemporal filtering. The method includes identifying image data to be rendered, reconstructing the image data to create reconstructed image data, utilizing a filter including a neural network having one or more skip connections and one or more recurrent layers, and returning the reconstructed image data."
11113819,"In various examples, image data may be received that represents an image. Corner detection may be used to identify pixels that may be candidate corner points. The image data may be converted from a higher dimensional color space to a converted image in a lower dimensional color space, and boundaries may be identified within the converted image. A set of the candidate corner points may be determined that are within a threshold distance to one of the boundaries, and the set of the candidate corner points may be analyzed to determine a subset of the candidate corner points representative of corners of polygons. Using the subset of the candidate corner points, one or more polygons may be identified, and a filter may be applied to the polygons to identify a polygon as corresponding to a fiducial marker boundary of a fiducial marker."
11113861,"This disclosure presents a process to generate one or more video frames through guiding the movements of a target object in an environment controlled by physics-based constraints. The target object is guided by the movements of a reference object from a motion capture (MOCAP) video clip. As disturbances, environmental factors, or other physics-based constraints interfere with the target object mimicking the reference object. A tracking agent, along with a corresponding neural network, can be used to compensate and modify the movements of the target object. Should the target object diverge significantly from the reference object, such as falling down, a recovery agent, along with a corresponding neural network, can be used to move the target object back into an approximate alignment with the reference object before resuming the tracking process."
11120609,A method dynamically selects one of a first sampling order and a second sampling order for a ray trace of pixels in a tile where the selection is based on a motion vector for the tile. The sampling order may be a bowtie pattern or an hourglass pattern. Subframes generated based on the sampling order are communicated over a bus along with motion vectors for tiles of the subframes.
11127167,"Many computing systems process data organized in a matrix format. For example, artificial neural networks perform numerous computations on data organized into matrices using conventional matrix arithmetic operations. One such operation is the transpose operation. Techniques are introduced for storing a matrix in a compressed format that allows, for example, a transpose operation to be performed during decompression. Thus, by utilizing the introduced techniques, transformations of compressed matrices such transposition can be achieved in a more effective way. Parallel processing may also be used to more efficiently compress and/or decompress."
11127719,"A TSV of a first semiconductor die may extend from a semiconductor substrate of the first semiconductor die through at least one metallization layer of the die to connect to a metallization layer to supply power to the second semiconductor die. By extending the TSV, resistance may be reduced, allowing for enhanced power delivery to the second semiconductor die. Resistance may be further reduced by allowing for the TSV to connect to a thicker metallization layer than would otherwise be possible. Also, in some embodiments, the TSV may connect to a metallization layer that is suitable for supplying power to both semiconductor dies. The first semiconductor die may be a top die or a bottom die in a face-to-face arrangement. Disclosed concepts may be extended to any number of dies included in a die stack that includes the face-to-face arrangement."
11130055,"Systems for granting remote access to, and methods of playing, a video game executing on a video game console coupled to a computer network or video games executing on hosting clients of a computer network. One embodiment of the system includes: (1) a stream distributor configured to receive a video stream conveying a view of a gamespace of the video game from the video game console via the computer network and transmit the video stream toward a remote client via the computer network and (2) a response receiver associated with the stream distributor and configured to receive a response stream from the remote client via the computer network and transmit the response stream toward the video game console."
11131711,"In-chip decoupling capacitor circuits refer to decoupling capacitors (DCAPs) that are placed on a chip. These DCAPs are generally used to manage power supply noise for the chip, and can be utilized individually or as a distributed system. In some cases, DCAPs may make up a significant portion of the chip. Unfortunately, defects in DCAPs will degrade over time, will encroach into active logic, and will further cause automatic test pattern generation (ATPG) failure. To date, there has been a lack of structural test coverage for DCAP circuits, which reduces test coverage of the chip as a whole. To this end, defects on the chip as they relate to DCAPs (i.e. shorts in the DCAP) may not be detected. The present disclosure provides a structural test system and method for DCAPs and other passive logic components located on-chip."
11132146,"Memory page table invalidations for multiple execution contexts (clients or guests) of a memory system are conventionally queued in a single physical command queue. The multiple execution contexts contend to access the queue, resulting in low performance. Instead of contending with other execution contexts to insert invalidation commands into a single physical command queue, a virtual interface and one or more virtual command queues are allocated to each guest. The execution contexts may simultaneously transmit invalidation commands for the memory system through their respective virtual interface. Additionally, each execution context may also transmit other (less often issued) commands through a hypervisor. Error handling and/or illegal access checks specific to invalidation commands that were previously performed by the hypervisor are now performed by the respective virtual interface(s)."
11132326,"Apparatuses, systems, and techniques to route data transfers between hardware devices. In at least one embodiment, a path over which to transfer data from a first hardware component of a computer system to a second hardware component of a computer system is determined based, at least in part, on one or more characteristics of different paths usable to transfer the data."
11132543,"A method, computer readable medium, and system are disclosed for performing unconstrained appearance-based gaze estimation. The method includes the steps of identifying an image of an eye and a head orientation associated with the image of the eye, determining an orientation for the eye by analyzing, within a convolutional neural network (CNN), the image of the eye and the head orientation associated with the image of the eye, and returning the orientation of the eye."
11133794,"This disclosure relates to a circuit comprising a first, second, and third data latch, and an input for a data signal. The first data latch may be configured to sample a delayed version of the data signal in response to a first control signal. The second data latch may be configured to sample the delayed version of the data signal in response to a run clock signal. The run clock signal may be configured to run for a predefined number of clock cycles subsequent to the first control signal. The third data latch may be configured to sample either an output signal of the first data latch or an output signal of the second data latch in response to a second control signal received after the predefined number of clock cycles of the run clock signal."
11137815,"Embodiments of the present invention provide methods and apparatus for metering GPU workload in real time. Metering of the GPU workload is performed by a Workload Metering (WLM) algorithm implemented in software or firmware that calculates a duty cycle for the graphics engine. The duty cycle forces the graphics engine to transition from a busy state to an idle state periodically based on measured power consumption, and engages race-to-sleep techniques to place the engine or engines in a low power state during the forced idle times, thereby reducing the overall power draw of the GPU to meet a predetermined power budget. According to some embodiments, the WLM algorithm is deployed on a microcontroller of a power management unit (PMU)."
11138009,"Systems and methods for an efficient and robust multiprocessor-coprocessor interface that may be used between a streaming multiprocessor and an acceleration coprocessor in a GPU are provided. According to an example implementation, in order to perform an acceleration of a particular operation using the coprocessor, the multiprocessor: issues a series of write instructions to write input data for the operation into coprocessor-accessible storage locations, issues an operation instruction to cause the coprocessor to execute the particular operation; and then issues a series of read instructions to read result data of the operation from coprocessor-accessible storage locations to multiprocessor-accessible storage locations."
11138018,"Profile-guided optimization is a technique for optimizing execution of computer programs using profile information to improve program runtime performance. Obtaining the profile information can be challenging, especially in live production environments such as high-performance gaming systems. A profiling strategy is provided herein that obtains profile information without requiring extra effort from users. The profiling strategy collects several approximate, lightweight profiles called piecemeal profiles over one or more lifetimes of a computer program, or application. The piecemeal profiles are then used to generate whole program application profiles that can then be used to improve the execution of the application. A piecemeal profile is profile information of a section or portion of an application."
11140216,"A computer streaming system includes a remote user device and a host streaming unit. The host streaming unit determines input methods suitable for the remote user device to interact with content streamed to the remote user using a selected application. The host streaming unit detects whether a user interface of the selected application is supported by the remote user device and dynamically institutes emulated native input support for the remote user device when the host streaming unit detects the user interface of the selected application is not supported by the remote user device. Additionally, the host streaming unit dynamically dismisses emulated native input support for the remote user device when the host streaming unit detects the user interface of the selected application is supported by the remote user device, causing the remote user device to return to native input control. Also provided is a method of streaming a computer application."
11144080,"High-resolution switched digital regulators are disclosed having fast cross corner and variable temperature response, with constrained ripple. The strength of the power transistors utilized by the regulator are adjusted to control the current delivered to the load. The regulators utilize a slow control loop in parallel with a primary fast switching loop. The slow loop uses the switching signal of the primary loop to estimate the load current and set the power transistor size accordingly."
11144087,"Performance monitors are placed on computational units in different clock domains of an integrated circuit. A central dispatcher generates trigger signals to the performance monitors to cause the performance monitors to respond to the trigger signals with packets reporting local performance counts for the associated computational units. The data in the packets are correlated into a single clock domain. By applying a trigger and reporting system, the disclosed approach can synchronize the performance metrics of the various computational units in the different clock domains without having to route a complex global clock reference signal to all of the performance monitors."
11144391,"Various embodiments include an on-die error correction code (ECC) system that preserves rectangular symbols of arbitrary size and shape, where the dimensions of the symbol are powers of two. Further, the on-die ECC system preserves symbols that include multiple rectangles of arbitrary size and shape, where the dimensions of each rectangle are powers of two, and where the vertical and horizontal offset between consecutive rectangles are also powers of two. If the on-die ECC system miscorrects a memory bit, then the miscorrection is constrained or restricted to the same symbol that includes the other error bits. Therefore, all error bits, including the miscorrected bit, are in the same symbol. As a result, a user ECC system, such as a symbol-based ECC system, can correct and detect any number of errors within a single symbol, even when the on-die ECC system miscorrects a memory bit."
11144754,"Apparatuses, systems, and techniques are described to determine locations of objects using images including digital representations of those objects. In at least one embodiment, a gaze of one or more occupants of a vehicle is determined independently of a location of one or more sensors used to detect those occupants."
11145108,A cube map is used for determining the appearance of a surface by means of a precomputed texture image. Embodiments of the present invention are drawn computer systems and methods for rendering a spherical projection as a cube map that mitigates non-uniform pixel density near the edges of the cube map to avoid artifacts and increase rendering performance.
11145110,"In examples, the number of rays used to sample lighting conditions of a light source in a virtual environment with respect to particular locations in the virtual environment may be adapted to scene conditions. An additional ray(s) may be used for locations that tend to be associated with visual artifacts in rendered images. A determination may be made on whether to cast an additional ray(s) to a light source for a location and/or a quantity of rays to cast. To make the determination variables such as visibilities and/or hit distances of ray-traced samples of the light source may be analyzed for related locations in the virtual environment, such as those in a region around the location (e.g., within an N-by-N kernel centered at the location). Factors may include variability in visibilities and/or hit distances, differences between visibilities and/or hit distances relative to the location, and magnitudes of hit distances."
11146662,A system and method for transmitting state based input over a network are presented. Embodiments of the present invention are operable to generate vector data comprising a composite of all state data associated with the state of all user input claims of a client system and transmit the vector data from the client device to a host device over a network. Embodiments of the present invention are further operable at the host device to determine a simulated input state at the client side by performing a comparison of the vector data currently received to a last known vector data and rendering output in response to the comparison.
11150663,"An autonomous driving system could create or exacerbate a hazardous driving situation due to incorrect machine learning, algorithm design, sensor limitations, environmental conditions or other factors. This technology presents solutions that use machine learning to detect when the autonomous driving system is in this state e.g., erratic or reckless driving and other behavior, in order to take remedial action to prevent a hazard such as a collision."
11150721,"A system and method are described for providing hints to a processing unit that subsequent operations are likely. Responsively, the processing unit takes steps to prepare for the likely subsequent operations. Where the hints are more likely than not to be correct, the processing unit operates more efficiently. For example, in an embodiment, the processing unit consumes less power. In another embodiment, subsequent operations are performed more quickly because the processing unit is prepared to efficiently handle the subsequent operations."
11151394,"Operations may comprise obtaining a first point cloud from a map representing a region. The operations may also include obtaining a second point cloud from one or more sensors of a vehicle traveling through the region. In addition, the operations may include identifying one or more subsets of clusters of second points of the second point cloud. The operations may also include determining correspondences between first points of the first point cloud and cluster points of the one or more subsets of clusters of the second point cloud. Moreover, the operations may include identifying at least a cluster of the one or more subsets of clusters, the identified cluster having, with respect to first points of the first point cloud, a correspondence percentage that is less than a threshold value. The operations may also include adjusting the second point cloud based on the identified cluster."
11151914,"In various examples, defective cells from a first layer of a multi-layer liquid crystal display (LCD) may be compensated for by using one or more cells from a second layer of the multi-layer LCD. Color values corresponding to additional cells of the first layer that may be affected by the compensation of the second layer may also be adjusted to counter the compensation in order to generate a final pixel or sub-pixel value that closely mirrors the desired value from the image data. In addition, backlighting of the LCD may be adjusted such that one or more cells of the backlights—e.g., individual light-emitting diodes (LEDs)—may be adjusted to further aid in compensating for or mitigating the appearance of the defective cell."
11154773,"A game-agnostic event detector can be used to automatically identify game events. Game-specific configuration data can be used to specify types of pre-processing to be performed on media for a game session, as well as types of detectors to be used to detect events for the game. Event data for detected events can be written to an event log in a form that is both human- and process-readable. The event data can be used for various purposes, such as to generate highlight videos or provide player performance feedback."
11157414,"In a ray tracer, a cache for streaming workloads groups ray requests for coherent successive bounding volume hierarchy traversal operations by sending common data down an attached data path to all ray requests in the group at the same time or about the same time. Grouping the requests provides good performance with a smaller number of cache lines."
11158346,"In various examples, durations of relatively high user activity within a gameplay session may be determined from user input events using a running user activity measurement. Once a duration is identified, it may be further analyzed to merge the duration with one or more other durations and/or to determine or predict whether the duration would be of sufficient interest for further action. A user interest score for an identified duration may be computed based on a set of the user input events that occur in the duration and used to determine and/or predict whether the duration would be of sufficient interest for further action. In some cases, an action may be performed based on determining the user interest score is greater than a statistical value that is computed from user interest scores of multiple identified durations."
11159153,"Mechanisms to reduce noise and/or energy consumption in PAM communication systems, utilizing conditional symbol substitution in each burst interval of a multi-data lane serial data bus."
11159304,"A clock data recovery (CDR) mechanism qualifies symbols received from the data detector prior to using those symbols to compute a timing gradient. The disclosed CDR mechanism analyzes one or more recently received symbols to determine whether the current symbol should be used in computing the time gradient. When configured with a Mueller-Muller phase detector, the timing gradient for the received signal is set to zero if the current symbol is a −2 or a +2 and the previous symbol is non-zero. Otherwise, the Mueller-Muller timing gradient is evaluated in the traditional manner. When configured with a minimum mean-squared error phase detector, the timing gradient for the received signal is set to zero if the previous symbol is non-zero. Otherwise, the minimum mean-squared error timing gradient is evaluated in the traditional manner."
11159655,"A user datagram protocol (UDP) is a well-known protocol for transferring data between two nodes of a network. When data is too large to fit within a single UDP packet that can be transmitted between the two nodes, the data needs to be segmented and transmitted with multiple packets and reassembled on the receiving node. Techniques are disclosed herein, for example, for offloading such segmentation, transmission, and reassembly from the central processing units (CPUs) of the nodes. Such offloading is performed efficiently, for example, by repurposing legacy protocol fields used in UDP transmission such as the internet protocol (IP) identification (ID), time to live (TTL), type of service (TOS), and/or EtherType fields to encode information needed for efficient segmentation, out of order reception, and reassembly."
11162788,"A high-definition map system receives sensor data from vehicles traveling along routes and combines the data to generate a high definition map for use in driving vehicles, for example, for guiding autonomous vehicles. A pose graph is built from the collected data, each pose representing location and orientation of a vehicle. The pose graph is optimized to minimize constraints between poses. Points associated with surface are assigned a confidence measure determined using a measure of hardness/softness of the surface. A machine-learning-based result filter detects bad alignment results and prevents them from being entered in the subsequent global pose optimization. The alignment framework is parallelizable for execution using a parallel/distributed architecture. Alignment hot spots are detected for further verification and improvement. The system supports incremental updates, thereby allowing refinements of subgraphs for incrementally improving the high-definition map for keeping it up to date."
11163303,"This disclosure presents an assisted driving vehicle system, including autonomous, semi-autonomous, and technology assisted vehicles, that can share sensor data among two or more controllers. A sensor can have one communication channel to a controller, thereby saving cabling and circuitry costs. The data from the sensor can be sent from one controller to another controller to enable redundancy and backup in case of a system failure. In another embodiment, sensor data from more than one sensor can be aggregated at one controller prior to the aggregated sensor data being communicated to another controller thereby saving bandwidth and reducing transmission times. The sharing of sensor data can be enabled through the use of a sensor data distributor, such as a converter, repeater, or a serializer/deserializer set located as part of the controller and communicatively coupled to another such device in another controller using a data interface communication channel."
11163859,"A computer system comprising a processor and a memory for storing instructions, that when executed by the processor performs a copy protection method. The copy protection method comprises executing a software loop of a first software application in a first operating system. A first call is executed in the software loop to a code portion. A decrypted code portion of the first software application is executed in a second operating system in response to the first call. The code portion is decrypted in response to a successful validation of the first software application."
11164360,"A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include opaque and alpha triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to determine primitives intersected by the ray, and return intersection information to a streaming multiprocessor for further processing. The hardware-based traversal coprocessor is configured to provide a deterministic result of intersected triangles regardless of the order that the memory subsystem returns triangle range blocks for processing, while opportunistically eliminating alpha intersections that lie further along the length of the ray than closer opaque intersections."
11164372,"The disclosure introduces polar stroking for representing paths. A system, method, and apparatus are disclosed for representing and rendering stroked paths employing polar stroking. In one example, a method of approximating a link of a path is provided that includes: (1) determining tangent angle changes of a link of a path, (2) evaluating the link in steps based on the tangent angle changes, and (3) providing a polar stroked representation of the link employing the steps, wherein the evaluating is performed non-recursively. A polar stroking system is also disclosed. In one example, the polar stroking system includes: (1) a path processor configured to decompose a path into links, and (2) a polar stroking processor configured to determine polar stroking intermediates of the links from a characterization of the links and generate, employing the polar stroking intermediates, a polar stroked representation for each of the links."
11165394,"The disclosure provides an improved transimpedance amplifier (TIA) that can operate at a higher bandwidth and lower noise compared to conventional TIAs. The TIA employs a data path with both feedback impedance and feedback capacitance for improved performance. The feedback impedance includes at least two resistors in series and at least one shunt capacitor, coupled between the at least two resistors, that helps to extend the circuit bandwidth and improve SNR at the same time. The capacitance value of the shunt capacitor can be selected based on both the bandwidth and noise. In one example, the TIA includes: (1) a biasing path, and (2) a data path, coupled to the biasing path, including multiple inverter stages and at least one feedback capacitance coupled across an even number of the multiple inverter stages. An optical receiver and a circuit having the TIA are also disclosed."
11165848,"A technique for evaluating qualitative streaming experience using session performance metadata is disclosed herein. A pipeline of a streaming service can be adapted to collect metadata, such as timestamps, from various components of the pipeline. The metadata can then be analyzed to calculate an objective quality metric for each streaming session using weighted scores derived from the metadata for a plurality of different components including, but not limited to, stutter, latency, and/or picture quality. The quality metric is designed to have high correlation with subjective measures of quality by users of the streaming service, but provides dense data samples compared to typical sparse responses collected from user feedback (e.g., user surveys). The objective quality metric can be utilized to quickly adjust, either manually or automatically, the streaming service parameters to improve the quality of the streaming service due to changes in, e.g., streaming content."
11169779,An adder circuit provides a first operand input and a second operand input to an XNOR cell. The XNOR cell transforms these inputs to a propagate signal that is applied to an OAT cell to produce a carry out signal. A third OAT cell transforms a third operand input and the propagate signal into a sum output signal.
11169858,"The disclosure is directed to a method of operating a game system where virtual machines (VM) supporting the game session can be reused by a second user after a first user ends their game session. In another aspect, the VM can be shut down if the number of VMs exceeds a target number of VMs or if an abnormality is detected in the VM. In another aspect, VMs can be instantiated in order to meet a target number of VMs. In another aspect, a software application is disclosed to execute the methods described herein. In another aspect, a game services system is disclosed that can operate a VM group, maintain a status parameter of the instantiated VMs, and service user requests for game sessions."
11170263,A technique utilizing speculative execution and rollback for performing data parallel training of a neural network model is disclosed. Activations for a layer of the neural network model are normalized during a speculative normalization operation using estimated normalization parameters associated with a partial population of a set of training data allocated to a particular processor. Normalization parameters associated with the total population of the set of training data are generated by a distributed reduce operation in parallel with the speculative normalization operation. An optional rollback operation can revert the activations to a pre-normalization state if the estimated normalization parameters for the partial population are subsequently determined to be inaccurate compared to the normalization parameters for the population of the set of training data distributed across a plurality of processors.
11170299,"In various examples, a deep neural network (DNN) is trained—using image data alone—to accurately predict distances to objects, obstacles, and/or a detected free-space boundary. The DNN may be trained with ground truth data that is generated using sensor data representative of motion of an ego-vehicle and/or sensor data from any number of depth predicting sensors—such as, without limitation, RADAR sensors, LIDAR sensors, and/or SONAR sensors. The DNN may be trained using two or more loss functions each corresponding to a particular portion of the environment that depth is predicted for, such that—in deployment—more accurate depth estimates for objects, obstacles, and/or the detected free-space boundary are computed by the DNN. In some embodiments, a sampling algorithm may be used to sample depth values corresponding to an input resolution of the DNN from a predicted depth map of the DNN at an output resolution of the DNN."
11170471,"A game-agnostic event detector can be used to automatically identify game events. Game-specific configuration data can be used to specify types of pre-processing to be performed on media for a game session, as well as types of detectors to be used to detect events for the game. Event data for detected events can be written to an event log in a form that is both human- and process-readable. The event data can be used for various purposes, such as to generate highlight videos or provide player performance feedback. The event data may be determined based upon output from detectors such as optical character recognition (OCR) engines, and the regions may be upscaled and binarized before OCR processing."
11170566,"One aspect of the disclosure provides a method for rendering an image. The method includes: placing primitives of the image in a screen space; binning the primitives into tiles of the screen space that the primitives touch; and rasterizing the tiles. The aforementioned rasterizing includes shading a subset of the primitives binned to one of the tiles over multiple passes at multiple shading rates, each of the shading rates is based at least on a frequency at which a color being shaded at each pass changes across the screen space, and the subset of the primitives are cached in an on-chip memory of a processor rendering the image between the passes."
11170740,"A technique for selecting locations of tear lines when displaying visual content. The technique includes receiving coordinates for one or more portions of a display where a tear is permitted and determining if a frame transition is to occur while rendered content is being scanned out for display within the one or more portions of the display where tear is permitted. If the frame transition is to occur while the scanline for the display is in the one or more portions of the display where tear is permitted, then the technique further includes allowing the frame transition to occur. If the frame transition is to occur while the scanline for the display is not in the one or more portions of the display where tear is permitted, then the technique further includes delaying the frame transition until at least when the scanline for the display is in the one or more portions of the display where tear is permitted."
11171798,"A network device configured to perform scalable, in-network computations is described. The network device is configured to process pull requests and/or push requests from a plurality of endpoints connected to the network. A collective communication primitive from a particular endpoint can be received at a network device. The collective communication primitive is associated with a multicast region of a shared global address space and is mapped to a plurality of participating endpoints. The network device is configured to perform an in-network computation based on information received from the participating endpoints before forwarding a response to the collective communication primitive back to one or more of the participating endpoints. The endpoints can inject pull requests (e.g., load commands) and/or push requests (e.g., store commands) into the network. A multicast capability enables tasks, such as a reduction operation, to be offloaded to hardware in the network device."
11176682,"In various examples, optical flow estimate (OFE) quality is improved when employing a hint-based algorithm in multi-level hierarchical motion estimation by using different scan orders at different resolution levels. A scan of an image performed with a scan order may initially leverage OFEs from a previous scan of the image, where the previous scan was performed using a different scan order. The OFEs leveraged from the previous scan are more likely to be of high accuracy until sufficient spatial hints are available to the hint-based algorithm for the scan to reduce the impact of potentially lower quality OFEs resulting from the different scan order of the previous scan."
11176967,"In various examples, recordings of gameplay sessions are enhanced by the application of special effects to relatively high(er) and/or low(er) interest durations of the gameplay sessions. Durations of relatively high(er) or low(er) predicted interest in a gameplay session are identified, for instance, based upon level of activity engaged in by a gamer during a particular gameplay session duration. Once identified, different variations of video characteristic(s) are applied to at least a portion of the identified durations for implementation during playback. The recordings may be generated and/or played back in real-time with a live gameplay session, or after completion of the gameplay session. Further, video data of the recordings themselves may be modified to include the special effects and/or indications of the durations and/or variations may be included in metadata and used for playback."
11182207,"Techniques are disclosed for reducing the latency between the completion of a producer task and the launch of a consumer task dependent on the producer task. Such latency exists when the information needed to launch the consumer task is unavailable when the producer task completes. Thus, various techniques are disclosed, where a task management unit initiates the retrieval of the information needed to launch the consumer task from memory in parallel with the producer task being launched. Because the retrieval of such information is initiated in parallel with the launch of the producer task, the information is often available when the producer task completes, thus allowing for the consumer task to be launched without delay. The disclosed techniques, therefore, enable the latency between completing the producer task and launching the consumer task to be reduced."
11182309,"Fabric Attached Memory (FAM) provides a pool of memory that can be accessed by one or more processors, such as a graphics processing unit(s) (GPU)(s), over a network fabric. In one instance, a technique is disclosed for using imperfect processors as memory controllers to allow memory, which is local to the imperfect processors, to be accessed by other processors as fabric attached memory. In another instance, memory address compaction is used within the fabric elements to fully utilize the available memory space."
11182598,"The present disclosure provides various approaches for smart area monitoring suitable for parking garages or other areas. These approaches may include ROI-based occupancy detection to determine whether particular parking spots are occupied by leveraging image data from image sensors, such as cameras. These approaches may also include multi-sensor object tracking using multiple sensors that are distributed across an area that leverage both image data and spatial information regarding the area, to provide precise object tracking across the sensors. Further approaches relate to various architectures and configurations for smart area monitoring systems, as well as visualization and processing techniques. For example, as opposed to presenting video of an area captured by cameras, 3D renderings may be generated and played from metadata extracted from sensors around the area."
11182649,"Training deep neural networks requires a large amount of labeled training data. Conventionally, labeled training data is generated by gathering real images that are manually labelled which is very time-consuming. Instead of manually labelling a training dataset, domain randomization technique is used generate training data that is automatically labeled. The generated training data may be used to train neural networks for object detection and segmentation (labelling) tasks. In an embodiment, the generated training data includes synthetic input images generated by rendering three-dimensional (3D) objects of interest in a 3D scene. In an embodiment, the generated training data includes synthetic input images generated by rendering 3D objects of interest on a 2D background image. The 3D objects of interest are objects that a neural network is trained to detect and/or label."
11182884,"The various embodiments of the present disclosure are directed towards methods for tone mapping High-Dynamic-Range (HDR) image data, as well as controlling the brightness of the image encoded by HDR the image data and/or the tone-mapped image data. HDR image is captured. A tone mapping function for the HDR image data is generated. To generate the tone mapping function, control points are dynamically determined based on an analysis of the HDR image data. The tone mapping function is fit to the control points. The tone mapping function is a non-linear function, and is described by a curve in a plane. The shape of the curve is constrained by a line generated from a portion of the control points. The tone mapping function is applied to the HDR image data. A color-compression is applied to the tone mapped image data to generate Standard Dynamic Range or Low Dynamic Range image data."
11182916,"In various examples, a deep neural network (DNN) is trained to accurately predict, in deployment, distances to objects and obstacles using image data alone. The DNN may be trained with ground truth data that is generated and encoded using sensor data from any number of depth predicting sensors, such as, without limitation, RADAR sensors, LIDAR sensors, and/or SONAR sensors. Camera adaptation algorithms may be used in various embodiments to adapt the DNN for use with image data generated by cameras with varying parameters—such as varying fields of view. In some examples, a post-processing safety bounds operation may be executed on the predictions of the DNN to ensure that the predictions fall within a safety-permissible range."
11184008,This disclosure relates to a receiver that includes a clock and data recovery loop and a phase offset loop. The clock and data recovery loop may be controlled by a sum of gradients for a plurality of data interleaves. The phase offset loop may be controlled by an accumulated differential gradient for each of the data interleaves.
11188442,"Memory, used by a computer to store data, is generally prone to faults, including permanent faults (i.e. relating to a lifetime of the memory hardware), and also transient faults (i.e. relating to some external cause) which are otherwise known as soft errors. Since soft errors can change the state of the data in the memory and thus cause errors in applications reading and processing the data, there is a desire to characterize the degree of vulnerability of the memory to soft errors. In particular, once the vulnerability for a particular memory to soft errors has been characterized, cost/reliability trade-offs can be determined, or soft error detection mechanisms (e.g. parity) may be selectively employed for the memory. In some cases, memory faults can be diagnosed by redundant execution and a diagnostic coverage may be determined."
11189075,"Methods and systems are described in some examples for changing the traversal of an acceleration data structure in a highly dynamic query-specific manner, with each query specifying test parameters, a test opcode and a mapping of test results to actions. In an example ray tracing implementation, traversal of a bounding volume hierarchy by a ray is performed with the default behavior of the traversal being changed in accordance with results of a test performed using the test opcode and test parameters specified in the ray data structure and another test parameter specified in a node of the bounding volume hierarchy. In an example implementation a traversal coprocessor is configured to perform the traversal of the bounding volume hierarchy."
11195331,"A neural network may be used to determine corner points of a skewed polygon (e.g., as displacement values to anchor box corner points) that accurately delineate a region in an image that defines a parking space. Further, the neural network may output confidence values predicting likelihoods that corner points of an anchor box correspond to an entrance to the parking spot. The confidence values may be used to select a subset of the corner points of the anchor box and/or skewed polygon in order to define the entrance to the parking spot. A minimum aggregate distance between corner points of a skewed polygon predicted using the CNN(s) and ground truth corner points of a parking spot may be used simplify a determination as to whether an anchor box should be used as a positive sample for training."
11200356,"In modeling contact between two or more objects (such as a robotic arm placing a block on a stack of blocks) or articulations of a series of linked joints (such as modeling a backhoe), current techniques can introduce additional energy into the system or fail to resolve a constraint imposed on the system. The current techniques attempt to resolve these issues, for example, by using very small time steps. Very small time steps, however, can significantly increase computational costs of the modeling simulation. The disclosed simulation system for rigid bodies uses a time interval to reduce linearization artifacts due to the small time steps and reduce computational costs with faster solver convergence by permitting more efficient bias calculations. High mass handling can also be improved through the more efficient bias calculations."
11200725,"A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include opaque and alpha triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to determine primitives intersected by the ray, and return intersection information to a streaming multiprocessor for further processing. The hardware-based traversal coprocessor is configured to omit reporting of one or more primitives the ray is determined to intersect. The omitted primitives include primitives which are provably capable of being omitted without a functional impact on visualizing the virtual scene."
11204849,"In various examples, one or more components or regions of a processing unit—such as a processing core, and/or component thereof—may be tested for faults during deployment in the field. To perform testing while in deployment, the state of a component subject to test may be retrieved and/or stored during the test to maintain state integrity, the component may be clamped to communicatively isolate the component from other components of the processing unit, a test vector may be applied to the component, and the output of the component may be compared against an expected output to determine if any faults are present. The state of the component may be restored after testing, and the clamp removed, thereby returning the component to its operating state without a perceivable detriment to operation of the processing unit in deployment."
11205086,"In various examples, sensor data—such as masked sensor data—may be used as input to a machine learning model to determine a confidence for object to person associations. The masked sensor data may focus the machine learning model on particular regions of the image that correspond to persons, objects, or some combination thereof. In some embodiments, coordinates corresponding to persons, objects, or combinations thereof, in addition to area ratios between various regions of the image corresponding to the persons, objects, or combinations thereof, may be used to further aid the machine learning model in focusing on important regions of the image for determining the object to person associations."
11209548,"Embodiments relate to methods for efficiently encoding sensor data captured by an autonomous vehicle and building a high definition map using the encoded sensor data. The sensor data can be LiDAR data which is expressed as multiple image representations. Image representations that include important LiDAR data undergo a lossless compression while image representations that include LiDAR data that is more error-tolerant undergo a lossy compression. Therefore, the compressed sensor data can be transmitted to an online system for building a high definition map. When building a high definition map, entities, such as road signs and road lines, are constructed such that when encoded and compressed, the high definition map consumes less storage space. The positions of entities are expressed in relation to a reference centerline in the high definition map. Therefore, each position of an entity can be expressed in fewer numerical digits in comparison to conventional methods."
11210253,"Techniques are disclosed for tracking memory page accesses in a unified virtual memory system. An access tracking unit detects a memory page access generated by a first processor for accessing a memory page in a memory system of a second processor. The access tracking unit determines whether a cache memory includes an entry for the memory page. If so, then the access tracking unit increments an associated access counter. Otherwise, the access tracking unit attempts to find an unused entry in the cache memory that is available for allocation. If so, then the access tracking unit associates the second entry with the memory page, and sets an access counter associated with the second entry to an initial value. Otherwise, the access tracking unit selects a valid entry in the cache memory; clears an associated valid bit; associates the entry with the memory page; and initializes an associated access counter."
11210537,"In various examples, detected object data representative of locations of detected objects in a field of view may be determined. One or more clusters of the detected objects may be generated based at least in part on the locations and features of the cluster may be determined for use as inputs to a machine learning model(s). A confidence score, computed by the machine learning model(s) based at least in part on the inputs, may be received, where the confidence score may be representative of a probability that the cluster corresponds to an object depicted at least partially in the field of view. Further examples provide approaches for determining ground truth data for training object detectors, such as for determining coverage values for ground truth objects using associated shapes, and for determining soft coverage values for ground truth objects."
11212073,"A system for data and clock recovery includes a timing error detector, a phase detector, and a phase increment injector. The phase increment injector may be used to determine an increment to affect an output of the phase detector or a clocking element. A sign of the increment is determined from a sign or direction of an accumulated version of a clock and data recovery gradient value."
11212539,"Systems and methods for efficient lossless compression of captured raw image information are presented. A method can comprise: receiving raw image data from an image capture device, segregating the pixel data into a base layer portion and an enhanced layer portion, reconfiguring the base layer portion expressed in the first color space values from a raw capture format into a pseudo second color space compression mechanism compatible format, and compressing the reconfigured base layer portion of first color space values. The raw image data can include pixel data are expressed in first color space values. The segregation can be based upon various factors, including a compression benefits analysis of a boundary location between the base layer portion and enhanced layer portion. The reconfiguring the base layer portion can include separating the base layer portion based upon multiple components within the raw data; and forming base layer video frames from the multiple components."
11212943,A datacenter cooling system is disclosed. The system includes a first cooling loop with a heat exchanger to exchange heat with a second cooling loop. The second cooling loop includes a cooling distribution unit (CDU) to exchange heat between the second cooling loop and a primary cooling loop.
11214273,"In a self-driving autonomous vehicle, a controller architecture includes multiple processors within the same box. Each processor monitors the others and takes appropriate safe action when needed. Some processors may run dormant or low priority redundant functions that become active when another processor is detected to have failed. The processors are independently powered and independently execute redundant algorithms from sensor data processing to actuation commands using different hardware capabilities (GPUs, processing cores, different input signals, etc.). Intentional hardware and software diversity improves fault tolerance. The resulting fault-tolerant/fail-operational system meets ISO26262 ASIL D specifications based on a single electronic controller unit platform that can be used for self-driving vehicles."
11216916,"Approaches presented herein can reduce temporal lag that may be introduced in a generated image sequence that utilizes temporal accumulation for denoising in dynamic scenes. A fast historical frame can be generated along with a full historical frame generated for a denoising process, with the fast historical frame being accumulated using an exponential moving average with a significantly higher blend weight. This fast history frame can be used to determine a clamping window that can be used to clamp a corresponding full historical value before, or after, reprojection. The fast historical blend weight can be adjusted to control the amount of noise versus temporal lag in an image sequence. In some embodiments, differences between fast and full historical values can also be used to determine an amount of spatial filtering to be applied."
11219824,"A gaming cloud gaming system and a method of initiating a gaming session. One embodiment of the gaming cloud gaming system includes a computing system having: (1) an entry point operable to receive a game session request and generate instructions for establishing a connection between a client and a game server, and (2) a dynamically configurable reverse proxy operable to proxy for the game server and configured to employ the instructions to create a route to a randomly selected port on the game server through which the connection is makeable."
11222232,"In various examples, the present disclosure relates to using temporal filters for automated real-time classification. The technology described herein improves the performance of a multiclass classifier that may be used to classify a temporal sequence of input signals—such as input signals representative of video frames. A performance improvement may be achieved, at least in part, by applying a temporal filter to an output of the multiclass classifier. For example, the temporal filter may leverage classifications associated with preceding input signals to improve the final classification given to a subsequent signal. In some embodiments, the temporal filter may also use data from a confusion matrix to correct for the probable occurrence of certain types of classification errors. The temporal filter may be a linear filter, a nonlinear filter, an adaptive filter, and/or a statistical filter."
11227448,"A content management system may maintain a scene description that represents a 3D virtual environment and a publish/subscribe model in which clients subscribe to content items that correspond to respective portions of the shared scene description. When changes are made to content, the changes may be served to subscribing clients. Rather than transferring entire descriptions of assets to propagate changes, differences between versions of content may be exchanged, which may be used construct updated versions of the content. Portions of scene description may reference other content items and clients may determine whether to request and load these content items for lazy loading. Content items may be identified by Uniform Resource Identifiers (URIs) used to reference the content items. The content management system may maintain states for client connections including for authentication, for the set of subscriptions in the publish/subscribe model, and for their corresponding version identifiers."
11231760,"Integrated circuits (ICs)—depending on a current workload—may exceed thermal cooling budgets. As a result, ICs often implement thermal sensors to measure temperatures at junctions or hot spots along the IC. Due to a distance between the thermal sensors and the various junctions, a thermal offset may be added to the temperature readings from the thermal sensors to more accurately estimate the temperature at the junctions. To account for different workload distributions—e.g., asymmetric or symmetric—the systems and methods described herein may dynamically adjust the thermal offsets. As a result, the efficiency of the IC may be increased as thermal settings for the IC may take into account the ability of the thermal cooling budget to effectively cool the IC under a current operating condition—thereby reducing premature throttling back or shutting down of power to the IC."
11232544,"Approaches presented herein can reduce temporal lag that may be introduced in a generated image sequence that utilizes temporal accumulation for denoising in dynamic scenes. A fast historical frame can be generated along with a full historical frame generated for a denoising process, with the fast historical frame being accumulated using an exponential moving average with a significantly higher blend weight. This fast history frame can be used to determine a clamping window that can be used to clamp a corresponding full historical value before, or after, reprojection. The fast historical blend weight can be adjusted to control the amount of noise versus temporal lag in an image sequence. In some embodiments, differences between fast and full historical values can also be used to determine an amount of spatial filtering to be applied."
11233730,"Introduced herein is a routing technique that, for example, routes a transaction to a destination port over a network that supports link aggregation and multi-port connection. In one embodiment, two tables that can be searched based on the target and supplemental routing IDs of the transaction are utilized to route the transaction to the proper port of the destination endpoint. In an embodiment, the first table provides a list of available ports at each hop/route point that can route the transaction to the destination endpoint, and the second table provides a supplemental routing ID that can select a specific group of ports from the first table that can correctly route the transaction to the proper port."
11238650,"Apparatuses, systems, and techniques to identify a shape or camera pose of a three-dimensional object from a two-dimensional image of the object. In at least one embodiment, objects are identified in an image using one or more neural networks that have been trained on objects of a similar category and a three-dimensional mesh template."
11238815,"A display controller within a display device includes a serial peripheral interface (SPI) that coordinates the updating of current settings for groups of light-emitting diodes (LEDs). The SPI controller operates in synchrony with a liquid-crystal display (LCD) vertical scan position in order to update the current settings for rows of LEDs in parallel with the updating of nearby rows of LCD pixels. When updating a row of LEDs, the SPI controller executes one or more SPI transactions included in an SPI program to write current settings for multiple LEDs nearly simultaneously. A compiler generates the SPI program based on the topology of LEDs included in the display device."
11243786,"The disclosure relates to the transfer of visuals (e.g., window visuals) over virtual frames that may be stored in any number of video frames of one or more video streams. The visuals may be split into two-dimensional (2D) pages of a virtual frame, with each of the 2D pages being a fraction of the size of video frames of the video stream(s). The virtual frame may be encoded to the video frames of the video stream(s) and later reconstructed in accordance with a page table."
11244226,"A method, computer readable medium, and system are disclosed for training a neural network model. The method includes the step of selecting an input vector from a set of training data that includes input vectors and sparse target vectors, where each sparse target vector includes target data corresponding to a subset of samples within an output vector of the neural network model. The method also includes the steps of processing the input vector by the neural network model to produce output data for the samples within the output vector and adjusting parameter values of the neural network model to reduce differences between the output vector and the sparse target vector for the subset of the samples."
11244493,"Disclosed approaches provide for interactions of secondary rays of light transport paths in a virtual environment to share lighting contributions when determining lighting conditions for a light transport path. Interactions may be shared based on similarities in characteristics (e.g., hit locations), which may define a region in which interactions may share lighting condition data. The region may correspond to a texel of a texture map and lighting contribution data for interactions may be accumulated to the texel spatially and/or temporally, then used to compute composite lighting contribution data that estimates radiance at an interaction. Approaches are also provided for reprojecting lighting contributions of interactions to pixels to share lighting contribution data from secondary bounces of light transport paths while avoiding potential over blurring."
11249727,"Many computing systems process data organized in a matrix format. For example, artificial neural networks (ANNs) perform numerous computations on data organized into matrices using conventional matrix arithmetic operations. One such operation, which is commonly performed, is the transpose operation. Additionally, many such systems need to process many matrices and/or matrices that are large in size. For sparse matrices that hold few significant values and many values that can be ignored, transmitting and processing all the values in such matrices is wasteful. Thus, techniques are introduced for storing a sparse matrix in a compressed format that allows for a matrix transpose operation to be performed on the compressed matrix without having to first decompress the compressed matrix. By utilizing the introduced techniques, more matrix operations can be performed than conventional systems."
11249905,"A parallel processing unit (PPU) can be divided into partitions. Each partition is configured to operate similarly to how the entire PPU operates. A given partition includes a subset of the computational and memory resources associated with the entire PPU. Software that executes on a CPU partitions the PPU for an admin user. A guest user is assigned to a partition and can perform processing tasks within that partition in isolation from any other guest users assigned to any other partitions. Because the PPU can be divided into isolated partitions, multiple CPU processes can efficiently utilize PPU resources."
11250296,"In various examples, object detections of a machine learning model are leveraged to automatically generate new ground truth data for images captured at different perspectives. The machine learning model may generate a prediction of a detected object at the different perspective, and an object tracking algorithm may be used to track the object through other images in a sequence of images where the machine learning model may not have detected the object. New ground truth data may be generated as a result of the object tracking algorithms outputs, and the new ground truth data may be used to retrain or update the machine learning model, train a different machine learning model, or increase the robustness of a ground truth data set that may be used for training machine learning models from various perspectives."
11250329,"A generative adversarial neural network (GAN) learns a particular task by being shown many examples. In one scenario, a GAN may be trained to generate new images including specific objects, such as human faces, bicycles, etc. Rather than training a complex GAN having a predetermined topology of features and interconnections between the features to learn the task, the topology of the GAN is modified as the GAN is trained for the task. The topology of the GAN may be simple in the beginning and become more complex as the GAN learns during the training, eventually evolving to match the predetermined topology of the complex GAN. In the beginning the GAN learns large-scale details for the task (bicycles have two wheels) and later, as the GAN becomes more complex, learns smaller details (the wheels have spokes)."
11250613,"Various techniques for adaptive rendering of images with noise reduction are described. More specifically, the present disclosure relates to approaches for rendering and denoising images—such as ray-traced images—in an iterative process that distributes computational efforts to pixels where denoised output is predicted with higher uncertainty. In some embodiments, an input image may be fed into a deep neural network (DNN) to jointly predict a denoised image and an uncertainty map. The uncertainty map may be used to create a distribution of additional samples (e.g., for one or more samples per pixel on average), and the additional samples may be used with the input image to adaptively render a higher quality image. This process may be repeated in a loop, until some criterion is satisfied, for example, when the denoised image converges to a designated quality, a time or sampling budget is satisfied, or otherwise."
11256528,"The present disclosure relates to streaming individual application windows and/or other desktop elements of a remote desktop. Data used to represent irrelevant desktop areas may be replaced with lower entropy data that may be highly compressed in a video stream and/or with data representative of other visual content. The video stream may also include desktop metadata (e.g., locations for desktop visuals, etc.) used to render the desktop elements on the local desktop. The desktop visuals of an application window may be rendered in a proxy window on the local desktop."
11256568,"The present invention facilitates efficient and effective utilization of storage management features. In one embodiment, a memory device comprises a memory interface, an ECC generation component, and storage components. The memory interface is configured to receive an access request to an address at which data is stored. The memory interface can also forward responses to the request including the data and ECC information associated with the data. The ECC generation component is configured to automatically establish an address at which the ECC information is stored based upon the receipt of the access request to an address at which data is stored. In one exemplary implementation, the internal establishment of the address at which the ECC information is stored is automatic. The storage components are configured to store the information."
11256835,A system and method for solving linear complementarity problems for rigid body simulation is disclosed. The method includes determining one or more contact constraints affecting an original object having an original mass. The method includes splitting the original object by a total number of the contact constraints into a plurality of sub-bodies. The method includes assigning a contact constraint to a corresponding sub-body. The method further includes solving contact constraints in isolation for each sub-body. The method also includes enforcing positions and orientations of each sub-body are identical.
11256961,"Segmentation is the identification of separate objects within an image. An example is identification of a pedestrian passing in front of a car, where the pedestrian is a first object and the car is a second object. Superpixel segmentation is the identification of regions of pixels within an object that have similar properties. An example is identification of pixel regions having a similar color, such as different articles of clothing worn by the pedestrian and different components of the car. A pixel affinity neural network (PAN) model is trained to generate pixel affinity maps for superpixel segmentation. The pixel affinity map defines the similarity of two points in space. In an embodiment, the pixel affinity map indicates a horizontal affinity and vertical affinity for each pixel in the image. The pixel affinity map is processed to identify the superpixels."
11257253,"The disclosure provides methods of encoding a path, a stroking system for paths, a renderer that generates a stroked tessellation of a path, and a method of determining a type of link of a path from a data structure. The data structure can be an array of indexed links that compactly encode a path. The position of one or more index values, such as a null index value, within an indexed link can encode the link's type. In one example, a method of encoding includes: (1) receiving a path having multiple links, wherein the links include at least one segment and at least one junction, and (2) generating an encoded path by encoding the links based on positional information of the links, wherein the encoding employs a same data structure for each of the links."
11263051,"Accesses between a processor and its external memory is reduced when the processor internally maintains a compressed version of values stored in the external memory. The processor can then refer to the compressed version rather than access the external memory. One compression technique involves maintaining a dictionary on the processor mapping portions of a memory to values. When all of the values of a portion of memory are uniform (e.g., the same), the value is stored in the dictionary for that portion of memory. Thereafter, when the processor needs to access that portion of memory, the value is retrieved from the dictionary rather than from external memory. Techniques are disclosed herein to extend, for example, the capabilities of such dictionary-based compression so that the amount of accesses between the processor and its external memory are further reduced."
11263525,"A neural network learns a particular task by being shown many examples. In one scenario, a neural network may be trained to label an image, such as cat, dog, bicycle, chair, etc. In other scenario, a neural network may be trained to remove noise from videos or identify specific objects within images, such as human faces, bicycles, etc. Rather than training a complex neural network having a predetermined topology of features and interconnections between the features to learn the task, the topology of the neural network is modified as the neural network is trained for the task, eventually evolving to match the predetermined topology of the complex neural network. In the beginning the neural network learns large-scale details for the task (bicycles have two wheels) and later, as the neural network becomes more complex, learns smaller details (the wheels have spokes)."
11265599,"In various examples, a media stream may be received by a re-encode system that may leverage a recode engine to convert (e.g., at an interval, based on a request, etc.) an inter-frame associated with the media stream to an intra-frame. The intra-frame may be converted from the inter-frame using parameters or other information associated with and received with the media stream. The converted intra-frame may be merged into an updated segment of the media stream in place of the original inter-frame to enable storage of the updated segment—or a portion thereof—for later use."
11270041,"Embodiments of the present invention provide a position-based dynamics approach for simulating objects using a set of points and constraints, applied as equations that restrict the relative motion of bodies. Forces are applied to the points to move them, and the constraints ensure that the points will not move in a way that is inconsistent with rules of the simulation. The present invention improves upon existing PBD approaches by using regularized constraints that directly correspond to well-defined energy potentials, and which can advantageously be solved independent of time step and iteration count."
11270161,"When a computer image is generated from a real-world scene having a semi-reflective surface (e.g. window), the computer image will create, at the semi-reflective surface from the viewpoint of the camera, both a reflection of a scene in front of the semi-reflective surface and a transmission of a scene located behind the semi-reflective surface. Similar to a person viewing the real-world scene from different locations, angles, etc., the reflection and transmission may change, and also move relative to each other, as the viewpoint of the camera changes. Unfortunately, the dynamic nature of the reflection and transmission negatively impacts the performance of many computer applications, but performance can generally be improved if the reflection and transmission are separated. The present disclosure uses deep learning to separate reflection and transmission at a semi-reflective surface of a computer image generated from a real-world scene."
11270197,"A distributed deep neural net (DNN) utilizing a distributed, tile-based architecture includes multiple chips, each with a central processing element, a global memory buffer, and a plurality of additional processing elements. Each additional processing element includes a weight buffer, an activation buffer, and vector multiply-accumulate units to combine, in parallel, the weight values and the activation values using stationary data flows."
11270495,"In examples, a list of elements may be divided into spans and each span may be allocated a respective memory range for output based on a worst-case compression ratio of a compression algorithm that will be used to compress the span. Worker threads may output compressed versions of the spans to the memory ranges. To ensure placement constraints of a data structure will be satisfied, boundaries of the spans may be adjusted prior to compression. The size allocated to a span (e.g., each span) may be increased (or decreasing) to avoid padding blocks while allowing for the span's compressed data to use a block allocated to an adjacent span. Further aspects of the disclosure provide for compaction of the portions of compressed data in memory in order to free up space which may have been allocated to account for the memory gaps which may result from variable compression ratios."
11270496,"The disclosure provides a renderer and a rendering process employing ray tracing and image-space filtering that interleaves the pixels of a frame into partial image fields and corresponding reduced-resolution images that are individually processed in parallel. In one example, the renderer includes: (1) an interface configured to receive scene information for rendering a full frame, and (2) a graphics processing system, coupled to the interface, configured to separate pixels of the full frame into different partial image fields that each include a unique set of interleaved pixels, render reduced-resolution images of the full frame by ray tracing the different partial image fields in parallel, independently apply image-space filtering to the reduced-resolution images in parallel, and merge the reduced-resolution images to provide a full rendered frame."
11275662,"Unavoidable physical phenomena, such as an alpha particle strikes, can cause soft errors in integrated circuits. Materials that emit alpha particles are ubiquitous, and higher energy cosmic particles penetrate the atmosphere and also cause soft errors. Some soft errors have no consequence, but others can cause an integrated circuit to malfunction. In some applications (e.g. driverless cars), proper operation of integrated circuits is critical to human life and safety. To minimize or eliminate the likelihood of a soft error becoming a serious malfunction, detailed assessment of individual potential soft errors and subsequent processor behavior is necessary. Embodiments of the present disclosure facilitate emulating a plurality of different, specific soft errors. Resilience may be assessed over the plurality of soft errors and application code may be advantageously engineered to improve resilience. Normal processor execution is halted to inject a given state error through a scan chain, and execution is subsequently resumed."
11276648,"An on-chip electromagnetic (EM) pulse protection circuit detects EM pulse attacks, generates an alarm, and performs a defensive action to protect the integrated circuit. The EM pulse protection circuit can be used with various integrated circuits or manufactured chips in which, for example, there is a desire to keep information secure, maintain the security of the chip, secure boot processes, and/or protect private keys."
11280609,"A high-definition map system receives sensor data from vehicles travelling along routes and combines the data to generate a high definition map for use in driving vehicles, for example, for guiding autonomous vehicles. A pose graph is built from the collected data, each pose representing location and orientation of a vehicle. The pose graph is optimized to minimize constraints between poses. Points associated with surface are assigned a confidence measure determined using a measure of hardness/softness of the surface. A machine-learning-based result filter detects bad alignment results and prevents them from being entered in the subsequent global pose optimization. The alignment framework is parallelizable for execution using a parallel/distributed architecture. Alignment hot spots are detected for further verification and improvement. The system supports incremental updates, thereby allowing refinements of subgraphs for incrementally improving the high-definition map for keeping it up to date."
11281221,"A method, computer readable medium, and system are disclosed for performing autonomous path navigation using deep neural networks. The method includes the steps of receiving image data at a deep neural network (DNN), determining, by the DNN, both an orientation of a vehicle with respect to a path and a lateral position of the vehicle with respect to the path, utilizing the image data, and controlling a location of the vehicle, utilizing the orientation of the vehicle with respect to the path and the lateral position of the vehicle with respect to the path."
11282258,"Image quality can be improved by rendering the image based on an importance map that indicates regions of the image that will benefit from more samples. Adaptive sampling determines a number of samples for each pixel of the image using a target sampling rate and the importance map for the image. The number of samples for each pixel needs to be a non-negative integer value, so the per-pixel sampling rates are quantized using per-pixel random values. The resulting quantized sampling rates provides a distribution of samples that closely matches the importance map. The per-pixel random values may vary over time so that the average of the distribution more closely matches the importance map."
11282261,"Enhanced techniques applicable to a ray tracing hardware accelerator for traversing a hierarchical acceleration structure are disclosed. The traversal efficiency of such hardware accelerators are improved, for example, by transforming a ray, in hardware, from the ray's coordinate space to two or more coordinate spaces at respective points in traversing the hierarchical acceleration structure. In one example, the hardware accelerator is configured to transform a ray, received from a processor, from the world space to at least one alternate world space and then to an object space in hardware before a corresponding ray-primitive intersection results are returned to the processor. The techniques disclosed herein facilitate the use of additional coordinate spaces to orient acceleration structures in a manner that more efficiently approximate the space occupied by the underlying primitives being ray-traced."
11283349,"This disclosure relates to current flattening circuits for an electrical load. The current flattening circuits incorporate randomize various parameters to add noise onto the supply current. This added noise may act to reduce the signal to noise ratio in the supply current, increasing the difficulty of identifying a computational artifact signal from power rail noise."
11284160,"A method for remotely provisioning resources for running a computer application is described. The method includes: receiving a request to execute a computer application using a virtual machine, the computer application having a static video portion and a user interactive video portion; while preparing the user interactive video portion, providing the static video portion to a user device remotely positioned relative to a server hosting the virtual machine; and streaming the user interactive video portion to the user device at an end of the static video portion. A start time of the static video portion is adjusted to accommodate a display time of the static video portion being different than a time required to prepare the user interactive video portion. A server and a system that are capable of performing the above method are also described."
11294441,"In various embodiments, rail decoupling circuits that are powered by an always on voltage rail allow a core voltage rail to power up independently of an I/O voltage rail without jeopardizing I/O pad circuits that are powered by the I/O voltage rail. In an embodiment, when the always on voltage rail is powered-up and a chip reset signal is asserted, the rail decoupling circuits drive control inputs of the I/O pad circuits based on default values. When the chip reset signal is de-asserted, the rail decoupling circuits drive the control inputs of the I/O pad circuits based on signals received from circuits powered by the core voltage rail. Because the rail decoupling circuits maintain control of the I/O pad circuits until the chip-reset is de-asserted, the core voltage rail can power up at any time before the chip-reset signal is de-asserted irrespective of when the I/O voltage rail powers up."
11294631,An adder circuit that includes an operand input and a second operand input to an XNOR cell. The XNOR cell is configured to provide the operand input and the second operand input to both a NAND gate and a first OAI cell. A second OAI cell transforms the output of the XNOR cell into a carry out signal.
11294713,"Apparatuses, systems, and techniques to parallelize operations in one or more programs with data copies from global memory to shared memory in each of the one or more programs. In at least one embodiment, a program performs operations on shared data and then asynchronously copies shared data to shared memory, and continues performing additional operations in parallel while the shared data is copied to shared memory until an indicator provided by an application programming interface to facilitate parallel computing, such as CUDA, informs said program that shared data has been copied to shared memory."
11295508,"A bounding volume is used to approximate the space an object occupies. If a more precise understanding beyond an approximation is required, the object itself is then inspected to determine what space it occupies. Often, a simple volume (such as an axis-aligned box) is used as bounding volume to approximate the space occupied by an object. But objects can be arbitrary, complicated shapes. So a simple volume often does not fit the object very well. That causes a lot of space that is not occupied by the object to be included in the approximation of the space being occupied by the object. Hardware-based techniques are disclosed herein, for example, for efficiently using multiple bounding volumes (such as axis-aligned bounding boxes) to represent, in effect, an arbitrarily shaped bounding volume to better fit the object, and for using such arbitrary bounding volumes to improve performance in applications such as ray tracing."
11295514,"Inverse rendering estimates physical scene attributes (e.g., reflectance, geometry, and lighting) from image(s) and is used for gaming, virtual reality, augmented reality, and robotics. An inverse rendering network (IRN) receives a single input image of a 3D scene and generates the physical scene attributes for the image. The IRN is trained by using the estimated physical scene attributes generated by the IRN to reproduce the input image and updating parameters of the IRN to reduce differences between the reproduced input image and the input image. A direct renderer and a residual appearance renderer (RAR) reproduce the input image. The RAR predicts a residual image representing complex appearance effects of the real (not synthetic) image based on features extracted from the image and the reflectance and geometry properties. The residual image represents near-field illumination, cast shadows, inter-reflections, and realistic shading that are not provided by the direct renderer."
11295515,"The present invention facilitates efficient and effective image processing. A network can comprise: a first system configured to perform a first portion of lighting calculations for an image and combing results of the first portion of lighting calculations for the image with results of a second portion of lighting calculations; and a second system configured to perform the second portion of lighting calculations and forward the results of the second portion of the lighting calculations to the first system. The first and second portion of lighting calculations can be associated with indirect lighting calculations and direct lighting calculations respectively. The first system can be a client in a local location and the second system can be a server in a remote location (e.g., a cloud computing environment). The first system and second system can be in a cloud and a video is transmitted to a local system."
11301697,"Various types of systems or technologies can be used to collect data in a 3D space. For example, LiDAR (light detection and ranging) and RADAR (radio detection and ranging) systems are commonly used to generate point cloud data for 3D space around vehicles, for such functions as localization, mapping, and tracking. This disclosure provides improved techniques for processing the point cloud data that has been collected. The improved techniques include mapping 3D point cloud data points into a 2D depth map, fetching a group of the mapped 3D point cloud data points that are within a bounded window of the 2D depth map; and generating geometric space parameters based on the group of the mapped 3D point cloud data points. The generated geometric space parameters may be used for object motion, obstacle detection, freespace detection, and/or landmark detection for an area surrounding a vehicle."
11302056,"Ray tracing hardware accelerators supporting multiple specifiers for controlling the traversal of a ray tracing acceleration data structure are disclosed. For example, traversal efficiency and complex ray tracing effects can be achieved by specifying traversals through such data structures using both programmable ray operations and explicit node masking. The explicit node masking utilizes dedicated fields in the ray and in nodes of the acceleration data structure to control traversals. Ray operations, however, are programmable per ray using opcodes and additional parameters to control traversals. Traversal efficiency is improved by enabling more aggressive culling of parts of the data structure based on the combination of explicit node masking and programmable ray operations. More complex ray tracing effects are enabled by providing for dynamic selection of nodes based on individual ray characteristics."
11302068,"Determining the occlusions or shadows for an area light within a scene is difficult, especially realistic shadowing in large and dynamic scenes. The disclosure provides an adaptive occlusion sampling process that uses voxel cone tracing to distribute the voxel tracing cones on the surface of area lights to obtain samples for shadowing in computer generated images or scenes. A method of adaptive occlusion sampling from a rectangular area light is disclosed that can be used to provide realistic shadowing in a computer generated scene. A process to compute a shadow of an area light within a scene is also disclosed herein that includes obtaining samples, employing voxel cone tracing, from a light surface of the area light based on sample points of a sampling grid created from sample patterns that are based on a determined number of cones."
11307863,"Systems and methods are provided for efficiently performing processing intensive operations, such as those involving large volumes of data, that enable accelerated processing time of these operations. In at least one embodiment, a system includes a graphics processor unit (GPU) including a memory and a plurality of cores. The plurality of cores perform a plurality of data analytics operations on a respectively allocated portion of a dataset, each of the plurality of cores using only the memory to store data input for each of the plurality of data analytics operations performed by the plurality of cores. The data storage for the plurality of data analytics operations performed by the plurality of cores is also provided solely by the memory."
11307903,"Embodiments of the present invention set forth techniques for allocating execution resources to groups of threads within a graphics processing unit. A compute work distributor included in the graphics processing unit receives an indication from a process that a first group of threads is to be launched. The compute work distributor determines that a first subcontext associated with the process has at least one processor credit. In some embodiments, CTAs may be launched even when there are no processor credits, if one of the TPCs that was already acquired has sufficient space. The compute work distributor identifies a first processor included in a plurality of processors that has a processing load that is less than or equal to the processor loads associated with all other processors included in the plurality of processors. The compute work distributor launches the first group of threads to execute on the first processor."
11308338,"In various examples, a deep neural network (DNN) is trained to accurately predict, in deployment, distances to objects and obstacles using image data alone. The DNN may be trained with ground truth data that is generated and encoded using sensor data from any number of depth predicting sensors, such as, without limitation, RADAR sensors, LIDAR sensors, and/or SONAR sensors. Camera adaptation algorithms may be used in various embodiments to adapt the DNN for use with image data generated by cameras with varying parameters—such as varying fields of view. In some examples, a post-processing safety bounds operation may be executed on the predictions of the DNN to ensure that the predictions fall within a safety-permissible range."
11308658,"Motion adaptive shading increases rendering performance for real-time animation in graphics systems while maintaining dynamic image quality. Each frame of an animation is statically displayed within a refresh interval, while a viewer's eyes move continuously relative to the image when actively tracking a moving object being displayed. As a result, a statically displayed frame is essentially smeared across the viewer's continuously moving retina over the lifetime of the frame, causing a perception of blur referred to as an eye-tracking motion blur effect. A region of an image depicting a moving object may be rendered at a lower shading rate because eye-tracking motion blur will substantially mask any blur introduced by reducing the shading rate. Reducing an average shading rate for rendering frames reduces computational effort per frame and may advantageously allow a rendering system to operate at a higher frame rate to provide a smoother, clearer visual experience."
11308684,"In various examples, a virtual light meter may be implemented along with ray tracing techniques in order to determine incident light values—e.g., incoming irradiance, incident radiance, etc.—for adjusting auto exposure values of rendered frames. For example, one or more rays may be used to sample incident light over a sampling pattern—such as a hemispherical sampling pattern—for any position in a virtual game environment. As a result, the incident light values may be sampled near a subject of interest in a scene or frame such that exposure values are consistent or stable regardless of the composition of the rendered frames."
11310513,A method and apparatus for enhancing motion estimation based on user input are provided. The motion estimation apparatus used for video encoding comprises a receiver operable to receive a user based input and an input analysis module operable to analyzed the user based input. The apparatus also comprises an encoder that is operable to compute displacement coordinates from the analyzed user based input for a current block in a target frame of a video stream and operable to determine a search area in a reference frame to search for a best match for the current block using the displacement coordinates. The encoder can also comprise a block match module operable to find a best match block for the current block in the search area of the reference frame using a block matching procedure.
11314985,"The disclosure provides method of training a machine-learning model employing a procedurally synthesized training dataset, a machine that includes a trained machine-learning model, and a method of operating a machine. In one example, the method of training includes: (1) generating training image definitions in accordance with variations in content of training images to be included in a training dataset, (2) rendering the training images corresponding to the training image definitions, (3) generating, at least partially in parallel with the rendering, ground truth data corresponding to the training images, the training images and the ground truth comprising the training dataset, and (4) training a machine-learning model using the training dataset and the ground truth data."
11315018,"A method, computer readable medium, and system are disclosed for neural network pruning. The method includes the steps of receiving first-order gradients of a cost function relative to layer parameters for a trained neural network and computing a pruning criterion for each layer parameter based on the first-order gradient corresponding to the layer parameter, where the pruning criterion indicates an importance of each neuron that is included in the trained neural network and is associated with the layer parameter. The method includes the additional steps of identifying at least one neuron having a lowest importance and removing the at least one neuron from the trained neural network to produce a pruned neural network."
11315310,"A global illumination data structure (e.g., a data structure created to store global illumination information for geometry within a scene to be rendered) is computed for the scene. Additionally, reservoir-based spatiotemporal importance resampling (RESTIR) is used to perform illumination gathering, utilizing the global illumination data structure. The illumination gathering includes identifying light values for points within the scene, where one or more points are selected within the scene based on the light values in order to perform ray tracing during the rendering of the scene."
11320273,"A system accesses a three-dimensional map of a geographic region and generates a two-dimensional projection of the road based on the three-dimensional map. The two-dimensional projection comprises a plurality of points along the road and each point is assigned a score measuring a navigability of the point. Based on the navigability score of each point and history of vehicle positions on the road, the system identifies a plurality of navigable points on the two-dimensional projection of the road. Based on the plurality of navigable points, the system determines a navigable surface corresponding to a physical area over which a vehicle may safely navigate and navigable surface boundaries surrounding that area. The navigable surface area and boundaries on the two-dimensional projection are converted into a three-dimensional representation, which the system uses to generate an updated three-dimensional map of the geographic region."
11320892,"Digital low-dropout micro voltage regulator configured to accept an external voltage and produce a regulated voltage. All active devices of the voltage regulator are digital devices. All signals of the voltage regulator, except the first voltage and the regulated voltage, may be characterized as digital signals. Some active devices of the voltage regulator may be physically separated from other active devices of the voltage regulator by active devices of non-voltage regulator circuitry."
11321816,"Embodiments of the present invention provide end-to-end frame time synchronization designed to improve smoothness for displaying images of 3D applications, such as PC gaming applications. Traditionally, an application that renders 3D graphics functions based on the assumption that the average render time will be used as the animation time for a given frame. When this condition is not met, and the render time for a frame does not match the average render time of prior frames, the frames are not captured or displayed at a consistent rate. This invention enables feedback to be provided to the rendering application for adjusting the animation times used to produce new frames, and a post-render queue is used to store completed frames for mitigating stutter and hitches. Flip control is used to sync the display of a rendered frame with the animation time used to generate the frame, thereby producing a smooth, consistent image."
11321865,"One embodiment of a method includes calculating one or more activation values of one or more neural networks trained to infer eye gaze information based, at least in part, on eye position of one or more images of one or more faces indicated by an infrared light reflection from the one or more images."
11323393,"A system and method for improving network storage accessibility, the method including: sending at least a first request for a data block to be sent from a storage device to a client device over a network connection; determining if the network is congested; initiating a client-specific buffer when it is determined that the network is congested, wherein the requested data block is stored in the client-specific buffer; and sending at least a second request for the data block stored within the client-specific buffer to be sent to the client device."
11327553,"Digital low-dropout micro voltage regulator configured to accept an external voltage and produce a regulated voltage. All active devices of the voltage regulator are digital devices. All signals of the voltage regulator, except the first voltage and the regulated voltage, may be characterized as digital signals. Some active devices of the voltage regulator may be physically separated from other active devices of the voltage regulator by active devices of non-voltage regulator circuitry."
11327900,"Multiprocessor clusters in a virtualized environment conventionally fail to provide memory access security, which is frequently a requirement for efficient utilization in multi-client settings. Without adequate access security, a malicious process may access what might be confidential data that belongs to a different client sharing the multiprocessor cluster. Furthermore, an inadvertent programming error in the code for one client process may accidentally corrupt data that belongs to the different client. Neither scenario is acceptable. Embodiments of the present disclosure provide access security by enabling each processing node within a multiprocessor cluster to virtualize and manage local memory access and only process access requests possessing proper access credentials. In this way, different applications executing on a multiprocessor cluster may be isolated from each other while advantageously sharing the hardware resources of the multiprocessor cluster."
11328112,"In order to expedite testing (such as silicon chip testing), a test pattern that indicates a timing, order, and frequency (e.g., speed) of signals sent during the test may be divided into different portions. Also, a frequency at which each portion of the test pattern is to be run is determined. Each portion is run at a frequency that can be supported by only that portion. As a result, the slowest portion of the test pattern only limits the frequency at which its portion is run, while other portions are run at a faster frequency. This reduces a time taken to run the test pattern in a testing environment."
11328169,"A temporal propagation network (TPN) system learns the affinity matrix for video image processing tasks. An affinity matrix is a generic matrix that defines the similarity of two points in space. The TPN system includes a guidance neural network model and a temporal propagation module and is trained for a particular computer vision task to propagate visual properties from a key-frame represented by dense data (color), to another frame that is represented by coarse data (grey-scale). The guidance neural network model generates an affinity matrix referred to as a global transformation matrix from task-specific data for the key-frame and the other frame. The temporal propagation module applies the global transformation matrix to the key-frame property data to produce propagated property data (color) for the other frame. For example, the TPN system may be used to colorize several frames of greyscale video using a single manually colorized key-frame."
11328173,"A temporal propagation network (TPN) system learns the affinity matrix for video image processing tasks. An affinity matrix is a generic matrix that defines the similarity of two points in space. The TPN system includes a guidance neural network model and a temporal propagation module and is trained for a particular computer vision task to propagate visual properties from a key-frame represented by dense data (color), to another frame that is represented by coarse data (grey-scale). The guidance neural network model generates an affinity matrix referred to as a global transformation matrix from task-specific data for the key-frame and the other frame. The temporal propagation module applies the global transformation matrix to the key-frame property data to produce propagated property data (color) for the other frame. For example, the TPN system may be used to colorize several frames of greyscale video using a single manually colorized key-frame."
11328471,"Systems and methods of the present disclosure relate to fine grained interleaved rendering applications in path tracing for cloud computing environments. For example, a renderer and a rendering process may be employed for ray or path tracing and image-space filtering that interleaves the pixels of a frame into partial image fields and corresponding reduced-resolution images that are individually processed in parallel. Parallelization techniques described herein may allow for high quality rendered frames in less time, thereby reducing latency (or lag, in gaming applications) in high performance applications."
11328472,A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to properly handle numerically challenging computations at or near edges and/or vertices of primitives and/or ensure that a single intersection is reported when a ray intersects a surface formed by primitives at or near edges and/or vertices of the primitives.
11331586,"In various examples, metadata of either a live stream game instance or a pre-recorded game instance may be included in a stream data from a game stream and used to enable access to play an instance of a game. A viewer of the stream may desire to participate in an instance of the game, and the system may use the metadata to determine authentication for the viewer with respect to a game platform hosting the game, access restrictions for the viewer with respect to the game, identification information for the streamer of the instance of the game, and/or game modification information for the particular instance of the game within the stream. This information may be used to seamlessly transition the viewer from a passive role in viewing the stream of the instance of the game on a streaming platform to actively participating in the instance of the game or another instance of the game on a gaming platform."
11335056,"Systems and methods are described for rendering complex surfaces or geometry. In at least one embodiment, neural signed distance functions (SDFs) can be used that efficiently capture multiple levels of detail (LODs), and that can be used to reconstruct multi-dimensional geometry or surfaces with high image quality. An example architecture can represent complex shapes in a compressed format with high visual fidelity, and can generalize across different geometries from a single learned example. Extremely small multi-layer perceptrons (MLPs) can be used with an octree-based feature representation for the learned neural SDFs."
11336476,"A network device configured to perform scalable, in-network computations is described. The network device is configured to process pull requests and/or push requests from a plurality of endpoints connected to the network. A collective communication primitive from a particular endpoint can be received at a network device. The collective communication primitive is associated with a multicast region of a shared global address space and is mapped to a plurality of participating endpoints. The network device is configured to perform an in-network computation based on information received from the participating endpoints before forwarding a response to the collective communication primitive back to one or more of the participating endpoints. The endpoints can inject pull requests (e.g., load commands) and/or push requests (e.g., store commands) into the network. A multicast capability enables tasks, such as a reduction operation, to be offloaded to hardware in the network device."
11340082,"According to an aspect of an embodiment, operations may comprise for each of the set of geographic X-positions, accessing an HD map of a geographical region surrounding the geographic X-position, determining a convergence range for the geographic X-position, and storing the convergence range for the geographic X-position in the HD map. The operations may also comprise accessing the HD map, predicting a next geographic X-position of a target vehicle, predicting a covariance of the predicted next geographic X-position, accessing the convergence range for the geographic X-position in the HD map closest to the predicted next geographic X-position, estimating a current geographic X-position of the target vehicle by performing a localization algorithm, and determining a confidence value for the estimated current geographic X-position of the target vehicle based on the predicted next geographic X-position, the predicted covariance, and the accessed convergence range."
11340355,"A vehicle computing system validates location data received from a Global Navigation Satellite System receiver with other sensor data. In one embodiment, the system calculates velocities with the location data and the other sensor data. The system generates a probabilistic model for velocity with a velocity calculated with location data and variance associated with the location data. The system determines a confidence score by applying the probabilistic model to one or more of the velocities calculated with other sensor data. In another embodiment, the system implements a machine learning model that considers features extracted from the sensor data. The system generates a feature vector for the location data and determines a confidence score for the location data by applying the machine learning model to the feature vector. Based on the confidence score, the system can validate the location data. The validated location data is useful for navigation and map updates."
11340701,"Machine learning systems and methods that learn glare, and thus determine gaze direction in a manner more resilient to the effects of glare on input images. The machine learning systems have an isolated representation of glare, e.g., information on the locations of glare points in an image, as an explicit input, in addition to the image itself. In this manner, the machine learning systems explicitly consider glare while making a determination of gaze direction, thus producing more accurate results for images containing glare."
11341369,"A technique for performing data parallel training of a neural network model is disclosed that incorporates batch normalization techniques using partial populations to generate normalization parameters. The technique involves processing, by each processor of a plurality of processors in parallel, a first portion of a sub-batch of training samples allocated to the processor to generate activations for the first portion of the sub-batch. Each processor analyzes the activations and transmits statistical measures for the first portion to an additional processor that reduces the statistical measures from multiple processors to generate normalization parameters for a partial population of the training samples that includes the first portion from each of the plurality of processors. The normalization parameters are then transmitted back to each of the processors to normalize the activations for both the first portion and a second portion of the sub-batch of training samples allocated to each processor."
11341710,"Approaches in accordance with various embodiments provide for fluid simulation with substantially reduced time and memory requirements with respect to conventional approaches. In particular, various embodiments can perform time and energy efficient, large scale fluid simulation on processing hardware using a method that does not solve for the Navier-Stokes equations to enforce incompressibility. Instead, various embodiments generate a density tensor and rigid body map tensor for a large number of particles contained in a sub-domain. Collectively, the density tensor and rigid body map may represent input channels of a network with three spatial-dimensions. The network may apply a series of operations to the input channels to predict an updated position and updated velocity for each particle at the end of a frame. Such approaches can handle tens of millions of particles within a virtually unbounded simulation domain, as compared to classical approaches that solve for the Navier-Stokes equations."
11343354,"In various examples, upon receiving an indication from a launcher application that a user desires to engage with a cloud gaming or computing service, and determining that a desired computing resource requested for such engagement is unavailable for allocation, one or more interactive content items may be presented in association with a display of the user's local computing device. User actuation of an interactive content item may cause presentation of an options window. One option may cause presentation of an additional content item in the background so it may be viewed after engagement. Another option may cause display of an additional content item, such as in place of the interactive content item or in a web browser external to the launcher application. This option may also cause cancellation of the user request for the allocation and removal of the user request from a queue."
11343940,"A cold plate that is configurable and for a datacenter liquid cooling system is disclosed. The cold plate includes a first section, a second section, and an intermediate layer, which is changeable and has first channels to enable flow of a coolant through the intermediate layer, and has second channels or at least one adapted second channel to concentrate the coolant or the flow of the coolant to at least one area within the configurable cold plate corresponding to at least a heat generating feature of an associated computing device."
11347668,"A unified cache subsystem includes a data memory configured as both a shared memory and a local cache memory. The unified cache subsystem processes different types of memory transactions using different data pathways. To process memory transactions that target shared memory, the unified cache subsystem includes a direct pathway to the data memory. To process memory transactions that do not target shared memory, the unified cache subsystem includes a tag processing pipeline configured to identify cache hits and cache misses. When the tag processing pipeline identifies a cache hit for a given memory transaction, the transaction is rerouted to the direct pathway to data memory. When the tag processing pipeline identifies a cache miss for a given memory transaction, the transaction is pushed into a first-in first-out (FIFO) until miss data is returned from external memory. The tag processing pipeline is also configured to process texture-oriented memory transactions."
11348308,"Systems and methods that facilitate efficient and effective shadow image generation are presented. In one embodiment, a hard shadow generation system comprises a compute shader, pixel shader and graphics shader. The compute shader is configured to retrieve pixel depth information and generate projection matrix information, wherein the generating includes performing dynamic re-projection from eye-space to light space utilizing the pixel depth information. The pixel shader is configured to create light space visibility information. The graphics shader is configured to perform frustum trace operations to produce hard shadow information, wherein the frustum trace operations utilize the light space visibility information. The light space visibility information can be considered irregular z information stored in an irregular z-buffer."
11351463,"A system, method, and computer program product are provided for simultaneously determining settings for a plurality of parameter variations. In use, a plurality of parameter variations associated with a device is identified, where the plurality of parameter variations are organized into a plurality of segments. Additionally, settings for each of the plurality of parameter variations are determined and consistency of the settings across the plurality of segments is ensured."
11353589,A system align point clouds obtained by sensors of a vehicle using kinematic iterative closest point with integrated motions estimates. The system receives lidar scans from a lidar mounted on the vehicle. The system derives point clouds from the lidar scan data. The system iteratively determines velocity parameters that minimize an aggregate measure of distance between corresponding points of the plurality of pairs of points. The system iteratively improves the velocity parameters. The system uses the velocity parameters for various purposes including for building high definition maps used for navigating the vehicle.
11354847,"A three-dimensional (3D) object reconstruction neural network system learns to predict a 3D shape representation of an object from a video that includes the object. The 3D reconstruction technique may be used for content creation, such as generation of 3D characters for games, movies, and 3D printing. When 3D characters are generated from video, the content may also include motion of the character, as predicted based on the video. The 3D object construction technique exploits temporal consistency to reconstruct a dynamic 3D representation of the object from an unlabeled video. Specifically, an object in a video has a consistent shape and consistent texture across multiple frames. Texture, base shape, and part correspondence invariance constraints may be applied to fine-tune the neural network system. The reconstruction technique generalizes well—particularly for non-rigid objects."
11361507,"Estimating a three-dimensional (3D) pose and shape of an articulated body mesh is useful for many different applications including health and fitness, entertainment, and computer graphics. A set of estimated 3D keypoint positions for a human body structure are processed to compute parameters defining the pose and shape of a parametric human body mesh using a set of geometric operations. During processing, 3D keypoints are extracted from the parametric human body mesh and a set of rotations are computed to align the extracted 3D keypoints with the estimated 3D keypoints. The set of rotations may correctly position a particular 3D keypoint location at a “joint”, but an arbitrary number of rotations of the “joint” keypoint may produce a twist in a connection to a child keypoint. Rules are applied to the set of rotations to resolve ambiguous twists and articulate the parametric human body mesh according to the computed parameters."
11363339,"A communication method between a source device and a target device utilizes speculative connection setup between the source device and the target device, target-device-side packet ordering, and fine-grained ordering to remove packet dependencies."
11364434,"While one type of input, either a mouse input or a joystick input, may be preferred for one type of a game, it may not be preferred, or even compatible, for another type of a game. Introduced herein is a game controller that employs a dedicated input, which is capable of the absolute accuracy of a mouse input or trackball input, but is also capable of measuring how far off center the input is (e.g., how far off center it has moved), and can also return to center when released, as is present in a joystick input. The introduced game controller integrates a touch sensing trackball to enjoy the benefits of both the mouse type input and joystick type input, in a single dedicated input, providing a user freedom to play any type of game without worrying about the compatibility of their game controllers."
11364883,"In various examples, activation criteria and/or braking profiles corresponding to automatic emergency braking (AEB) systems and/or collision mitigation warning (CMW) systems may be determined using sensor data representative of an environment to a front, side, and/or rear of a vehicle. For example, activation criteria for triggering an AEB system and/or CMW system may be adjusted by leveraging the availability of additional information with regards to the surrounding environment of a vehicle—such as the presence of a trailing vehicle. In addition, the braking profile for the AEB activation may be adjusted based on information about the presence of and/or location of vehicles to the front, rear, and/or side of the vehicle. By adjusting the activation criteria and/or braking profiles of an AEB system, the potential for collisions with dynamic objects in the environment is reduced and the overall safety of the vehicle and its passengers is increased."
11365976,"The autonomous vehicle generates an overlapped image by overlaying HD map data over sensor data and rendering the overlaid images. The visualization process is repeated as the vehicle drives along the route. The visualization may be displayed on a screen within the vehicle or at a remote device. The system performs reverse rendering of a scene based on map data from a selected point. For each line of sight originating at the selected point, the system identifies the farthest object in the map data. Accordingly, the system eliminates objects obstructing the view of the farthest objects in the HD map as viewed from the selected point. The system further allows filtering of objects using filtering criteria based on semantic labels. The system generates a view from the selected point such that 3D objects matching the filtering criteria are eliminated from the view."
11367160,"A parallel processing unit (e.g., a GPU), in some examples, includes a hardware scheduler and hardware arbiter that launch graphics and compute work for simultaneous execution on a SIMD/SIMT processing unit. Each processing unit (e.g., a streaming multiprocessor) of the parallel processing unit operates in a graphics-greedy mode or a compute-greedy mode at respective times. The hardware arbiter, in response to a result of a comparison of at least one monitored performance or utilization metric to a user-configured threshold, can selectively cause the processing unit to run one or more compute work items from a compute queue when the processing unit is operating in the graphics-greedy mode, and cause the processing unit to run one or more graphics work items from a graphics queue when the processing unit is operating in the compute-greedy mode. Associated methods and systems are also described."
11367208,"Operations may comprise obtaining a plurality of light detection and ranging (LIDAR) scans of a region. The operations may also comprise identifying a plurality of LIDAR poses that correspond to the plurality of LIDAR scans. In addition, the operations may comprise identifying, as a plurality of keyframes, a plurality of images of the region that are captured during capturing of the plurality of LIDAR scans. The operations may also comprise determining, based on the plurality of LIDAR poses, a plurality of camera poses that correspond to the keyframes. Further, the operations may comprise identifying a plurality of two-dimensional (2D) keypoints in the keyframes. The operations also may comprise generating one or more three-dimensional (3D) keypoints based on the plurality of 2D keypoints and the respective camera poses of the plurality of keyframes."
11367240,"In various examples, the actual spatial properties of a virtual environment are used to produce, for a pixel, an anisotropic filter kernel for a filter having dimensions and weights that accurately reflect the spatial characteristics of the virtual environment. Geometry of the virtual environment may be computed based at least in part on a projection of a light source onto a surface through an occluder, in order to determine a footprint that reflects a contribution of the light source to lighting conditions of the pixel associated with a point on the surface. The footprint may define a size, orientation, and/or shape of the anisotropic filter kernel and corresponding filter weights. The anisotropic filter kernel may be applied to the pixel to produce a graphically-rendered image of the virtual environment."
11367241,"Raytracing can be used to generate high quality, physics-based water caustics patterns in real time. A caustics map is generate to represent locations and normals of points across a water surface. Rays from a light source that are reflected and refracted from these points, as determined by the locations and normals, and can generate hit points on a surface. Neighboring points can be used to help determine the resulting caustics pattern. In one embodiment, information for neighboring points in the caustics map can be used to generate scale factors for geometric regions to be projected onto the surface for each hit point. In another embodiment, these points serve as vertices of a caustic mesh that can be projected onto the surface, where the brightness at a primitive is determined by the size of the primitive area defined by the vertices of the caustics mesh."
11367244,"The disclosure presents a technique for utilizing ray tracing to produce high quality visual scenes with shadows while minimizing computing costs. The disclosed technique can lower the number of rays needed for shadow region rendering and still maintain a targeted visual quality for the scene. In one example, a method for denoising a ray traced scene is disclosed that includes: (1) applying a pixel mask to a data structure of data from the scene, wherein the applying uses the scene at full resolution and pixels at the edge of a depth boundary change are identified using the pixel mask, (2) generating a penumbra mask using the data structure, (3) adjusting HitT values in the packed data buffer utilizing the penumbra mask, and (4) denoising the scene by reducing scene noise in the data of the data structure with adjusted HitT values."
11367268,"Object re-identification refers to a process by which images that contain an object of interest are retrieved from a set of images captured using disparate cameras or in disparate environments. Object re-identification has many useful applications, particularly as it is applied to people (e.g. person tracking). Current re-identification processes rely on convolutional neural networks (CNNs) that learn re-identification for a particular object class from labeled training data specific to a certain domain (e.g. environment), but that do not apply well in other domains. The present disclosure provides cross-domain disentanglement of id-related and id-unrelated factors. In particular, the disentanglement is performed using a labeled image set and an unlabeled image set, respectively captured from different domains but for a same object class. The identification-related features may then be used to train a neural network to perform re-identification of objects in that object class from images captured from the second domain."
11372465,"In various examples, a voltage monitor may determine whether the voltage supplied to at least one component of a computing system is safe using two sets of thresholds—e.g., a high-frequency over-voltage (OV) threshold, a high-frequency under-voltage (UV) threshold, a low-frequency OV threshold, and a low-frequency UV threshold. A high-frequency voltage error detector may compare the supplied or input voltage to the high-frequency OV and UV thresholds and a low-frequency voltage error detector that may filter the supplied voltage to remove or reduce noise and then may compare the filtered voltage to the low-frequency OV and UV thresholds. Upon detecting a voltage error, a safety monitor may cause a change to an operating state of the at least one component."
11372548,"Some systems compress data utilized by a user mode software without the user mode software being aware of any compression taking place. To maintain that illusion, such systems prevent user mode software from being aware of and/or accessing the underlying compressed states of the data. While such an approach protects proprietary compression techniques used in such systems from being deciphered, such restrictions limit the ability of user mode software to use the underlying compressed forms of the data in new ways. Disclosed herein are various techniques for allowing user-mode software to access the underlying compressed states of data either directly or indirectly. Such techniques can be used, for example, to allow various user-mode software on a single system or on multiple systems to exchange data in the underlying compression format of the system(s) even when the user mode software is unable to decipher the compression format."
11373358,"Ray tracing hardware accelerators supporting motion blur and moving/deforming geometry are disclosed. For example, dynamic objects in an acceleration data structure are encoded with temporal and spatial information. The hardware includes circuitry that test ray intersections against moving/deforming geometry by applying such temporal and spatial information. Such circuitry accelerates the visibility sampling of moving geometry, including rigid body motion and object deformation, and its associated moving bounding volumes to a performance similar to that of the visibility sampling of static geometry."
11373359,"Disclosed approaches may leverage the actual spatial and reflective properties of a virtual environment—such as the size, shape, and orientation of a bidirectional reflectance distribution function (BRDF) lobe of a light path and its position relative to a reflection surface, a virtual screen, and a virtual camera—to produce, for a pixel, an anisotropic kernel filter having dimensions and weights that accurately reflect the spatial characteristics of the virtual environment as well as the reflective properties of the surface. In order to accomplish this, geometry may be computed that corresponds to a projection of a reflection of the BRDF lobe below the surface along a view vector to the pixel. Using this approach, the dimensions of the anisotropic filter kernel may correspond to the BRDF lobe to accurately reflect the spatial characteristics of the virtual environment as well as the reflective properties of the surface."
11373622,"Various embodiments disclose a system that includes a first source processor that generates a first stream of graphics data, a second source processor that generates a second stream of graphics data, a display device that displays at least one of the first stream of graphics data and the second stream of graphics data, and a timing controller that is coupled to the first source processor and the second source processor and receives a first control signal to enter into a self-refresh state, in response, enters into the self-refresh state, causes the display device to display a first frame stored in memory, wherein the first frame includes at least a portion of data included in the first stream of graphics data, receives a second stream of graphics data, exits the self-refresh state, and causes the display device to display the second stream of graphics data."
11375119,"A system calibrates one or more sensors mounted to an autonomous vehicle. From the one or more sensors, the system identifies a primary sensor and a secondary sensor. The system determines a reference angle for the primary sensor, and based on that reference angle for the primary sensor, a scan-start time representing a start of a scan and a scan-end time representing an end of a scan. The system receives, from the primary sensor, a primary set of scan data recorded from the scan-start time to the scan-end time. The system receives, from the secondary sensor, a secondary set of sensor data recorded from the scan-start time to the scan-end time. The system calibrates the primary and secondary sensors by determining a relative transform for transforming points between the first set of scan data and the second set of scan data."
11375176,"When an image is projected from 3D, the viewpoint of objects in the image, relative to the camera, must be determined. Since the image itself will not have sufficient information to determine the viewpoint of the various objects in the image, techniques to estimate the viewpoint must be employed. To date, neural networks have been used to infer such viewpoint estimates on an object category basis, but must first be trained with numerous examples that have been manually created. The present disclosure provides a neural network that is trained to learn, from just a few example images, a unique viewpoint estimation network capable of inferring viewpoint estimations for a new object category."
11376500,"Personalized coaching is provided to users of an application, such as players of an electronic gaming application. Data can be obtained that demonstrates how skilled users utilize an application, such as how professional players play a game. This data can be used to train a machine learning model for the game. Gameplay data for an identified player can be obtained, and related information provided as input to the trained model. The model can infer one or more actions or strategies to be taken by the player in order to achieve a determined goal. The information can be conveyed to the player using visual, audio, or haptic guidance during gameplay, or can be provided offline, such as with video or rendered replay of the game session. The types of advice or coaching given can vary depending upon factors such as the goals, skill level, and preferences of the player, and can update over time."
11379420,"Compressed data is oftentimes beneficial for reducing the computing resources required, for example, to transmit and store data. The compression of data is particularly useful when dealing with sparse data (data that includes numerous zeros or near-zero values) and only non-zero values above a certain threshold have significance. When dealing with compressed data, oftentimes the data needs to be decompressed for processing (e.g., by deep learning networks or other applications configured to operate on sparse, or other uncompressed data). Instructions are disclosed for supporting the decompression of compressed data by a processing unit such as a CPU and GPU."
11379708,"An integrated circuit such as, for example a graphics processing unit (GPU), includes a dynamic power controller for adjusting operating voltage and/or frequency. The controller may receive current power used by the integrated circuit and a predicted power determined based on instructions pending in a plurality of processors. The controller determines adjustments that need to be made to the operating voltage and/or frequency to minimize the difference between the current power and the predicted power. An in-system reinforced learning mechanism is included to self-tune parameters of the controller."
11379944,"A texture processing pipeline in a graphics processing unit generates the surface appearance for objects in a computer-generated scene. This texture processing pipeline determines, at multiple stages within the texture processing pipeline, whether texture operations and texture loads may be processed at an accelerated rate. At each stage that includes a decision point, the texture processing pipeline assumes that the current texture operation or texture load can be accelerated unless specific, known information indicates that the texture operation or texture load cannot be accelerated. As a result, the texture processing pipeline increases the number of texture operations and texture loads that are accelerated relative to the number of texture operations and texture loads that are not accelerated."
11380041,"Enhanced techniques applicable to a ray tracing hardware accelerator for traversing a hierarchical acceleration structure are disclosed. For example, traversal efficiency is improved by combining programmable traversals based on ray operations with per-node static configurations that modify traversal behavior. The per-node static configurations enable creators of acceleration data structures to optimize for potential traversals without necessarily requiring detailed information about ray characteristics and ray operations used when traversing the acceleration structure. Moreover, by providing for selective exclusion of certain nodes using per-node static configurations, less memory is needed to express an acceleration structure that includes, for example, different geometric levels of details corresponding to a single object."
11380049,"In various embodiments, a finite aperture omni-directional camera is modeled by aligning a finite aperture lens and focal point with the omni-directional part of the projection. For example, each point on an image plane maps to a direction in camera space. For a spherical projection, the lens can be orientated along this direction and the focal point is picked along this direction at focal distance from the lens. For a cylindrical projection, the lens can be oriented along the projected direction on the two dimensional (2D) xz-plane, as the projection is not omni-directional in the y direction. The focal point is picked along the (unprojected) direction so its projection on the xz-plane is at focal distance from the lens. The final outgoing ray can be constructed by sampling of a point on this oriented lens and shooting a ray from there through the focal point."
11381431,"A receiver receives communications over a communication channel, which may distort an incoming communication signal. In order to counter this distortion, the frequency response of the receiver is manipulated by adjusting several frequency response parameters. Each frequency response parameter controls at least a portion of the frequency response of the receiver. The optimal values for the frequency response parameters are determined by modifying an initial set of values for the frequency response parameters through one or more of stochastic hill climbing operations until a performance metric associated with the receiver reaches a local maximum. The modified values are displaced through one or more mutation operations. The stochastic hill climbing operations may subsequently be performed on the mutated values to generate the final values for the frequency response parameters."
11385464,"In an embodiment, an augmented reality display provides an expanded eye box and enlarged field of view through the use of holographic optical elements. In at least one example, an incoupling element directs an image into a waveguide, which transmits the image to a set of outcoupling gratings. In one example, a set of holographic optical elements opposite the outcoupling elements reflect the image to the user with an enlarged field of view while maintaining an expanded eye box."
11388391,"Head-mounted Displays (HMDs) are commonly used for virtual reality, mixed reality, and augmented reality. HMDs are, by definition, worn on the head of a user to provide a display in the line of sight of the user. By viewing the display, the user is able to experience one of the aforementioned types of reality. Oftentimes, HMDs are configured to integrate live video captured from the user's perspective, especially in the case of the HMD providing augmented reality where a virtual environment is combined with video of the real world. The present disclosure provides a configuration for a HMD having an array of image sensors to accurately capture image data to form the live video from the user's perspective."
11390301,Techniques to characterize driving scenarios for autonomous vehicles characterize a path in a driving scenario according to metrics such as narrowness and effort. The scenarios may be characterized using a tree-based or tensor-based approach.
11391578,"According to an aspect of an embodiment, operations may comprise accessing a set of vehicle poses of one or more vehicles; for each of the set of vehicle poses, accessing a high definition (HD) map of a geographical region surrounding the vehicle pose, with the HD map comprising a three-dimensional (3D) representation of the geographical region, determining a measure of constrainedness for the vehicle pose, with the measure of constrainedness representing a confidence for performing localization for the vehicle pose based on 3D structures surrounding the vehicle pose, and storing the measure of constrainedness for the vehicle pose; and for each of the geographical regions surrounding each of the set of vehicle poses, determining a measure of constrainedness for the geographical region based on measures of constrainedness of vehicle poses within the geographical region, and storing the measure of constrainedness for the geographical region."
11392829,"Approaches in accordance with various embodiments provide for the processing of sparse matrices for mathematical and programmatic operations. In particular, various embodiments enforce sparsity constraints for performing sparse matrix multiply-add instruction (MMA) operations. Deep neural networks can exhibit significant sparsity in the data used in operations, both in the activations and weights. The computational load can be reduced by excluding zero-valued data elements. A sparsity constraint is applied across all submatrices of a sparse matrix, providing fine-grained structured sparsity that is evenly distributed across the matrix. The matrix may then be compressed since a minimum number of elements of the matrix are known to have zero value. Matrix operations are then performed using these matrices."
11394686,"A method for network communication includes receiving from a first network a data packet having a header specifying a first source address in the first network and a destination address in a second network and looking up the first source address in a network address translation (NAT) table. Upon finding, in response to looking up the first source address, that the first source address is not listed in the NAT table, an entry is added to the NAT table specifying a corresponding second source address in the second network. One or more additional first source addresses that are not listed in the NAT table are predictively selected, and one or more further entries are added to the NAT table specifying one or more second source addresses in the public network corresponding to the one or more additional first source addresses."
11395239,"In various examples, radio frequency conducted power of a device—such as a human interface device (HID)—may be adjusted to account for various operating conditions. For example, when a user holds the device in their hand, the radiated power level of the device may be reduced to a level that reduces transmission performance of the device. To account for this, one or more detection mechanisms may be used to determine whether the device is held in hand and, when determined to be held in hand, the radio frequency conducted power of the device may be increased—while complying with regulatory requirements governing wireless transmissions—to increase the performance of the device. When not held in hand, the radio frequency conducted power may be less, thereby resulting in consistent performance of the device under varying operating conditions."
11398047,"The disclosure provides a system to render a virtual reality (VR) scene, and a method and computer program product to determine a follower pose in a VR simulator during a simulation step. In one example, the method includes: (1) computing one or more current candidate poses utilizing input parameters, wherein each of the current candidate poses is a temporal projection of a follower pose along a respective sweep direction towards a leader pose, and wherein an obstruction is located between the follower pose and the leader pose, (2) selecting a target pose from the one or more current candidate poses, (3) refining the target pose utilizing physics-based constraints and the input parameters, wherein the physics-based constraints use a surface of the obstruction, and (4) rendering a new follower pose based on the refined target pose."
11403121,"The disclosure relates to the transfer of per-pixel transparency information using video codecs that do not provide an alpha channel (alternatively referred to as “transparency-agnostic video codecs”). For example, alpha information of visual elements may be transcoded into the supported channels of a video stream to generate additional samples of a supported color space, which are representative of the alpha information. After being encoded by a “transparency-agnostic video codec” and transmitted, the received alpha information may then be extracted from the supported channels of the video stream to render the received visuals with corresponding per-pixel transparency."
11405053,"In various examples, metadata may be generated corresponding to compressed data streams that are compressed according to serial compression algorithms—such as arithmetic encoding, entropy encoding, etc.—in order to allow for parallel decompression of the compressed data. As a result, modification to the compressed data stream itself may not be required, and bandwidth and storage requirements of the system may be minimally impacted. In addition, by parallelizing the decompression, the system may benefit from faster decompression times while also reducing or entirely removing the adoption cycle for systems using the metadata for parallel decompression."
11408934,"Manufacturers perform tests on chips before the chips are shipped to customers. However, defects can occur on a chip after the manufacturer testing and when the chips are used in a system or device. The defects can occur due to aging or the environment in which the chip is employed and can be critical; especially when the chips are used in systems such as autonomous vehicles. To verify the structural integrity of the IC during the lifetime of the product, an in-system test (IST) is disclosed. The IST enables self-testing mechanisms for an IC in working systems. The IST mechanisms provide structural testing of the ICs when in a functional system and at a manufacturer's level of testing. Unlike ATE tests that are running on a separate environment, the IST provides the ability to go from a functional world view to a test mode."
11409597,"An error reporting system utilizes a parity checker to receive data results from execution of an original instruction and a parity bit for the data. A decoder receives an error correcting code (ECC) for data resulting from execution of a shadow instruction of the original instruction, and data error correction is initiated on the original instruction result on condition of a mismatch between the parity bit and the original instruction result, and the decoder asserting a correctable error in the original instruction result."
11411563,"A circuit includes a set of multiple bit generating cells. One or more adjustable current sources is coupled to introduce perturbations into outputs of the bit generating cells. Based on the perturbations, the outputs of a subset less than all of the bit generating cells are selected, and applied as a control."
11416311,"Approaches in accordance with various embodiments can reduce scheduling delays due to concurrent processing requests, as may involve VSyncs in multi-streaming systems. The software synchronization signals can be staggered relative to each other by offsetting an initial synchronization signal. These software synchronization signals can be readjusted over time such that each synchronization signal maintains the same relative offset, as may be with respect to other applications or containers."
11417011,"Learning to estimate a 3D body pose, and likewise the pose of any type of object, from a single 2D image is of great interest for many practical graphics applications and generally relies on neural networks that have been trained with sample data which annotates (labels) each sample 2D image with a known 3D pose. Requiring this labeled training data however has various drawbacks, including for example that traditionally used training data sets lack diversity and therefore limit the extent to which neural networks are able to estimate 3D pose. Expanding these training data sets is also difficult since it requires manually provided annotations for 2D images, which is time consuming and prone to errors. The present disclosure overcomes these and other limitations of existing techniques by providing a model that is trained from unlabeled multi-view data for use in 3D pose estimation."
11417063,"One or more images (e.g., images taken from one or more cameras) may be received, where each of the one or more images may depict a two-dimensional (2D) view of a three-dimensional (3D) scene. Additionally, the one or more images may be utilized to determine a three-dimensional (3D) representation of a scene. This representation may help an entity navigate an environment represented by the 3D scene."
11418212,"In various embodiments, an encoded sequence (e.g., a compressed sequence for uncompressed data) that includes variable-length codes is decoded in an iterative fashion to generate a decoded sequence of symbols. During each iteration, a group of threads decode in parallel the codes in the encoded sequence to generate symbols. The group of threads then compute offsets based on the sizes of the symbols. Subsequently, the group of threads generates in parallel a contiguous portion of the decoded sequence based on the symbols, an output address, and the offsets."
11418852,"A method, computer readable medium, and system are disclosed for monitoring a pipeline to detect anomalies such as unusual latency associated with a particular stage. Each stage of the pipeline is configured to update metadata associated with content being processed by inserting a time stamp into the metadata when processing of the content is completed by the stage. The server device can collect the metadata from the last stage of the pipeline and analyze the metadata in order to generate metrics for the pipeline, including a residual latency and/or a gain for each stage of the pipeline. In an embodiment, the content is a frame of video to be displayed on a client device after being rendered by a server device, such as through a streaming service (e.g., a video game streaming service). The server device can adjust the pipeline based on the metrics to improve performance."
11424000,"In various examples, a test system is provided for executing built-in-self-test (BIST) according to JTAG and IEEE 1500 on chips deployed in-field. Hardware and software selectively connect onto the IEEE 1500 serial interface for running BIST while the chip is being used in deployment—such as in an autonomous vehicle. In addition to providing a mechanism to connect onto the serial interface, the hardware and software may reduce memory requirements and runtime associated with running the test sequences, thereby making BIST possible in deployment. Furthermore, some embodiments include components configured to store functional states of clocks, power, and input/output prior to running BIST, which permits restoration of the functional states after the BIST."
11428536,"A system accesses a three-dimensional map of a geographic region and generates a two-dimensional projection of the road based on the three-dimensional map. The two-dimensional projection comprises a plurality of points along the road and each point is assigned a score measuring a navigability of the point. Based on the navigability score of each point and history of vehicle positions on the road, the system identifies a plurality of navigable points on the two-dimensional projection of the road. Based on the plurality of navigable points, the system determines a navigable surface corresponding to a physical area over which a vehicle may safely navigate and navigable surface boundaries surrounding that area. The navigable surface area and boundaries on the two-dimensional projection are converted into a three-dimensional representation, which the system uses to generate an updated three-dimensional map of the geographic region."
11429419,"In various examples, access to VM memory by virtualization software is secured using a trusted firmware of a host controller to validate one or more of a command to read a VM's memory and/or the data read from VM memory in order to protect against improper access to data in VM memory. If validation fails, the firmware may refrain from reading the data and/or from providing the virtualization software with access to the data. The data may include a request command from a VM regarding establishing or modifying a connection using the host controller to another entity, such as another device within or outside of the virtualization environment. The virtualization software may use the request command to facilitate the connection. The host controller may provide an eXtensible Host Controller Interface (xHCI) or a different type of interface for the connection."
11429534,"A system in having M memory controllers between a first memory and a second memory having N operative memory slices, where N and M are not evenly divisible, includes logic to operate the M memory controllers to linearly distribute addresses of the second memory across the N operative memory slices. The system may be utilized in commercial applications such as data centers, autonomous vehicles, and machine learning."
11430134,"An optical flow accelerator (OFA) which provides hardware-based acceleration of optical flow and stereo disparity determination is described. A system is described which includes an OFA configured to determine a first optical flow using a first disparity search technique, and to determine a second optical flow using a second disparity search technique that is different from the first disparity search technique. The system also includes a processor configured to combine the first optical flow and the second optical flow to generate a third optical flow. In some implementations, the first and second disparity search techniques are based upon Semi-Global Matching (SGM). In some implementations, the OFA is further configurable to determine stereo disparity."
11430172,"A system and method for generating a set of samples stratified across two-dimensional elementary intervals of a two-dimensional space is disclosed within the application. A computer-implemented technique for generating the set of samples includes selecting an elementary interval associated with a stratification of the two-dimensional space, initializing at least one data structure that indicates valid regions within the elementary interface based on other samples previously placed within the two-dimensional space, and generating a sample in a valid region of the elementary interval utilizing the at least one data structure to identify the valid region prior to generating the sample. In some embodiments, the data structures comprise a pair of binary trees. The process can be repeated for each elementary interval of a selected stratification to generate the set of stratified two-dimensional samples."
11435756,"Systems and methods for performing visual odometry more rapidly. Pairs of representations from sensor data (such as images from one or more cameras) are selected, and features common to both representations of the pair are identified. Portions of bundle adjustment matrices that correspond to the pair are updated using the common features. These updates are maintained in register memory until all portions of the matrices that correspond to the pair are updated. By selecting only common features of one particular pair of representations, updated matrix values may be kept in registers. Accordingly, matrix updates for each common feature may be collectively saved with a single write of the registers to other memory. In this manner, fewer write operations are performed from register memory to other memory, thus reducing the time required to update bundle adjustment matrices and thus speeding the bundle adjustment process."
11435794,A cooling system for a datacenter is disclosed. An evaporative cooling subsystem provides blown air for cooling the datacenter and a repurposable refrigerant cooling subsystem controls moisture of the blown air in a first configuration and independently cools the datacenter in a second configuration.
11435885,"User interfaces and methods are disclosed. In some embodiments, a plurality of source artifacts is displayed. A selector is operable to indicate a selected set of the source artifacts. The selected set corresponds to those of the source artifacts that intersect at least partially with a selection region. An output artifact is displayed having an output attribute that represents a combination of source attributes from the source artifacts in the selected set."
11436484,"In various examples, physical sensor data may be generated by a vehicle in a real-world environment. The physical sensor data may be used to train deep neural networks (DNNs). The DNNs may then be tested in a simulated environment—in some examples using hardware configured for installation in a vehicle to execute an autonomous driving software stack—to control a virtual vehicle in the simulated environment or to otherwise test, verify, or validate the outputs of the DNNs. Prior to use by the DNNs, virtual sensor data generated by virtual sensors within the simulated environment may be encoded to a format consistent with the format of the physical sensor data generated by the vehicle."
11436704,"In order to more accurately white balance an image, weightings can be determined for pixels of an image when computing an illuminant color value of the image and/or a scene. The weightings can be based at least in part on the Signal-to-Noise Ratio (SNR) of the pixels. The SNR may be actual SNR or SNR estimated from brightness levels of the pixels. SNR weighting (e.g., SNR adjustment) may reduce the effect of pixels with high noise on the computed illuminant color value. For example, one or more channel values of the illuminant color value can be determined based on the weightings and color values of the pixels. One or more color gain values can be determined based on the one or more channel values of the illuminant color value and used to white balance the image."
11436837,"In various examples, live perception from sensors of a vehicle may be leveraged to detect and classify intersection contention areas in an environment of a vehicle in real-time or near real-time. For example, a deep neural network (DNN) may be trained to compute outputs—such as signed distance functions—that may correspond to locations of boundaries delineating intersection contention areas. The signed distance functions may be decoded and/or post-processed to determine instance segmentation masks representing locations and classifications of intersection areas or regions. The locations of the intersections areas or regions may be generated in image-space and converted to world-space coordinates to aid an autonomous or semi-autonomous vehicle in navigating intersections according to rules of the road, traffic priority considerations, and/or the like."
11439002,A printed circuit board includes a first voltage plane disposed on a first surface of a first electrically insulating layer and a second voltage plane. An inter-layer slot that is formed through the first electrically insulating layer and includes an electrically conductive material electrically couples the first voltage plane to the second voltage plane.
11439010,"This disclosure provides a multi-layered printed circuit board (PC) that has signal array region. The signal array region has a width and circumscribes a power core region and has signal vias connected to respective signal ball pads, and ground vias connected to respective ground ball pads within the signal array region that have an associated ball pad pitch. The PCB also has an inner current power layer. The signal and ground vias are arranged on the component layer in a pattern and extend into the inner current layer. The pattern forms current power paths across the width of the signal array region, such that the current power paths have a width that is at least about 50% as wide as the ball pad pitch."
11442795,Convergence of threads executing common code sections is facilitated using instructions inserted at strategic locations in computer code sections. The inserted instructions enable the threads in a warp or other group to cooperate with a thread scheduler to promote thread convergence.
11443475,"One embodiment of a method for computing a texture color includes tracing a ray cone through a graphics scene, determining a curvature of a first surface within the graphics scene at a point where the ray cone hits the first surface based on differential barycentric coordinates associated with the point, determining, based on the curvature of the first surface, a width of the ray cone at a subsequent point where the ray cone hits a second surface within the graphics scene, and computing a texture color based on the width of the ray cone."
11443555,"The present disclosure provides various approaches for smart area monitoring suitable for parking garages or other areas. These approaches may include ROI-based occupancy detection to determine whether particular parking spots are occupied by leveraging image data from image sensors, such as cameras. These approaches may also include multi-sensor object tracking using multiple sensors that are distributed across an area that leverage both image data and spatial information regarding the area, to provide precise object tracking across the sensors. Further approaches relate to various architectures and configurations for smart area monitoring systems, as well as visualization and processing techniques. For example, as opposed to presenting video of an area captured by cameras, 3D renderings may be generated and played from metadata extracted from sensors around the area."
11443832,"The present disclosure provides methods, systems, and computer program products that use deep learning models to classify candidate mutations detected in sequencing data, particularly suboptimal sequencing data. The methods, systems, and programs provide for increased efficiency, accuracy, and speed in identifying mutations from a wide range of sequencing data."
11449709,"A neural network is trained to focus on a domain of interest. For example, in a pre-training phase, the neural network in trained using synthetic training data, which is configured to omit or limit content less relevant to the domain of interest, by updating parameters of the neural network to improve the accuracy of predictions. In a subsequent training phase, the pre-trained neural network is trained using real-world training data by updating only a first subset of the parameters associated with feature extraction, while a second subset of the parameters more associated with policies remains fixed."
11450057,"Enhanced techniques applicable to a ray tracing hardware accelerator for traversing a hierarchical acceleration structure and its underlying primitives are disclosed. For example, traversal speed is improved by grouping processing of primitives sharing at least one feature (e.g., a vertex or an edge) during ray-primitive intersection testing. Grouping the primitives for ray intersection testing can reduce processing (e.g., projections and transformations of primitive vertices and/or determining edge function values) because at least a portion of the processing results related to the shared feature in one primitive can be used in determine whether the ray intersects another primitive(s). Processing triangles sharing an edge can double the culling rate of the triangles in the ray/triangle intersection test without replicating the hardware."
11450059,"High quality image rendering can be achieved in part by using inverse transform sampling to direct sampling toward regions of greater importance, such as regions with higher brightness values, to reduce noise and improve convergence. Inverse transform sampling can be achieved more efficiently by reformulating as a ray-tracing problem, using tree traversal units that can be accelerated. A geometric mesh can be generated based on a set of cumulative distribution functions (CDFs) for various rows and columns of pixels in a texture, and individual rays can be traced against this mesh, with those rays having a higher probability of intersection at a point with greater importance, such as a higher brightness value. A probability distribution function to be used for importance sampling can be derived by analyzing partial derivatives of the CDF geometry at the intersection location."
11450077,"Appearance driven automatic three-dimensional (3D) modeling enables optimization of a 3D model comprising the shape and appearance of a particular 3D scene or object. Triangle meshes and shading models may be jointly optimized to match the appearance of a reference 3D model based on reference images of the reference 3D model. Compared with the reference 3D model, the optimized 3D model is a lower resolution 3D model that can be rendered in less time. More specifically, the optimized 3D model may include fewer geometric primitives compared with the reference 3D model. In contrast with the conventional inverse rendering or analysis-by-synthesis modeling tools, the shape and appearance representations of the 3D model are automatically generated that, when rendered, match the reference images. Appearance driven automatic 3D modeling has a number of uses, including appearance-preserving simplification of extremely complex assets, conversion between rendering systems, and even conversion between geometric scene representations."
11451718,"Alternating Current (AC) light sources can cause images captured using a rolling shutter to include alternating darker and brighter regions—known as flicker bands—due to some sensor rows being exposed to different intensities of light than others. Flicker bands may be compensated for by extracting them from images that are captured using exposures that at least partially overlap in time. Due to the overlap, the images may be subtracted from each other so that scene content substantially cancels out, leaving behind flicker bands. The images may be for a same frame captured by at least one sensor, such as different exposures for a frame. For example, the images used to extract flicker bands may be captured using different exposure times that share a common start time, such as using a multi-exposure sensor where light values are read out at different times during light integration. Two or more images captured for a frame may be used for flicker band extraction, such as the two images that include flicker bands with the greatest phase difference."
11455145,"Various embodiments include a modulo operation generator associated with a cache memory in a computer-based system. The modulo operation generator generates a first sum by performing an addition and/or a subtraction function on an input address. A first portion of the first sum is applied to a lookup table that generates a correction value. The correction value is then added to a second portion of the first sum to generate a second sum. The second sum is adjusted, as needed, to be less than the divisor. The adjusted second sum forms a residue value that identifies a cache memory slice in which the input data value corresponding to the input address is stored. By generating the residue value in this manner, the cache memory distributes input data values among the slices in a cache memory even when the number of slices is not a power of two."
11455768,"In a ray tracer, to prevent any long-running query from hanging the graphics processing unit, a traversal coprocessor provides a preemption mechanism that will allow rays to stop processing or time out early. The example non-limiting implementations described herein provide such a preemption mechanism, including a forward progress guarantee, and additional programmable timeout options that can be time or cycle based. Those programmable options provide a means for quality of service timing guarantees for applications such as virtual reality (VR) that have strict timing requirements."
11455790,"A style-based generative network architecture enables scale-specific control of synthesized output data, such as images. During training, the style-based generative neural network (generator neural network) includes a mapping network and a synthesis network. During prediction, the mapping network may be omitted, replicated, or evaluated several times. The synthesis network may be used to generate highly varied, high-quality output data with a wide variety of attributes. For example, when used to generate images of people's faces, the attributes that may vary are age, ethnicity, camera viewpoint, pose, face shape, eyeglasses, colors (eyes, hair, etc.), hair style, lighting, background, etc. Depending on the task, generated output data may include images, audio, video, three-dimensional (3D) objects, text, etc."
11455807,"In various examples, a neural network may be trained for use in vehicle re-identification tasks—e.g., matching appearances and classifications of vehicles across frames—in a camera network. The neural network may be trained to learn an embedding space such that embeddings corresponding to vehicles of the same identify are projected closer to one another within the embedding space, as compared to vehicles representing different identities. To accurately and efficiently learn the embedding space, the neural network may be trained using a contrastive loss function or a triplet loss function. In addition, to further improve accuracy and efficiency, a sampling technique—referred to herein as batch sample—may be used to identify embeddings, during training, that are most meaningful for updating parameters of the neural network."
11456941,"In various examples, an extensible network traffic engineering platform monitors network traffic and application performance to dynamically update network ingress and egress communication paths for increasing performance of the application—such as a cloud gaming application, a cloud virtual reality (VR) application, and/or another high performance application types. Pluggable, distributed, application-centric network monitors, policy engines, and network configurators are implemented at the edge to detect degraded network and application performance and dynamically update network routing to account for the same."
11458409,"In various examples, game session audio data—e.g., representing speech of users participating in the game—may be monitored and/or analyzed to determine whether inappropriate language is being used. Where inappropriate language is identified, the portions of the audio corresponding to the inappropriate language may be edited or modified such that other users do not hear the inappropriate language. As a result, toxic behavior or language within instances of gameplay may be censored—thereby enhancing the user experience and making online gaming environments safer for more vulnerable populations. In some embodiments, the inappropriate language may be reported—e.g., automatically—to the game developer or game application host in order to suspend, ban, or otherwise manage users of the system that have a proclivity for toxic behavior."
11460580,"According to an aspect of an embodiment, operations may comprise receiving a search query for points near a query-point, accessing a compressed octree representation of a point cloud comprising 3D points of a region, and traversing the compressed octree representation to identify regions that overlap a search space by, marking a current node as overlapping the search space responsive to determining that the current node is a leaf node, identifying a child node of the current node and performing a nearest neighbor search in the child node responsive to determining that a region represented by the current node overlaps the search space, and identifying a sibling node of the current node and performing the nearest neighbor search in the sibling node responsive to determining that a region represented by the current node does not overlap the search space."
11460897,A computing device comprises: a base portion; a display portion that is movably coupled to the base portion and includes a housing having a movable panel and one or more fixed panels; and a mechanical assembly that positions the movable panel away from the one or more fixed panels as the display portion opens away from the base portion.
11463272,"A network device configured to perform scalable, in-network computations is described. The network device is configured to process pull requests and/or push requests from a plurality of endpoints connected to the network. A collective communication primitive from a particular endpoint can be received at a network device. The collective communication primitive is associated with a multicast region of a shared global address space and is mapped to a plurality of participating endpoints. The network device is configured to perform an in-network computation based on information received from the participating endpoints before forwarding a response to the collective communication primitive back to one or more of the participating endpoints. The endpoints can inject pull requests (e.g., load commands) and/or push requests (e.g., store commands) into the network. A multicast capability enables tasks, such as a reduction operation, to be offloaded to hardware in the network device."
11468582,"In various examples, a two-dimensional (2D) and three-dimensional (3D) deep neural network (DNN) is implemented to fuse 2D and 3D object detection results for classifying objects. For example, regions of interest (ROIs) and/or bounding shapes corresponding thereto may be determined using one or more region proposal networks (RPNs)—such as an image-based RPN and/or a depth-based RPN. Each ROI may be extended into a frustum in 3D world-space, and a point cloud may be filtered to include only points from within the frustum. The remaining points may be voxelated to generate a volume in 3D world space, and the volume may be applied to a 3D DNN to generate one or more vectors. The one or more vectors, in addition to one or more additional vectors generated using a 2D DNN processing image data, may be applied to a classifier network to generate a classification for an object."
11468630,"The disclosure provides a cloud-based renderer and methods of rendering a scene on a computing system using a combination of raytracing and rasterization. In one example, a method of rendering a scene includes: (1) generating at least one raytracing acceleration structure from scene data of the scene, (2) selecting raytracing and rasterization algorithms for rendering the scene based on the scene data, and (3) rendering the scene utilizing a combination of the raytracing algorithms and the rasterization algorithms, wherein the rasterization algorithms utilize primitive cluster data from the raytracing acceleration structures."
11468915,"In various examples, users may access a tool that automatically generates video montages from video clips of the user's gameplay according to parameterized recipes. As a result, a user may select—or allow the system to select—clips corresponding to gameplay of the user and customize one or more parameters (e.g., transitions, music, audio, graphics, etc.) of a recipe, and a video montage may be generated automatically according to a montage script output using the recipe. As such, a user may have a video montage generated with little user involvement, and without requiring any skill or expertise in video editing software. In addition, even for experienced video editors, automatic video montage generation may be a useful alternative to save the time and effort of manually curating video montages."
11470394,"A communication method between a source device and a target device utilizes speculative connection setup between the source device and the target device, target-device-side packet ordering, and fine-grained ordering to remove packet dependencies."
11474519,"A system and method for an on-demand shuttle, bus, or taxi service able to operate on private and public roads provides situational awareness and confidence displays. The shuttle may include ISO 26262 Level 4 or Level 5 functionality and can vary the route dynamically on-demand, and/or follow a predefined route or virtual rail. The shuttle is able to stop at any predetermined station along the route. The system allows passengers to request rides and interact with the system via a variety of interfaces, including without limitation a mobile device, desktop computer, or kiosks. Each shuttle preferably includes an in-vehicle controller, which preferably is an AI Supercomputer designed and optimized for autonomous vehicle functionality, with computer vision, deep learning, and real time ray tracing accelerators. An AI Dispatcher performs AI simulations to optimize system performance according to operator-specified system parameters."
11474710,"One aspect of the current disclosure provides a method for utilizing a plurality of memories associated with a plurality of devices in a computer system. The method includes: receiving an application-specific data set for executing a ray tracing application employing the devices; determining whether the data set is fully replicable in each memory; when the data set is not fully replicable in any of the memories, determining a maximum amount of the data set that is replicable in each memory while distributing a remaining amount of the data set across the memories; and identifying, based on application-specific information of the ray tracing application, a first subsection of the data set that corresponds to the maximum amount of the data set and a second subsection of the data set that corresponds to the remaining amount of the data set, wherein the first subsection is accessed more frequently than the second subsection."
11474897,"Often there are errors when reading data from computer memory. To detect and correct these errors, there are multiple types of error correction codes. Disclosed is an error correction architecture that creates a codeword having a data portion and an error correction code portion. Swizzling rearranges the order of bits and distributes the bits among different codewords. Because the data is redistributed, a potential memory error of up to N contiguous bits, where N for example equals 2 times the number of codewords swizzled together, only affects up to, at most, two bits per swizzled codeword. This keeps the error within the error detecting capabilities of the error correction architecture. Furthermore, this can allow improved error correction and detection without requiring a change to error correcting code generators and checkers."
11475542,A neural network-based rendering technique increases temporal stability and image fidelity of low sample count path tracing by optimizing a distribution of samples for rendering each image in a sequence. A sample predictor neural network learns spatio-temporal sampling strategies such as placing more samples in dis-occluded regions and tracking specular highlights. Temporal feedback enables a denoiser neural network to boost the effective input sample count and increases temporal stability. The initial uniform sampling step typically present in adaptive sampling algorithms is not needed. The sample predictor and denoiser operate at interactive rates to achieve significantly improved image quality and temporal stability compared with conventional adaptive sampling techniques.
11475549,"High dynamic range (HDR) support is provided for legacy application programs, such as games that are configured to display standard dynamic range (SDR) frames. HDR frames may be generated without modifying the legacy application program. The buffer creation process of the legacy application program is intercepted and modified before creation of the SDR format buffer so that the buffer is configured to use an upgraded SDR format having an increased bit depth compared with a conventional SDR buffer. Rather than tone mapping and quantizing rendered image data to the lower bit depth for storage in the conventional SDR buffer, the rendered image data is tone mapped and quantized for storage at the increased bit depth of the upgraded SDR buffer. Therefore, the luminance and greater dynamic range of the tone mapped data is better preserved compared with outputting conventional SDR frames."
11476852,"When a signal glitches, logic receiving the signal may change in response, thereby charging and/or discharging nodes within the logic and dissipating power. Providing a glitch-free signal may reduce the number of times the nodes are charged and/or discharged, thereby reducing the power dissipation. A technique for eliminating glitches in a signal is to insert a storage element that samples the signal after it is done changing to produce a glitch-free output signal. The storage element is enabled by a “ready” signal having a delay that matches the delay of circuitry generating the signal. The technique prevents the output signal from changing until the final value of the signal is achieved. The output signal changes only once, typically reducing the number of times nodes in the logic receiving the signal are charged and/or discharged so that power dissipation is also reduced."
11477004,"A clock data recovery circuit detects illegal decisions for received data, accumulates a phase gradient for the data, determines a number of the illegal decisions in a configured window for receiving the data, and if the number of the illegal decisions exceeds a pre-defend number in the window, applies a sum of the accumulated phase gradient and a phase increment having a sign of the accumulated phase gradient to a clock circuit for the data receiver."
11481950,"Graphics processing unit (GPU) performance and power efficiency is improved using machine learning to tune operating parameters based on performance monitor values and application information. Performance monitor values are processed using machine learning techniques to generate model parameters, which are used by a control unit within the GPU to provide real-time updates to the operating parameters. In one embodiment, a neural network processes the performance monitor values to generate operating parameters in real-time."
11482008,"According to an aspect of an embodiment, operations may comprise determining a target position and orientation for a calibration board with respect to a camera of a vehicle, detecting a first position and orientation of the calibration board with respect to the camera of the vehicle, determining instructions for moving the calibration board from the first position and orientation to the target position and orientation, transmitting the instructions to a device, detecting a second position and orientation of the calibration board, determining whether the second position and orientation is within a threshold of matching the target position and orientation, and, in response to determining that the second position and orientation is within the threshold of matching the target position and orientation, capturing one or more calibration camera images using the camera and calibrating one or more sensors of the vehicle using the one or more calibration camera images."
11485308,"In various examples, systems and methods are disclosed that accurately identify driver and passenger in-cabin activities that may indicate a biomechanical distraction that prevents a driver from being fully engaged in driving a vehicle. In particular, image data representative of an image of an occupant of a vehicle may be applied to one or more deep neural networks (DNNs). Using the DNNs, data indicative of key point locations corresponding to the occupant may be computed, a shape and/or a volume corresponding to the occupant may be reconstructed, a position and size of the occupant may be estimated, hand gesture activities may be classified, and/or body postures or poses may be classified. These determinations may be used to determine operations or settings for the vehicle to increase not only the safety of the occupants, but also of surrounding motorists, bicyclists, and pedestrians."
11487341,"Systems and techniques for improving the performance of circuits while adapting to dynamic voltage drops caused by the execution of noisy instructions (e.g. high power consuming instructions) are provided. The performance is improved by slowing down the frequency of operation selectively for types of noisy instructions. An example technique controls a clock by detecting an instruction of a predetermined noisy type that is predicted to have a predefined noise characteristic (e.g. a high level of noise generated on the voltage rails of a circuit due to greater amount of current drawn by the instruction), and, responsive to the detecting, deceasing a frequency of the clock. The detecting occurs before execution of the instruction. The changing of the frequency in accordance with instruction type enables the circuits to be operated at high frequencies even if some of the workloads include instructions for which the frequency of operation is slowed down."
11487498,"In various examples, when a local user initiates an instance of a video conference application, the user may be provided with a user interface (UI) that displays an icon corresponding to the user as well as several other icons corresponding to participants in the instance of the video conference application. As the users converse, the local user may find that a particular participant is speaking loudly compared to the other remote users. The local user may then select an icon corresponding to the particular participant and move the icon away from the local user's icon in the UI. Based on moving the remote user's icon away from the local user's icon, the system may reduce the output volume of the audio data for the participant. Further, if the local user moves the participant icon closer to the local user's icon, the volume for the participant may be increased."
11487673,A system for managing virtual memory. The system includes a first processing unit configured to execute a first operation that references a first virtual memory address. The system also includes a first memory management unit (MMU) associated with the first processing unit and configured to generate a first page fault upon determining that a first page table that is stored in a first memory unit associated with the first processing unit does not include a mapping corresponding to the first virtual memory address. The system further includes a first copy engine associated with the first processing unit. The first copy engine is configured to read a first command queue to determine a first mapping that corresponds to the first virtual memory address and is included in a first page state directory. The first copy engine is also configured to update the first page table to include the first mapping.
11487919,"A cable driving a large system such as cable driven machines, cable cars or tendons in a human or robot is typically modeled as a large number of small segments that are connected via joints. The two main difficulties with this model are satisfying the inextensibility constraint and handling the typically large mass ratio between the segments and the objects they connect. This disclosure introduces an effective approach to solving these problems. The introduced approach simulates the effect of a cable using a new type of distance constraint called ‘cable joint’ that changes both its attachment points and its rest length dynamically. The introduced approach models a cable connecting a series of objects, e.g., components of a robot, as a sequence of cable joints, reducing the complexity of the simulation from the order of the number of segments in the cable to the number of connected objects."
11487968,"Systems and methods for more accurate and robust determination of subject characteristics from an image of the subject. One or more machine learning models receive as input an image of a subject, and output both facial landmarks and associated confidence values. Confidence values represent the degrees to which portions of the subject's face corresponding to those landmarks are occluded, i.e., the amount of uncertainty in the position of each landmark location. These landmark points and their associated confidence values, and/or associated information, may then be input to another set of one or more machine learning models which may output any facial analysis quantity or quantities, such as the subject's gaze direction, head pose, drowsiness state, cognitive load, or distraction state."
11488418,"Estimating a three-dimensional (3D) pose of an object, such as a hand or body (human, animal, robot, etc.), from a 2D image is necessary for human-computer interaction. A hand pose can be represented by a set of points in 3D space, called keypoints. Two coordinates (x,y) represent spatial displacement and a third coordinate represents a depth of every point with respect to the camera. A monocular camera is used to capture an image of the 3D pose, but does not capture depth information. A neural network architecture is configured to generate a depth value for each keypoint in the captured image, even when portions of the pose are occluded, or the orientation of the object is ambiguous. Generation of the depth values enables estimation of the 3D pose of the object."
11489541,"In artificial neural networks, and other similar applications, there is typically a large amount of data involved that is considered sparse data. Due to the large size of the data involved in such applications, it is helpful to compress the data to save bandwidth resources when transmitting the data and save memory resources when storing the data. Introduced herein is a compression technique that selects elements with significant values from data and restructures them into a structured sparse format. By generating metadata that enforces the structured sparse format and organizing the data according to the metadata, the introduced technique not only reduces the size of the data but also consistently places the data in a particular format. As such, hardware can be simplified and optimized to process the data much faster and much more efficiently than the conventional compression techniques that rely on a non-structured sparsity format."
11494265,"In general, data is susceptible to errors caused by faults in hardware (i.e. permanent faults), such as faults in the functioning of memory and/or communication channels. To detect errors in data caused by hardware faults, the error correcting code (ECC) was introduced, which essentially provides a sort of redundancy to the data that can be used to validate that the data is free from errors caused by hardware faults. In some cases, the ECC can also be used to correct errors in the data caused by hardware faults. However, the ECC itself is also susceptible to errors, including specifically errors caused by faults in the ECC logic. A method, computer readable medium, and system are thus provided for securing against errors in an ECC."
11494370,"Latency of in-system test (IST) execution for a hardware component of an in-field (deployed) computing platform may be reduced when a value of a physical operating parameter can be changed without rebooting the computing platform. A test (e.g., patterns or vectors) is executed for varying values of the physical operating parameter (e.g., supply voltage, clock speed, temperature, noise magnitude/duration, operating current, and the like), providing the ability to detect faults in the hardware components."
11494879,"A neural network architecture is disclosed for restoring noisy data. The neural network is a blind-spot network that can be trained according to a self-supervised framework. In an embodiment, the blind-spot network includes a plurality of network branches. Each network branch processes a version of the input data using one or more layers associated with kernels that have a receptive field that extends in a particular half-plane relative to the output value. In one embodiment, the versions of the input data are offset in a particular direction and the convolution kernels are rotated to correspond to the particular direction of the associated network branch. In another embodiment, the versions of the input data are rotated and the convolution kernel is the same for each network branch. The outputs of the network branches are composited to de-noise the image. In some embodiments, Bayesian filtering is performed to de-noise the input data."
11494976,"Approaches are presented for training an inverse graphics network. An image synthesis network can generate training data for an inverse graphics network. In turn, the inverse graphics network can teach the synthesis network about the physical three-dimensional (3D) controls. Such an approach can provide for accurate 3D reconstruction of objects from 2D images using the trained inverse graphics network, while requiring little annotation of the provided training data. Such an approach can extract and disentangle 3D knowledge learned by generative models by utilizing differentiable renderers, enabling a disentangled generative model to function as a controllable 3D “neural renderer,” complementing traditional graphics renderers."
11495568,"An IC package including an integrated circuit die having a major surface and one or more solder bumps located on the major surface in at least one corner region of the major surface and a substrate having a surface, the surface including bump pads thereon. The major surface of the integrated circuit die faces the substrate surface, the one or more solder bumps are bonded to individual ones of the bump pads to thereby form a bond joint, the major surface of the integrated circuit die has a footprint area of at least about 400 mm2. A ratio of a coefficient of thermal expansion of the substrate (CTEsub) to a coefficient of thermal expansion of the integrated circuit die (CTEdie) is at least about 3:1. A method of manufacturing an IC package is also disclosed."
11495928,"A power adapter has a solenoid actuated retaining latch controlled by an electronic circuit that detects the presence or absence of AC mains voltage. When the assembled AC-DC adapter and plug assembly are removed from the wall, the latch detects removal and unlocks the plug assembly for easy removal without undue force required by the user. The circuit is designed for minimal power consumption, and the solenoid only consumes power when it is engaging or disengaging the latch."
11496773,"A method, computer readable medium, and system are disclosed for identifying residual video data. This data describes data that is lost during a compression of original video data. For example, the original video data may be compressed and then decompressed, and this result may be compared to the original video data to determine the residual video data. This residual video data is transformed into a smaller format by means of encoding, binarizing, and compressing, and is sent to a destination. At the destination, the residual video data is transformed back into its original format and is used during the decompression of the compressed original video data to improve a quality of the decompressed original video data."
11498007,"A technique for analyzing data in order to detect issues within a cloud-based service is disclosed. Host computing devices in a data center launch virtual machines, where at least some virtual machines run a pipelined stack for a streaming service. Virtual machines in the host computing devices generate event data including timestamps. Metadata generated by the pipelined stack during each streaming session is analyzed to identify deadzones in the corresponding host computing device, and the event data is processed to identify potential root causes of the corresponding deadzones. The event data can be generated by the virtual machine hosting the streaming service or by different virtual machines on the same host computing device. A distribution of events of each event type relative to the identified deadzones is determined and an operation of the host computing device can be adjusted based on the distribution."
11501467,"A remote device utilizes ray tracing to compute a light field for a scene to be rendered, where the light field includes information about light reflected off surfaces within the scene. This light field is then compressed utilizing lossless or lossy compression and one or more video compression techniques that implement temporal reuse, such that only differences between the light field for the scene and a light field for a previous scene are compressed. The compressed light field data is then sent to a client device that decompresses the light field data and uses such data to obtain the light field for the scene at the client device. This light field is then used by the client device to compute global illumination for the scene. The global illumination may be used to accurately render the scene at the mobile device, resulting in a realistic scene that is presented by the mobile device."
11501572,"In various examples, a set of object trajectories may be determined based at least in part on sensor data representative of a field of view of a sensor. The set of object trajectories may be applied to a long short-term memory (LSTM) network to train the LSTM network. An expected object trajectory for an object in the field of view of the sensor may be computed by the LSTM network based at least in part an observed object trajectory. By comparing the observed object trajectory to the expected object trajectory, a determination may be made that the observed object trajectory is indicative of an anomaly."
11502867,"A network device configured to perform scalable, in-network computations is described. The network device is configured to process pull requests and/or push requests from a plurality of endpoints connected to the network. A collective communication primitive from a particular endpoint can be received at a network device. The collective communication primitive is associated with a multicast region of a shared global address space and is mapped to a plurality of participating endpoints. The network device is configured to perform an in-network computation based on information received from the participating endpoints before forwarding a response to the collective communication primitive back to one or more of the participating endpoints. An injection policy comprising the issuing of credits enables each endpoint to limit the amount of collective communication primitives injected into the network simultaneously to reduce network congestion caused by increased network traffic due to the multicast capability of the network devices."
11506888,"A gaze tracking system for use by the driver of a vehicle includes an opaque frame circumferentially enclosing a transparent field of view of the driver, light emitting diodes coupled to the opaque frame for emitting infrared light onto various regions of the driver's eye gazing through the transparent field of view, and diodes for sensing intensity of infrared light reflected off of various regions of the driver's eye."
11507704,"Various implementations of a current flattening circuit are disclosed, including those utilizing a feedback current regulator, a feedforward current regulator, and a constant current source."
11507846,"Artificial neural networks (ANNs) are computing systems that imitate a human brain by learning to perform tasks by considering examples. By representing an artificial neural network utilizing individual paths each connecting an input of the ANN to an output of the ANN, a complexity of the ANN may be reduced, and the ANN may be trained and implemented in a much faster manner when compared to an implementation using fully connected ANN graphs."
11508049,"In various examples, a deep neural network (DNN) is trained for sensor blindness detection using a region and context-based approach. Using sensor data, the DNN may compute locations of blindness or compromised visibility regions as well as associated blindness classifications and/or blindness attributes associated therewith. In addition, the DNN may predict a usability of each instance of the sensor data for performing one or more operations—such as operations associated with semi-autonomous or autonomous driving. The combination of the outputs of the DNN may be used to filter out instances of the sensor data—or to filter out portions of instances of the sensor data determined to be compromised—that may lead to inaccurate or ineffective results for the one or more operations of the system."
11508076,"A neural network model receives color data for a sequence of images corresponding to a dynamic scene in three-dimensional (3D) space. Motion of objects in the image sequence results from a combination of a dynamic camera orientation and motion or a change in the shape of an object in the 3D space. The neural network model generates two components that are used to produce a 3D motion field representing the dynamic (non-rigid) part of the scene. The two components are information identifying dynamic and static portions of each image and the camera orientation. The dynamic portions of each image contain motion in the 3D space that is independent of the camera orientation. In other words, the motion in the 3D space (estimated 3D scene flow data) is separated from the motion of the camera."
11508112,"Techniques are disclosed for improving the throughput of ray intersection or visibility queries performed by a ray tracing hardware accelerator. Throughput is improved, for example, by releasing allocated resources before ray visibility query results are reported by the hardware accelerator. The allocated resources are released when the ray visibility query results can be stored in a compressed format outside of the allocated resources. When reporting the ray visibility query results, the results are reconstructed based on the results stored in the compressed format. The compressed format storage can be used for ray visibility queries that return no intersections or terminate on any hit ray visibility query. One or more individual components of allocated resources can also be independently deallocated based on the type of data to be returned and/or results of the ray visibility query."
11508113,"Recurrent blurring may be used to render frames of a virtual environment, where the radius of a filter for a pixel is based on a number of successfully accumulated frames that correspond to that pixel. To account for rejections of accumulated samples for the pixel, ray-traced samples from a lower resolution version of a ray-traced render may be used to increase the effective sample count for the pixel. Parallax may be used to control the accumulation speed along with an angle between a view vector that corresponds to the pixel. A magnitude of one or more dimensions of a filter applied to the pixel may be based on an angle of a view vector that corresponds to the pixel to cause reflections to elongate along an axis under glancing angles. The dimension(s) may be based on a direction of a reflected specular lobe associated with the pixel."
11512964,"According to an aspect of an embodiment, operations may comprise obtaining a pose graph that comprises a plurality of nodes. The operations may also comprise dividing the pose graph into a plurality of pose subgraphs, each pose subgraph comprising one or more respective pose subgraph interior nodes and one or more respective pose subgraph boundary nodes. The operations may also comprise generating one or more boundary subgraphs based on the plurality of pose subgraphs, each of the one or more boundary subgraphs comprising one or more respective boundary subgraph boundary nodes and comprising one or more respective boundary subgraph interior nodes. The operations may also comprise obtaining an optimized pose graph by performing a pose graph optimization. The pose graph optimization may comprise performing a pose subgraph optimization of the plurality of pose subgraphs and performing a boundary subgraph optimization of the plurality of boundary subgraphs."
11513686,"Accesses between a processor and its external memory is reduced when the processor internally maintains a compressed version of values stored in the external memory. The processor can then refer to the compressed version rather than access the external memory. One compression technique involves maintaining a dictionary on the processor mapping portions of a memory to values. When all of the values of a portion of memory are uniform (e.g., the same), the value is stored in the dictionary for that portion of memory. Thereafter, when the processor needs to access that portion of memory, the value is retrieved from the dictionary rather than from external memory. Techniques are disclosed herein to extend, for example, the capabilities of such dictionary-based compression so that the amount of accesses between the processor and its external memory are further reduced."
11513814,"Diagnostics and boot up for AV hardware and software of a computer system of an autonomous vehicle may be performed based at least on receiving a shutdown or power off indication, then a computing state of the computer system may be suspended with the computer system entering a low-power mode. The suspended computing state can be rapidly restored without requiring a reboot and diagnostics for key-on. To ensure the integrity of the saved computing state, the computer system may exit the low-power mode, rerun the diagnostics, reload the programs, and then reenter the low-power mode. Restoring the suspended computing state may be triggered by a user inserting an ignition key, pressing a button to turn on the vehicle, opening a door to the vehicle, remotely unlocking the vehicle, remotely starting the vehicle, etc."
11514293,"In various examples, historical trajectory information of objects in an environment may be tracked by an ego-vehicle and encoded into a state feature. The encoded state features for each of the objects observed by the ego-vehicle may be used—e.g., by a bi-directional long short-term memory (LSTM) network—to encode a spatial feature. The encoded spatial feature and the encoded state feature for an object may be used to predict lateral and/or longitudinal maneuvers for the object, and the combination of this information may be used to determine future locations of the object. The future locations may be used by the ego-vehicle to determine a path through the environment, or may be used by a simulation system to control virtual objects—according to trajectories determined from the future locations—through a simulation environment."
11514637,"A method, computer readable medium, and system are disclosed for implementing automatic level-of-detail for physically-based materials. The method includes the steps of identifying a declarative representation of a material to be rendered, creating a reduced complexity declarative representation of the material by applying one or more term rewriting rules to the declarative representation of the material, and returning the reduced complexity declarative representation of the material."
11514682,"According to one or more embodiments, operations may comprise obtaining a first point cloud. The operations also comprise performing segmentation of the first point cloud, the segmentation generating one or more clusters of points of the point cloud. The operations also comprise determining, for each respective cluster of the plurality of clusters, a respective geometric feature of a corresponding object that corresponds to the respective cluster. The operations also comprise obtaining a second point cloud. The operations also comprise assigning a plurality of weights that comprises assigning a respective weight to each respective cluster based on the respective geometric feature that corresponds to the respective cluster. The operations also comprise obtaining a second point cloud and aligning the first point cloud with the second point cloud based on the plurality of weights."
11520345,"In various examples, a path perception ensemble is used to produce a more accurate and reliable understanding of a driving surface and/or a path there through. For example, an analysis of a plurality of path perception inputs provides testability and reliability for accurate and redundant lane mapping and/or path planning in real-time or near real-time. By incorporating a plurality of separate path perception computations, a means of metricizing path perception correctness, quality, and reliability is provided by analyzing whether and how much the individual path perception signals agree or disagree. By implementing this approach—where individual path perception inputs fail in almost independent ways—a system failure is less statistically likely. In addition, with diversity and redundancy in path perception, comfortable lane keeping on high curvature roads, under severe road conditions, and/or at complex intersections, as well as autonomous negotiation of turns at intersections, may be enabled."
11522565,"A packed error correction code (ECC) technique opportunistically embeds ECC check-bits with compressed data. When compressed, the data is encoded in fewer bits and is therefore fragmented when stored or transmitted compared with the uncompressed data. The ECC check-bits may be packed with compressed data at “source” points. The check-bits are transmitted along with the compressed data and, at any “intermediate” point between the source and a “destination” the check-bits may be used to detect and correct errors in the compressed data. In contrast with conventional systems, packed ECC enables end-to-end coverage for sufficiently-compressed data within the processor and also externally. While storage circuitry typically is protected by structure-specific ECC, protection is also beneficial for data as it is transmitted between processing and/or storage units."
11523539,"A protective shroud includes a top plate, a first side plate that is adapted to be disposed proximate a first edge region of a plurality of cooling fins of a heat exchanger for an integrated circuit, and a second side plate that is adapted to be disposed proximate a second edge region of the plurality of cooling fins."
11526644,"The disclosure provides using test processors to provide a more flexible solution compared to the existing DFX blocks that are used for controlling test networks in chips. The test processors provide a highly flexible solution since programming of the test processors can be changed at any time; even after manufacturing, and can support practically an unlimited number of core chips in any configuration. The high flexibility provided via the test processors can reduce engineering effort needed in design and verification, accelerate schedules, and may prevent additional tapeouts in case of DFX design bugs. By making debug and diagnosis easier by providing an opportunity to change debug behavior as needed, the time-to-market timeline can be accelerated. Accordingly, the disclosure provides a chip with a test processor, a multi-chip processing system with a test processor, and a method of designing a chip having a test processor."
11531088,"In various examples, a deep neural network(s) (e.g., a convolutional neural network) may be trained to detect moving and stationary obstacles from RADAR data of a three dimensional (3D) space. In some embodiments, ground truth training data for the neural network(s) may be generated from LIDAR data. More specifically, a scene may be observed with RADAR and LIDAR sensors to collect RADAR data and LIDAR data for a particular time slice. The RADAR data may be used for input training data, and the LIDAR data associated with the same or closest time slice as the RADAR data may be annotated with ground truth labels identifying objects to be detected. The LIDAR labels may be propagated to the RADAR data, and LIDAR labels containing less than some threshold number of RADAR detections may be omitted. The (remaining) LIDAR labels may be used to generate ground truth data."
11532168,"A deep neural network(s) (DNN) may be used to detect objects from sensor data of a three dimensional (3D) environment. For example, a multi-view perception DNN may include multiple constituent DNNs or stages chained together that sequentially process different views of the 3D environment. An example DNN may include a first stage that performs class segmentation in a first view (e.g., perspective view) and a second stage that performs class segmentation and/or regresses instance geometry in a second view (e.g., top-down). The DNN outputs may be processed to generate 2D and/or 3D bounding boxes and class labels for detected objects in the 3D environment. As such, the techniques described herein may be used to detect and classify animate objects and/or parts of an environment, and these detections and classifications may be provided to an autonomous vehicle drive stack to enable safe planning and control of the autonomous vehicle."
11537139,"In various examples, sensor data may be received that represents a field of view of a sensor of a vehicle located in a physical environment. The sensor data may be applied to a machine learning model that computes both a set of boundary points that correspond to a boundary dividing drivable free-space from non-drivable space in the physical environment and class labels for boundary points of the set of boundary points that correspond to the boundary. Locations within the physical environment may be determined from the set of boundary points represented by the sensor data, and the vehicle may be controlled through the physical environment within the drivable free-space using the locations and the class labels."
11538231,"In various examples, sensor data may be adjusted to represent a virtual field of view different from an actual field of view of the sensor, and the sensor data—with or without virtual adjustment—may be applied to a stereographic projection algorithm to generate a projected image. The projected image may then be applied to a machine learning model—such as a deep neural network (DNN)—to detect and/or classify features or objects represented therein."
11541309,"Many times, users play games to certain places in the game and decide to save the game and resume it later. When users resume the game, they have to wait for it to load, wade through menus to select the saved game, and wait again for the game to resume. The introduced technique directly suspends and resume games that are rendered on a cloud server based on user initiated suspend and resume control commands. As the games are directly suspended and resumed, the users can skip past menu and screen loading. The introduced technique can track game information of multiples users in cloud tokens, and can move these cloud tokens from one memory location to another based on the user initiated suspend and resume control commands."
11544818,"Users often desire to capture certain images from an application. Existing methods of capturing images can result in low-resolution images due to limitations of the display device providing the images. This disclosure provides a method of capturing higher resolution images from source images. Techniques are also disclosed to reduce the storage size associated with the higher resolution images. Through capturing low-resolution versions of the same source images, image effects can be captured and applied to the higher resolution images where those image effects may be altered or missing. Frequency spectrum combination can be used to combine the low-resolution image data and the higher resolution image data. The higher resolution images can be processed using a segmentation scheme, such as tiling, without reducing or limiting the image effects."
11545450,This disclosure provides an integrated circuit device that includes a RDL that is interlocked with a bump (or “pillar”). The interlocked interface provides the contact RDL-bump interface with increased structural stability that can better withstand the thermal stresses associated with high performance devices IC devices. The interlock structure mitigates crack/delamination that occurs at the RDL-bump interface in large IC chips that are generally subjected to higher stresses during operation.
11546568,"Apparatuses, systems, and techniques are presented to perform monocular view synthesis of a dynamic scene. Single and multi-view depth information can be determined for a collection of images of a dynamic scene, and a blender network can be used to combine image features for foreground, background, and missing image regions using fused depth maps inferred form the single and multi-view depth information."
11550325,Techniques to generate driving scenarios for autonomous vehicles characterize a path in a driving scenario according to metrics such as narrowness and effort. Nodes of the path are assigned a time for action to avoid collision from the node. The generated scenarios may be simulated in a computer.
11550584,"Various techniques for accelerating Smith-Waterman sequence alignments are provided. For example, threads in a group of threads are employed to use an interleaved cell layout to store relevant data in registers while computing sub-alignment data for one or more local alignment problems. In another example, specialized instructions that reduce the number of cycles required to compute each sub-alignment score are utilized. In another example, threads are employed to compute sub-alignment data for a subset of columns of one or more local alignment problems while other threads begin computing sub-alignment data based on partial result data received from the preceding threads. After computing a maximum sub-alignment score, a thread stores the maximum sub-alignment score and the corresponding position in global memory."
11557022,A neural network-based rendering technique increases temporal stability and image fidelity of low sample count path tracing by optimizing a distribution of samples for rendering each image in a sequence. A sample predictor neural network learns spatio-temporal sampling strategies such as placing more samples in dis-occluded regions and tracking specular highlights. Temporal feedback enables a denoiser neural network to boost the effective input sample count and increases temporal stability. The initial uniform sampling step typically present in adaptive sampling algorithms is not needed. The sample predictor and denoiser operate at interactive rates to achieve significantly improved image quality and temporal stability compared with conventional adaptive sampling techniques.
11561624,"For mechanical keyboards or other input devices with individual mechanical key buttons, and particularly for compact keyboards used for laptops and other such devices, the size of the up and down arrow keys is usually half the size of most other keys on the keyboard. For example, each letter key on a physical keyboard is typically double the size of each of the up and down arrow keys on that same keyboard. Due to the smaller physical size of the up and down arrow keys, a modified mechanical configuration is used which results in a variation in the tactile feel of the various buttons of the keyboard for a user. The present disclosure discloses a capacitive touch enabled key with a corresponding tactile button to allow the key to represent multiple different inputs while also maintaining a same tactile response as other single input keys of the input device."
11563579,"Approaches in accordance with various embodiments allow for zero-touch enrollment of devices with respective manager systems. In at least one embodiment, a device at startup can contact a central directory service (CDS) for information about an associated manager. The CDS can authenticate the device using device information included in the request, and can send a challenge token to the device in response. The challenge token can include information for the manager, protected with multiple layers of security that should only be able to be decrypted by the authenticated device. The device can decrypt this challenge token to determine the manager information, and can convert this challenge token to a bearer token. The device can then send a request to the determined manager that includes the bearer token, which the manager can use to authenticate the device. The manager can then send the device appropriate configuration information."
11566903,"The autonomous vehicle generates an overlapped image by overlaying HD map data over sensor data and rendering the overlaid images. The visualization process is repeated as the vehicle drives along the route. The visualization may be displayed on a screen within the vehicle or at a remote device. The system performs reverse rendering of a scene based on map data from a selected point. For each line of sight originating at the selected point, the system identifies the farthest object in the map data. Accordingly, the system eliminates objects obstructing the view of the farthest objects in the HD map as viewed from the selected point. The system further allows filtering of objects using filtering criteria based on semantic labels. The system generates a view from the selected point such that 3D objects matching the filtering criteria are eliminated from the view."
11567728,"The disclosure is directed to a process that can predict and prevent an audio artifact from occurring. The process can monitor the systems, processes, and execution threads on a larger system/device, such as a mobile or in-vehicle device. Using a learning algorithm, such as deep neural network (DNN), the information collected can generate a prediction of whether an audio artifact is likely to occur. The process can use a second learning algorithm, which also can be a DNN, to generate recommended system adjustments that can attempt to prevent the audio glitch from occurring. The recommendations can be for various systems and components on the device, such as changing the processing system frequency, the memory frequency, and the audio buffer size. After the audio artifact has been prevented, the system adjustments can be reversed fully or in steps to return the system to its state prior to the system adjustments."
11568523,"Apparatuses, systems, and techniques to perform a fast Fourier transform operation. In at least one embodiment, a fast Fourier transform operation is performed based on one or more parameters, wherein the one or more parameters indicate information about one or more operands of the fast Fourier transform."
11568625,"Apparatuses, systems, and techniques to train and apply a first machine learning model to identify a plurality of regions of interest within an input image, and to train and apply a plurality of second machine learning models to identify one or more objects within each region of interest identified by the first machine learning model."
11568861,"In various examples, systems and methods of the present disclosure combine open and closed dialog systems into an intelligent dialog management system. A text query may be processed by a natural language understanding model trained to associate the text query with a domain tag, intent classification, and/or input slots. Using the domain tag, the natural language understanding model may identify information in the text query corresponding to input slots needed for answering the text query. The text query and related information may then be passed to a dialog manager to direct the text query to the proper domain dialog system. Responses retrieved from the domain dialog system may be provided to the user via text output and/or via a text to speech component of the dialog management system."
11569939,"A system includes a first device and a second device coupled to a link. The first device is to transmit one or more request frames for synchronization of a data layer, each request frame including a quantity of bits and an error code. The second device is to receive a first set of bits corresponding to the quantity of bits in each request frame. The second device is to perform an error decode operation on the first set of bits using a first portion of the first set of bits and determine the first set of bits correspond to a frame boundary of the one more request frames responsive to a success of the error decode operation. The second device is to transmit an acknowledgement of the synchronization of the data layer based on determining the first set of bits corresponds to the frame boundary."
11573269,"In various examples, a test system is provided for executing built-in-self-test (BIST) on integrated circuits deployed in the field. The integrated circuits may include a first device and a second device, the first device having direct access to external memory, which stores test data, and the second device having indirect access to the external memory by way of the first device. In addition to providing a mechanism to permit the first device and the second device to run test concurrently, the hardware and software may reduce memory requirements and runtime associated with running the test sequences, thereby making real-time BIST possible in deployment. Furthermore, some embodiments permit a single external memory image to cater to different SKU configurations."
11573795,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
11573854,"Various embodiments include a memory device that recovers from write errors and read errors more quickly relative to prior memory devices. Certain patterns of write data and read data may result on poor signal quality on the memory interface between memory controllers and memory devices. The disclosed memory device, synchronously with the memory controller, scrambles read data before transmitting the data to the memory controller and descrambles received from the memory controller. The scrambling and descrambling results in a different pattern on the memory interface even for the same read data or write data. Therefore, when a write operation or a read operation fails, and the operation is replayed, the pattern transmitted on the memory interface is different when the operation is replayed. As a result, the memory device more easily recovers from data patterns that cause poor signal quality on the memory interface."
11573856,"In various examples, a system includes a memory operating within a first risk level and circuitry operating within a second risk level that indicates more risk than the first risk level. The circuitry reads and/or writes data to a first memory address within the memory, and reads and/or writes an error detection code to a second memory address within the memory."
11573872,"In various examples, one or more components or regions of a processing unit—such as a processing core, and/or component thereof—may be tested for faults during deployment in the field. To perform testing while in deployment, the state of a component subject to test may be retrieved and/or stored during the test to maintain state integrity, the component may be clamped to communicatively isolate the component from other components of the processing unit, a test vector may be applied to the component, and the output of the component may be compared against an expected output to determine if any faults are present. The state of the component may be restored after testing, and the clamp removed, thereby returning the component to its operating state without a perceivable detriment to operation of the processing unit in deployment."
11573921,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
11574097,"Techniques to improve the accuracy and speed for detection and remediation of difficult to test nodes in a circuit design netlist. The techniques utilize improved netlist representations, test point insertion, and trained neural networks."
11574155,"Approaches are presented for training and using scene graph generators for transfer learning. A scene graph generation technique can decompose a domain gap into individual types of discrepancies, such as may relate to appearance, label, and prediction discrepancies. These discrepancies can be reduced, at least in part, by aligning the corresponding latent and output distributions using one or more gradient reversal layers (GRLs). Label discrepancies can be addressed using self-pseudo-statistics collected from target data. Pseudo statistic-based self-learning and adversarial techniques can be used to manage these discrepancies without the need for costly supervision from a real-world dataset."
11574481,"Systems and methods for detecting blockages in images are described. An example method may include receiving a plurality of images captured by a camera installed on an apparatus. The method may include identifying one or more candidate blocked regions in the plurality of images. Each of the candidate blocked regions may contain image data caused by blockages in the camera's field-of-view. The method may further include assigning scores to the one or more candidate blocked regions based on relationships among the one or more candidate blocked regions in the plurality of images. In response to a determination that one of the scores is above a predetermined blockage threshold, the method may include generating an alarm signal for the apparatus."
11574654,"In various examples, recordings of gameplay sessions are enhanced by the application of special effects to relatively high(er) and/or low(er) interest durations of the gameplay sessions. Durations of relatively high(er) or low(er) predicted interest in a gameplay session are identified, for instance, based upon level of activity engaged in by a gamer during a particular gameplay session duration. Once identified, different variations of video characteristic(s) are applied to at least a portion of the identified durations for implementation during playback. The recordings may be generated and/or played back in real-time with a live gameplay session, or after completion of the gameplay session. Further, video data of the recordings themselves may be modified to include the special effects and/or indications of the durations and/or variations may be included in metadata and used for playback."
11575494,"A system includes a first device and a second device coupled to a link having one or more paths associated with transmitting a clock signal. The first device is to transmit a set of bits associated with a pattern via the one more paths. The set of bits are transmitted using a first clock signal having a first frequency less than a second frequency associated with data transmission operations. The second device is to receive the set of bits associated with the pattern, determine a number of pulses associated with the set of bits over a first period, and determine the number of pulses, associated with the set of bits, satisfies a predetermined condition relating to the number of pulses for the first period. The second device is to initiate a training of the link in response to determining the number of pulses satisfies the predetermined condition."
11579629,"In various examples, a sequential deep neural network (DNN) may be trained using ground truth data generated by correlating (e.g., by cross-sensor fusion) sensor data with image data representative of a sequences of images. In deployment, the sequential DNN may leverage the sensor correlation to compute various predictions using image data alone. The predictions may include velocities, in world space, of objects in fields of view of an ego-vehicle, current and future locations of the objects in image space, and/or a time-to-collision (TTC) between the objects and the ego-vehicle. These predictions may be used as part of a perception system for understanding and reacting to a current physical environment of the ego-vehicle."
11579852,"System and method of compiling a program having a mixture of host code and device code to enable Profile Guided Optimization (PGO) for device code execution. An exemplary integrated compiler can compile source code programmed to be executed by a host processor (e.g., CPU) and a co-processor (e.g., a GPU) concurrently. The compilation can generate an instrumented executable code which includes: profile instrumentation counters for the device functions; and instructions for the host processor to allocate and initialize device memory for the counters and to retrieve collected profile information from the device memory to generate instrumentation output. The output is fed back to the compiler for compiling the source code a second time to generate optimized executable code for the device functions defined in the source code."
11579925,"A parallel processing unit (PPU) can be divided into partitions. Each partition is configured to operate similarly to how the entire PPU operates. A given partition includes a subset of the computational and memory resources associated with the entire PPU. Software that executes on a CPU partitions the PPU for an admin user. A guest user is assigned to a partition and can perform processing tasks within that partition in isolation from any other guest users assigned to any other partitions. Because the PPU can be divided into isolated partitions, multiple CPU processes can efficiently utilize PPU resources."
11580395,"A latent code defined in an input space is processed by the mapping neural network to produce an intermediate latent code defined in an intermediate latent space. The intermediate latent code may be used as appearance vector that is processed by the synthesis neural network to generate an image. The appearance vector is a compressed encoding of data, such as video frames including a person's face, audio, and other data. Captured images may be converted into appearance vectors at a local device and transmitted to a remote device using much less bandwidth compared with transmitting the captured images. A synthesis neural network at the remote device reconstructs the images for display."
11582297,"Methods, systems, and devices are provided herein for a mechanism to identify link down reasons. As described herein, a first port of a first peer device may be determined to have unexpectedly changed to a port down state. Subsequently, a topology file may be referenced to identify a second port of a second peer device with which the first peer device is intended to have a link if not for the first port being in a port down state. In some examples, port settings of the first port may be compared with port settings of the second port. If a port setting for the first port mismatches an associated port setting for the second port, an alert message may be transmitted to a network administrator indicating this mismatch as a possible reason for the first port being in the port down state."
11582431,"Apparatuses, systems, and techniques to receive, at one or more processor associated with an image signal processing (ISP) pipeline, a compressed image generated by an image sensor, wherein the compressed image is captured at a first bit-depth associated with the image sensor and is compressed to a second bit-depth that is lower than the first bit-depth, and wherein the ISP is associated with a third bit-depth that is lower than the first bit-depth and higher than the second bit-depth; and decompress the compressed image according to a power curve to generate a partially decompressed image having the third bit-depth, wherein a plurality of regions of the partially decompressed image are decompressed at separate decompression amounts based on a corresponding pixel value of each region of the plurality of regions."
11588608,"A device includes a transmitter to transmit serialized data within a differential direct-current (DC) signal over a differential output line, a multiplexer circuit coupled to the transmitter, and a calibration circuit coupled between the differential output line, a multi-phase clock, and the multiplexer circuit. The multiplexer circuit is to select the serialized data from ones of multiple input lines according to a multi-phase clock and pass the selected serialized data to the transmitter. The serialized data includes a calibration bit pattern. The calibration circuit is to capture and digitize the differential DC signal into a digital stream, measure an error value from the digital stream that is associated with distortion based on the calibration bit pattern, convert the error value into a gradient value, and correct one or more phases of the multi-phase clock to compensate for the distortion based on the gradient value."
11590929,"Systems and methods are disclosed herein for implementation of a vehicle command operation system that may use multi-modal technology to authenticate an occupant of the vehicle to authorize a command and receive natural language commands for vehicular operations. The system may utilize sensors to receive data indicative of a voice command from an occupant of the vehicle. The system may receive second sensor data to aid in the determination of the corresponding vehicular operation in response to the received command. The system may retrieve authentication data for the occupants of the vehicle. The system authenticates the occupant to authorize a vehicular operation command using a neural network based on at least one of the first sensor data, the second sensor data, and the authentication data. Responsive to the authentication, the system may authorize the operation to be performed in the vehicle based on the vehicular operation command."
11590989,"According to an aspect of an embodiment, operations may comprise receiving a plurality of frame sets generated while navigating a local environment, receiving an occupancy map (OMap) representation of the local environment, for each of the plurality of frame sets, generating, using the OMap representation, one or more instances each comprising a spatial cluster of neighborhood 3D points generated from a 3D sensor scan of the local environment, and classifying each of the instances as dynamic or static, tracking instances classified as dynamic across the plurality of frame sets using a tracking algorithm, assigning a single instance ID to tracked instances classified as dynamic across the plurality of frame sets, estimating a bounding box for each of the instances in each of the plurality of frame sets, and employing the instances as ground truth data in a training of one or more deep learning classifiers."
11592828,"In various examples, motifs, watermarks, and/or signature inputs are applied to a deep neural network (DNN) to detect faults in underlying hardware and/or software executing the DNN. Information corresponding to the motifs, watermarks, and/or signatures may be compared to the outputs of the DNN generated using the motifs, watermarks and/or signatures. When a the accuracy of the predictions are below a threshold, or do not correspond to the expected predictions of the DNN, the hardware and/or software may be determined to have a fault—such as a transient, an intermittent, or a permanent fault. Where a fault is determined, portions of the system that rely on the computations of the DNN may be shut down, or redundant systems may be used in place of the primary system. Where no fault is determined, the computations of the DNN may be relied upon by the system."
11593001,"A VPU and associated components include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators are used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer is included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU executes a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
11593290,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
11593344,"A computer-implemented method may include monitoring an age of a tile of a map, where the map includes multiple tiles including the tile. The method may also include, based on the age exceeding a threshold age, determining that the tile of the map is to be updated, and receiving a location indicator from a vehicle. The method may additionally include transmitting an update message to a vehicle traversing a track within the tile as indicated by the location indicator, where the update message includes instructions to cause the vehicle to gather and submit sensor data to a computing system. The method may also include receiving the sensor data from the vehicle, and updating the tile of the map based on the received sensor data."
11593661,"A neural network is trained to identify one or more features of an image. The neural network is trained using a small number of original images, from which a plurality of additional images are derived. The additional images generated by rotating and decoding embeddings of the image in a latent space generated by an autoencoder. The images generated by the rotation and decoding exhibit changes to a feature that is in proportion to the amount of rotation."
11593988,"In various examples, transmittance may be computed using a power-series expansion of an exponential integral of a density function. A term of the power-series expansion may be evaluated as a combination of values of the term for different orderings of samples in the power-series expansion. A sample may be computed from a combination of values at spaced intervals along the function and a discontinuity may be compensated for based at least on determining a version of the function that includes an alignment of a first point with a second point of the function. Rather than arbitrarily or manually selecting a pivot used to expand the power-series, the pivot may be computed as an average of values of the function. The transmittance estimation may be computed from the power-series expansion using a value used to compute the pivot (for a biased estimate) or using all different values (for an unbiased estimate)."
11594006,"There are numerous features in video that can be detected using computer-based systems, such as objects and/or motion. The detection of these features, and in particular the detection of motion, has many useful applications, such as action recognition, activity detection, object tracking, etc. The present disclosure provides a neural network that learns motion from unlabeled video frames. In particular, the neural network uses the unlabeled video frames to perform self-supervised hierarchical motion learning. The present disclosure also describes how the learned motion can be used in video action recognition."
11594014,"According to an aspect of an embodiment, operations may comprise obtaining a first point cloud that includes a first point. The operations also comprises obtaining a second point cloud that is a copy of the first point cloud and that includes a second point that is a copy of the first point. The operations also comprises moving the second point cloud with respect to the first point cloud according to a first vector. The operations also comprises identifying a closest point of the first point cloud that is closest to the second point of the second point cloud. The operations also comprises determining a second vector between the closest point and the second point. The operations also comprises determining a measure of usefulness of the first point based on the first vector and the second vector. The operations also comprises indicating the measure of usefulness of the first point."
11594962,"This disclosure relates to current flattening circuits for an electrical load. The current flattening circuits incorporate randomize various parameters to add noise onto the supply current. This added noise may act to reduce the signal to noise ratio in the supply current, increasing the difficulty of identifying a computational artifact signal from power rail noise."
11595152,"Embodiments of the present disclosure relate to a binary clustered forward error correction encoding scheme. Systems and methods are disclosed that define binary clustered encodings of the media packets from which forward error correction (FEC) packets are computed. The different encodings specify which media packets in a frame are used to compute each FEC packet (a frame includes M media packets). The different encodings may be defined based on the quantity of media packets in a frame, M≤floor(2N), where each bit of the binary representation of N is associated with a different cluster pair encoding of the media packets. Each cluster pair includes a cluster for which the bit=0 and a cluster for which the bit=1. Computing FEC packets using at least two cluster pair encodings provides redundancy for each media packet, thereby improving media packet recovery rates."
11597078,"A robotic control system directs a robot to take an object from a human grasp by obtaining an image of a human hand holding an object, estimating the pose of the human hand and the object, and determining a grasp pose for the robot that will not interfere with the human hand. In at least one example, a depth camera is used to obtain a point cloud of the human hand holding the object. The point cloud is provided to a deep network that is trained to generate a grasp pose for a robotic gripper that can take the object from the human's hand without pinching or touching the human's fingers."
11598876,"According to an aspect of an embodiment, operations may comprise receiving, from a LIDAR mounted on a vehicle, a first 3D point cloud comprising points of a region around the vehicle as observed by the LIDAR. The operations may also comprise accessing an HD map comprising a second 3D point cloud comprising points of the region around the vehicle. The operations may also comprise segmenting LIDAR ground points from LIDAR non-ground points in the first 3D point cloud. The operations may also comprise segmenting map ground points from map non-ground points in the second 3D point cloud. The operations may also comprise determining a pose of the vehicle by matching the LIDAR ground points to the map ground points and by matching the LIDAR non-ground points to the map non-ground points."
11600036,"In examples, a filter used to denoise shadows for a pixel(s) may be adapted based at least on variance in temporally accumulated ray-traced samples. A range of filter values for a spatiotemporal filter may be defined based on the variance and used to exclude temporal ray-traced samples that are outside of the range. Data used to compute a first moment of a distribution used to compute variance may be used to compute a second moment of the distribution. For binary signals, such as visibility, the first moment (e.g., accumulated mean) may be equivalent to a second moment (e.g., the mean squared). In further respects, spatial filtering of a pixel(s) may be skipped based on comparing the mean of variance of the pixel(s) to one or more thresholds and based on the accumulated number of values for the pixel."
11600554,A device including a stack of dies. Each of the dies can have unit stair-step conductive paths of connection features which include through-die via structures and routing structures. The unit stair-step conductive paths of one of the dies can be interconnected to another one of the unit stair-step conductive paths of another one of the dies to form one of a plurality conductive stair-case structures through two or more of the dies. The unit stair-step conductive paths can be connected to reduce signal cross talk between the conductive stair-case structures whereby at least some of the conductive stair-case structures are connected to transmit a same polarity of electrical signals are spatially separated in a dimension that is perpendicular to a major surface of the dies. A method of manufacturing the device is also disclosed.
11604470,"In various examples, a current claimed set of points representative of a volume in an environment occupied by a vehicle at a time may be determined. A vehicle-occupied trajectory and at least one object-occupied trajectory may be generated at the time. An intersection between the vehicle-occupied trajectory and an object-occupied trajectory may be determined based at least in part on comparing the vehicle-occupied trajectory to the object-occupied trajectory. Based on the intersection, the vehicle may then execute the first safety procedure or an alternative procedure that, when implemented by the vehicle when the object implements the second safety procedure, is determined to have a lesser likelihood of incurring a collision between the vehicle and the object than the first safety procedure."
11604649,"A technique for block data transfer is disclosed that reduces data transfer and memory access overheads and significantly reduces multiprocessor activity and energy consumption. Threads executing on a multiprocessor needing data stored in global memory can request and store the needed data in on-chip shared memory, which can be accessed by the threads multiple times. The data can be loaded from global memory and stored in shared memory using an instruction which directs the data into the shared memory without storing the data in registers and/or cache memory of the multiprocessor during the data transfer."
11604654,Described approaches provide for effectively and scalably using multiple GPUs to build and probe hash tables and materialize results of probes. Random memory accesses by the GPUs to build and/or probe a hash table may be distributed across GPUs and executed concurrently using global location identifiers. A global location identifier may be computed from data of an entry and identify a global location for an insertion and/or probe using the entry. The global location identifier may be used by a GPU to determine whether to perform an insertion or probe using an entry and/or where the insertion or probe is to be performed. To coordinate GPUs in materializing results of probing a hash table a global offset to the global output buffer may be maintained in memory accessible to each of the GPUs or the GPUs may compute global offsets using an exclusive sum of the local output buffer sizes.
11604944,"In various examples, systems and methods are disclosed that preserve rich spatial information from an input resolution of a machine learning model to regress on lines in an input image. The machine learning model may be trained to predict, in deployment, distances for each pixel of the input image at an input resolution to a line pixel determined to correspond to a line in the input image. The machine learning model may further be trained to predict angles and label classes of the line. An embedding algorithm may be used to train the machine learning model to predict clusters of line pixels that each correspond to a respective line in the input image. In deployment, the predictions of the machine learning model may be used as an aid for understanding the surrounding environment—e.g., for updating a world model—in a variety of autonomous machine applications."
11604967,"Various examples of the present disclosure include a stereoscopic deep neural network (DNN) that produces accurate and reliable results in real-time. Both LIDAR data (supervised training) and photometric error (unsupervised training) may be used to train the DNN in a semi-supervised manner. The stereoscopic DNN may use an exponential linear unit (ELU) activation function to increase processing speeds, as well as a machine learned argmax function that may include a plurality of convolutional layers having trainable parameters to account for context. The stereoscopic DNN may further include layers having an encoder/decoder architecture, where the encoder portion of the layers may include a combination of three-dimensional convolutional layers followed by two-dimensional convolutional layers."
11605001,"A style-based generative network architecture enables scale-specific control of synthesized output data, such as images. During training, the style-based generative neural network (generator neural network) includes a mapping network and a synthesis network. During prediction, the mapping network may be omitted, replicated, or evaluated several times. The synthesis network may be used to generate highly varied, high-quality output data with a wide variety of attributes. For example, when used to generate images of people's faces, the attributes that may vary are age, ethnicity, camera viewpoint, pose, face shape, eyeglasses, colors (eyes, hair, etc.), hair style, lighting, background, etc. Depending on the task, generated output data may include images, audio, video, three-dimensional (3D) objects, text, etc."
11605217,"A style-based generative network architecture enables scale-specific control of synthesized output data, such as images. During training, the style-based generative neural network (generator neural network) includes a mapping network and a synthesis network. During prediction, the mapping network may be omitted, replicated, or evaluated several times. The synthesis network may be used to generate highly varied, high-quality output data with a wide variety of attributes. For example, when used to generate images of people's faces, the attributes that may vary are age, ethnicity, camera viewpoint, pose, face shape, eyeglasses, colors (eyes, hair, etc.), hair style, lighting, background, etc. Depending on the task, generated output data may include images, audio, video, three-dimensional (3D) objects, text, etc."
11605384,"Systems and methods of presenting interrupting content during human speech are disclosed. The proposed systems offer improved duplex communications in conversational AI platforms. In some embodiments, the system receives speech data and evaluates the data using linguistic models. If the linguistic models detect indications of linguistic irregularities such as mispronunciation, a smart feedback assistant can determine that the system should interrupt the speaker in near-real-time and provide feedback regarding their pronunciation. In addition, conversational irregularities may also be detected, causing the smart feedback assistant to interrupt with presentation of moderating guidance. In some cases, emotion models may also be utilized to detect emotional states based on the speaker's voice in order to offer near-immediate feedback. Users can also customize the manner and occasions in which they are interrupted."
11609572,"In various examples, a trigger signal may be received that is indicative of a vehicle maneuver to be performed by a vehicle. A recommended vehicle trajectory for the vehicle maneuver may be determined in response to the trigger signal being received. To determine the recommended vehicle trajectory, sensor data may be received that represents a field of view of at least one sensor of the vehicle. A value of a control input and the sensor data may then be applied to a machine learning model(s) and the machine learning model(s) may compute output data that includes vehicle control data that represents the recommended vehicle trajectory for the vehicle through at least a portion of the vehicle maneuver. The vehicle control data may then be sent to a control component of the vehicle to cause the vehicle to be controlled according to the vehicle control data."
11609761,"A method, computer readable medium, and processor are described herein for inline data inspection by using a decoder to decode a load instruction, including a signal to cause a circuit in a processor to indicate whether data loaded by a load instruction exceeds a threshold value. Moreover, an indication of whether data loaded by a load instruction exceeds a threshold value may be stored."
11609860,"In various embodiments, a computing system includes, for example, a plurality of processing units that share access to a system cache. A cache management application receives, for example, resource savings information for each processing unit. The resource savings information indicates, for example, amounts of a resource (e.g., power) that are saved when different units of the system cache are allocated to a processing unit. The cache management application determines, for example, the number of units of system cache to allocate to each processing unit based on the received resource savings information."
11609879,"In various embodiments, a parallel processor includes a parallel processor module implemented within a first die and a memory system module implemented within a second die. The memory system module is coupled to the parallel processor module via an on-package link. The parallel processor module includes multiple processor cores and multiple cache memories. The memory system module includes a memory controller for accessing a DRAM. Advantageously, the performance of the parallel processor module can be effectively tailored for memory bandwidth demands that typify one or more application domains via the memory system module."
11609899,"Approaches in accordance with various embodiments can perform spatial hash map updates while ensuring the atomicity of the updates for arbitrary data structures. A hash map can be generated for a dataset where entries in the hash map may correspond to multiple independent values, such as pixels of an image to be rendered. Update requests for independent values may be received on multiple concurrent threads, but change requests for independent values corresponding to a hash map entry can be aggregated from a buffer and processed iteratively in a single thread for a given hash map entry. In the case of multi-resolution spatial hashing where data can be stored at various discretization levels, this operation can be repeated to propagate changes from one level to another."
11610115,"In various examples, a generative model is used to synthesize datasets for use in training a downstream machine learning model to perform an associated task. The synthesized datasets may be generated by sampling a scene graph from a scene grammar—such as a probabilistic grammar—and applying the scene graph to the generative model to compute updated scene graphs more representative of object attribute distributions of real-world datasets. The downstream machine learning model may be validated against a real-world validation dataset, and the performance of the model on the real-world validation dataset may be used as an additional factor in further training or fine-tuning the generative model for generating the synthesized datasets specific to the task of the downstream machine learning model."
11610122,"A latent code defined in an input space is processed by the mapping neural network to produce an intermediate latent code defined in an intermediate latent space. The intermediate latent code may be used as appearance vector that is processed by the synthesis neural network to generate an image. The appearance vector is a compressed encoding of data, such as video frames including a person's face, audio, and other data. Captured images may be converted into appearance vectors at a local device and transmitted to a remote device using much less bandwidth compared with transmitting the captured images. A synthesis neural network at the remote device reconstructs the images for display."
11610360,"A real-time neural radiance caching technique for path-traced global illumination is implemented using a neural network for caching scattered radiance components of global illumination. The neural (network) radiance cache handles fully dynamic scenes, and makes no assumptions about the camera, lighting, geometry, and materials. In contrast with conventional caching, the data-driven approach sidesteps many difficulties of caching algorithms, such as locating, interpolating, and updating cache points. The neural radiance cache is trained via online learning during rendering. Advantages of the neural radiance cache are noise reduction and real-time performance. Importantly, the runtime overhead and memory footprint of the neural radiance cache are stable and independent of scene complexity."
11610370,"Systems and methods enable optimization of a 3D model representation comprising the shape and appearance of a particular 3D scene or object. The opaque 3D mesh (e.g., vertex positions and corresponding topology) and spatially varying material attributes are jointly optimized based on image space losses to match multiple image observations (e.g., reference images of the reference 3D scene or object). A geometric topology defines faces and/or cells in the opaque 3D mesh that are visible and may be randomly initialized and optimized through training based on the image space losses. Applying the geometry topology to an opaque 3D mesh for learning the shape improves accuracy of silhouette edges and performance compared with using transparent mesh representations. In contrast with approaches that require an initial guess for the topology and/or an exhaustive testing of possible geometric topologies, the 3D model representation is learned based on image space differences without requiring an initial guess."
11610435,"A latent code defined in an input space is processed by the mapping neural network to produce an intermediate latent code defined in an intermediate latent space. The intermediate latent code may be used as appearance vector that is processed by the synthesis neural network to generate an image. The appearance vector is a compressed encoding of data, such as video frames including a person's face, audio, and other data. Captured images may be converted into appearance vectors at a local device and transmitted to a remote device using much less bandwidth compared with transmitting the captured images. A synthesis neural network at the remote device reconstructs the images for display."
11611458,"A receiver includes a decision feed forward equalization (DFFE) system coupled to a partial response (PR) system. The partial response system generates, based on a digital signal that includes pre-cursor intersymbol interference (ISI) and post-cursor ISI introduced by a communication channel, a detected signal including a set of detected symbol values. The detected signal is equalized to a partial response. The DFFE system includes a PR inverter to generate a set of estimated transmitted symbol values based on the set of detected symbol values and DFFE circuitry to cancel the pre-cursor ISI and the post-cursor ISI from the detected signal using the set of estimated transmitted symbols and a set of tap coefficients to obtain a compensated signal and a set of compensated symbol values."
11613201,"In various examples, high beam control for vehicles may be automated using a deep neural network (DNN) that processes sensor data received from vehicle sensors. The DNN may process the sensor data to output pixel-level semantic segmentation masks in order to differentiate actionable objects (e.g., vehicles with front or back lights lit, bicyclists, or pedestrians) from other objects (e.g., parked vehicles). Resulting segmentation masks output by the DNN(s), when combined with one or more post processing steps, may be used to generate masks for automated high beam on/off activation and/or dimming or shading—thereby providing additional illumination of an environment for the driver while controlling downstream effects of high beam glare for active vehicles."
11615602,"Appearance driven automatic three-dimensional (3D) modeling enables optimization of a 3D model comprising the shape and appearance of a particular 3D scene or object. Triangle meshes and shading models may be jointly optimized to match the appearance of a reference 3D model based on reference images of the reference 3D model. Compared with the reference 3D model, the optimized 3D model is a lower resolution 3D model that can be rendered in less time. More specifically, the optimized 3D model may include fewer geometric primitives compared with the reference 3D model. In contrast with the conventional inverse rendering or analysis-by-synthesis modeling tools, the shape and appearance representations of the 3D model are automatically generated that, when rendered, match the reference images. Appearance driven automatic 3D modeling has a number of uses, including appearance-preserving simplification of extremely complex assets, conversion between rendering systems, and even conversion between geometric scene representations."
11616019,"A semiconductor assembly is described that includes a substrate having top and bottom sides. An integrated circuit die coupled to the substrate includes first and second distinct sets of ground pads. In some embodiments, the first and second sets of ground pads are configured to have distinct ground return paths to a host system. In further embodiments, one of the ground return paths may include a metal plate coupled between ground contacts on the top side of the substrate and ground contacts on a printed circuit board of the host system."
11616023,"In accordance with the disclosure, an inductor may be formed over a semiconductor substrate of one or both dies in a face-to-face die arrangement while reducing the parasitic capacitance between the inductor and the adjacent die. In disclosed embodiments, a semiconductor device may include a void (e.g., an air gap) between the inductor and the adjacent die to reduce the parasitic capacitance between the inductor and the adjacent die. The void may be formed in the die that includes the inductor and/or the adjacent die. In some respects, the void may be etched in interface layers (e.g., comprising bump pads and dielectric material) between the semiconductor dies, and may extend along the length of the inductor."
11617951,"A game summary may be produced using an event log of in-game events and corresponding game content based on game data associated with a gameplay session(s). The event log may include metadata that indicates times of in-game events and associations between in-game events and game content items that capture the in-game events. A user may interact with in-game events with temporal context, allowing for more informed selections and a better understanding of the gameplay session. Using the event log, a game summary may provide such features as a timeline to convey relative timing of in-game events, a list of in-game events, a map of a virtual environment of the game that is temporally annotated based on in-game events, game status information, and statistical and performance information. A game summary may show trends over time and/or game sessions and convey information for selected sets of players, such as teams."
11619661,"In various embodiments, a current measurement circuit measures an input current within an integrated circuit. The current measurement circuit includes an integration capacitor, an operational amplifier, a comparison capacitor, an inverter, and multiple switches. The current measurement circuit is coupled to a clocking circuit that, during operation, generates a two-phase clock having a frequency that is proportional to the input current. At least a portion of the switches are turned on during a first phase of the two-phase clock and are turned off during a second phase of the two-phase clock."
11619724,"According to an aspect of an embodiment, operations may comprise (a) accessing a portion of a high definition (HD) map comprising a point cloud of a region through which a vehicle is driving, (b) identifying a base LIDAR from a plurality of LIDARs mounted on the vehicle, (c) for each of the LIDARs: receiving a LIDAR scan comprising a point cloud of the region, and determining a pose for the LIDAR, (d) for each LIDAR other than the base LIDAR, determining a transform for the LIDAR with respect to the base LIDAR, (e) repeating (c) to generate a plurality of samples, (f) for each of the samples, repeating (d) to determine a plurality of transforms for each LIDAR with respect to the base LIDAR, and (g) calibrating each of the LIDARs other than the base LIDAR by determining an aggregate transform for the LIDAR."
11620169,"When communicating through shared memory, a producer thread generates a value that is written to a location in a shared memory. The value is read from the shared memory by a consumer thread. The challenge is to ensure that the consumer thread reads the location only after the value is written and is thereby synchronized. When a memory location is written by a producer thread, a flag that is simultaneously stored in the memory location along with the value is toggled. The consumer thread tracks information to determine whether the flag stored in the location indicates whether the producer has written the value to the location. The flag is read and written simultaneously with reading and writing the location in memory, thereby eliminating the need for a memory fence. After all of the consumer threads read the value, the location may be reused to write additional value(s) and simultaneously toggle the flag."
11620521,"A style-based generative network architecture enables scale-specific control of synthesized output data, such as images. During training, the style-based generative neural network (generator neural network) includes a mapping network and a synthesis network. During prediction, the mapping network may be omitted, replicated, or evaluated several times. The synthesis network may be used to generate highly varied, high-quality output data with a wide variety of attributes. For example, when used to generate images of people's faces, the attributes that may vary are age, ethnicity, camera viewpoint, pose, face shape, eyeglasses, colors (eyes, hair, etc.), hair style, lighting, background, etc. Depending on the task, generated output data may include images, audio, video, three-dimensional (3D) objects, text, etc."
11625225,"Various embodiments include a modulo operation generator associated with a cache memory in a computer-based system. The modulo operation generator generates a first sum by performing an addition and/or a subtraction function on an input address. A first portion of the first sum is applied to a lookup table that generates a correction value. The correction value is then added to a second portion of the first sum to generate a second sum. The second sum is adjusted, as needed, to be less than the divisor. The adjusted second sum forms a residue value that identifies a cache memory slice in which the input data value corresponding to the input address is stored. By generating the residue value in this manner, the cache memory efficiently distributes input data values among the slices in a cache memory even when the number of slices is not a power of two."
11625279,"In general, an application executes on a compute unit, such as a central processing unit (CPU) or graphics processing unit (GPU), to perform some function(s). In some circumstances, improved performance of an application, such as a graphics application, may be provided by executing the application across multiple compute units. However, when using multiple compute units in this manner, synchronization must be provided between the compute units. Synchronization, including the sharing of the data, is typically accomplished through memory. While a shared memory may cause bottlenecks, employing local memory for each compute unit may itself require synchronization (coherence) which can be costly in terms of resources, delay, etc. The present disclosure provides read-write page replication for multiple compute units that avoids the traditional challenges associated with coherence."
11625605,"Apparatuses, systems, and techniques to optimize kernel selection for performing a computation. In at least one embodiment, a neural network is trained and utilized to generate a list of kernels so that an (e.g., optimal) kernel may be identified. The neural network receives characteristics of the input matrices and determines relevancy scores for a list of possible kernels. Based on an ordered listing of kernels by relevant score, a kernel is selected from the list and utilized to perform the computation and provide the result."
11625613,"A latent code defined in an input space is processed by the mapping neural network to produce an intermediate latent code defined in an intermediate latent space. The intermediate latent code may be used as appearance vector that is processed by the synthesis neural network to generate an image. The appearance vector is a compressed encoding of data, such as video frames including a person's face, audio, and other data. Captured images may be converted into appearance vectors at a local device and transmitted to a remote device using much less bandwidth compared with transmitting the captured images. A synthesis neural network at the remote device reconstructs the images for display."
11625894,"Multiple snapshots of a scene are captured within an executing application (e.g., a video game). When each snapshot is captured, associated color values per pixel and a distance or depth value z per pixel are stored. The depth information from the snapshots is accessed, and a point cloud representing the depth information is constructed. A mesh structure is constructed from the point cloud. The light field(s) on the surface(s) of the mesh structure are calculated. A surface light field is represented as a texture. A renderer uses the surface light field with geometry information to reproduce the scene captured in the snapshots. The reproduced scene can be manipulated and viewed from different perspectives."
11630312,"An augmented reality display system includes a first beam path for a foveal inset image on a holographic optical element, a second beam path for a peripheral display image on the holographic optical element, and pupil position tracking logic that generates control signals to set a position of the foveal inset as perceived through the holographic optical element, to determine the peripheral display image, and to control a moveable stage."
11630653,"A computation graph is accessed. In the computation graph, operations to be performed are represented as interior nodes, inputs to the operations are represented as leaf nodes, and a result of the operations is represented as a root. Selected sets of the operations are combined to form respective kernels of operations. Code is generated execute the kernels of operations. The code is executed to determine the result."
11630800,"In one embodiment of the present invention, a programmable vision accelerator enables applications to collapse multi-dimensional loops into one dimensional loops. In general, configurable components included in the programmable vision accelerator work together to facilitate such loop collapsing. The configurable elements include multi-dimensional address generators, vector units, and load/store units. Each multi-dimensional address generator generates a different address pattern. Each address pattern represents an overall addressing sequence associated with an object accessed within the collapsed loop. The vector units and the load store units provide execution functionality typically associated with multi-dimensional loops based on the address pattern. Advantageously, collapsing multi-dimensional loops in a flexible manner dramatically reduces the overhead associated with implementing a wide range of computer vision algorithms. Consequently, the overall performance of many computer vision applications may be optimized."
11631210,"A fully-connected neural network may be configured for execution by a processor as a fully-fused neural network by limiting slow global memory accesses to reading and writing inputs to and outputs from the fully-connected neural network. The computational cost of fully-connected neural networks scale quadratically with its width, whereas its memory traffic scales linearly. Modern graphics processing units typically have much greater computational throughput compared with memory bandwidth, so that for narrow, fully-connected neural networks, the linear memory traffic is the bottleneck. The key to improving performance of the fully-connected neural network is to minimize traffic to slow “global” memory (off-chip memory and high-level caches) and to fully utilize fast on-chip memory (low-level caches, “shared” memory, and registers), which is achieved by the fully-fused approach. A real-time neural radiance caching technique for path-traced global illumination is implemented using the fully-fused neural network for caching scattered radiance components of global illumination."
11631239,"Iterative prediction systems and methods for the task of action detection process an inputted sequence of video frames to generate an output of both action tubes and respective action labels, wherein the action tubes comprise a sequence of bounding boxes on each video frame. An iterative predictor processes large offsets between the bounding boxes and the ground-truth."
11632275,"A transceiver circuit includes a receiver front end utilizing a ring oscillator, and a transmitter front end utilizing a pass-gate circuit in a first feedback path across a last-stage driver circuit. The transceiver circuit provides low impedance at low frequency and high impedance at high frequency, and desirable peaking behavior."
11634149,"In a self-driving autonomous vehicle, a controller architecture includes multiple processors within the same box. Each processor monitors the others and takes appropriate safe action when needed. Some processors may run dormant or low priority redundant functions that become active when another processor is detected to have failed. The processors are independently powered and independently execute redundant algorithms from sensor data processing to actuation commands using different hardware capabilities (GPUs, processing cores, different input signals, etc.). Intentional hardware and software diversity improves fault tolerance. The resulting fault-tolerant/fail-operational system meets ISO26262 ASIL-D specifications based on a single electronic controller unit platform that can be used for self-driving vehicles."
11635623,The computational scaling challenges of holographic displays are mitigated by techniques for generating holograms that introduce foveation into a wave front recording planes approach to hologram generation. Spatial hashing is applied to organize the points or polygons of a display object into keys and values.
11635986,"A parallel processing unit (PPU) can be divided into partitions. Each partition is configured to operate similarly to how the entire PPU operates. A given partition includes a subset of the computational and memory resources associated with the entire PPU. Software that executes on a CPU partitions the PPU for an admin user. A guest user is assigned to a partition and can perform processing tasks within that partition in isolation from any other guest users assigned to any other partitions. Because the PPU can be divided into isolated partitions, multiple CPU processes can efficiently utilize PPU resources."
11636063,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
11636609,"Machine learning systems and methods that determine gaze direction by using face orientation information, such as facial landmarks, to modify eye direction information determined from images of the subject's eyes. System inputs include eye crops of the eyes of the subject, as well as face orientation information such as facial landmarks of the subject's face in the input image. Facial orientation information, or facial landmark information, is used to determine a coarse prediction of gaze direction as well as to learn a context vector of features describing subject face pose. The context vector is then used to adaptively re-weight the eye direction features determined from the eye crops. The re-weighted features are then combined with the coarse gaze prediction to determine gaze direction."
11636668,"A method includes filtering a point cloud transformation of a 3D object to generate a 3D lattice and processing the 3D lattice through a series of bilateral convolution networks (BCL), each BCL in the series having a lower lattice feature scale than a preceding BCL in the series. The output of each BCL in the series is concatenated to generate an intermediate 3D lattice. Further filtering of the intermediate 3D lattice generates a first prediction of features of the 3D object."
11636689,"In various examples, lane location criteria and object class criteria may be used to determine a set of objects in an environment to track. For example, lane information, freespace information, and/or object detection information may be used to filter out or discard non-essential objects (e.g., objects that are not in an ego-lane or adjacent lanes) from objects detected using an object detection algorithm. Further, objects corresponding to non-essential object classes may be filtered out to generate a final filtered set of objects to be tracked that may be of a lower quantity than the actual number of detected objects. As a result, object tracking may only be executed on the final filtered set of objects, thereby decreasing compute requirements and runtime of the system without sacrificing object tracking accuracy and reliability with respect to more pertinent objects."
11636814,"A display device includes an array of LEDs, an array of LCD pixels, and a display controller. The display controller is configured to compensate for one or more sources of color variation in light produced by the LEDs. The display controller can determine a first color variation at a given LCD pixel based on the distance between the given LCD pixel and one or more LEDs. The display controller can also determine a second color variation at the given LCD pixel based on a current level supplied to the one or more LEDs. The display controller configures the given LCD pixel to filter light that is received from the one or more LEDs in a manner that reduces or eliminates either or both of the first and second color variations."
11637998,"Apparatuses, systems, and techniques to receive, at one or more processors associated with an image signal processing (ISP) pipeline for a camera, an image generated using an image sensor of the camera, wherein the image comprises a plurality of channels associated with color information of the image; process, by the one or more processors, the plurality of channels of the image to generate a plurality of luminance and/or radiance values; generate, by the one or more processors, an updated version of the image using the plurality of luminance and/or radiance values; and output the updated version of the image."
11638028,A method dynamically selects one of a first sampling order and a second sampling order for a ray trace of pixels in a tile where the selection is based on a motion vector for the tile. The sampling order may be a bowtie pattern or an hourglass pattern.
11644834,"Autonomous driving is one of the world's most challenging computational problems. Very large amounts of data from cameras, RADARs, LIDARs, and HD-Maps must be processed to generate commands to control the car safely and comfortably in real-time. This challenging task requires a dedicated supercomputer that is energy-efficient and low-power, complex high-performance software, and breakthroughs in deep learning AI algorithms. To meet this task, the present technology provides advanced systems and methods that facilitate autonomous driving functionality, including a platform for autonomous driving Levels 3, 4, and/or 5. In preferred embodiments, the technology provides an end-to-end platform with a flexible architecture, including an architecture for autonomous vehicles that leverages computer vision and known ADAS techniques, providing diversity and redundancy, and meeting functional safety standards. The technology provides for a faster, more reliable, safer, energy-efficient and space-efficient System-on-a-Chip, which may be integrated into a flexible, expandable platform that enables a wide-range of autonomous vehicles, including cars, taxis, trucks, and buses, as well as watercraft and aircraft."
11645492,"Apparatuses, systems, and techniques to infer a sequence of actions to perform using one or more neural networks trained, at least in part, by optimizing a probability distribution function using a cost function, wherein the probability distribution represents different sequences of actions that can be performed. In at least one embodiment, a model predictive control problem is formulated as a Bayesian inference task to infer a set of solutions."
11645530,"A method, computer readable medium, and system are disclosed for visual sequence learning using neural networks. The method includes the steps of replacing a non-recurrent layer within a trained convolutional neural network model with a recurrent layer to produce a visual sequence learning neural network model and transforming feedforward weights for the non-recurrent layer into input-to-hidden weights of the recurrent layer to produce a transformed recurrent layer. The method also includes the steps of setting hidden-to-hidden weights of the recurrent layer to initial values and processing video image data by the visual sequence learning neural network model to generate classification or regression output data."
11645533,"IR drop predictions are obtained using a maximum convolutional neural network. A circuit structure is partitioned into a grid. For cells of the circuit structure in sub-intervals of a clock period, power consumption of the cell is amortized into a set of grid tiles that include portions of the cell, thus forming a set of power maps. The power maps are applied to a neural network to generate IR drop predictions for the circuit structure."
11645810,"A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include opaque and alpha triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to determine primitives intersected by the ray, and return intersection information to a streaming multiprocessor for further processing. The hardware-based traversal coprocessor is configured to omit reporting of one or more primitives the ray is determined to intersect. The omitted primitives include primitives which are provably capable of being omitted without a functional impact on visualizing the virtual scene."
11646240,"Through-hole mounted semiconductor assemblies are described. A printed circuit board (“PCB”) has first and second PCB sides and has a through hole therein. The through hole defines a hole area. A semiconductor package may be disposed in the hole area such that the semiconductor package is at least partially exposed on one or more of the first and the second PCB sides. Package contacts on the semiconductor package may be electrically coupled to PCB contacts disposed on one or more of the PCB sides. In some embodiments, one or more support structures may be coupled to the PCB and may touch the semiconductor package. In some embodiments, cooling devices may be placed in thermal communication with the semiconductor package on both sides of the PCB."
11646742,"A phase-locked loop (PLL) device includes a first phase detector to receive an in-phase reference clock and an in-phase feedback clock, the first phase detector to output a first phase error; a second phase detector to receive a quadrature reference clock and a quadrature feedback clock, the second phase detector to output a second phase error; a proportional path component to generate first current pulses from the first phase error and second current pulses from the second phase error; an integrator circuit coupled to the proportional path component, the integrator circuit to sum, within a current output signal, the first current pulses and the second current pulses; a ring oscillator to be driven by the current output signal; and a pair of phase interpolators coupled to an output of the ring oscillator, the pair of phase interpolators to respectively generate the in-phase feedback clock and the quadrature feedback clock."
11646863,"A receiving link device includes a receiver (RX) to receive a data signal from a transmitting link device, the receiver including an equalizer to detect RX tap values and a processing device coupled to the receiver, the processing device to perform operations including: programming the receiver with information related to target RX tap values that are associated RX pre-cursors or RX post-cursors; detecting, using the equalizer, that an RX pre-cursor value is greater or less than a target RX tap value; generating, based on the detecting, a tap message including an up or a down command to decrease or increase a corresponding transmitter (TX) pre-cursor value of the transmitting link device; and causing the tap message to be provided to a local transmitter to be transmitted to a remote receiver of the transmitting link device, which causes the transmitting link device to adjust the corresponding TX pre-cursor value."
11647227,"Disclosed approaches may provide for non-blocking video processing pipelines that have the ability to efficiently share transform hardware resources. Transform hardware resources may be shared across processing parameters, such as pixel block dimensions, transform types, video stream bit depths, and/or multiple coding formats, as well as for inter-frame and intra-frame encoding. The video processing pipeline may be divided into phases, each phase having half-butterfly circuits to perform a respective portion of computations of a transform. The phases may be selectable and configurable to perform transforms for multiple different combinations of the processing parameters. In each configuration, the phases may be capable of performing a transform by a sequential pass through at least some of the phases resulting in high throughput. Approaches are also described related to improving the performance and efficiency of transpose operations of transforms."
11648481,"Automated detection of events in content can be performed using regions of information associated with various user interface or display elements. Certain elements can be indicative of a type of event, and regions associated with these elements can be analyzed on a per-frame basis. If one of these primary regions shows a state or transition that is indicative of one of these events, one or more secondary regions can be analyzed as well to attempt to verify whether that event occurred, as well as whether that event qualifies for selection for additional use. Selected events can be used for purposes such as to generate highlight montages, training videos, or user profiles. These events may be positioned at different layers of an event hierarchy, where child regions are only analyzed for frames where a parent region is indicative of a type of event."
11648945,"In various examples, live perception from sensors of a vehicle may be leveraged to detect and classify intersections in an environment of a vehicle in real-time or near real-time. For example, a deep neural network (DNN) may be trained to compute various outputs—such as bounding box coordinates for intersections, intersection coverage maps corresponding to the bounding boxes, intersection attributes, distances to intersections, and/or distance coverage maps associated with the intersections. The outputs may be decoded and/or post-processed to determine final locations of, distances to, and/or attributes of the detected intersections."
11651194,A graph neural network to predict net parasitics and device parameters by transforming circuit schematics into heterogeneous graphs and performing predictions on the graphs. The system may achieve an improved prediction rate and reduce simulation errors.
11651215,"In various examples, one or more deep neural networks (DNNs) are executed to regress on control points of a curve, and the control points may be used to perform a curve fitting operation—e.g., Bezier curve fitting—to identify landmark locations and geometries in an environment. The outputs of the DNN(s) may thus indicate the two-dimensional (2D) image-space and/or three-dimensional (3D) world-space control point locations, and post-processing techniques—such as clustering and temporal smoothing—may be executed to determine landmark locations and poses with precision and in real-time. As a result, reconstructed curves corresponding to the landmarks—e.g., lane line, road boundary line, crosswalk, pole, text, etc.—may be used by a vehicle to perform one or more operations for navigating an environment."
11651520,"The disclosure provides computer systems for processing paths and a renderer that generates a stroked tessellation of a path. A data structure for processing the paths can be used, wherein the data structure is an array of indexed links that compactly encode a path. The position of one or more index values, such as a null index value, within an indexed link can encode a link's type. In one example, the computer system for processing links of a path includes one or more processing units to perform one or more operations including: (1) analyzing a data structure that encodes a link of a path, the data structure having multiple indices that refer to a control point coordinate array corresponding to the link, and (2) determining a type of the link based on a presence of at least one index null value for at least one of the indices."
11651547,"Robust temporal gradients, representing differences in shading results, can be computed between current and previous frames in a temporal denoiser for ray-traced renderers. Backward projection can be used to locate matching surfaces, with the relevant parameters of those surfaces being carried forward and used for patching. Backward projection can be performed for each stratum in a current frame, a stratum representing a set of adjacent pixels. A pixel from each stratum is selected that has a matching surface in the previous frame, using motion vectors generated during the rendering process. A comparison of the depth of the normals, or the visibility buffer data, can be used to determine whether a given surface is the same in the current frame and the previous frame, and if so then parameters of the surface from the previous frame G-buffer is used to patch the G-buffer for the current frame."
11652827,"Various approaches are disclosed to virtualizing intrusion detection and prevention. Disclosed approaches provide for an embedded system having a hypervisor that provides a virtualized environment supporting any number of guest OSes. The virtualized environment may include a security engine on an internal communication channel between the guest OS and a virtualized hardware interface (e.g., an Ethernet or CAN interface) to analyze network traffic to protect the guest OS from other guest OSes or other network components, and to protect those network components from the guest OS. The security engine may be on a different partition than the guest OS and the virtualized hardware interface providing the components with isolated execution environments that protect against malicious code execution. Each guest OS may have its own security engine customized for the guest OS to account for what is typical or expected traffic for the guest OS."
11652982,"In one embodiment, a system receives pixel data from a pair of regions of an image generated by an imaging device, the pair of regions includes a first region and a second region, where the first region includes a first plurality of pixels and the second region includes a second plurality of pixels. The system determines a plurality of pixel pairs, where a pixel pair includes a first pixel from the first plurality of pixels and a second pixel from the second plurality of pixels. The system calculates a plurality of contrasts based on the plurality of pixel pairs. The system determines a contrast distribution based on the plurality of contrasts. The system calculates a value representative of a capability of the imaging device to detect contrast based on the contrast distribution. The system determines a reduction in contrast detectability of the imaging device based on the value."
11653455,"A method for forming a printed circuit board includes: forming on a substrate a first conductive layer for a first edge connector pin and a first conductive layer for a second edge connector pin, wherein the first conductive layer for the first edge connector pin and the first conductive layer for the second edge connector pin are electrically coupled to one another via a first conductive layer for an electrical bridging element; electroplating a second conductive layer onto both the first conductive layer for the first edge connector pin and the first conductive layer for the second edge connector pin via a plating current conductor; and removing at least a portion of the electrical bridging element to electrically separate the first edge connector pin from the second edge connector pin."
11656277,"Methods and structures are described for detecting clock anomalies. Example methods include measuring a duration of a first phase of the clock signal, monitoring a duration of a second phase of the clock signal, and determining whether the duration of the second phase has exceeded the measured duration of the first phase. If so, a clock stop detection signal is asserted. Example structures include a detector circuit having an input for sensing the clock signal. The circuit is operable to measure a duration of a first clock phase instance, to monitor a duration of a second clock phase instance, and to assert an output if the duration of the second clock phase instance exceeds the measured duration of the first clock phase instance."
11656665,"Systems and methods for operating a datacenter are disclosed. In at least one embodiment, hybrid cooling unit is disclosed wherein an evaporative cooler is to provide a source of cooled air and a liquid heat exchanger is to provide a source of cooled liquid for cooling one or more electronic components, the hybrid cooling unit further including an air inlet to direct a flow of external air to remove heat from the evaporative cooler and the liquid heat exchanger."
11657263,"Systems and methods for determining the gaze direction of a subject and projecting this gaze direction onto specific regions of an arbitrary three-dimensional geometry. In an exemplary embodiment, gaze direction may be determined by a regression-based machine learning model. The determined gaze direction is then projected onto a three-dimensional map or set of surfaces that may represent any desired object or system. Maps may represent any three-dimensional layout or geometry, whether actual or virtual. Gaze vectors can thus be used to determine the object of gaze within any environment. Systems can also readily and efficiently adapt for use in different environments by retrieving a different set of surfaces or regions for each environment."
11657532,"In various examples, surface profile estimation and bump detection may be performed based on a three-dimensional (3D) point cloud. The 3D point cloud may be filtered in view of a portion of an environment including drivable free-space, and within a threshold height to factor out other objects or obstacles other than a driving surface and protuberances thereon. The 3D point cloud may be analyzed—e.g., using a sliding window of bounding shapes along a longitudinal or other heading direction—to determine one-dimensional (1D) signal profiles corresponding to heights along the driving surface. The profile itself may be used by a vehicle—e.g., an autonomous or semi-autonomous vehicle—to help in navigating the environment, and/or the profile may be used to detect bumps, humps, and/or other protuberances along the driving surface, in addition to a location, orientation, and geometry thereof."
11657535,"Systems and methods for automatic camera calibration without using a robotic actuator or similar hardware. An electronic display screen projects an image of a simulated three-dimensional calibration pattern, such as a checkerboard, oriented in a particular pose. The camera captures an image of the calibration pattern that is displayed on the screen, and this image together with the transform of the simulated three-dimensional calibration pattern are used to calibrate the camera. Multiple different pictures of different poses are employed to determine the optimal set of poses that produces the lowest reprojection error. To aid in selecting different poses, i.e., spatial positions and orientations of the simulated three-dimensional calibration pattern, poses may be selected from only that portion of the camera's field of view which is expected to be typically used in operation of the camera."
11657571,"Systems and methods enable optimization of a 3D model representation comprising the shape and appearance of a particular 3D scene or object. The opaque 3D mesh (e.g., vertex positions and corresponding topology) and spatially varying material attributes are jointly optimized based on image space losses to match multiple image observations (e.g., reference images of the reference 3D scene or object). A geometric topology defines faces and/or cells in the opaque 3D mesh that are visible and may be randomly initialized and optimized through training based on the image space losses. Applying the geometry topology to an opaque 3D mesh for learning the shape improves accuracy of silhouette edges and performance compared with using transparent mesh representations. In contrast with approaches that require an initial guess for the topology and/or an exhaustive testing of possible geometric topologies, the 3D model representation is learned based on image space differences without requiring an initial guess."
11657627,"In various examples, frames of a video may include a first visual object that may appear relative to a second visual object within a region of the frames. Once a relationship between the first visual object and the region is known, one or more operations may be performed on the relative region. For example, optical character recognition may be performed on the relative region where the relative region is known to contain textual information. As a result, the identification of the first visual object may serve as an anchor for determining the location of the relative region including the second visual object—thereby increasing accuracy and efficiency of the system while reducing run-time."
11657897,"The present invention provides methods, systems, computer program products that use deep learning with neural networks to denoise ATAC-seq datasets. The methods, systems, and programs provide for increased efficiency, accuracy, and speed in identifying genomic sites of chromatin accessibility in a wide range of tissue and cell types."
11660535,"The disclosure provides features or schemes that improve a user's experience with an interactive computer product by reducing latency through late latching and late warping. The late warping can be applied by imaging hardware based on late latch inputs and is applicable for both local and cloud computing environments. In one aspect, the disclosure provides a method of operating an imaging system employing late latching and late warping. In one example the method of operating an imaging system includes: (1) rendering a rendered image based on a user input from an input device and scene data from an application engine, (2) obtaining a late latch input from the input device, (3) rendering, employing imaging hardware, a warped image by late warping at least a portion of the rendered image based on the late latch input, and (4) updating state information in the application engine with late latch and warp information."
11663036,"A parallel processing unit (PPU) can be divided into partitions. Each partition is configured to operate similarly to how the entire PPU operates. A given partition includes a subset of the computational and memory resources associated with the entire PPU. Software that executes on a CPU partitions the PPU for an admin user. A guest user is assigned to a partition and can perform processing tasks within that partition in isolation from any other guest users assigned to any other partitions. Because the PPU can be divided into isolated partitions, multiple CPU processes can efficiently utilize PPU resources."
11663701,"This disclosure presents a method and computer program product to denoise a ray traced scene. An apparatus for processing a ray traced scene is also disclosed. In one example, the method includes: (1) generating filtered scene data by filtering modified scene data from original scene data utilizing a spatial filter, and (2) providing a denoised ray traced scene by adjusting the filtered scene data utilizing a temporal filter. The modified and adjusted scene data can be sent to a rendering processor or system to complete rendering to generate a final scene."
11663767,"Attributes of graphics objects are processed in a plurality of graphics processing pipelines. A streaming multiprocessor (SM) retrieves a first set of parameters associated with a set of graphics objects from a first set of buffers. The SM performs a first set of operations on the first set of parameters according to a first phase of processing to produce a second set of parameters stored in a second set of buffers. The SM performs a second set of operations on the second set of parameters according to a second phase of processing to produce a third set of parameters stored in a third set of buffers. One advantage of the disclosed techniques is that work is redistributed from a first phase to a second phase of graphics processing without having to copy the attributes to and retrieve the attributes from the cache or system memory, resulting in reduced power consumption."
11663770,"A bounding volume is used to approximate the space an object occupies. If a more precise understanding beyond an approximation is required, the object itself is then inspected to determine what space it occupies. Often, a simple volume (such as an axis-aligned box) is used as bounding volume to approximate the space occupied by an object. But objects can be arbitrary, complicated shapes. So a simple volume often does not fit the object very well. That causes a lot of space that is not occupied by the object to be included in the approximation of the space being occupied by the object. Hardware-based techniques are disclosed herein, for example, for efficiently using multiple bounding volumes (such as axis-aligned bounding boxes) to represent, in effect, an arbitrarily shaped bounding volume to better fit the object, and for using such arbitrary bounding volumes to improve performance in applications such as ray tracing."
11663773,"Devices, systems, and techniques to incorporate lighting effects into computer-generated graphics. In at least one embodiment, a virtual scene comprising a plurality of lights is rendered by randomly sampling a set of lights from among the plurality of lights prior to rendering a frame of graphics. A subset of the set of lights is selected and used to render pixels within one or more portions of the frame."
11663945,"A patch scanning display apparatus and a technique for reconstructing a target image frame on a projection surface is disclosed. The patch scanning display apparatus includes a backlight and a spatial light modulator (SLM). An optical scanning device scans the image projected by the SLM across the projection surface in accordance with a scan trajectory. A decomposition model is used to generate a set of image patches based on the target image frame and the scan trajectory. In an embodiment, the decomposition model is a projective non-negative matrix factorization model. The set of image patches are utilized to generate a modulation signal for the SLM and a binary backlight signal is then generated for each time step of the scan trajectory within a frame period to activate or deactivate the light-emitting elements of the backlight during the frame period at a high refresh rate while the projected image is scanned."
11665029,"A feed forward equalizer including a first set of filter taps having a first set of filter tap coefficients to be adapted and a second set of one or more filter taps having one or more filter tap coefficients to be constrained. The feed forward equalizer includes an adaptation component to determine a set of adapted filter tap coefficient values corresponding to the first set of filter tap coefficients and a constraint function component to determine a constrained filter tap coefficient value for the second set of the one or more filter taps having the one or more filter tap coefficients to be constrained using a constraint function based on at least a portion of the set of adapted filter tap coefficient values. The feed forward equalizer generates, based at least in part on the constrained filter tap coefficient value, an equalized signal including a set of estimated symbol values."
11668750,"During functional/normal operation of an integrated circuit including multiple independent processing elements, a selected independent processing element is taken offline and the functionality of the selected independent processing element is then tested while the remaining independent processing elements continue functional operation. To minimize voltage drops resulting from current fluctuations produced by the testing of the processing element, clocks used to synchronize operations within each partition of a processing element are staggered. This varies the toggle rate within each partition of the processing element during the testing of the processing core, thereby reducing the resulting voltage drop. This may also improve test quality within an automated test equipment (ATE) environment."
11669421,"Unavoidable physical phenomena, such as an alpha particle strikes, can cause soft errors in integrated circuits. Materials that emit alpha particles are ubiquitous, and higher energy cosmic particles penetrate the atmosphere and also cause soft errors. Some soft errors have no consequence, but others can cause an integrated circuit to malfunction. In some applications (e.g. driverless cars), proper operation of integrated circuits is critical to human life and safety. To minimize or eliminate the likelihood of a soft error becoming a serious malfunction, detailed assessment of individual potential soft errors and subsequent processor behavior is necessary. Embodiments of the present disclosure facilitate emulating a plurality of different, specific soft errors. Resilience may be assessed over the plurality of soft errors and application code may be advantageously engineered to improve resilience. Normal processor execution is halted to inject a given state error through a scan chain, and execution is subsequently resumed."
11670001,"In an embodiment, a system provides object tracking and 6D pose estimations to a robot that performs different tasks such as manipulation and navigation. In an embodiment the 6D object pose is determined using a Rao-Blackwellized particle filtering framework, where the 3-D rotation and the 3-D translation of the object is decoupled. In an embodiment, the system provides the 3-D translation of an object along with a full distribution over the 3-D rotation. In an embodiment, the 3-D rotation is determined by discretizing the rotation space, and training an autoencoder network to construct a codebook of feature embeddings for the discretized rotations. In an embodiment, the system is able to track objects with arbitrary symmetries while also maintaining adequate posterior distributions."
11673061,"A game-agnostic event detector can be used to automatically identify game events. Event data for detected events can be written to an event log in a form that is both human- and process-readable. Descriptive text for the event data can come from a common event dictionary that is hierarchical in nature, such that events of the same type can be correlated across different games even though the precise nature or appearance of those events may be different. The event data can be used for various purposes, such as to generate highlight videos or provide player performance feedback."
11675083,"An autonomous vehicle system removes ephemeral points from lidar samples. The system receives a plurality of light detection and ranging (lidar) samples captured by a lidar sensor. Along with the lidar samples, the system receives an aligned pose and an unwinding transform for each of the lidar samples. The system determines one or more occupied voxel cells in a three-dimensional (3D) space using the lidar samples, their aligned poses, and their unwinding transforms. The system identifies occupied voxel cells representative of noise associated with motion of an object relative to the lidar sensor. The system filters the occupied voxel cells by removing the cells representative of noise. The system inputs the filtered occupied voxel cells in a 3D map comprising voxel cells, e.g., during the map generation and/or a map update."
11675092,"A vehicle, for example, an autonomous vehicle receives signals from a global navigation satellite system (GNSS) and determines accurate location of the vehicle using the GNSS signal. The vehicle performs localization to determine the location of the vehicle as it drives. The autonomous vehicle uses sensor data and a high definition map to determine an accurate location of the autonomous vehicle. The autonomous vehicle uses accurate location of the vehicle to determine RTK corrections that is used for improving GNSS location estimates at a future location. The RTK corrections may be transmitted to other vehicles."
11675359,"In various examples, a deep learning solution for path detection is implemented to generate a more abstract definition of a drivable path without reliance on explicit lane-markings—by using a detection-based approach. Using approaches of the present disclosure, the identification of drivable paths may be possible in environments where conventional approaches are unreliable, or fail—such as where lane markings do not exist or are occluded. The deep learning solution may generate outputs that represent geometries for one or more drivable paths in an environment and confidence values corresponding to path types or classes that the geometries correspond. These outputs may be directly useable by an autonomous vehicle—such as an autonomous driving software stack—with minimal post-processing."
11675704,"In a ray tracer, a cache for streaming workloads groups ray requests for coherent successive bounding volume hierarchy traversal operations by sending common data down an attached data path to all ray requests in the group at the same time or about the same time. Grouping the requests provides good performance with a smaller number of cache lines."
11676284,"Various types of image analysis benefit from a multi-stream architecture that allows the analysis to consider shape data. A shape stream can process image data in parallel with a primary stream, where data from layers of a network in the primary stream is provided as input to a network of the shape stream. The shape data can be fused with the primary analysis data to produce more accurate output, such as to produce accurate boundary information when the shape data is used with semantic segmentation data produced by the primary stream. A gate structure can be used to connect the intermediate layers of the primary and shape streams, using higher level activations to gate lower level activations in the shape stream. Such a gate structure can help focus the shape stream on the relevant information and reduces any additional weight of the shape stream."
11676307,"According to an aspect of an embodiment, operations may comprise capturing, at a vehicle as the vehicle travels, LIDAR scans and camera images. The operations may further comprise selecting, at the vehicle as the vehicle travels, a subset of the LIDAR scans and the camera images that are determined to be useful for calibration. The operations may further comprise computing, at the vehicle as the vehicle travels, LIDAR-to-camera transformations for the subset of the LIDAR scans and the camera images using an optimization algorithm. The operations may further comprise calibrating, at the vehicle as the vehicle travels, one or more sensors of the vehicle based on the LIDAR-to-camera transformations."
11676326,"One embodiment of a method for computing a texture color includes tracing a ray cone through a graphics scene, determining at least one axis of an ellipse formed by the ray cone intersecting a plane associated with geometry within the graphics scene at a hit point, computing one or more gradients along the at least one axis of the ellipse, and computing a texture color based on the one or more gradients and a texture."
11676364,"In various examples, sensor data representative of an image of a field of view of a vehicle sensor may be received and the sensor data may be applied to a machine learning model. The machine learning model may compute a segmentation mask representative of portions of the image corresponding to lane markings of the driving surface of the vehicle. Analysis of the segmentation mask may be performed to determine lane marking types, and lane boundaries may be generated by performing curve fitting on the lane markings corresponding to each of the lane marking types. The data representative of the lane boundaries may then be sent to a component of the vehicle for use in navigating the vehicle through the driving surface."
11677839,"Apparatuses, systems, and techniques are directed to automatic coalescing of GPU-initiated network communications. In one method, a communication engine receives, from a shared memory application executing on a first graphics processing unit (GPU), a first communication request assigned to or having a second GPU as a destination to be processed. The communication engine determines that the first communication request satisfies a coalescing criterion and stores the first communication request in association with a group of requests that have a common property. The communication engine coalesces the group of requests into a coalesced request and transports the coalesced request to the second GPU over a network."
11678120,"Apparatuses, systems, and techniques are presented to reduce noise in audio. In at least one embodiment, one or more neural networks are used to determine a noise signal in one or more speech signals."
11681340,"A graphics subsystem includes a printed circuit board (PCB), a set of one or more fans, and a heat sink. A graphics processing unit (GPU) is integrated into the PCB. The PCB is shortened to occupy a portion of the width of the graphics subsystem. The heat sink is coupled to the PCB and/or GPU and configured to extend beyond an edge of the PCB, thereby occupying a larger portion of the width of the graphics subsystem compared to the PCB. A first fan is disposed partially or fully beyond the edge of the PCB and is configured to direct air through the portion of the heat sink that extends beyond the edge of the PCB, along a first airflow path, and out of the graphics subsystem. A second fan is configured to direct air through the heat sink, along a second airflow path, towards the GPU."
11681341,A cooling system for a datacenter is disclosed. An evaporative cooling subsystem provides blown air for cooling the datacenter and a repurposable refrigerant cooling subsystem controls moisture of the blown air in a first configuration and independently cools the datacenter in a second configuration.
11682100,"In various examples, a signal processing pipeline is dynamically generated or instantiated for a signal processing request. To generate the pipeline, a graph topology—including nodes and edges—may be created to represent features, functionality, and characteristics of a signal processing system. The nodes, representing processing tasks, may be connected via edges having associated costs for performing, by a node, a processing task on an output of a prior or edge-connected node. For a given signal processing request, the nodes or processing tasks to be included may be selected and, using a graph routing algorithm and the costs between and among the determined nodes, a path through the nodes may be determined—thereby defining, at least in part, the signal processing pipeline."
11682199,"A style-based generative network architecture enables scale-specific control of synthesized output data, such as images. During training, the style-based generative neural network (generator neural network) includes a mapping network and a synthesis network. During prediction, the mapping network may be omitted, replicated, or evaluated several times. The synthesis network may be used to generate highly varied, high-quality output data with a wide variety of attributes. For example, when used to generate images of people's faces, the attributes that may vary are age, ethnicity, camera viewpoint, pose, face shape, eyeglasses, colors (eyes, hair, etc.), hair style, lighting, background, etc. Depending on the task, generated output data may include images, audio, video, three-dimensional (3D) objects, text, etc."
11682272,"Systems and methods are disclosed herein for a pedestrian crossing warning system that may use multi-modal technology to determine attributes of a person and provide a warning to the person in response to a calculated risk level to effect a reduction of the risk level. The system may utilize sensors to receive data indicative of a trajectory of a person external to the vehicle. Specific attributes of the person such as age or walking aids may be determined. Based on the trajectory data and the specific attributes, a risk level may be determined by the system using a machine learning model. The system may cause emission of a warning to the person in response to the risk level."
11683043,"A time-to-digital converter (TDC) circuit includes control logic and a first self-referenced delay cell circuit coupled to the control logic. The first self-referenced delay cell circuit includes: a first bank of capacitors coupled to a first node between a first positive input and a first positive output, where the first bank of capacitors is selectively controlled by a first control signal from the control logic, the first control signal including a first up value corresponding to a first positive threshold; and a second bank of capacitors coupled to a second node between a first negative input and a first negative output, where the second bank of capacitors is selectively controlled by a second control signal from the control logic, the second control signal including a first down value corresponding to a first negative threshold."
11683243,"A client computer executes a client agent that determines the time between when an input is transmitted from a client computer to a remote server and when updated graphics are received from the remote server in response. The client agent interacts with a server agent that executes on the remote server. The client agent transmits an emulated keystroke to the server agent. In response, the server agent modifies a graphics object and composites the modified graphics object with a currently rendered frame. The client computer receives the frame and identifies the modified graphics object, indicating that the emulated keystroke was received by the remote server. The client agent then computes the time difference between when the emulated keystroke was transmitted to the remote server and when the modified graphics object was detected and/or displayed at the client computer. This time difference indicates the responsiveness of the remote desktop implementation."
11683253,"Novel solutions are provided for consistent Quality of Service in cloud gaming system that adaptively and dynamically compensate for poor network conditions by moderating rendered frame rates using frame rate capping to optimize for network latency savings (or surplus). In further embodiments, the encoding/sent frame rate to the client can also be managed in addition, or as an alternative to capping the rendered frame rates. The claimed embodiments not only maintain a constant Quality of Service (QoS) for the user, but may also be employed to leverage higher-performing networks to reduce operational costs."
11683302,"Verified deliveries are commonplace for various exchanges of goods, packages, and/or other items, but often require close proximity or contact between the exchanging parties or devices associated therewith—e.g., for digital or physical signature. To remedy this, system and methods described herein may leverage an ad hoc network established between a device of a provider and a device of a consumer for exchanging codes or tokens—that may be validated by an authentication service—to provide a verification process during an exchange between the parties. As a result, a safe distance may be maintained between the parties throughout the transaction—thereby avoiding exchange of germs while also increasing safety and security of both parties—and the verification process may be more reliable and secure."
11683453,"In various examples, cloud computing systems may store frames of video streams and metadata generated from the frames in separate data stores, with each type of data being indexed using shared timestamps. Thus, the frames of a video stream may be stored and/or processed and corresponding metadata of the frames may be stored and/or generated across any number of devices of the cloud computing system (e.g., edge and/or core devices) while being linked by the timestamps. A client device may provide a request or query to dynamically annotate the video stream using a particular subset of the metadata. In processing the request or query, the timestamps may be used to retrieve video data representing frames of the video stream and metadata extracted from those frames across the data stores. The retrieved metadata and video data may be used to annotate the frames for display on the client device."
11687133,"A computing device comprises: a heat sink that has a plurality of cooling fins and a vapor chamber; one or more heat-generating electronic devices that are thermally coupled to the vapor chamber; and at least one cooling fan configured to direct cooling air across the plurality of cooling fins, wherein a first fin included in the plurality of cooling fins and a second fin included in the plurality of cooling fins form a first air passage that has a first air inlet opening and a first air outlet opening, and wherein the first fin is adjacent to the second fin, and a first distance between the first fin and the second fin proximate to the first air inlet opening is less than a second distance between the first fin and the second fin proximate to the first air outlet opening."
11687435,"A processing unit can include a performance monitor for monitoring the performance of the processing unit and associated sub-units. The performance monitor can include a state machine. The state machine can be implemented via state machine data entries stored in a memory associated with the performance monitor. A state machine data entry includes information indicating a state transition condition and output signals. The state transition condition includes a current state and input signals required to meet the condition. The output signals include a next state, one or more counter actions, and one or more triggers. The performance monitor implements logic circuits that determine, based on input signals and the state machine data entries, the next state to transition and associated output signals. The state machine data entries can be written and re-written by a user."
11687679,"Various implementations of a current flattening circuit are disclosed, including those utilizing a feedback current regulator, a feedforward current regulator, and a constant current source."
11688042,"Various approaches are disclosed to temporally and spatially filter noisy image data—generated using one or more ray-tracing effects—in a graphically rendered image. Rather than fully sampling data values using spatial filters, the data values may be sparsely sampled using filter taps within the spatial filters. To account for the sparse sampling, locations of filter taps may be jittered spatially and/or temporally. For filtering efficiency, a size of a spatial filter may be reduced when historical data values are used to temporally filter pixels. Further, data values filtered using a temporal filter may be clamped to avoid ghosting. For further filtering efficiency, a spatial filter may be applied as a separable filter in which the filtering for a filter direction may be performed over multiple iterations using reducing filter widths, decreasing the chance of visual artifacts when the spatial filter does not follow a true Gaussian distribution."
11688074,"In various examples, a background of an object may be modified to generate a training image. A segmentation mask may be generated and used to generate an object image that includes image data representing the object. The object image may be integrated into a different background and used for data augmentation in training a neural network. Data augmentation may also be performed using hue adjustment (e.g., of the object image) and/or rendering three-dimensional capture data that corresponds to the object from selected views. Inference scores may be analyzed to select a background for an image to be included in a training dataset. Backgrounds may be selected and training images may be added to a training dataset iteratively during training (e.g., between epochs). Additionally, early or late fusion nay be employed that uses object mask data to improve inferencing performed by a neural network trained using object mask data."
11688181,"In various examples, a multi-sensor fusion machine learning model—such as a deep neural network (DNN)—may be deployed to fuse data from a plurality of individual machine learning models. As such, the multi-sensor fusion network may use outputs from a plurality of machine learning models as input to generate a fused output that represents data from fields of view or sensory fields of each of the sensors supplying the machine learning models, while accounting for learned associations between boundary or overlap regions of the various fields of view of the source sensors. In this way, the fused output may be less likely to include duplicate, inaccurate, or noisy data with respect to objects or features in the environment, as the fusion network may be trained to account for multiple instances of a same object appearing in different input representations."
11689750,"Embodiments of the present disclosure relate to workload-based dynamic throttling of video processing functions. Systems and methods are disclosed that dynamically throttle video processing and/or streaming based on a workload. Live video is captured from one or more sources (e.g., cameras) and stored. The video is then provided to a video processing engine and a video streaming engine. The video processing engine may perform one or more operations such as object detection, object tracking, and object classification to produce characterization data (e.g., bounding boxes, object trajectories, alerts, object labels, object counts, boundary crossings, intersection highlighting, etc.). System resource usage and performance of the video processing and streaming are monitored to produce workload data (e.g., metrics). Based on the policies and the workload data, the video streaming and/or processing is dynamically reconfigured by adjusting parameters provided to the video streaming and processing engines."
11693470,"In various examples, a voltage monitor may determine whether the voltage supplied to at least one component of a computing system is safe using two sets of thresholds—e.g., a high-frequency over-voltage (OV) threshold, a high-frequency under-voltage (UV) threshold, a low-frequency OV threshold, and a low-frequency UV threshold. A high-frequency voltage error detector may compare the supplied or input voltage to the high-frequency OV and UV thresholds and a low-frequency voltage error detector that may filter the supplied voltage to remove or reduce noise and then may compare the filtered voltage to the low-frequency OV and UV thresholds. Upon detecting a voltage error, a safety monitor may cause a change to an operating state of the at least one component."
11693667,"Systems and methods are provided for efficiently performing processing intensive operations, such as those involving large volumes of data, that enable accelerated processing time of these operations. In at least one embodiment, a system includes a graphics processor unit (GPU) including a memory and a plurality of cores. The plurality of cores perform a plurality of data analytics operations on a respectively allocated portion of a dataset, each of the plurality of cores using only the memory to store data input for each of the plurality of data analytics operations performed by the plurality of cores. The data storage for the plurality of data analytics operations performed by the plurality of cores is also provided solely by the memory."
11693753,"In various examples, permanent faults in hardware component(s) and/or connections to the hardware component(s) of a computing platform may be predicted before they occur using in-system testing. As a result of this prediction, one or more remedial actions may be determined to enhance the safety of the computing platform (e.g., an autonomous vehicle). A degradation rate of a performance characteristic associated with the hardware component may be determined, detected, and/or computed by monitoring values of performance characteristics over time using fault testing."
11694072,"A method and system are disclosed for training a model that implements a machine-learning algorithm. The technique utilizes latent descriptor vectors to change a multiple-valued output problem into a single-valued output problem and includes the steps of receiving a set of training data, processing, by a model, the set of training data to generate a set of output vectors, and adjusting a set of model parameters and component values for at least one latent descriptor vector in the plurality of latent descriptor vectors based on the set of output vectors. The set of training data includes a plurality of input vectors and a plurality of desired output vectors, and each input vector in the plurality of input vectors is associated with a particular latent descriptor vector in a plurality of latent descriptor vectors. Each latent descriptor vector comprises a plurality of scalar values that are initialized prior to training the model."
11694643,"In various examples, a low-latency variable backlight liquid crystal display (LCD) system is disclosed. The LCD system may reduce latency and video lag by performing an analysis of peak pixel values within subsets of pixels using a rendering device, prior to transmitting the frame to a display device for display. As a result, the display device may receive the peak pixel value data prior to or concurrently with the frame data, and may begin updating the backlight settings of the display without having to wait for a substantial portion of the frame to be received. In this way, the LCD system may avoid the full frame delay of conventional systems, allowing the LCD system to more reliably support high-performance applications such as gaming."
11695601,"A system includes a transmitter to transmit a set of bits associated with signaling having one or more levels. The system includes a receiver coupled to the transmitter, the receiver to receive the set of bits and generate a first plurality of digital values, each digital value generated at a first timing value and a plurality of reference voltages, the reference voltage incremented based at least in part on generating a digital value of the first plurality of digital values. The receiver is to generate a second plurality of digital values at a second timing value and the plurality of reference voltages, the first timing value incremented to the second timing value based at least in part on generating the first plurality of digital values. The system includes a controller to determine an amplitude associated with each the first and second plurality of digital values."
11698272,"An end-to-end system for data generation, map creation using the generated data, and localization to the created map is disclosed. Mapstreams—or streams of sensor data, perception outputs from deep neural networks (DNNs), and/or relative trajectory data—corresponding to any number of drives by any number of vehicles may be generated and uploaded to the cloud. The mapstreams may be used to generate map data—and ultimately a fused high definition (HD) map—that represents data generated over a plurality of drives. When localizing to the fused HD map, individual localization results may be generated based on comparisons of real-time data from a sensor modality to map data corresponding to the same sensor modality. This process may be repeated for any number of sensor modalities and the results may be fused together to determine a final fused localization result."
11698869,"The subject application relates to computing an authentication tag for partial transfers scheduled across multiple direct memory access (DMA) engines. Apparatuses, systems, and techniques are described for computing an authentication tag for a data transfer when the data transfer is scheduled as partial transfers across a specified number of direct memory access (DMA) engines. An orchestration circuit stores partial authentication tags, computed by the DMA engines, and corresponding adjustment exponents during one or more rounds in which the partial transfers are scheduled and processed by the specified number of DMA engines. During a last round, a combined authentication tag can be computed based on the partial authentication tags and the corresponding adjustment exponents stored by the orchestration circuit during the rounds."
11699662,"In accordance with the disclosure, one or both semiconductor dies in a face-to-face arrangement may include a probe pad layer formed on a face of the die to allow the die to be individually tested prior to assembly of the dies. Thus, faulty dies may be discarded individually so they are not included in a composite semiconductor device, thereby increasing device yields. The probe pad layer also allows dies to be matched so that a composite semiconductor device achieves desired performance, which may further increase device yields. In some embodiments, the probe pads of the probe pad layer formed on the face of the die may be used to individually test the die, and may remain inactive, or inert, during operation of the composite semiconductor device."
11700402,"A performance metrics of a receiver is obtained using frames of an application hosted by a server that are received via a network. The one or more performance metrics include information indicative of a current occupancy of a frame buffer corresponding to the receiver and information indicative of a target occupancy of the frame buffer corresponding to the receiver. The frame buffer of the receiver is used to queue frames of the application for display. A frame rate associated with rendering at least one next frame of the application is adjusted using the one or more performance metrics of the receiver to control population of the frame buffer. Subsequent frames of the application hosted by the server are rendered using the adjusted frame rate. Upon rendering the subsequent frames, the server sends the subsequent frames to the receiver for display."
11700419,"In various examples, a media stream may be received by a re-encode system that may leverage a recode engine to convert (e.g., at an interval, based on a request, etc.) an inter-frame associated with the media stream to an intra-frame. The intra-frame may be converted from the inter-frame using parameters or other information associated with and received with the media stream. The converted intra-frame may be merged into an updated segment of the media stream in place of the original inter-frame to enable storage of the updated segment—or a portion thereof—for later use."
11700713,An adapter plate and a fastening system for fastening a manifold to a rack in a datacenter is disclosed. The adapter plate is associated with the manifold and has holes to receive buttons in configurable positions. The configurable positions enable the buttons to mate with keyholes of a bracket of the rack in order to fasten the manifold to the bracket.
11701771,"In at least one embodiment, a system determines a set of possible grasp poses that allow a robot to successfully grasp an object by generating a set of potential grasp poses, and then evaluating the performance of each potential grasp pose. In at least one embodiment, the system performs a refinement operation on the grasp poses, and based on an evaluation of the poses, creates an improved set of possible grasps for the object."
11703348,"A semi-public blockchain maintained on one or more nodes in a map cloud platform comprises data for maintaining a global map of a predetermined geographic area. The blockchain also comprises a plurality of data records, where each data record is associated with an update to a global map. When a message associated with a map update to the global map is received, the nodes of the blockchain determine a consensus by evaluating the map update, where the evaluating comprises performing a plurality of proofs including a proof of location, a proof of iterations, a proof of physical delivery and a proof of safety. When consensus is attained and the map update is validated, a data record associated with the map update is generated and added to the blockchain with a timestamp and a link to prior data records in the blockchain."
11703921,"Apparatuses, systems, and techniques to cool computer processors. In at least one embodiment, a system comprises one or more processors and a heatsink connected by a flexible heat conduit to the one or more processors, and a position of the heatsink is adjustable."
11704067,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
11704167,"Approaches in accordance with various embodiments can reduce scheduling delays due to concurrent processing requests, as may involve VSyncs in multi-streaming systems. The software synchronization signals can be staggered relative to each other by offsetting an initial synchronization signal. These software synchronization signals can be readjusted over time such that each synchronization signal maintains the same relative offset, as may be with respect to other applications or containers."
11704781,"The various embodiments of the present disclosure are directed towards methods for tone mapping High-Dynamic-Range (HDR) image data, as well as controlling the brightness of the image encoded by HDR the image data and/or the tone-mapped image data. HDR image is captured. A tone mapping function for the HDR image data is generated. To generate the tone mapping function, control points are dynamically determined based on an analysis of the HDR image data. The tone mapping function is fit to the control points. The tone mapping function is a non-linear function, and is described by a curve in a plane. The shape of the curve is constrained by a line generated from a portion of the control points. The tone mapping function is applied to the HDR image data. A color-compression is applied to the tone mapped image data to generate Standard Dynamic Range or Low Dynamic Range image data."
11704814,"In various examples, an adaptive eye tracking machine learning model engine (“adaptive-model engine”) for an eye tracking system is described. The adaptive-model engine may include an eye tracking or gaze tracking development pipeline (“adaptive-model training pipeline”) that supports collecting data, training, optimizing, and deploying an adaptive eye tracking model that is a customized eye tracking model based on a set of features of an identified deployment environment. The adaptive-model engine supports ensembling the adaptive eye tracking model that may be trained on gaze vector estimation in surround environments and ensemble based on a plurality of eye tracking variant models and a plurality of facial landmark neural network metrics."
11704857,"A three-dimensional (3D) object reconstruction neural network system learns to predict a 3D shape representation of an object from a video that includes the object. The 3D reconstruction technique may be used for content creation, such as generation of 3D characters for games, movies, and 3D printing. When 3D characters are generated from video, the content may also include motion of the character, as predicted based on the video. The 3D object construction technique exploits temporal consistency to reconstruct a dynamic 3D representation of the object from an unlabeled video. Specifically, an object in a video has a consistent shape and consistent texture across multiple frames. Texture, base shape, and part correspondence invariance constraints may be applied to fine-tune the neural network system. The reconstruction technique generalizes well—particularly for non-rigid objects."
11704860,"One embodiment of a computer-implemented method for processing ray tracing operations in parallel includes receiving a plurality of rays and a corresponding set of importance sampling instructions for each ray included in the plurality of rays for processing, wherein each ray represents a path from a light source to at least one point within a three-dimensional (3D) environment, and each corresponding set of importance sampling instruction is based at least in part on one or more material properties associated with at least one surface of at least one object included in the 3D environment; assigning each ray included in the plurality of rays to a different processing core included in a plurality of processing cores; and for each ray included in the plurality of rays, causing the processing core assigned to the ray to execute the corresponding set of importance sampling instructions on the ray to generate a direction for a secondary ray that is produced when the ray intersects a surface of an object within the 3D environment."
11704863,A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to properly handle numerically challenging computations at or near edges and/or vertices of primitives and/or ensure that a single intersection is reported when a ray intersects a surface formed by primitives at or near edges and/or vertices of the primitives.
11704890,"In various examples, a deep neural network (DNN) is trained—using image data alone—to accurately predict distances to objects, obstacles, and/or a detected free-space boundary. The DNN may be trained with ground truth data that is generated using sensor data representative of motion of an ego-vehicle and/or sensor data from any number of depth predicting sensors—such as, without limitation, RADAR sensors, LIDAR sensors, and/or SONAR sensors. The DNN may be trained using two or more loss functions each corresponding to a particular portion of the environment that depth is predicted for, such that—in deployment—more accurate depth estimates for objects, obstacles, and/or the detected free-space boundary are computed by the DNN. In some embodiments, a sampling algorithm may be used to sample depth values corresponding to an input resolution of the DNN from a predicted depth map of the DNN at an output resolution of the DNN."
11705150,"Systems and methods for generating real-time synthetic crowd responses for events, to augment the experience of event participants, remote viewers, and the like. Various sensors monitor the event in question, and various event properties are derived from their output using an event state model. These event properties, along with various event parameters such as score, time remaining, etc., are then input to a machine learning model that determines a real-time synthetic audience reaction tailored to the immediate state of the event. Reaction parameters are used to generate a corresponding crowd or audience audio signal, which may be broadcast to event participants, viewers, spectators, or anyone who may be interested. This instantaneous, realistic crowd reaction more closely simulates the experience of events with full on-site audiences, enhancing the viewing experience of both event participants and those watching."
11706293,"A network device including a first data structure storing a set of buffer profile types. Each buffer profile type is associated with one or more configuration parameters. The network device further includes a second data structure storing a set of peer device identifiers, wherein each peer device identifier of the set of peer device identifiers is associated with a buffer profile type. The network device includes a buffer management application to receive first data associated with a first peer network device coupled via a first link to an interface component of the network device, determine the first data matches a first peer device identifier stored in the second data structure, and assign a first buffer profile type to the interface component of the network device, wherein the first buffer profile type is associated with the first peer device identifier in the second data structure."
11709812,"One embodiment sets forth a technique for generating a tree structure within a computer memory for storing sparse data. The technique includes dividing a matrix into a first plurality of equally sized regions. The technique also includes dividing at least one region in the first plurality of regions into a second plurality of regions, where the second plurality of regions includes a first region and one or more second regions that have a substantially equal number of nonzero matrix values and are formed within the first region. The technique further includes creating the tree structure within the computer memory by generating a first plurality of nodes representing the first plurality of regions, generating a second plurality of nodes representing the second plurality of regions, and grouping, under a first node representing the first region, one or more second nodes representing the one or more second regions."
11711905,"An apparatus includes at least one heat pipe that is adapted to be thermally coupled to an integrated circuit and has an evaporator portion and a first condenser portion, wherein the first condenser portion extends away from the evaporator portion; a first plurality of cooling fins that is attached to the first condenser portion; a first movable support that is thermally coupled to the first condenser portion and is configured to move a second plurality of cooling fins relative to the first plurality of cooling fins; and the second plurality of cooling fins, which is attached to the first movable support."
11712621,"In various examples, potentially highlight-worthy video clips are identified from a gameplay session that a gamer might then selectively share or store for later viewing. The video clips may be identified in an unsupervised manner based on analyzing game data for durations of predicted interest. A classification model may be trained in an unsupervised manner to classify those video clips without requiring manual labeling of game-specific image or audio data. The gamer can select the video clips as highlights (e.g., to share on social media, store in a highlight reel, etc.). The classification model may be updated and improved based on new video clips, such as by creating new video-clip classes."
11713978,"An end-to-end system for data generation, map creation using the generated data, and localization to the created map is disclosed. Mapstreams—or streams of sensor data, perception outputs from deep neural networks (DNNs), and/or relative trajectory data—corresponding to any number of drives by any number of vehicles may be generated and uploaded to the cloud. The mapstreams may be used to generate map data—and ultimately a fused high definition (HD) map—that represents data generated over a plurality of drives. When localizing to the fused HD map, individual localization results may be generated based on comparisons of real-time data from a sensor modality to map data corresponding to the same sensor modality. This process may be repeated for any number of sensor modalities and the results may be fused together to determine a final fused localization result."
11715251,"Training deep neural networks requires a large amount of labeled training data. Conventionally, labeled training data is generated by gathering real images that are manually labelled which is very time-consuming. Instead of manually labelling a training dataset, domain randomization technique is used generate training data that is automatically labeled. The generated training data may be used to train neural networks for object detection and segmentation (labelling) tasks. In an embodiment, the generated training data includes synthetic input images generated by rendering three-dimensional (3D) objects of interest in a 3D scene. In an embodiment, the generated training data includes synthetic input images generated by rendering 3D objects of interest on a 2D background image. The 3D objects of interest are objects that a neural network is trained to detect and/or label."
11720440,"Various embodiments include a parallel processing computer system that detects memory errors as a memory client loads data from memory and disables the memory client from storing data to memory, thereby reducing the likelihood that the memory error propagates to other memory clients. The memory client initiates a stall sequence, while other memory clients continue to execute instructions and the memory continues to service memory load and store operations. When a memory error is detected, a specific bit pattern is stored in conjunction with the data associated with the memory error. When the data is copied from one memory to another memory, the specific bit pattern is also copied, in order to identify the data as having a memory error."
11720472,"Memory, used by a computer to store data, is generally prone to faults, including permanent faults (i.e. relating to a lifetime of the memory hardware), and also transient faults (i.e. relating to some external cause) which are otherwise known as soft errors. Since soft errors can change the state of the data in the memory and thus cause errors in applications reading and processing the data, there is a desire to characterize the degree of vulnerability of the memory to soft errors. In particular, once the vulnerability for a particular memory to soft errors has been characterized, cost/reliability trade-offs can be determined, or soft error detection mechanisms (e.g. parity) may be selectively employed for the memory. In some cases, memory faults can be diagnosed by redundant execution and a diagnostic coverage may be determined."
11721089,"In various examples, the present disclosure relates to using temporal filters for automated real-time classification. The technology described herein improves the performance of a multiclass classifier that may be used to classify a temporal sequence of input signals—such as input signals representative of video frames. A performance improvement may be achieved, at least in part, by applying a temporal filter to an output of the multiclass classifier. For example, the temporal filter may leverage classifications associated with preceding input signals to improve the final classification given to a subsequent signal. In some embodiments, the temporal filter may also use data from a confusion matrix to correct for the probable occurrence of certain types of classification errors. The temporal filter may be a linear filter, a nonlinear filter, an adaptive filter, and/or a statistical filter."
11722417,Various embodiments include techniques for reducing high-frequency interference to a wireless communications channel emanating from a wired communications channel. The techniques are directed towards an application that determines a mode of a particular wired communications channel. The mode of the wired communications channel is indicative of the frequency ranges at which the interference is generated. The application further determines a frequency and/or bandwidth of the wireless communications channel. The application selects a slew rate that reduces the high frequency interference from the wired communications channel at the frequency and/or bandwidth of the wireless communications channel. The application thereby optimizes the reduction of the high-frequency interference from the particular wired communications channel to the particular wireless communications channel.
11722671,"The present disclosure is directed to a method and system for increasing virtual machine (VM) density on a server system through adaptive rendering by dynamically shifting video rendering tasks to a client computing device. In one embodiment, a processor in a server manages virtual machines in the server by controlling a number of VMs and an amount of system resources allocated to the VMs. The number of VMs and the amount of resources allocated to the VMs are controlled by shifting video rendering from at least one of the VMs to a client device, and increasing the number of the VMs in the server after the shifting."
11724401,"Apparatuses, systems, and techniques determine a set of grasp poses that would allow a robot to successfully grasp an object that is proximate to at least one additional object. In at least one embodiment, the set of grasp poses is modified based on a determination that at least one of the grasp poses in the set of grasp poses would interfere with at least one additional object that is proximate to the object."
11725959,"In various examples, a gaze direction of a user's eyes may be tracked and synced with perception data of the vehicle to determine POIs that the user is interested in. In some examples, POIs may be stored as waypoints in a waypoint catalog or store and included as part of a map. As a user is driving in a vehicle down a roadway, a system onboard the vehicle may access the map to determine locations of the vehicle, and may reference the waypoint catalog to determine the POIs that the vehicle passes. Using an advertiser name, contact information, an advertisement image, advertiser website information, links to additional content, etc. relating to each waypoint, a log of the passed POIs may be stored for access by the user."
11726139,"Manufacturers perform tests on chips before the chips are shipped to customers. However, defects can occur on a chip after the manufacturer testing and when the chips are used in a system or device. The defects can occur due to aging or the environment in which the chip is employed and can be critical; especially when the chips are used in systems such as autonomous vehicles. To verify the structural integrity of the IC during the lifetime of the product, an in-system test (IST) is disclosed. The IST enables self-testing mechanisms for an IC in working systems. The IST mechanisms provide structural testing of the ICs when in a functional system and at a manufacturer's level of testing. Unlike ATE tests that are running on a separate environment, the IST provides the ability to go from a functional world view to a test mode."
11726755,"Apparatuses, systems, and techniques for caching of compiled shader programs in a cloud computing environment."
11726757,"The disclosure provides processors that are configured to perform dynamic programming according to an instruction, a method for configuring a processor for dynamic programming according to an instruction and a method of computing a modified Smith Waterman algorithm employing an instruction for configuring a parallel processing unit. In one example, the method for configuring includes: (1) receiving, by execution cores of the processor, an instruction that directs the execution cores to compute a set of recurrence equations employing a matrix, (2) configuring the execution cores, according to the set of recurrence equations, to compute states for elements of the matrix, and (3) storing the computed states for current elements of the matrix in registers of the execution cores, wherein the computed states are determined based on the set of recurrence equations and input data."
11726857,"Apparatuses, systems, and techniques to detect faults in processing pipelines are described. One accelerator circuit includes a fixed-function circuit that performs an operation corresponding to a layer of a neural network. The fixed-function circuit includes a set of homogeneous processing units and a fault scanner circuit. The fault scanner circuit includes an additional homogeneous processing unit to scan each processing unit of the set for functional faults in a sequence."
11727272,"According to an aspect of an embodiment, operations may comprise receiving a point cloud representing a region. The operations may also comprise identifying a cluster of points in the point cloud having a higher intensity than points outside the cluster of points. The operations may also comprise determining a bounding box around the cluster of points. The operations may also comprise identifying a traffic sign within the bounding box. The operations may also comprise projecting the bounding box to coordinates of an image of the region captured by a camera. The operations may also comprise employing a deep learning model to classify a traffic sign type of the traffic sign in a portion of the image within the projected bounding box. The operations may also comprise storing information regarding the traffic sign and the traffic sign type in a high definition (HD) map of the region."
11727535,"In examples, threads of a schedulable unit (e.g., a warp or wavefront) of a parallel processor may be used to sample visibility of pixels with respect to one or more light sources. The threads may receive the results of the sampling performed by other threads in the schedulable unit to compute a value that indicates whether a region corresponds to a penumbra (e.g., using a wave intrinsic function). Each thread may correspond to a respective pixel and the region may correspond to the pixels of the schedulable unit. A frame may be divided into the regions with each region corresponding to a respective schedulable unit. In denoising ray-traced shadow information, the values for the regions may be used to avoid applying a denoising filter to pixels of regions that are outside of a penumbra while applying the denoising filter to pixels of regions that are within a penumbra."
11727621,"Apparatuses, systems, and techniques to generate blue noise masks for real-time image rendering and enhancement. In at least one embodiment, a vector-valued noise mask is generated and applied to one or more images to generate one or more enhanced images for image processing (e.g., real-time image rendering). In at least one embodiment, the noise mask includes vector values per pixel and is able to handle the temporal domain (e.g., add time to the spatial domain) to improve image quality when rendering images over multiple frames."
11727632,"In various examples, shader bindings may be recorded in a shader binding table that includes shader records. Geometry of a 3D scene may be instantiated using object instances, and each may be associated with a respective set of the shader records using a location identifier of the set of shader records in memory. The set of shader records may represent shader bindings for an object instance under various predefined conditions. One or more of these predefined conditions may be implicit in the way the shader records are arranged in memory (e.g., indexed by ray type, by sub-geometry, etc.). For example, a section selector value (e.g., a section index) may be computed to locate and select a shader record based at least in part on a result of a ray tracing query (e.g., what sub-geometry was hit, what ray type was traced, etc.)."
11729063,"Methods, systems, and devices are provided herein for providing a visually guided topology wiring scheme. As described herein, after determining that a first end of a cable has been inserted at a first port of a first peer device, a wiring application may reference a topology file to identify a second port of a second peer device with which the first peer device is intended to have a link. Subsequently, the wiring application may activate an indicator associated with the second port to mimic an indicator associated with the first port. For example, the wiring application may cause both indicators associated with each port to flash according to a same or similar flashing pattern, to produce or illuminate at a similar or identical color (e.g., approximately the same color), to flash at approximately a same rate, or by substantially synchronizing a flashing of each indicator."
11734872,"The disclosure presents a technique for utilizing ray tracing to produce high quality visual scenes with shadows while minimizing computing costs. The disclosed technique can lower the number of rays needed for shadow region rendering and still maintain a targeted visual quality for the scene. In one example, a method for denoising a ray traced scene is disclosed that includes: (1) applying a pixel mask to a data structure of data from the scene, wherein the applying uses the scene at full resolution and pixels at the edge of a depth boundary change are identified using the pixel mask, (2) generating a penumbra mask using the data structure, (3) adjusting HitT values in the packed data buffer utilizing the penumbra mask, and (4) denoising the scene by reducing scene noise in the data of the data structure with adjusted HitT values."
11734890,"A three-dimensional (3D) model of an object is recovered from two-dimensional (2D) images of the object. Each image in the set of 2D images includes the object captured from a different camera position and deformations of a base mesh that defines the 3D model may be computed corresponding to each image. The 3D model may also include a texture map that represents the lighting and material properties of the 3D model. Recovery of the 3D model relies on analytic antialiasing to provide a link between pixel colors in the 2D images and geometry of the 3D model. A modular differentiable renderer design yields high performance by leveraging existing, highly optimized hardware graphics pipelines to reconstruct the 3D model. The differential renderer renders images of the 3D model and differences between the rendered images and reference images are propagated backwards through the rendering pipeline to iteratively adjust the 3D model."
11738770,"According to an aspect of an embodiment, operations may comprise accessing an HD map of a region comprising information describing an intersection of two or more roads and describing lanes of the two or more roads that intersect the intersection, automatically identifying constraints on the lanes at the intersection, automatically calculating, based on the constraints on the lanes at the intersection, lane connectivity for the intersection, displaying, on a user interface, the automatically calculated lane connectivity for the intersection, receiving, from a user through the user interface, confirmation that the automatically calculated lane connectivity for the intersection is an actual lane connectivity for the intersection, and adding the actual lane connectivity for the intersection to the information describing the intersection in the HD map."
11741015,A system for managing virtual memory. The system includes a first processing unit configured to execute a first operation that references a first virtual memory address. The system also includes a first memory management unit (MMU) associated with the first processing unit and configured to generate a first page fault upon determining that a first page table that is stored in a first memory unit associated with the first processing unit does not include a mapping corresponding to the first virtual memory address. The system further includes a first copy engine associated with the first processing unit. The first copy engine is configured to read a first command queue to determine a first mapping that corresponds to the first virtual memory address and is included in a first page state directory. The first copy engine is also configured to update the first page table to include the first mapping.
11741633,"Disclosed are apparatuses, systems, and techniques to render images depicting light interacting with media that have volume attenuation, using optimized spectral rendering that emulates rendering of the media in tristimulus color rendering schemes."
11741736,"In various examples, sensor data—such as masked sensor data—may be used as input to a machine learning model to determine a confidence for object to person associations. The masked sensor data may focus the machine learning model on particular regions of the image that correspond to persons, objects, or some combination thereof. In some embodiments, coordinates corresponding to persons, objects, or combinations thereof, in addition to area ratios between various regions of the image corresponding to the persons, objects, or combinations thereof, may be used to further aid the machine learning model in focusing on important regions of the image for determining the object to person associations."
11741949,"In various examples, as a user is speaking or presenting content during an online video conference, the data stream may be processed to generate a textual representation (e.g., transcript) of the audio and/or information relating to the video. The textual representation and/or video related information may then be processed to determine a context or one or more topic(s) of discussion. Based on the determined context/topic(s), a corresponding neural network(s) may be selected. Once a neural network has been selected, comments may be retrieved from a chat feature of the application and applied to the neural network. The neural network may then output data to indicate the relevance of the comments to the determined discussion topic. Based on the relevance of the comment, the comment may be allowed, prioritized, deleted, de-emphasized, or otherwise filtered in the chat feature."
11742006,"Various embodiments include a memory device that is capable of performing command address interface training operations, to determine that certain timing conditions are met, with fewer I/O pins relative to prior approaches. Prior approaches for command address interface training involve loading data via a set of input pins, a clock signal, and a clock enable signal that identifies when the input pins should be sampled. Instead, the disclosed memory device generates a data pattern within the memory device that matches the data pattern continuously being transmitted to the memory device by an external memory controller. The memory device compares the generated data pattern with the received data pattern and transmits the result of the comparison on one or more data output pins. The memory controller receives and analyzes the result of the comparison to determine whether the command address interface training passed or failed."
11742007,"Various embodiments include a memory device that is capable of performing write training operations, to determine that certain timing conditions are met, without storing data patterns in memory. Prior approaches for write training involve storing a long data pattern into the memory followed by reading the long data pattern to determine whether the data was written to memory correctly. Instead, the disclosed memory device generates a data pattern within the memory device that matches the data pattern being transmitted to the memory device by an external memory controller. If the data pattern generated by the memory device matches the data pattern received from the memory controller, then the memory device stores a pass status in a register. If the data patterns do not match, then the memory device stores a pass status in a register. The memory controller reads the register to determine whether the write training passed or failed."
11745347,"Candidate grasping models of a deformable object are applied to generate a simulation of a response of the deformable object to the grasping model. From the simulation, grasp performance metrics for stress, deformation controllability, and instability of the response to the grasping model are obtained, and the grasp performance metrics are correlated with robotic grasp features."
11747455,"A system calibrates one or more sensors mounted to an autonomous vehicle. From the one or more sensors, the system identifies a primary sensor and a secondary sensor. The system determines a reference angle for the primary sensor, and based on that reference angle for the primary sensor, a scan-start time representing a start of a scan and a scan-end time representing an end of a scan. The system receives, from the primary sensor, a primary set of scan data recorded from the scan-start time to the scan-end time. The system receives, from the secondary sensor, a secondary set of sensor data recorded from the scan-start time to the scan-end time. The system calibrates the primary and secondary sensors by determining a relative transform for transforming points between the first set of scan data and the second set of scan data."
11747766,"A method for rendering a light field comprises projecting rays from a viewpoint positioned at a first side of a spatial light modulator (SLM) to a clipping plane positioned at an opposing side of the SLM to form an elemental view frustum within a three-dimensional scene and rendering objects within the elemental view frustum to generate components of a first elemental image for the first elemental region. The SLM may include a tiled array of non-overlapping elemental regions and a top edge and a bottom edge of a first elemental region of the non-overlapping elemental regions are intersected by the rays to form the elemental view frustum. Furthermore, the light field may include the first elemental image and additional elemental images corresponding to the array of elemental regions and each one of the additional elemental images is rendered using an additional elemental view frustum."
11748845,"Systems, processes, and techniques to automatically detect and enlarge a speaking one of plurality of participants on one side of a video conference. In at least one embodiment, the speaking participant is identified using one or more heuristics and/or one or more neural networks."
11748887,"Systems and methods to detect one or more segments of one or more objects within one or more images based, at least in part, on a neural network trained in an unsupervised manner to infer the one or more segments. Systems and methods to help train one or more neural networks to detect one or more segments of one or more objects within one or more images in an unsupervised manner."
11749963,"Embodiments are disclosed for driving a vertical cavity surface emitting laser (VCSEL). An example method includes injecting, via a universal driver, a direct current (DC) bias current to a VCSEL. The VCSEL is configured to convert the modulated signal into an optical signal encoding one or more bits. The example method further includes providing a modulated signal to the VCSEL. The modulated signal encodes a digital sequence comprising the one or more bits using a modulation method."
11750192,"Bit generating cells are subjected to processes that accelerate aging-related characteristics before they are configured for use in the field (enrolled). Aging improves the reliability of the cells by shifting device characteristic in a direction that improves the cell behavior with respect not only to aging but also environment variations. Outputs of the cells are read, and the cells are reconfigured with a bias to output an opposite value, and then aged for enrollment."
11750226,"Various embodiments include an error correction code (ECC) system that provides protection against various errors in addition to data bit errors. In general, ECC codes protect against data bit errors, where one or more data bits in a data word contain the wrong value. The ECC code is based on the original data bits, such that a data bit error results in a data word that is inconsistent with the ECC code generated for and stored with the data word. The present embodiments generate ECC codes based on address information and/or sequencing information in addition to the data bits in the data word. As a result, the present embodiments detect bit errors in this address information and/or sequencing information. Such errors include write address decoding errors, read address decoding errors, write enable errors, and stale data errors."
11751359,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a first flow controller within a cooling manifold is associated with a second flow controller and with a tube there between; and the first flow controller is movable in at least one direction relative to dimensions of the cooling manifold so that it can be positioned for mating with a server tray or box and so that the second flow controller can be mated with a rack manifold."
11754716,"Embodiments relate to methods for efficiently encoding sensor data captured by an autonomous vehicle and building a high definition map using the encoded sensor data. The sensor data can be LiDAR data which is expressed as multiple image representations. Image representations that include important LiDAR data undergo a lossless compression while image representations that include LiDAR data that is more error-tolerant undergo a lossy compression. Therefore, the compressed sensor data can be transmitted to an online system for building a high definition map. When building a high definition map, entities, such as road signs and road lines, are constructed such that when encoded and compressed, the high definition map consumes less storage space. The positions of entities are expressed in relation to a reference centerline in the high definition map. Therefore, each position of an entity can be expressed in fewer numerical digits in comparison to conventional methods."
11755025,"In various examples, a trigger signal may be received that is indicative of a vehicle maneuver to be performed by a vehicle. A recommended vehicle trajectory for the vehicle maneuver may be determined in response to the trigger signal being received. To determine the recommended vehicle trajectory, sensor data may be received that represents a field of view of at least one sensor of the vehicle. A value of a control input and the sensor data may then be applied to a machine learning model(s) and the machine learning model(s) may compute output data that includes vehicle control data that represents the recommended vehicle trajectory for the vehicle through at least a portion of the vehicle maneuver. The vehicle control data may then be sent to a control component of the vehicle to cause the vehicle to be controlled according to the vehicle control data."
11756254,"Light contribution information can be determined and cached for use in rendering image frames for a scene. In at least one embodiment, a spatial hash data structure can be used to split the scene into regions, such as octahedral voxels. Using cast light rays, an average light contribution can be computed for each individual voxel. Those light values can then be used to build a cumulative distribution function for each voxel that can be used to select which lights to sample for a given frame during rendering. The sampling for a region or voxel can be based at least in part upon the number of contributing lights for that region, as well as the relative contributions of those lights. Such an approach can be very bandwidth and cache efficient, while providing high image quality."
11756258,"One embodiment of a method for computing a texture color includes tracing a ray cone through a graphics scene, determining a curvature of a first surface within the graphics scene at a point where the ray cone hits the first surface based on differential barycentric coordinates associated with the point, determining, based on the curvature of the first surface, a width of the ray cone at a subsequent point where the ray cone hits a second surface within the graphics scene, and computing a texture color based on the width of the ray cone."
11757615,"A device includes feed-forward clock circuitry to provide a receiver (RX) clock to a sampler circuit that samples a data lane of a set of RX data lanes, the feed-forward clock circuitry having a temperature-induced delay. The device also includes an RX phase-locked loop (PLL) coupled between the feed-forward clock circuitry and the sampler circuit. The RX PLL includes a phase interpolator positioned in a feedback path of the RX PLL. The phase interpolator has a negative delay that matches the temperature-induced delay of the feed-forward clock circuitry to cause the sampler circuit to cancel out the common noise shared between the feed-forward clock circuitry and the data lane."
11758120,"In one embodiment, a system determines pixel data from a pair of regions of an image generated by an imaging device, the pair of regions includes a first region and a second region, where the first region includes a first plurality of pixels and the second region includes a second plurality of pixels. The system determines a plurality of pixel pairs of the image, where a pixel pair includes a first pixel from the first plurality of pixels and a second pixel from the second plurality of pixels. The system calculates a plurality of contrasts based on the plurality of pixel pairs, where a contrast is calculated between the first pixel and the second pixel. The system determines a contrast distribution based on the plurality of contrasts. The system calculates a value representative of a capability of the imaging device to detect contrast based on the contrast distribution."
11763168,"A generative adversarial neural network (GAN) learns a particular task by being shown many examples. In one scenario, a GAN may be trained to generate new images including specific objects, such as human faces, bicycles, etc. Rather than training a complex GAN having a predetermined topology of features and interconnections between the features to learn the task, the topology of the GAN is modified as the GAN is trained for the task. The topology of the GAN may be simple in the beginning and become more complex as the GAN learns during the training, eventually evolving to match the predetermined topology of the complex GAN. In the beginning the GAN learns large-scale details for the task (bicycles have two wheels) and later, as the GAN becomes more complex, learns smaller details (the wheels have spokes)."
11763520,"Determining the occlusions or shadows for an area light within a scene is difficult, especially realistic shadowing in large and dynamic scenes. The disclosure provides an adaptive occlusion sampling process that uses voxel cone tracing to distribute the voxel tracing cones on the surface of area lights to obtain samples for shadowing in computer generated images or scenes. A method of adaptive occlusion sampling from a rectangular area light is disclosed that can be used to provide realistic shadowing in a computer generated scene. A process to compute a shadow of an area light within a scene is also disclosed herein that includes obtaining samples, employing voxel cone tracing, from a light surface of the area light based on sample points of a sampling grid created from sample patterns that are based on a determined number of cones."
11768241,"In various examples, a test system is provided for executing built-in-self-test (BIST) on integrated circuits deployed in the field. The integrated circuits may include a first device and a second device, the first device having direct access to external memory, which stores test data, and the second device having indirect access to the external memory by way of the first device. In addition to providing a mechanism to permit the first device and the second device to run test concurrently, the hardware and software may reduce memory requirements and runtime associated with running the test sequences, thereby making real-time BIST possible in deployment. Furthermore, some embodiments permit a single external memory image to cater to different SKU configurations."
11768686,"In a streaming cache, multiple, dynamically sized tracking queues are employed. Request tracking information is distributed among the plural tracking queues to selectively enable out-of-order memory request returns. A dynamically controlled policy assigns pending requests to tracking queues, providing for example in-order memory returns in some contexts and/or for some traffic and out of order memory returns in other contexts and/or for other traffic."
11769040,"A distributed deep neural net (DNN) utilizing a distributed, tile-based architecture implemented on a semiconductor package. The package includes multiple chips, each with a central processing element, a global memory buffer, and processing elements. Each processing element includes a weight buffer, an activation buffer, and multiply-accumulate units to combine, in parallel, the weight values and the activation values."
11769052,"In various examples, a deep neural network (DNN) is trained—using image data alone—to accurately predict distances to objects, obstacles, and/or a detected free-space boundary. The DNN may be trained with ground truth data that is generated using sensor data representative of motion of an ego-vehicle and/or sensor data from any number of depth predicting sensors—such as, without limitation, RADAR sensors, LIDAR sensors, and/or SONAR sensors. The DNN may be trained using two or more loss functions each corresponding to a particular portion of the environment that depth is predicted for, such that—in deployment—more accurate depth estimates for objects, obstacles, and/or the detected free-space boundary are computed by the DNN. In some embodiments, a sampling algorithm may be used to sample depth values corresponding to an input resolution of the DNN from a predicted depth map of the DNN at an output resolution of the DNN."
11769298,"The disclosure introduces polar stroking for representing paths. A system, method, and apparatus are disclosed for representing and rendering stroked paths employing polar stroking. In one example, a method of approximating a path is provided that includes: (1) evaluating, in parallel, multiple links of a path, wherein each link of the multiple links is evaluated in steps based on tangent angle changes of the link, and (2) providing a polar stroked representation of the path employing the steps. A computing system for rendering is also provided. In one example, the computing system includes one or more processing units to perform one or more operations including generating, in parallel, a polar stroked representation of individual links of a path, and rendering a stroked tessellation of the path based on the polar stroked representations of the individual links."
11769481,Generation of synthetic speech from an input text sequence may be difficult when durations of individual phonemes forming the input text sequence are unknown. A predominantly parallel process may model speech rhythm as a separate generative distribution such that phoneme duration may be sampled at inference. Additional information such as pitch or energy may also be sampled to provide improved diversity for synthetic speech generation.
11769495,"In various examples, systems and methods of the present disclosure combine open and closed dialog systems into an intelligent dialog management system. A text query may be processed by a natural language understanding model trained to associate the text query with a domain tag, intent classification, and/or input slots. Using the domain tag, the natural language understanding model may identify information in the text query corresponding to input slots needed for answering the text query. The text query and related information may then be passed to a dialog manager to direct the text query to the proper domain dialog system. Responses retrieved from the domain dialog system may be provided to the user via text output and/or via a text to speech component of the dialog management system."
11770215,"Packet flows between a transmitter and a receiver in an unreliable and unordered switched packet network may be established as a result of receiving a second packet comprising a second memory operation on a memory address. The transmission of memory load command packets followed by memory store command packets in the packet flow may be serialized, and a synchronization operation may be executed between the transmitter and the receiver when a packet count at the receiver satisfies a number of data packets in the packet flow."
11774250,"According to an aspect of an embodiment, operations may comprise accessing high definition (HD) map data of a region, presenting, via a user interface, information describing the HD map data, receiving instructions, via the user interface, for modifying the HD map data by adding one or more synthetic objects to locations in the HD map data, modifying the HD map data based on the received instructions, and generating a synthetic track in the modified HD map data comprising, for each of one or more vehicle poses, generated synthetic sensor data based on the one or more synthetic objects in the modified HD map data."
11774963,"In various examples, at least partial control of a vehicle may be transferred to a control system remote from the vehicle. Sensor data may be received from a sensor(s) of the vehicle and the sensor data may be encoded to generate encoded sensor data. The encoded sensor data may be transmitted to the control system for display on a virtual reality headset of the control system. Control data may be received by the vehicle and from the control system that may be representative of a control input(s) from the control system, and actuation by an actuation component(s) of the vehicle may be caused based on the control input."
11775570,"High definition maps for autonomous vehicles are very high resolution and detailed, and hence require storage of a great deal of data. A vehicle computing system provides multi-layered caching makes this data usable in a system that requires very low latency on every operation. The system determines which routes are most likely to be driven in the near future by the car, and ensures that the route is cached on the vehicle before beginning the route. The system provides efficient formats for moving map data from server to car and for managing the on-car disk. The system further provides real-time accessibility of nearby map data as the car moves, while providing data access at optimal speeds."
11775829,"A latent code defined in an input space is processed by the mapping neural network to produce an intermediate latent code defined in an intermediate latent space. The intermediate latent code may be used as appearance vector that is processed by the synthesis neural network to generate an image. The appearance vector is a compressed encoding of data, such as video frames including a person's face, audio, and other data. Captured images may be converted into appearance vectors at a local device and transmitted to a remote device using much less bandwidth compared with transmitting the captured images. A synthesis neural network at the remote device reconstructs the images for display."
11776490,"A display device includes an array of LEDs, an array of LCD pixels, and a display controller that compensates for one or more sources of color variation in light produced by the LEDs having multiple color components that change differently as a function of distance. The display controller can determine a variation of a received color value from a color of light emitted by a given LED at a given LCD pixel based on the distance between the given LCD pixel and the given LED, and determine an accumulated color value that includes the variation and multiple other corresponding variations of other received color values of light emitted by multiple other emitters determined based on respective distances from the given LCD pixel. The display controller configures the given LCD pixel to filter light that is received from the LEDs in a manner that reduces or eliminates the color variation."
11777483,"In various embodiments, a comparison circuit compares voltages within an integrated circuit. The comparison circuit includes a comparison capacitor, an inverter, and multiple switches. A first terminal of the comparison capacitor is coupled to both a first terminal of a first switch and a first terminal of a second switch. A second terminal of the comparison capacitor is coupled to both a first terminal of a third switch and an input of the inverter. An output of the inverter is coupled to both a second terminal of the third switch and a first terminal of a fourth switch. A second terminal of the fourth switch is coupled to a first terminal of a fifth switch and a first output of the comparison circuit. At least a portion of the switches are turned on during a comparison model and are turned off during a reset mode."
11783230,"In various examples, object detections of a machine learning model are leveraged to automatically generate new ground truth data for images captured at different perspectives. The machine learning model may generate a prediction of a detected object at the different perspective, and an object tracking algorithm may be used to track the object through other images in a sequence of images where the machine learning model may not have detected the object. New ground truth data may be generated as a result of the object tracking algorithms outputs, and the new ground truth data may be used to retrain or update the machine learning model, train a different machine learning model, or increase the robustness of a ground truth data set that may be used for training machine learning models from various perspectives."
11783455,"Approaches presented herein can reduce temporal lag that may be introduced in a generated image sequence that utilizes temporal accumulation for denoising in dynamic scenes. A fast historical frame can be generated along with a full historical frame generated for a denoising process, with the fast historical frame being accumulated using an exponential moving average with a significantly higher blend weight. This fast history frame can be used to determine a clamping window that can be used to clamp a corresponding full historical value before, or after, reprojection. The fast historical blend weight can be adjusted to control the amount of noise versus temporal lag in an image sequence. In some embodiments, differences between fast and full historical values can also be used to determine an amount of spatial filtering to be applied."
11783510,"Apparatuses, systems, and techniques are presented to generate image or video content representing at least one point of view. In at least one embodiment, one or more neural networks are used to generate one or more images of one or more objects from a first point of view based at least in part upon one or more images of the one or more objects from a second point of view."
11783532,"A target image corresponding to a novel view may be synthesized from two source images, corresponding source camera poses, and pixel attribute correspondences between the two source images. A particular object in the target image need only be visible in one of the two source images for successful synthesis. Each pixel in the target image is defined according to an identified pixel in one of the two source images. The identified source pixel provides attributes such as color, texture, and feature descriptors for the target pixel. The source and target camera poses are used to define geometric relationships for identifying the source pixels. In an embodiment, the pixel attribute correspondences are optical flow that defines movement of attributes from a first image of the two source images to a second image of the two source images."
11784835,"A circuit includes a set of multiple bit generating cells. One or more adjustable characterization circuits are coupled to inputs to the bit generating cells to affect the outputs of the bit generating cells. Based on the effect of the characterization circuit(s) on the outputs of the bit generating cells, a subset less than all of the bit generating cells is selected."
11784890,"A system includes a first device and a second device coupled to a link including two or more data paths and a first portion and a second portion. The first device is to transmit a number of bits corresponding to a message before training the link on the first portion of the link, where the number of bits is equal to a number of the two or more data paths, and where each data path transmits one bit of the number of bits. The second device is to receive the message before training the link. The second device is to perform a decode operation on the number of bits received to determine the corresponding message and transmit a second message or data on the second portion of the link in response to performing the decode operation on the number of bits."
11784906,"A display device for measuring the end-to-end latency of a computing system. The computing system includes an input device, a computing device, and the display device. The display device is directly connected with the input device and receives input data packets generated by the input device in response to received user input events. The display device passes the input packets to the computing device for graphics processing. The display device measures the end-to-end latency comprising the sum of three latencies. A first latency comprises an input delay of the input device. A second latency comprises an amount of time between generation of the input packet and a corresponding change in pixel values caused by the input event at the display device. A third latency comprises a display latency. The display device also displays latency information associated with the measured end-to-end latency."
11788861,"An end-to-end system for data generation, map creation using the generated data, and localization to the created map is disclosed. Mapstreams—or streams of sensor data, perception outputs from deep neural networks (DNNs), and/or relative trajectory data—corresponding to any number of drives by any number of vehicles may be generated and uploaded to the cloud. The mapstreams may be used to generate map data—and ultimately a fused high definition (HD) map—that represents data generated over a plurality of drives. When localizing to the fused HD map, individual localization results may be generated based on comparisons of real-time data from a sensor modality to map data corresponding to the same sensor modality. This process may be repeated for any number of sensor modalities and the results may be fused together to determine a final fused localization result."
11789445,"In various examples, at least partial control of a vehicle may be transferred to a control system remote from the vehicle. Sensor data may be received from a sensor(s) of the vehicle and the sensor data may be encoded to generate encoded sensor data. The encoded sensor data may be transmitted to the control system for display on a virtual reality headset of the control system. Control data may be received by the vehicle and from the control system that may be representative of a control input(s) from the control system, and actuation by an actuation component(s) of the vehicle may be caused based on the control input."
11789449,"In various examples, sensor data representative of a field of view of at least one sensor of a vehicle in an environment is received from the at least one sensor. Based at least in part on the sensor data, parameters of an object located in the environment are determined. Trajectories of the object are modeled toward target positions based at least in part on the parameters of the object. From the trajectories, safe time intervals (and/or safe arrival times) over which the vehicle occupying the plurality of target positions would not result in a collision with the object are computed. Based at least in part on the safe time intervals (and/or safe arrival times) and a position of the vehicle in the environment a trajectory for the vehicle may be generated and/or analyzed."
11789649,A combined on-package and off-package memory system uses a custom base-layer within which are fabricated one or more dedicated interfaces to off-package memories. An on-package processor and on-package memories are also directly coupled to the custom base-layer. The custom base-layer includes memory management logic between the processor and memories (both off and on package) to steer requests. The memories are exposed as a combined memory space having greater bandwidth and capacity compared with either the off-package memories or the on-package memories alone. The memory management logic services requests while maintaining quality of service (QoS) to satisfy bandwidth requirements for each allocation. An allocation may include any combination of the on and/or off package memories. The memory management logic also manages data migration between the on and off package memories.
11789811,"Often there are errors when reading data from computer memory. To detect and correct these errors, there are multiple types of error correction codes. Disclosed is an error correction architecture that creates a codeword having a data portion and an error correction code portion. Swizzling rearranges the order of bits and distributes the bits among different codewords. Because the data is redistributed, a potential memory error of up to N contiguous bits, where N for example equals 2 times the number of codewords swizzled together, only affects up to, at most, two bits per swizzled codeword. This keeps the error within the error detecting capabilities of the error correction architecture. Furthermore, this can allow improved error correction and detection without requiring a change to error correcting code generators and checkers."
11789869,"The technology disclosed herein involves tracking contention and using the tracked contention to reduce latency of exclusive memory operations. The technology enables a processor to track which locations in main memory are contentious and to modify the order exclusive memory operations are processed based on the contentiousness. A thread can include multiple exclusive operations for the same memory location (e.g., exclusive load and a complementary exclusive store). The multiple exclusive memory operations can be added to a queue and include one or more intervening operations between them in the queue. The processor may process the operations in the queue based on the order they were added and may use the tracked contention to perform out-of-order processing for some of the exclusive operations. For example, the processor can execute the exclusive load operation and because the corresponding location is contentious can process the complementary exclusive store operation before the intervening operations."
11790230,"In various examples, a deep neural network (DNN) is trained to accurately predict, in deployment, distances to objects and obstacles using image data alone. The DNN may be trained with ground truth data that is generated and encoded using sensor data from any number of depth predicting sensors, such as, without limitation, RADAR sensors, LIDAR sensors, and/or SONAR sensors. Camera adaptation algorithms may be used in various embodiments to adapt the DNN for use with image data generated by cameras with varying parameters—such as varying fields of view. In some examples, a post-processing safety bounds operation may be executed on the predictions of the DNN to ensure that the predictions fall within a safety-permissible range."
11790556,"Optical center is determined on a column-by-column and row-by-row basis by identifying brightest pixels in respective columns and rows. The brightest pixels in each column are identified and a line is fit to those pixels. Similarly, brightest pixels in each row are identified and a second line is fit to those pixels. The intersection of the two lines is the optical center."
11790594,"Disclosed approaches provide for irradiance caches which may be used to share irradiance between ray interactions spatially and/or temporally. An irradiance cache may store incoming irradiance or outgoing irradiance and may be updated by casting one or more rays from one or more locations to sample irradiance for the location(s). The number of rays that are cast may be reduced by ranking the locations, irradiance caches, and/or corresponding groups of geometry based on one or more characteristics thereof. For example, a ranking score may be computed based on camera distance, camera visibility, and/or a number of frames since a prior update. When sampling a location, outgoing irradiance from an outgoing irradiance cache may be used to determine shading when a hit distance of a ray used to generate the sample exceeds a threshold value."
11790595,"A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include opaque and alpha triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to determine primitives intersected by the ray, and return intersection information to a streaming multiprocessor for further processing. The hardware-based traversal coprocessor is configured to provide a deterministic result of intersected triangles regardless of the order that the memory subsystem returns triangle range blocks for processing, while opportunistically eliminating alpha intersections that lie further along the length of the ray than closer opaque intersections."
11790596,"Various techniques for adaptive rendering of images with noise reduction are described. More specifically, the present disclosure relates to approaches for rendering and denoising images—such as ray-traced images—in an iterative process that distributes computational efforts to pixels where denoised output is predicted with higher uncertainty. In some embodiments, an input image may be fed into a deep neural network (DNN) to jointly predict a denoised image and an uncertainty map. The uncertainty map may be used to create a distribution of additional samples (e.g., for one or more samples per pixel on average), and the additional samples may be used with the input image to adaptively render a higher quality image. This process may be repeated in a loop, until some criterion is satisfied, for example, when the denoised image converges to a designated quality, a time or sampling budget is satisfied, or otherwise."
11790598,"A three-dimensional (3D) density volume of an object is constructed from tomography images (e.g., x-ray images) of the object. The tomography images are projection images that capture all structures of an object (e.g., human body) between a beam source and imaging sensor. The beam effectively integrates along a path through the object producing a tomography image at the imaging sensor, where each pixel represents attenuation. A 3D reconstruction pipeline includes a first neural network model, a fixed function backprojection unit, and a second neural network model. Given information for the capture environment, the tomography images are processed by the reconstruction pipeline to produce a reconstructed 3D density volume of the object. In contrast with a set of 2D slices, the entire 3D density volume is reconstructed, so two-dimensional (2D) density images may be produced by slicing through any portion of the 3D density volume at any angle."
11790609,"A method, computer readable medium, and system are disclosed for overlaying a cell onto a polygon meshlet. The polygon meshlet may include a grouping of multiple geometric shapes such as triangles, and the cell may include a square-shaped boundary. Additionally, every polygon (e.g., a triangle or other geometric shape) within the polygon meshlet that has at least one edge fully inside the cell is removed to create an intermediate meshlet. A selected vertex is determined from all vertices (e.g., line intersections) of the intermediate meshlet that are located within the cell, based on one or more criteria, and all the vertices of the intermediate meshlet that are located within the cell are replaced with the selected vertex to create a modified meshlet. The modified meshlet is then rendered (e.g., as part of a process to generate a scene to be viewed)."
11790633,"The disclosure provides a learning framework that unifies both semantic segmentation and semantic edge detection. A learnable recurrent message passing layer is disclosed where semantic edges are considered as explicitly learned gating signals to refine segmentation and improve dense prediction quality by finding compact structures for message paths. The disclosure includes a method for coupled segmentation and edge learning. In one example, the method includes: (1) receiving an input image, (2) generating, from the input image, a semantic feature map, an affinity map, and a semantic edge map from a single backbone network of a convolutional neural network (CNN), and (3) producing a refined semantic feature map by smoothing pixels of the semantic feature map using spatial propagation, and controlling the smoothing using both affinity values from the affinity map and edge values from the semantic edge map."
11790669,"In various examples, systems and methods are disclosed herein for a vehicle command operation system that may use technology across multiple modalities to cause vehicular operations to be performed in response to determining a focal point based on a gaze of an occupant. The system may utilize sensors to receive first data indicative of an eye gaze of an occupant of the vehicle. The system may utilize sensors to receive second data indicative of other data from the occupant. The system may then calculate a gaze vector based on the data indicative of the eye gaze of the occupant. The system may determine a focal point based on the gaze vector. In response to determining the focal point, the system causes an operation to be performed in the vehicle based on the second data."
11791319,"Edge-connected semiconductor systems are described along with methods of making and using the same. First and second integrated circuit packages are obtained, each including a substrate assembly having top and bottom sides and an edge that extends between the top and the bottom sides. Edge contacts are disposed on the edges of the substrate assemblies. A ganged assembly is formed by establishing conductive paths between the edge contacts of the substrate assemblies. The ganged assembly is coupled to a printed circuit board (“PCB”) by coupling host contacts on one or more of the substrate assemblies to corresponding contacts on the PCB."
11791871,"Apparatuses, systems, and techniques to determine precoding weights for fifth-generation (5G) new radio (NR) downlink transmission in parallel. In at least one embodiment, a parallel processor includes one or more circuits to perform precoding for a 5G downlink signal using two or more processing threads in parallel."
11791938,"Apparatuses, systems, and techniques to decode encoded data. In at least one embodiment, parts of information for decoding the encoded data is provided to a plurality of processors, and parts of data decoded by the plurality of processors is combined."
11792451,"Embodiments of the present invention provide a low-latency approach for local or remote application streaming that reaches high FPS targets without overloading the available streaming bandwidth, for example, by limiting the bit rate to the same value that is used by traditional 60 FPS streaming solutions. A client device and server device cooperate to actively monitor and control a video stream to maintain an acceptable balance between latency and video quality by adjusting the frequency or resolution when necessary to improve the streaming experience. When the server device captures and transmits frames at a higher rate, the software stack executing on the client device is able to display frames with less delay, even on a display device limited to 60 Hz, thereby achieving additional latency reduction."
11797301,"A method, computer readable medium, and processor are disclosed for performing matrix multiply and accumulate (MMA) operations. The processor includes a datapath configured to execute the MMA operation to generate a plurality of elements of a result matrix at an output of the datapath. Each element of the result matrix is generated by calculating at least one dot product of corresponding pairs of vectors associated with matrix operands specified in an instruction for the MMA operation. A dot product operation includes the steps of: generating a plurality of partial products by multiplying each element of a first vector with a corresponding element of a second vector; aligning the plurality of partial products based on the exponents associated with each element of the first vector and each element of the second vector; and accumulating the plurality of aligned partial products into a result queue utilizing at least one adder."
11797302,"A method, computer readable medium, and processor are disclosed for performing matrix multiply and accumulate (MMA) operations. The processor includes a datapath configured to execute the MMA operation to generate a plurality of elements of a result matrix at an output of the datapath. Each element of the result matrix is generated by calculating at least one dot product of corresponding pairs of vectors associated with matrix operands specified in an instruction for the MMA operation. A dot product operation includes the steps of: generating a plurality of partial products by multiplying each element of a first vector with a corresponding element of a second vector; aligning the plurality of partial products based on the exponents associated with each element of the first vector and each element of the second vector; and accumulating the plurality of aligned partial products into a result queue utilizing at least one adder."
11797303,"A method, computer readable medium, and processor are disclosed for performing matrix multiply and accumulate (MMA) operations. The processor includes a datapath configured to execute the MMA operation to generate a plurality of elements of a result matrix at an output of the datapath. Each element of the result matrix is generated by calculating at least one dot product of corresponding pairs of vectors associated with matrix operands specified in an instruction for the MMA operation. A dot product operation includes the steps of: generating a plurality of partial products by multiplying each element of a first vector with a corresponding element of a second vector; aligning the plurality of partial products based on the exponents associated with each element of the first vector and each element of the second vector; and accumulating the plurality of aligned partial products into a result queue utilizing at least one adder."
11798183,"Apparatuses, systems, and techniques to estimate or predict depth information for image data. In at least one embodiment, depth information is predicted based at least in part on color information and geometry information associated with an image."
11798514,"Embodiments of the present invention provide a novel solution that uses subjective end-user input to generate optimal image quality settings for an application. Embodiments of the present invention enable end-users to rank and/or select various adjustable application parameter settings in a manner that allows them to specify which application parameters and/or settings are most desirable to them for a given application. Based on the feedback received from end-users, embodiments of the present invention may generate optimal settings for whatever performance level the end-user desires. Furthermore, embodiments of the present invention may generate optimal settings that may be benchmarked either on a server farm or on an end-user's client device."
11798923,Layout techniques for chip packages on printed circuit boards are disclosed that address the multivariate problem of minimizing routing distances for high-speed I/O pins between chip packages while simultaneously providing for the rapid provision of transient power demands to the chip packages. The layout techniques may also enable improved thermal management for the chip packages.
11799799,"A switch architecture enables ports to stash packets in unused buffers on other ports, exploiting excess internal bandwidth that may exist, for example, in a tiled switch. This architecture leverages unused port buffer memory to improve features such as congestion handling and error recovery."
11799953,"Methods, systems, and devices are provided herein for a mechanism to identify link down reasons. As described herein, a first port of a first peer device may be determined to have unexpectedly changed to a port down state. Subsequently, a topology file may be referenced to identify a second port of a second peer device with which the first peer device is intended to have a link if not for the first port being in a port down state. In some examples, port settings of the first port may be compared with port settings of the second port. If a port setting for the first port mismatches an associated port setting for the second port, an alert message may be transmitted to a network administrator indicating this mismatch as a possible reason for the first port being in the port down state."
11801443,One embodiment of a computer-implemented method for generating mouse sensitivity recommendations includes generating mouse movement data corresponding to one or more mouse movements performed by a user while interacting with a software application; generating a predicted efficiency for each mouse sensitivity level included in a plurality of mouse sensitivity levels based on the mouse movement data; and determining one or more mouse sensitivity levels to provide to the user based on the predicted efficiencies.
11801861,"In various examples, systems and methods are disclosed that preserve rich, detail-centric information from a real-world image by augmenting the real-world image with simulated objects to train a machine learning model to detect objects in an input image. The machine learning model may be trained, in deployment, to detect objects and determine bounding shapes to encapsulate detected objects. The machine learning model may further be trained to determine the type of road object encountered, calculate hazard ratings, and calculate confidence percentages. In deployment, detection of a road object, determination of a corresponding bounding shape, identification of road object type, and/or calculation of a hazard rating by the machine learning model may be used as an aid for determining next steps regarding the surrounding environment—e.g., navigating around the road debris, driving over the road debris, or coming to a complete stop—in a variety of autonomous machine applications."
11803192,"Systems and methods for performing visual odometry more rapidly. Pairs of representations from sensor data (such as images from one or more cameras) are selected, and features common to both representations of the pair are identified. Portions of bundle adjustment matrices that correspond to the pair are updated using the common features. These updates are maintained in register memory until all portions of the matrices that correspond to the pair are updated. By selecting only common features of one particular pair of representations, updated matrix values may be kept in registers. Accordingly, matrix updates for each common feature may be collectively saved with a single write of the registers to other memory. In this manner, fewer write operations are performed from register memory to other memory, thus reducing the time required to update bundle adjustment matrices and thus speeding the bundle adjustment process."
11803380,"To synchronize operations of a computing system, a new type of synchronization barrier is disclosed. In one embodiment, the disclosed synchronization barrier provides for certain synchronization mechanisms such as, for example, “Arrive” and “Wait” to be split to allow for greater flexibility and efficiency in coordinating synchronization. In another embodiment, the disclosed synchronization barrier allows for hardware components such as, for example, dedicated copy or direct-memory-access (DMA) engines to be synchronized with software-based threads."
11803668,"In various examples, an integrated circuit includes first and second portions operating within separate domains. The second portion has an interface that connects the first and second portions. The second portion selectively locks the interface to prevent communication with the first portion over the interface, and selectively unlocks the interface to allow communication with the first portion over the interface."
11803759,"Apparatuses, systems, and techniques are described to determine locations of objects using images including digital representations of those objects. In at least one embodiment, a gaze of one or more occupants of a vehicle is determined independently of a location of one or more sensors used to detect those occupants."
11804000,"Methods and systems are described in some examples for changing the traversal of an acceleration data structure in a highly dynamic query-specific manner, with each query specifying test parameters, a test opcode and a mapping of test results to actions. In an example ray tracing implementation, traversal of a bounding volume hierarchy by a ray is performed with the default behavior of the traversal being changed in accordance with results of a test performed using the test opcode and test parameters specified in the ray data structure and another test parameter specified in a node of the bounding volume hierarchy. In an example implementation a traversal coprocessor is configured to perform the traversal of the bounding volume hierarchy."
11804002,"Ray tracing hardware accelerators supporting multiple specifiers for controlling the traversal of a ray tracing acceleration data structure are disclosed. For example, traversal efficiency and complex ray tracing effects can be achieved by specifying traversals through such data structures using both programmable ray operations and explicit node masking. The explicit node masking utilizes dedicated fields in the ray and in nodes of the acceleration data structure to control traversals. Ray operations, however, are programmable per ray using opcodes and additional parameters to control traversals. Traversal efficiency is improved by enabling more aggressive culling of parts of the data structure based on the combination of explicit node masking and programmable ray operations. More complex ray tracing effects are enabled by providing for dynamic selection of nodes based on individual ray characteristics."
11804003,"High quality image rendering can be achieved in part by using inverse transform sampling to direct sampling toward regions of greater importance, such as regions with higher brightness values, to reduce noise and improve convergence. Inverse transform sampling can be achieved more efficiently by reformulating as a ray-tracing problem, using tree traversal units that can be accelerated. A geometric mesh can be generated based on a set of cumulative distribution functions (CDFs) for various rows and columns of pixels in a texture, and individual rays can be traced against this mesh, with those rays having a higher probability of intersection at a point with greater importance, such as a higher brightness value. A probability distribution function to be used for importance sampling can be derived by analyzing partial derivatives of the CDF geometry at the intersection location."
11804050,"Apparatuses, systems, and techniques to collaboratively train one or more machine learning models. Parameter reviewers may be configured to compare sets of machine learning model parameter information in order to generate one or more machine learning models, such as neural networks."
11804262,"A machine memory includes multiple memory cells. Word lines, each with at least one word line driver, are coupled to the memory cells along rows. The word line drivers of at least some adjacent pairs of the word lines are coupled together by a pull-down transistor, in a manner that reduces read disturb of the memory cells."
11804708,"An electrostatic discharge protection circuit is disclosed. It comprises a stacked drain-ballasted NMOS devices structure and a gate bias circuit. The gate bias circuit includes an inverter, a first gate bias output terminal, and a second gate bias output terminal. The first gate bias output terminal is coupled to a gate of a first one of the drain-ballasted NMOS devices. The second gate bias output terminal runs from an output of the inverter to a gate of a second one of the drain-ballasted NMOS devices."
11806616,"A game-agnostic event detector can be used to automatically identify game events. Game-specific configuration data can be used to specify types of pre-processing to be performed on media for a game session, as well as types of detectors to be used to detect events for the game. Event data for detected events can be written to an event log in a form that is both human- and process-readable. The event data can be used for various purposes, such as to generate highlight videos or provide player performance feedback."
11808805,"One embodiment of the present invention sets forth an integrated circuit. The integrated circuit includes a plurality of subunits associated with a plurality of operating voltages. The integrated circuit also includes one or more voltage regulator circuits that convert a first input voltage into a first plurality of output voltages during a first test, wherein the plurality of output voltages is delivered to the plurality of subunits via a plurality of output channels."
11809319,"The technology disclosed herein involves tracking contention and using the tracked contention to manage processor cache. The technology can be implemented in a processor's cache controlling logic and can enable the processor to track which locations in main memory are contentious. The technology can use the contentiousness of locations to determine where to store the data in cache and how to allocate and evict cache lines in the cache. In one example, the technology can store the data in a shared cache when the location is contentious and can bypass the shared cache and store the data in the private cache when the location is uncontentious. This may be advantageous because storing the data in shared cache can reduce or avoid having multiple copies in different private caches and can reduce the cache coherency overhead involved to keep copies in the private caches in sync."
11809719,"Various embodiments include a memory device that is capable of performing write training operations. Prior approaches for write training involve storing a long data pattern into the memory followed by reading the long data pattern to determine whether the data was written to memory correctly. Instead, the disclosed memory device stores a first data pattern (e.g., in a FIFO memory within the memory device) or generates the first data pattern (e.g., using PRBS) that is compared with a second data pattern being transmitted to the memory device by an external memory controller. If data patterns match, then the memory device stores a pass status in a register, otherwise a fail status is stored in the register. The memory controller reads the register to determine whether the write training passed or failed."
11809773,"A virtual reality (VR) audio rendering system and method include spatializing microphone-captured real-world sounds according to a VR setting. In a game streaming system, when a player speaks through a microphone, the voice is processed by geometrical acoustic (GA) simulation configured for a virtual scene, and thereby spatialized audio effects specific to the scene are added. The GA simulation may include generating an impulse response using sound propagation simulation and dynamic HRTF-based listener directivity. When the GA-processed voice of the player is played, the local player or other fellow players can hear it as if the sound travels in the scenery and according to the geometries in the virtual scene. This mechanism can advantageously place the players' chatting in the same virtual world like built-in game audio, thereby advantageously providing enhanced immersive VR experience to users."
11809989,"When a signal glitches, logic receiving the signal may change in response, thereby charging and/or discharging nodes within the logic and dissipating power. Providing a glitch-free signal may reduce the number of times the nodes are charged and/or discharged, thereby reducing the power dissipation. A technique for eliminating glitches in a signal is to insert a storage element that samples the signal after it is done changing to produce a glitch-free output signal. The storage element is enabled by a “ready” signal having a delay that matches the delay of circuitry generating the signal. The technique prevents the output signal from changing until the final value of the signal is achieved. The output signal changes only once, typically reducing the number of times nodes in the logic receiving the signal are charged and/or discharged so that power dissipation is also reduced."
11810268,"Apparatuses, systems, and techniques are presented to generate images with one or more visual effects applied. In at least one embodiment, one or more visual effects are applied to one or more images having a resolution that is less than a first resolution and those visual effects approximated for one or more images having a resolution that is greater than or equal to the first resolution."
11810274,"Apparatuses, systems, and techniques to perform effective tone management for image data. In an embodiment, a set of contrast gain curves are generated corresponding to a set of tonal ranges of an input image. An output image may then be generated by at least applying corresponding contrast gain curves to tonal ranges of the input image."
11810308,"Due to the factors such as lens distortion and camera misalignment, stereoscopic image pairs often contain vertical disparities. Introduced herein is a method and apparatus that determine and correct vertical disparities in stereoscopic image pairs using an optical flow map. Instead of discarding vertical motion vectors of the optical flow map, the introduced concept extracts and analyzes the vertical motion vectors from the optical flow map and vertically aligns the images using the vertical disparity determined from the vertical motion vectors. The introduced concept recognizes that although not apparent, vertical motion does exist in stereoscopic images and can be used to correct the vertical disparity in stereoscopic images."
11810632,"In various examples, a test system is provided for executing built-in-self-test (BIST) according to JTAG and IEEE 1500 on chips deployed in-field. Hardware and software selectively connect onto the IEEE 1500 serial interface for running BIST while the chip is being used in deployment—such as in an autonomous vehicle. In addition to providing a mechanism to connect onto the serial interface, the hardware and software may reduce memory requirements and runtime associated with running the test sequences, thereby making BIST possible in deployment. Furthermore, some embodiments include components configured to store functional states of clocks, power, and input/output prior to running BIST, which permits restoration of the functional states after the BIST."
11812589,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a refrigerant distribution unit (RDU) distributes first refrigerant from a refrigerant reservoir to one or more cold plates to extract heat from at least one computing device and also interfaces between a first refrigerant cooling loop having a first refrigerant and a second refrigerant cooling loop, so that a second refrigerant cooling loop uses second refrigerant to dissipate at least part of such heat through a second condenser unit to an ambient environment."
11816185,"Volumetric quantification can be performed for various parameters of an object represented in volumetric data. Multiple views of the object can be generated, and those views provided to a set of neural networks that can generate inferences in parallel. The inferences from the different networks can be used to generate pseudo-labels for the data, for comparison purposes, which enables a co-training loss to be determined for the unlabeled data. The co-training loss can then be used to update the relevant network parameters for the overall data analysis network. If supervised data is also available then the network parameters can further be updated using the supervised loss."
11816404,"Monte Carlo and quasi-Monte Carlo integration are simple numerical recipes for solving complicated integration problems, such as valuating financial derivatives or synthesizing photorealistic images by light transport simulation. A drawback of a straightforward application of (quasi-)Monte Carlo integration is the relatively slow convergence rate that manifests as high error of Monte Carlo estimators. Neural control variates may be used to reduce error in parametric (quasi-)Monte Carlo integration—providing more accurate solutions in less time. A neural network system has sufficient approximation power for estimating integrals and is efficient to evaluate. The efficiency results from the use of a first neural network that infers the integral of the control variate and using normalizing flows to model a shape of the control variate."
11816481,"A method, computer readable medium, and processor are disclosed for performing matrix multiply and accumulate (MMA) operations. The processor includes a datapath configured to execute the MMA operation to generate a plurality of elements of a result matrix at an output of the datapath. Each element of the result matrix is generated by calculating at least one dot product of corresponding pairs of vectors associated with matrix operands specified in an instruction for the MMA operation. A dot product operation includes the steps of: generating a plurality of partial products by multiplying each element of a first vector with a corresponding element of a second vector; aligning the plurality of partial products based on the exponents associated with each element of the first vector and each element of the second vector; and accumulating the plurality of aligned partial products into a result queue utilizing at least one adder."
11816482,"A method, computer readable medium, and processor are disclosed for performing matrix multiply and accumulate (MMA) operations. The processor includes a datapath configured to execute the MMA operation to generate a plurality of elements of a result matrix at an output of the datapath. Each element of the result matrix is generated by calculating at least one dot product of corresponding pairs of vectors associated with matrix operands specified in an instruction for the MMA operation. A dot product operation includes the steps of: generating a plurality of partial products by multiplying each element of a first vector with a corresponding element of a second vector; aligning the plurality of partial products based on the exponents associated with each element of the first vector and each element of the second vector; and accumulating the plurality of aligned partial products into a result queue utilizing at least one adder."
11816783,"Enhanced techniques applicable to a ray tracing hardware accelerator for traversing a hierarchical acceleration structure are disclosed. For example, traversal efficiency is improved by combining programmable traversals based on ray operations with per-node static configurations that modify traversal behavior. The per-node static configurations enable creators of acceleration data structures to optimize for potential traversals without necessarily requiring detailed information about ray characteristics and ray operations used when traversing the acceleration structure. Moreover, by providing for selective exclusion of certain nodes using per-node static configurations, less memory is needed to express an acceleration structure that includes, for example, different geometric levels of details corresponding to a single object."
11816790,"A rule set or scene grammar can be used to generate a scene graph that represents the structure and visual parameters of objects in a scene. A renderer can take this scene graph as input and, with a library of content for assets identified in the scene graph, can generate a synthetic image of a scene that has the desired scene structure without the need for manual placement of any of the objects in the scene. Images or environments synthesized in this way can be used to, for example, generate training data for real world navigational applications, as well as to generate virtual worlds for games or virtual reality experiences."
11816890,"In various examples, one or more Machine Learning Models (MLMs) are used to identify content items in a video stream and present information associated with the content items to viewers of the video stream. Video streamed to a user(s) may be applied to an MLM(s) trained to detect an object(s) therein. The MLM may directly detect particular content items or detect object types, where a detection may be narrowed to a particular content item using a twin neural network, and/or an algorithm. Metadata of an identified content item may be used to display a graphical element selectable to acquire the content item in the game or otherwise. In some examples, object detection coordinates from an object detector used to identify the content item may be used to determine properties of an interactive element overlaid on the video and presented on or in association with a frame of the video."
11816987,"In various examples, audio alerts of emergency response vehicles may be detected and classified using audio captured by microphones of an autonomous or semi-autonomous machine in order to identify travel directions, locations, and/or types of emergency response vehicles in the environment. For example, a plurality of microphone arrays may be disposed on an autonomous or semi-autonomous machine and used to generate audio signals corresponding to sounds in the environment. These audio signals may be processed to determine a location and/or direction of travel of an emergency response vehicle (e.g., using triangulation). Additionally, to identify siren types—and thus emergency response vehicle types corresponding thereto—the audio signals may be used to generate representations of a frequency spectrum that may be processed using a deep neural network (DNN) that outputs probabilities of alert types being represented by the audio data. The locations, direction of travel, and/or siren type may allow an ego-vehicle or ego-machine to identify an emergency response vehicle and to make planning and/or control decisions in response."
11817117,"In various examples, end of speech (EOS) for an audio signal is determined based at least in part on a rate of speech for a speaker. For a segment of the audio signal, EOS is indicated based at least in part on an EOS threshold determined based at least in part on the rate of speech for the speaker."
11817886,"In various examples, metadata may be generated corresponding to compressed data streams that are compressed according to serial compression algorithms—such as arithmetic encoding, entropy encoding, etc.—in order to allow for parallel decompression of the compressed data. As a result, modification to the compressed data stream itself may not be required, and bandwidth and storage requirements of the system may be minimally impacted. In addition, by parallelizing the decompression, the system may benefit from faster decompression times while also reducing or entirely removing the adoption cycle for systems using the metadata for parallel decompression."
11818192,"In various examples, the decoding and upscaling capabilities of a client device are analyzed to determine encoding parameters and operations used by a content streaming server to generate encoded video streams. The quality of the upscaled content of the client device may be monitored by the streaming servers such that the encoding parameters may be updated based on the monitored quality. In this way, the encoding operations of one or more streaming servers may be more effectively matched to the decoding and upscaling abilities of one or more client devise such that an increased number of client devices may be served by the streaming servers."
11822398,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, an alternate cooling loop with its own fluid source and a liquid-to-air heat exchanger is used to provide cooling for the at least one computing component alternatively from a secondary cooling loop that is associated with a primary cooling loop and a chilling facility."
11822491,"Fabric Attached Memory (FAM) provides a pool of memory that can be accessed by one or more processors, such as a graphics processing unit(s) (GPU)(s), over a network fabric. In one instance, a technique is disclosed for using imperfect processors as memory controllers to allow memory, which is local to the imperfect processors, to be accessed by other processors as fabric attached memory. In another instance, memory address compaction is used within the fabric elements to fully utilize the available memory space."
11822541,"Various techniques for accelerating Smith-Waterman sequence alignments are provided. For example, threads in a group of threads are employed to use an interleaved cell layout to store relevant data in registers while computing sub-alignment data for one or more local alignment problems. In another example, specialized instructions that reduce the number of cycles required to compute each sub-alignment score are utilized. In another example, threads are employed to compute sub-alignment data for a subset of columns of one or more local alignment problems while other threads begin computing sub-alignment data based on partial result data received from the preceding threads. After computing a maximum sub-alignment score, a thread stores the maximum sub-alignment score and the corresponding position in global memory."
11822926,"Apparatuses, systems, and techniques to optimize device communications disclosed. In at least one embodiment, one or more neural networks are used to determine optimal power and frequency states for communication links between processing devices."
11823318,"Techniques are disclosed herein for interleaving textures. In the disclosed techniques, multiple textures that would otherwise be accessed separately are interleaved into a single, interleaved texture that can be used to access the multiple textures together. The interleaved texture can include alternating blocks from the multiple textures. The interleaved texture can be generated when the multiple textures are being loaded into memory. Further, the interleaved texture can be accessed using multiple texture headers that are associated with different textures in the interleaved texture. Each of texture headers includes a stride indicating the distance between two blocks from a same texture in the interleaved texture."
11823319,"One embodiment of a method for rendering one or more graphics images includes tracing one or more rays through a graphics scene; computing one or more surface normals associated with intersections of the one or more rays with one or more surfaces, where computing each surface normal includes: computing a plurality of intermediate surface normals associated with a plurality of adjacent voxels of a grid, and interpolating the plurality of intermediate surface normals; and rendering one or more graphics images based on the one or more surface normals."
11823320,"In examples, a list of elements may be divided into spans and each span may be allocated a respective memory range for output based on a worst-case compression ratio of a compression algorithm that will be used to compress the span. Worker threads may output compressed versions of the spans to the memory ranges. To ensure placement constraints of a data structure will be satisfied, boundaries of the spans may be adjusted prior to compression. The size allocated to a span (e.g., each span) may be increased (or decreasing) to avoid padding blocks while allowing for the span's compressed data to use a block allocated to an adjacent span. Further aspects of the disclosure provide for compaction of the portions of compressed data in memory in order to free up space which may have been allocated to account for the memory gaps which may result from variable compression ratios."
11823321,"Recurrent blurring may be used to render frames of a virtual environment, where the radius of a filter for a pixel is based on a number of successfully accumulated frames that correspond to that pixel. To account for rejections of accumulated samples for the pixel, ray-traced samples from a lower resolution version of a ray-traced render may be used to increase the effective sample count for the pixel. Parallax may be used to control the accumulation speed along with an angle between a view vector that corresponds to the pixel. A magnitude of one or more dimensions of a filter applied to the pixel may be based on an angle of a view vector that corresponds to the pixel to cause reflections to elongate along an axis under glancing angles. The dimension(s) may be based on a direction of a reflected specular lobe associated with the pixel."
11823355,Pixel depth information is used to determine a weight to apply to neighboring pixels when using a sharpening filter. A difference between neighboring pixel depths is evaluated and pixels with pixel depths that exceed a threshold are given less weight than other pixels. A sharpening mask may be generated using adjusted pixel colors.
11823415,"An autoencoder may be trained to predict 3D pose labels using simulation data extracted from a simulated environment, which may be configured to represent an environment in which the 3D pose estimator is to be deployed. Assets may be used to mimic the deployment environment such as 3D models or textures and parameters used to define deployment scenarios and/or conditions that the 3D pose estimator will operate under in the environment. The autoencoder may be trained to predict a segmentation image from an input image that is invariant to occlusions. Further, the autoencoder may be trained to exclude areas of the input image from the object that correspond to one or more appendages of the object. The 3D pose may be adapted to unlabeled real-world data using a GAN, which predicts whether output of the 3D pose estimator was generated from real-world data or simulated data."
11824533,"Voltage level conversion circuits include PMOS pull-down devices or NMOS pull-up devices, and inverters with outputs that determine gate voltages of these devices. The inverters are powered by moving supply voltages, for example complementary supply voltages generated from a pair of cross-coupled inverters. The cross-coupled inverters may implement a data storage latch with the moving supply voltages generated from the internal data storage nodes of the latch."
11824791,"A switching system having input ports and output ports and comprising an input queued (IQ) switch with virtual channels. Typically, only one virtual channel can, at a given time, access a given output port. Typically, the IQ switch includes an arbiter apparatus that controls the input ports and output ports to ensure that an input port transmits at most one cell at a time, and/or that an output port receives a cell over only one virtual channel, and/or an output port receives at most one cell at a time."
11828549,"An electronic device includes an integrated circuit and a heat exchanger. The heat exchanger includes a heat pipe and a first plurality of cooling fins and a second plurality of cooling fins. The heat pipe is thermally coupled to the integrated circuit and has an evaporator portion and a condenser portion, where the condenser portion extends away from the evaporator portion. The first plurality of cooling fins are attached to the condenser portion and proximate to the evaporation portion and form a plenum having a first associated pressure drop when a cooling fluid flows across the first plurality of cooling fins at a first velocity. The second plurality of cooling fins are attached to the condenser portion and distal from the evaporation portion and form a flow path having a second associated pressure drop when the cooling fluid flows across the second plurality of cooling fins at the first velocity."
11829170,"Systems and methods are disclosed related to low-power dynamic offset calibration of an error amplifier. An analog linear voltage regulator circuit tracks changes between a reference voltage and a regulated voltage to keep the regulated voltage as close as possible to the reference voltage. The analog linear voltage regulator includes an error amplifier that measures the error between the reference and regulated voltages and feedback circuitry. The error amplifier and feedback circuitry should be calibrated to correct for any offset within the circuits. The described offset calibration technique not only compensates for the offset in the error amplifier but also cancels any mismatch in the feedback network. During operation, conditions such as temperature and supply voltage may vary causing the offset to change. The technique is low power and dynamically cancels the offset even when the linear regulator is operating to supply the desired voltage."
11829213,"A cooling system for a datacenter is disclosed. A multiple mode cooling subsystem of the cooling system has a form factor for one or more racks of the datacenter, has two or more different cooling systems, and is adjustable to different cooling requirements of the datacenter within different cooling capacities offered by the two or more different cooling systems."
11829215,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, an alternate cooling loop with its own fluid source and a liquid-to-liquid heat exchanger is used to provide cooling for the at least one computing component alternatively from a secondary cooling loop that is associated with a primary cooling loop and a chilling facility."
11830123,"One embodiment of a computer-implemented method for processing data within a fixed-function pipeline included in an execution unit includes receiving a first input from a first processing unit, wherein the first input corresponds to a first fixed-function; executing the first fixed-function on the first input to generate a first output, wherein the first fixed-function is executed on the first input prior to executing the first fixed-function on one or more inputs received from a plurality of processing cores that are processing a plurality of rays, and wherein each ray represents a path from a light source to at least one point within a three-dimensional (3D) environment; and transmitting the first output to the first processing unit for further processing."
11830125,"Raytracing can be used to generate high quality, physics-based water caustics patterns in real time. A caustics map is generate to represent locations and normals of points across a water surface. Rays from a light source that are reflected and refracted from these points, as determined by the locations and normals, and can generate hit points on a surface. Neighboring points can be used to help determine the resulting caustics pattern. In one embodiment, information for neighboring points in the caustics map can be used to generate scale factors for geometric regions to be projected onto the surface for each hit point. In another embodiment, these points serve as vertices of a caustic mesh that can be projected onto the surface, where the brightness at a primitive is determined by the size of the primitive area defined by the vertices of the caustics mesh."
11830145,"A manifold voxel mesh or surface mesh is manufacturable by carving a single block of material and a non-manifold mesh is not manufacturable. Conventional techniques for constructing or extracting a surface mesh from an input point cloud often produce a non-manifold voxel mesh. Similarly, extracting a surface mesh from a voxel mesh that includes non-manifold geometry produces a surface mesh that includes non-manifold geometry. To ensure that the surface mesh includes only manifold geometry, locations of the non-manifold geometry in the voxel mesh are detected and converted into manifold geometry. The result is a manifold voxel mesh from which a manifold surface mesh of the object may be extracted."
11830160,"In various examples, a single camera is used to capture two images of a scene from different locations. A trained neural network, taking the two images as inputs, outputs a scene structure map that indicates a ratio of height and depth values for pixel locations associated with the images. This ratio may indicate the presence of an object above a surface (e.g., road surface) within the scene. Object detection then can be performed on non-zero values or regions within the scene structure map."
11830259,"State information can be determined for a subject that is robust to different inputs or conditions. For drowsiness, facial landmarks can be determined from captured image data and used to determine a set of blink parameters. These parameters can be used, such as with a temporal network, to estimate a state (e.g., drowsiness) of the subject. To improve robustness, an eye state determination network can determine eye state from the image data, without reliance on intermediate landmarks, that can be used, such as with another temporal network, to estimate the state of the subject. A weighted combination of these values can be used to determine an overall state of the subject. To improve accuracy, individual behavior patterns and context information can be utilized to account for variations in the data due to subject variation or current context rather than changes in state."
11831608,"In various examples, firewalls may include machine learning models that are automatically trained and applied to analyze service inputs submitted to input processing services and to identify whether service inputs are desirable (e.g., will result in an undesirable status code if processed by a service). When a service input is determined by a firewall to be desirable, the firewall may push the service input through to the input processing service for normal processing. When a service input is determined by the firewall to be undesirable, the firewall may block or drop the service input before it reaches the input processing service and/or server. This may be used to prevent the service input, which is likely to be undesirable, from touching a server that hosts the input processing service (e.g., preventing a crash)."
11832416,"Systems and methods for datacenter are disclosed. In at least one embodiment, a system or method herein causes a process for a structure that includes a component tracking system, where such a system includes individual components within individual servers or individual racks, the process being based in part on at least location information and configuration information from one or more of an optical sensor or a radio sensor associated with a motile-support that is adapted for at least three dimensional (3D) movement in a space having the individual servers or the individual racks."
11833681,"In at least one embodiment, under the control of a robotic control system, a gripper on a robot is positioned to grasp a 3-dimensional object. In at least one embodiment, the relative position of the object and the gripper is determined, at least in part, by using a camera mounted on the gripper."
11835342,"Operations of the present disclosure include obtaining a first measure of velocity of a vehicle based on a plurality of locations determined for the vehicle. The operations also include obtaining, based on IMU measurements of an inertial measurement unit (IMU) of the vehicle, a second measure of velocity of the vehicle. In addition, the operations include performing calibration of the IMU based on the first measure of velocity and the second measure of velocity."
11835357,"Camera based localization performed to determine a current pose of an autonomous vehicle without the aid of depth sensors such as LiDAR. The vehicle comprises an imaging system configured to capture image frames depicting portions of the surrounding area. Based on an initial pose of the vehicle, edgels corresponding to three-dimensional locations are loaded and mapped to corresponding edge pixels of the captured image frame. A pose of the vehicle is optimized based upon the determined correspondences by identifying a transformation that minimizes a distance between the edgels and their corresponding edge pixels. The determined transformation can be applied to the initial pose to determine an updated pose of the vehicle."
11836361,"While a compiler compiles source code to create an executable binary, code is added into the compiled source code that, when executed, identifies and stores in a metadata table base and bounds information associated with memory allocations. Additionally, additional code is added into the compiled source code that performs memory safety checks during execution. This updated compiled source code automatically determines a safety of memory access requests during execution by performing an out-of-bounds (OOB) check using the base and bounds information retrieved and stored in the metadata table. This enables the identification and avoidance of unsafe memory operations during the implementation of the executable by a GPU."
11836490,"Apparatuses, systems, and techniques to optimize memory usage when performing matrix operations. In at least one embodiment, a matrix is optimized to limit memory and storage requirements while minimizing loss of precision for a sum of the members of the matrix."
11836527,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
11836597,"Motivated by the ability of humans to quickly and accurately detect visual artifacts in images, a neural network model is trained to identify and locate visual artifacts in a sequence of rendered images without comparing the sequence of rendered images against a ground truth reference. Examples of visual artifacts include aliasing, blurriness, mosaicking, and overexposure. The neural network model provides a useful fully-automated tool for evaluating the quality of images produced by rendering systems. The neural network model may be trained to evaluate the quality of images for video processing, encoding, and/or compression techniques. In an embodiment, the sequence includes at least four images corresponding to a video or animation."
11836645,"In various examples, performance capabilities of a consumer—such as inference rates of a neural network executing on underlying hardware—may be tested or demonstrated for producers that have lower production rates than consumption rates of the consumer. For example, augmented data instances may be leveraged to augment production data from the producer in order to increase a frequency of transmission of data instances to a consumer. As a result, a data set including additional or alternative instances of data may be generated to emulate real-world data for demonstrating potential performance capabilities of a consuming algorithm beyond a currently required performance capability corresponding to a producer."
11836844,"Systems and methods relate to the determination of accurate motion vectors, for rendering situations such as a noisy Monte Carlo integration where image object surfaces are at least partially translucent. To optimize the search for “real world” positions, this invention defines the background as first path vertices visible through multiple layers of refractive interfaces. To find matching world positions, the background is treated as a single layer morphing in a chaotic way, permitting the optimized algorithm to be executed only once. Further improving performance over the prior linear gradient descent, the present techniques can apply a cross function and numerical optimization, such as Newton's quadratic target or other convergence function, to locate pixels via a vector angle minimization. Determined motion vectors can then serve as input for services including image denoising."
11838126,"Apparatuses, systems, and techniques to select fifth-generation (5G) new radio data. In at least one embodiment, a processor includes one or more circuits to select 5G new radio signal information in parallel."
11840238,"In various examples, systems and methods are disclosed that detect hazards on a roadway by identifying discontinuities between pixels on a depth map. For example, two synchronized stereo cameras mounted on an ego-machine may generate images that may be used extract depth or disparity information. Because a hazard's height may cause an occlusion of the driving surface behind the hazard from a perspective of a camera(s), a discontinuity in disparity values may indicate the presence of a hazard. For example, the system may analyze pairs of pixels on the depth map and, when the system determines that a disparity between a pair of pixels satisfies a disparity threshold, the system may identify the pixel nearest the ego-machine as a hazard pixel."
11841458,"A neural network is trained to focus on a domain of interest. For example, in a pre-training phase, the neural network in trained using synthetic training data, which is configured to omit or limit content less relevant to the domain of interest, by updating parameters of the neural network to improve the accuracy of predictions. In a subsequent training phase, the pre-trained neural network is trained using real-world training data by updating only a first subset of the parameters associated with feature extraction, while a second subset of the parameters more associated with policies remains fixed."
11841987,"Machine learning systems and methods that learn glare, and thus determine gaze direction in a manner more resilient to the effects of glare on input images. The machine learning systems have an isolated representation of glare, e.g., information on the locations of glare points in an image, as an explicit input, in addition to the image itself. In this manner, the machine learning systems explicitly consider glare while making a determination of gaze direction, thus producing more accurate results for images containing glare."
11842280,"In training a deep neural network using reduced precision, gradient computation operates on larger values without affecting the rest of the training procedure. One technique trains the deep neural network to develop loss, scales the loss, computes gradients at a reduced precision, and reduces the magnitude of the computed gradients to compensate for scaling of the loss. In one example non-limiting arrangement, the training forward pass scales a loss value by some factor S and the weight update reduces the weight gradient contribution by 1/S. Several techniques can be used for selecting scaling factor S and adjusting the weight update."
11842440,"In various examples, locations of directional landmarks, such as vertical landmarks, may be identified using 3D reconstruction. A set of observations of directional landmarks (e.g., images captured from a moving vehicle) may be reduced to 1D lookups by rectifying the observations to align directional landmarks along a particular direction of the observations. Object detection may be applied, and corresponding 1D lookups may be generated to represent the presence of a detected vertical landmark in an image."
11842528,"An online system builds a high definition (HD) map for a geographical region based on sensor data captured by a plurality of autonomous vehicles driving through a geographical region. The autonomous vehicles detect map discrepancies based on differences in the surroundings observed using sensor data compared to the high definition map and send messages describing these map discrepancies to the online system. The online system updates existing occupancy maps to improve the accuracy of the occupancy maps (OMaps), and to thereby improve passenger and pedestrian safety. While vehicles are in motion, they can continuously collect data about their surroundings. When new data is available from the various vehicles within a fleet, this can be updated in a local representation of the occupancy map and can be passed to the online HD map system (e.g., in the cloud) for updating the master occupancy map shared by all of the vehicles."
11847508,Convergence of threads executing common code sections is facilitated using instructions inserted at strategic locations in computer code sections. The inserted instructions enable the threads in a warp or other group to cooperate with a thread scheduler to promote thread convergence.
11847538,"Apparatuses, systems, and techniques to train a generative model based at least in part on a private dataset. In at least one embodiment, the generative model is trained based at least in part on a differentially private Sinkhorn algorithm, for example, using backpropagation with gradient descent to determine a gradient of a set of parameters of the generative models and modifying the set of parameters based at least in part on the gradient."
11847550,"A method, computer program product, and system perform computations using a processor. A first instruction including a first index vector operand and a second index vector operand is received and the first index vector operand is decoded to produce first coordinate sets for a first array, each first coordinate set including at least a first coordinate and a second coordinate of a position of a non-zero element in the first array. The second index vector operand is decoded to produce second coordinate sets for a second array, each second coordinate set including at least a third coordinate and a fourth coordinate of a position of a non-zero element in the second array. The first coordinate sets are summed with the second coordinate sets to produce output coordinate sets and the output coordinate sets are converted into a set of linear indices."
11847733,"A ray (e.g., a traced path of light, etc.) is generated from an originating pixel within a scene being rendered. Additionally, one or more shadow map lookups are performed for the originating pixel to estimate an intersection of the ray with alpha-tested geometry within the scene. A shadow map stores the distance of geometry as seen from the point of view of the light, and alpha-tested geometry includes objects within the scene being rendered that have a determined texture and opacity. Further, the one or more shadow map lookups are performed to determine a visibility value for the pixel (e.g., that identifies whether the originating pixel is in a shadow) and a distance value for the pixel (e.g., that identifies how far the pixel is from the light). Further still, the visibility value and the distance value for the pixel are passed to a denoiser."
11847737,"Apparatuses, systems, and techniques are presented to reduce temporal lag when a dynamic event is occurring in computer generated video. In one embodiment, a first averaging algorithm is utilized to determine a display value for a pixel based at least in part on previous pixel values. Once a dynamic event is detected, a set of the previous pixel values is averaged using a second averaging algorithm. The pixel value is updated based on the first averaging of the pixel values and the second averaging of the pixel values to determine a current pixel value."
11851014,"In various examples, systems and methods are disclosed that accurately identify driver and passenger in-cabin activities that may indicate a biomechanical distraction that prevents a driver from being fully engaged in driving a vehicle. In particular, image data representative of an image of an occupant of a vehicle may be applied to one or more deep neural networks (DNNs). Using the DNNs, data indicative of key point locations corresponding to the occupant may be computed, a shape and/or a volume corresponding to the occupant may be reconstructed, a position and size of the occupant may be estimated, hand gesture activities may be classified, and/or body postures or poses may be classified. These determinations may be used to determine operations or settings for the vehicle to increase not only the safety of the occupants, but also of surrounding motorists, bicyclists, and pedestrians."
11851015,"In various examples, systems and methods are disclosed that accurately identify driver and passenger in-cabin activities that may indicate a biomechanical distraction that prevents a driver from being fully engaged in driving a vehicle. In particular, image data representative of an image of an occupant of a vehicle may be applied to one or more deep neural networks (DNNs). Using the DNNs, data indicative of key point locations corresponding to the occupant may be computed, a shape and/or a volume corresponding to the occupant may be reconstructed, a position and size of the occupant may be estimated, hand gesture activities may be classified, and/or body postures or poses may be classified. These determinations may be used to determine operations or settings for the vehicle to increase not only the safety of the occupants, but also of surrounding motorists, bicyclists, and pedestrians."
11852813,"In an embodiment, an augmented reality display is provided that incorporates a prescription lens for the wearer. In an embodiment, an image is generated from a display and directed into the edge of the prescription lens, and the lens acts as a waveguide. The image is internally reflected within the prescription lens, and is directed to the wearer by an image combiner embedded within the prescription lens. In an embodiment, the augmented reality display can be adjusted for many common vision problems including myopia, hyperopia, astigmatism, and presbyopia."
11853764,"One embodiment of a computer-implemented method for compiling a material graph into a set of instructions for execution within an execution unit includes receiving a first material graph having a plurality of nodes, wherein each node included in the plurality of nodes represents a different surface property of a material; parsing the material graph to generate an expression tree that includes one or more expressions for each node included in the plurality of nodes; and generating a set of byte code instructions corresponding to the material graph based on the expression tree, wherein the byte code instructions are executable by a plurality of processing cores included within the execution unit."
11854141,"Techniques are disclosed for improving the throughput of ray intersection or visibility queries performed by a ray tracing hardware accelerator. Throughput is improved, for example, by releasing allocated resources before ray visibility query results are reported by the hardware accelerator. The allocated resources are released when the ray visibility query results can be stored in a compressed format outside of the allocated resources. When reporting the ray visibility query results, the results are reconstructed based on the results stored in the compressed format. The compressed format storage can be used for ray visibility queries that return no intersections or terminate on any hit ray visibility query. One or more individual components of allocated resources can also be independently deallocated based on the type of data to be returned and/or results of the ray visibility query."
11854401,"In various examples, a sequential deep neural network (DNN) may be trained using ground truth data generated by correlating (e.g., by cross-sensor fusion) sensor data with image data representative of a sequences of images. In deployment, the sequential DNN may leverage the sensor correlation to compute various predictions using image data alone. The predictions may include velocities, in world space, of objects in fields of view of an ego-vehicle, current and future locations of the objects in image space, and/or a time-to-collision (TTC) between the objects and the ego-vehicle. These predictions may be used as part of a perception system for understanding and reacting to a current physical environment of the ego-vehicle."
11854660,"To mitigate pulse shape degradation along a signal route, the signal is driven from two ends. One end of the route is loaded and the other is relatively unloaded. The loaded route and unloaded route may traverse two different metal layers on a printed circuit board. The two routes may thus be related such that the unloaded route has less RC distortion effects on the signal than does the loaded route."
11855804,"A network device serving as a local VXLAN) Tunnel Endpoint (VTEP) includes a communication interface, a first processor and a packet processor. The communication interface communicates between the local VTEP and remote VTEPs, each VTEP has a respective VXLAN Identifier (VNI). The first processor imports a Downstream-VNI (D-VNI) to be used in forwarding packets from the local VTEP to a remote VTEP, creates a unique egress Routing Interface (RIF) that is translatable into the imported D-VNI, and associates the unique egress RIF with one or more route entries in the local VTEP. The packet processor receives a packet destined to the remote VTEP, looks up the packet in the route entries in the local VTEP to retrieve the unique egress RIF, translates the unique egress RIF into the imported D-VNI, encapsulates the packet with the imported D-VNI, and forwards the encapsulated packet in accordance with the unique egress RIF."
11856044,"Apparatuses, systems, and techniques for isolating the performance of a quality-of-service (QoS) policy for improved data streaming systems and applications. In at least one embodiment, a metric is determined for a QoS policy used to provide an application session based on a value of at least one characteristic of the application session that reflects an impact of one or more external conditions beyond the control of the QoS policy."
11857872,"High performance applications—such as cloud game streaming, cloud virtual reality (VR), remote desktop, and others—are sensitive to various network conditions, such as latency, jitter, and packet loss. Systems of the present disclosure may match network characteristics for a user device with latency requirements for a particular application type, and application sessions may be forwarded or distributed to a suitable data center. To accomplish this, application specific network tests may be executed to determine requirements for executing a high performing application session for a user. The result of these tests, in addition to application specific performance requirements, may be used to find a suitable data center—from a set of available data centers—that is capable of hosting the application session without degradation. As a result, efficient use of distributed infrastructures may be accomplished, while avoiding congestion and hot-spots, and providing an optimized application experience for end users."
11860067,"Systems and methods for evaluating cooling characteristics are disclosed. In at least one embodiment, a thermal test vehicle can be used to simulate a thermal performance of a computing unit."
11860455,"In an embodiment, a modular augmented reality display is provided that incorporates prescription eyewear that can be used separately by the wearer. In an embodiment, an image is generated from a removable display attached to the eyewear and directed into the edge of a prescription lens, which acts as a waveguide. The image is internally reflected within the prescription lens, and is directed to the wearer by an image combiner embedded within the prescription lens. In an embodiment, the augmented reality display includes a wearable belt pouch that includes a battery and support electronics connected to the eyewear so that the weight on the eyewear is reduced."
11860628,"To determine a path through a pose configuration space, trajectories of poses may be evaluated in parallel based at least on translating the trajectories along at least one axis of the pose configuration space (e.g., an orientation axis). A trajectory may include at least a portion of a turn having a fixed turn radius. Turns or turn portions that have the same turn radius and initial orientation can be translatively shifted along and processed in parallel along the orientation axis as they are translated copies of each other, but with different starting points. Trajectories may be evaluated based at least on processing variables used to evaluate reachability as bit vectors with threads effectively performing large vector operations in synchronization. A parallel reduction pattern may be used to account for dependencies that may exist between sections of a trajectory for evaluating reachability, allowing for the sections to be processed in parallel."
11861229,"Various embodiments include a memory device that is capable of transferring both commands and data via a single clock signal input. In order to initialize the memory device to receive commands, a memory controller transmits a synchronization command to the memory device. The synchronization command establishes command start points that identify the beginning clock cycle of a command that is transferred to the memory device over multiple clock cycles. Thereafter, the memory controller transmits subsequent commands to the memory device according to a predetermined command length. The predetermined command length is based on the number of clock cycles needed to transfer each command to the memory device. Adjacent command start points are separated from one another by the predetermined command length. In this manner, the memory device avoids the need for a second lower speed clock signal for transferring commands to the memory device."
11861758,"Apparatuses, systems, and techniques to process packet data in parallel. In at least one embodiment, packet data is processed by (e.g., one or more algorithms expressed in CUDA code executing on) a Graphics Processing Unit (“GPU”)."
11861811,A neural network-based rendering technique increases temporal stability and image fidelity of low sample count path tracing by optimizing a distribution of samples for rendering each image in a sequence. A sample predictor neural network learns spatio-temporal sampling strategies such as placing more samples in dis-occluded regions and tracking specular highlights. Temporal feedback enables a denoiser neural network to boost the effective input sample count and increases temporal stability. The initial uniform sampling step typically present in adaptive sampling algorithms is not needed. The sample predictor and denoiser operate at interactive rates to achieve significantly improved image quality and temporal stability compared with conventional adaptive sampling techniques.
11861890,"A style-based generative network architecture enables scale-specific control of synthesized output data, such as images. During training, the style-based generative neural network (generator neural network) includes a mapping network and a synthesis network. During prediction, the mapping network may be omitted, replicated, or evaluated several times. The synthesis network may be used to generate highly varied, high-quality output data with a wide variety of attributes. For example, when used to generate images of people's faces, the attributes that may vary are age, ethnicity, camera viewpoint, pose, face shape, eyeglasses, colors (eyes, hair, etc.), hair style, lighting, background, etc. Depending on the task, generated output data may include images, audio, video, three-dimensional (3D) objects, text, etc."
11863390,"Apparatuses, systems, and techniques are presented to configure computing resources to perform various tasks. In at least one embodiment, an approach presented herein can be used to verify whether a network of computing nodes is properly configured based, at least in part, on one or more expected data strings generated by the network of computing nodes."
11863832,"A method for remotely provisioning resources for running a computer application is described. The method includes: causing, using one or more processing units, an initialization of a user interactive video portion of a computer application, the computer application being executed using a remote server; determining a runtime of a static video portion of the computer application and a time required to complete initialization of the user interactive portion using information provided by the remote server; and delaying a start time of displaying the static video portion when the runtime of the static video portion is shorter than the time required to complete the initialization of the user interactive portion. A device that is capable of performing the above method and a server are also described."
11864359,"A remediation system for threshold leaks in a datacenter liquid cooling system is disclosed. The system includes a fluid controller and a power controller that are adapted to receive input from a learning subsystem that can determine that a threshold leak has occurred even though a computing component is functioning normally, so that a change in power state to reduce reliance on the coolant and so that a change of flow of the coolant may be effected."
11867515,"According to an aspect of an embodiment, operations may comprise accessing a set of vehicle poses of one or more vehicles; for each of the set of vehicle poses, accessing a high definition (HD) map of a geographical region surrounding the vehicle pose, with the HD map comprising a three-dimensional (3D) representation of the geographical region, determining a measure of constrainedness for the vehicle pose, with the measure of constrainedness representing a confidence for performing localization for the vehicle pose based on 3D structures surrounding the vehicle pose, and storing the measure of constrainedness for the vehicle pose; and for each of the geographical regions surrounding each of the set of vehicle poses, determining a measure of constrainedness for the geographical region based on measures of constrainedness of vehicle poses within the geographical region, and storing the measure of constrainedness for the geographical region."
11867744,"Techniques for isolating interfaces while testing a semiconductor device include a semiconductor device having a link interface that couples the semiconductor device to a high-speed data transfer link, a clock control unit that transmits one or more clock signals to the link interface; and a protection module. The protection module asserts a clock stop request to the clock control unit and, in response to receiving a clock stop acknowledgement from the clock control unit, asserts a clamp enable to cause the link interface to be isolated from portions of the semiconductor device. After waiting for a first predetermined period of time to expire, the protection module de-asserts the clock stop request."
11869149,"In various embodiments, an unsupervised training application executes a neural network on a first point cloud to generate keys and values. The unsupervised training application generates output vectors based on a first query set, the keys, and the values and then computes spatial features based on the output vectors. The unsupervised training application computes quantized context features based on the output vectors and a first set of codes representing a first set of 3D geometry blocks. The unsupervised training application modifies the first neural network based on a likelihood of reconstructing the first point cloud, the quantized context features, and the spatial features to generate an updated neural network. A trained machine learning model includes the updated neural network, a second query set, and a second set of codes representing a second set of 3D geometry blocks and maps a point cloud to a representation of 3D geometry instances."
11869483,Generation of synthetic speech from an input text sequence may be difficult when durations of individual phonemes forming the input text sequence are unknown. A predominantly parallel process may model speech rhythm as a separate generative distribution such that phoneme duration may be sampled at inference. Additional information such as pitch or energy may also be sampled to provide improved diversity for synthetic speech generation.
11871011,"Systems and methods for efficient lossless compression of captured raw image information are presented. A method can comprise: receiving raw image data from an image capture device, segregating the pixel data into a base layer portion and an enhanced layer portion, reconfiguring the base layer portion expressed in the first color space values from a raw capture format into a pseudo second color space compression mechanism compatible format, and compressing the reconfigured base layer portion of first color space values. The raw image data can include pixel data are expressed in first color space values. The segregation can be based upon various factors, including a compression benefits analysis of a boundary location between the base layer portion and enhanced layer portion. The reconfiguring the base layer portion can include separating the base layer portion based upon multiple components within the raw data; and forming base layer video frames from the multiple components."
11871018,"Disclosed are techniques for compressing data of an image. Intermediate pixels may be determined. Each location of the image may be associated with a block of a plurality of blocks of a first size and a block of a plurality of blocks of a second size. For each block of the first size and of the second size, a first cost for a first mode and a second cost for a second mode may be determined in parallel using the intermediate pixels. A final mode and a final block size may be selected for each location of the image using the first cost and the second cost for each of a respective block of the first size and a respective block of the second size associated with a corresponding location. Final pixels may be determined, and a representation of the image may be obtained based on the final pixels."
11874662,"This disclosure presents an assisted driving vehicle system, including autonomous, semi-autonomous, and technology assisted vehicles, that can share sensor data among two or more controllers. A sensor can have one communication channel to a controller, thereby saving cabling and circuitry costs. The data from the sensor can be sent from one controller to another controller to enable redundancy and backup in case of a system failure. Sensor data from more than one sensor can be aggregated at one controller prior to the aggregated sensor data being communicated to another controller thereby saving bandwidth and reducing transmission times. The sharing of sensor data can be enabled through the use of a sensor data distributor, such as a converter, repeater, or a serializer/deserializer set located as part of the controller and communicatively coupled to another such device in another controller using a data interface communication channel."
11874663,"A system and method for an on-demand shuttle, bus, or taxi service able to operate on private and public roads provides situational awareness and confidence displays. The shuttle may include ISO 26262 Level 4 or Level 5 functionality and can vary the route dynamically on-demand, and/or follow a predefined route or virtual rail. The shuttle is able to stop at any predetermined station along the route. The system allows passengers to request rides and interact with the system via a variety of interfaces, including without limitation a mobile device, desktop computer, or kiosks. Each shuttle preferably includes an in-vehicle controller, which preferably is an AI Supercomputer designed and optimized for autonomous vehicle functionality, with computer vision, deep learning, and real time ray tracing accelerators. An AI Dispatcher performs AI simulations to optimize system performance according to operator-specified system parameters."
11874742,"In various embodiments, a software program uses hardware features of a parallel processor to checkpoint a context associated with an execution of a software application on the parallel processor. The software program uses a preemption feature of the parallel processor to cause the parallel processor to stop executing instructions in accordance with the context. The software program then causes the parallel processor to collect state data associated with the context. After generating a checkpoint based on the state data, the software program causes the parallel processor to resume executing instructions in accordance with the context."
11875057,"A processing unit can include a performance monitor for monitoring the performance of the processing unit and associated sub-units. The performance monitor includes a logic analyzer, and implements a state machine via state machine data entries stored in a memory associated with the performance monitor. A state machine data entry includes output signals associated with state transitions. The output signals include a next state and a trigger to the logic analyzer. The performance monitor implements logic circuits that determine, based on input signals and the state machine data entries, the next state to transition and associated output signals. If a state transition includes a trigger to the logic analyzer, the trigger is transmitted to the logic analyzer. In response to the trigger, the logic analyzer assembles and samples input signals and stores the sampled input signals into the memory associated with the performance monitor, overwriting the state machine data entries."
11875444,"One embodiment of a computer-implemented method for decompressing a compressed texture block includes identifying a first texel included in a plurality of texels, wherein the plurality of texels forms at least a portion of a compressed texture block; determining a first location within the compressed texel block that corresponds to the first texel; and extracting the first texel from the first location without decompressing any of the other texels included in the plurality of texels."
11875449,"Systems and methods are described for rendering complex surfaces or geometry. In at least one embodiment, neural signed distance functions (SDFs) can be used that efficiently capture multiple levels of detail (LODs), and that can be used to reconstruct multi-dimensional geometry or surfaces with high image quality. An example architecture can represent complex shapes in a compressed format with high visual fidelity, and can generalize across different geometries from a single learned example. Extremely small multi-layer perceptrons (MLPs) can be used with an octree-based feature representation for the learned neural SDFs."
11875478,"Systems and methods are disclosed for dynamically smoothing images based on network conditions to adjust a bitrate needed to transmit the images. Content in the images is smoothed to reduce the quantity of bits needed to encode each image. Filtering the images modifies regions including content having a high frequency of pixel variation, reducing the frequency, so the pixel colors in the region appear “smoothed” or homogeneous. In other words, a region of an image showing a grassy lawn has a high frequency of variation from pixel to pixel resulting from the fine detail of separate blades of grass that may be similar in color, but not homogeneous. Encoding the region as a single shade of green (or multi-pixel regions of different shades of green) enables a viewer to recognize it as a grassy lawn while greatly reducing the number of bits needed to represent the region."
11876697,"In various examples, an extensible network traffic engineering platform monitors network traffic and application performance to dynamically update network ingress and egress communication paths for increasing performance of the application—such as a cloud gaming application, a cloud virtual reality (VR) application, and/or another high performance application types. Pluggable, distributed, application-centric network monitors, policy engines, and network configurators are implemented at the edge to detect degraded network and application performance and dynamically update network routing to account for the same."
11876782,"In various examples, a first network interface duplicates received network traffic and forwards a first set of network traffic data to a central processing unit (CPU) and a second set of identical network traffic to one or more parallel processing units (PPUs). In an embodiment, the one or more PPUs analyze the second set of network traffic to identify whether the second set of network traffic is malicious. First, the one or more PPUs filter and classify the second set of network traffic into flows, or logical groupings or subsets of the second set of network traffic. Second, the one or more PPUs sort the network packets within each flow and extract features of interest specific to each flow. Using the extracted features of interest, one or more deep learning techniques infer a status indicating whether each flow is malicious (mal) or good. The one or more PPUs then forward the status for each flow to the CPU for use in determining which network traffic from the first set of network traffic is to be forwarded to a second network interface."
11878682,"In various examples, systems and methods are disclosed for generating and/or analyzing candidate paths for a multi-body vehicle—e.g., a tractor trailer truck—based on obstacle avoidance considerations and using an uncertainty representation for the vehicle. The uncertainty representation may correspond to a trailer portion of the multi-body vehicle to account for the variations in rotation of the trailer with respect to the tractor. As such, the uncertainty representation may be indicative of a probability that the trailer of the vehicle occupies locations and/or points in world space. This probability—combined with the probability of locations of actors in the environment—may be used to generate candidate paths that satisfy various constraints—e.g., a minimum stochastic distance—between the vehicle and the actor."
11880261,"A system, method, and apparatus of power management for computing systems are included herein that optimize individual frequencies of components of the computing systems using machine learning. The computing systems can be tightly integrated systems that consider an overall operating budget that is shared between the components of the computing system while adjusting the frequencies of the individual components. An example of an automated method of power management includes: (1) learning, using a power management (PM) agent, frequency settings for different components of a computing system during execution of a repetitive application, and (2) adjusting the frequency settings of the different components using the PM agent, wherein the adjusting is based on the repetitive application and one or more limitations corresponding to a shared operating budget for the computing system."
11880265,"A receiver device includes detection logic, an error counter, and an interrupt logic. The detection logic is to receive a first set of data frames and detect one or more frame errors in the first set of data frames. The error counter is to store a number of the one or more frame errors detected in the first set of data frames. The interrupt logic can be coupled to the error counter. The interrupt logic is to specify a period and compare the number of the one or more frame errors with a threshold number of frame errors during the period, where the interrupt logic is to indicate an interrupt responsive to the number of the one or more frame errors detected within the period satisfying the threshold number of frame errors."
11880466,"A game cloud server, a method of operating a cloud server, and a method of playing a game on a game cloud server are disclosed. In one example, the game cloud server includes: (1) one or more processing units that virtually supports different gaming applications according to a gaming operating mode, and (2) an operating mode selector that is coupled to the one or more processing units and has (2A) a virtual fusing register that selects the gaming operating mode for executing the different virtually supported gaming applications, and (2B) a security processor that enables a secure virtual fusing based on documented security files authorizing selection of the gaming operating mode, separately from executing an operating system of the one or more processing units, wherein the gaming operating mode is a reconfigurable operating mode selectable from at least one signed license file of the documented security files."
11880927,"A three-dimensional (3D) object reconstruction neural network system learns to predict a 3D shape representation of an object from a video that includes the object. The 3D reconstruction technique may be used for content creation, such as generation of 3D characters for games, movies, and 3D printing. When 3D characters are generated from video, the content may also include motion of the character, as predicted based on the video. The 3D object construction technique exploits temporal consistency to reconstruct a dynamic 3D representation of the object from an unlabeled video. Specifically, an object in a video has a consistent shape and consistent texture across multiple frames. Texture, base shape, and part correspondence invariance constraints may be applied to fine-tune the neural network system. The reconstruction technique generalizes well—particularly for non-rigid objects."
11881255,"A multi-rank circuit system utilizing a shared IO channel includes a first stage of multiple selectors coupled to input multiple digital busses, and a second stage including one or more selectors coupled to receive outputs of the first stage of selectors and to individually select one of the outputs of the first stage of selectors to one or more control circuits for IO circuits of the ranks. The system switches one of the ranks to be an active rank on the shared IO channel, and operates the first stage of selectors to select one of the digital busses to the second stage of selectors in advance of switching a next active rank to the shared IO channel."
11882678,"A redundancy shut-off system for a datacenter liquid cooling system is disclosed. The redundancy shut-off system has a first ball valve located above a datacenter platform and coupling between a row manifold of a secondary cooling loop and a rack manifold of a rack, where the first ball valve provides redundancy to a second ball valve located below the datacenter platform."
11884294,"In various examples, sensor data may be collected using one or more sensors of an ego-vehicle to generate a representation of an environment surrounding the ego-vehicle. The representation may include lanes of the roadway and object locations within the lanes. The representation of the environment may be provided as input to a longitudinal speed profile identifier, which may project a plurality of longitudinal speed profile candidates onto a target lane. Each of the plurality of longitudinal speed profiles candidates may be evaluated one or more times based on one or more sets of criteria. Using scores from the evaluation, a target gap and a particular longitudinal speed profile from the longitudinal speed profile candidates may be selected. Once the longitudinal speed profile for a target gap has been determined, the system may execute a lane change maneuver according to the longitudinal speed profile."
11885907,"In various examples, a deep neural network(s) (e.g., a convolutional neural network) may be trained to detect moving and stationary obstacles from RADAR data of a three dimensional (3D) space, in both highway and urban scenarios. RADAR detections may be accumulated, ego-motion-compensated, orthographically projected, and fed into a neural network(s). The neural network(s) may include a common trunk with a feature extractor and several heads that predict different outputs such as a class confidence head that predicts a confidence map and an instance regression head that predicts object instance data for detected objects. The outputs may be decoded, filtered, and/or clustered to form bounding shapes identifying the location, size, and/or orientation of detected object instances. The detected object instances may be provided to an autonomous vehicle drive stack to enable safe planning and control of the autonomous vehicle."
11886262,"A method for managing power in a multiple processor computing device includes detecting a first amount of power being used by a first processor of the computing device; determining an amount of extra power available based on the first amount of power and a power budget for the first processor; and transmits a value to a driver associated with a second processor of the computing device, wherein the value indicates the amount of extra power available, wherein the driver adjusts at least one operating parameter of the second processor based on the amount of extra power available."
11886634,"In various examples, systems and methods are disclosed that provide highly accurate gaze predictions that are specific to a particular user by generating and applying, in deployment, personalized calibration functions to outputs and/or layers of a machine learning model. The calibration functions corresponding to a specific user may operate on outputs (e.g., gaze predictions from a machine learning model) to provide updated values and gaze predictions. The calibration functions may also be applied one or more last layers of the machine learning model to operate on features identified by the model and provide values that are more accurate. The calibration functions may be generated using explicit calibration methods by instructing users to gaze at a number of identified ground truth locations within the interior of the vehicle. Once generated, the calibration functions may be modified or refined through implicit gaze calibration points and/or regions based on gaze saliency maps."
11886744,"A method, computer program product, apparatus, and system are provided. Some embodiments may include transmitting a request to make one or more writes associated with an identification tag. The request may include the identification tag, the one or more writes, a first instruction to make the one or more writes to one of a plurality of persistence levels of a memory, and a second instruction to respond with at least one first indication that the one or more writes associated with the identification tag have been written to at least one of the one of the plurality of persistence levels of the memory. Some embodiments may include receiving the at least one first indication that the one or more writes associated with the identification tag have been written to at least one of the one of the plurality of persistence levels of the memory."
11886885,"One embodiment of the present invention sets forth a data pipeline, which includes a first mousetrap element and a second mousetrap element in a first pipeline stage. Each mousetrap element includes a request latch that, when enabled, allows a request signal to pass from the first pipeline stage to a second pipeline stage following the first pipeline stage in the data pipeline. Each mousetrap element also includes a data latch that, when enabled, allows a data element to pass from the first pipeline stage to the second pipeline stage. Each mousetrap element further includes a latch controller that enables and disables the request and data latches based on a phase signal that alternates between a first value that configures the first mousetrap element to transmit data to the second pipeline stage and a second value that configures the second mousetrap element to transmit data to the second pipeline stage."
11886980,"Neural networks, in many cases, include convolution layers that are configured to perform many convolution operations that require multiplication and addition operations. Compared with performing multiplication on integer, fixed-point, or floating-point format values, performing multiplication on logarithmic format values is straightforward and energy efficient as the exponents are simply added. However, performing addition on logarithmic format values is more complex. Conventionally, addition is performed by converting the logarithmic format values to integers, computing the sum, and then converting the sum back into the logarithmic format. Instead, logarithmic format values may be added by decomposing the exponents into separate quotient and remainder components, sorting the quotient components based on the remainder components, summing the sorted quotient components to produce partial sums, and multiplying the partial sums by the remainder components to produce a sum. The sum may then be converted back into the logarithmic format."
11887245,"One embodiment of a method for rendering one or more graphics images includes tracing one or more rays through a graphics scene; computing one or more surface normals associated with intersections of the one or more rays with one or more surfaces, where computing each surface normal includes: computing a plurality of intermediate surface normals associated with a plurality of adjacent voxels of a grid, and interpolating the plurality of intermediate surface normals; and rendering one or more graphics images based on the one or more surface normals."
11889122,"A technique for streaming and a client device that uses the technique are disclosed herein. The disclosed technique determines context complexity of streamed data and determines whether to discard or select the streamed data for a future reference frame based on the context complexity of the streamed data. The streamed data is discarded if the content complexity is higher than a content complexity threshold, and the streamed data is selected if the content complexity is not higher than a content complexity threshold. This is based on the realization that error propagation in the case of a less complex video sequence is not very bothersome to the end user experience whereas corruption will be very severe in cases of highly complex sequences."
11891036,"In various examples, activation criteria and/or braking profiles corresponding to automatic emergency braking (AEB) systems and/or collision mitigation warning (CMW) systems may be determined using sensor data representative of an environment to a front, side, and/or rear of a vehicle. For example, activation criteria for triggering an AEB system and/or CMW system may be adjusted by leveraging the availability of additional information with regards to the surrounding environment of a vehicle—such as the presence of a trailing vehicle. In addition, the braking profile for the AEB activation may be adjusted based on information about the presence of and/or location of vehicles to the front, rear, and/or side of the vehicle. By adjusting the activation criteria and/or braking profiles of an AEB system, the potential for collisions with dynamic objects in the environment is reduced and the overall safety of the vehicle and its passengers is increased."
11892629,"Virtual reality (VR) displays are computer displays that present images or video in a manner that simulates a real experience for the viewer. In many cases, VR displays are implemented as head-mounted displays (HMDs) which provide a display in the line of sight of the user. Because current HMDs are composed of a display panel and magnifying lens with a gap therebetween, proper functioning of the HMDs limits their design to a box-like form factor, thereby negatively impacting both comfort and aesthetics. The present disclosure provides a different configuration for a VR display which allows for improved comfort and aesthetics, including specifically at least one coherent light source, at least one pupil replicating waveguide coupled to the at least one coherent light source to receive light therefrom, and at least one spatial light modulator coupled to the at least one pupil replicating waveguide to modulate the light."
11892898,"Configurations for data center component monitoring are disclosed. In at least one embodiment, movement of a server component is determined based on sensor data and the movement is used to diagnose a root cause for a server component failure."
11892946,"Apparatuses, systems, and techniques to allocate portions of a virtual address space to allow virtual machines to share data. In at least one embodiment, at least a portion of a virtual memory address space is made accessible to multiple virtual machines and is mapped to memory addresses of different physical devices using, at least in part, a cache-coherent protocol."
11893423,"A parallel processing unit (PPU) can be divided into partitions. Each partition is configured to operate similarly to how the entire PPU operates. A given partition includes a subset of the computational and memory resources associated with the entire PPU. Software that executes on a CPU partitions the PPU for an admin user. A guest user is assigned to a partition and can perform processing tasks within that partition in isolation from any other guest users assigned to any other partitions. Because the PPU can be divided into isolated partitions, multiple CPU processes can efficiently utilize PPU resources."
11893468,"Apparatuses, systems, and techniques to identify a goal of a demonstration. In at least one embodiment, video data of a demonstration is analyzed to identify a goal. Object trajectories identified in the video data are analyzed with respect to a task predicate satisfied by a respective object trajectory, and with respect to motion predicate. Analysis of the trajectory with respect to the motion predicate is used to assess intentionality of a trajectory with respect to the goal."
11893653,"The present invention facilitates efficient and effective utilization of unified virtual addresses across multiple components. In one embodiment, the presented new approach or solution uses Operating System (OS) allocation on the central processing unit (CPU) combined with graphics processing unit (GPU) driver mappings to provide a unified virtual address (VA) across both GPU and CPU. The new approach helps ensure that a GPU VA pointer does not collide with a CPU pointer provided by OS CPU allocation (e.g., like one returned by “malloc” C runtime API, etc.)."
11895808,A cooling system for a datacenter is disclosed. The datacenter cooling system includes a refrigerant cooling loop to extract heat from a secondary cooling loop that is located within the datacenter or to provide supplemental cooling to one or more components of the datacenter that are coupled to the secondary cooling loop.
11895809,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a sensor string is associated with a first fluid line having a first flow controller and with a second fluid line having a second flow controller, so that sections of such a sensor string are enabled to maintain electrical connectivity there through by a mechanical coupling of a first flow controller and a second flow controller."
11897471,"In various examples, live perception from sensors of a vehicle may be leveraged to detect and classify intersections in an environment of a vehicle in real-time or near real-time. For example, a deep neural network (DNN) may be trained to compute various outputs—such as bounding box coordinates for intersections, intersection coverage maps corresponding to the bounding boxes, intersection attributes, distances to intersections, and/or distance coverage maps associated with the intersections. The outputs may be decoded and/or post-processed to determine final locations of, distances to, and/or attributes of the detected intersections."
11899609,"A system includes a first device and a second device coupled to a link having one or more lanes. The first device is to transmit two or more frames to synchronize the one or more data lanes, where each frame comprises a quantity of bits. The second device is to receive a first set of bits from each data lane corresponding to the quantity of bits in each frame of the two or more frames. The second device is to determine that the first set of bits received from a data lane of the one or more data lanes does not correspond to a frame boundary of the two or more frames. The second device is further to synchronize each data lane of the one or more data lanes with respect to the frame boundary, responsive to determining that the first set of bits does not correspond to the frame boundary."
11899749,"In various examples, training methods as described to generate a trained neural network that is robust to various environmental features. In an embodiment, training includes modifying images of a dataset and generating boundary boxes and/or other segmentation information for the modified images which is used to train a neural network."
11900629,"In various examples, surface profile estimation and bump detection may be performed based on a three-dimensional (3D) point cloud. The 3D point cloud may be filtered in view of a portion of an environment including drivable free-space, and within a threshold height to factor out other objects or obstacles other than a driving surface and protuberances thereon. The 3D point cloud may be analyzed—e.g., using a sliding window of bounding shapes along a longitudinal or other heading direction—to determine one-dimensional (1D) signal profiles corresponding to heights along the driving surface. The profile itself may be used by a vehicle—e.g., an autonomous or semi-autonomous vehicle—to help in navigating the environment, and/or the profile may be used to detect bumps, humps, and/or other protuberances along the driving surface, in addition to a location, orientation, and geometry thereof."
11902705,"Apparatuses, systems, and techniques to enhance video are disclosed. In at least one embodiment, one or more neural networks are used to create, from a first video, a second video having one or more additional video frames."
11906660,"In various examples, a deep neural network (DNN) may be used to detect and classify animate objects and/or parts of an environment. The DNN may be trained using camera-to-LiDAR cross injection to generate reliable ground truth data for LiDAR range images. For example, annotations generated in the image domain may be propagated to the LiDAR domain to increase the accuracy of the ground truth data in the LiDAR domain—e.g., without requiring manual annotation in the LiDAR domain. Once trained, the DNN may output instance segmentation masks, class segmentation masks, and/or bounding shape proposals corresponding to two-dimensional (2D) LiDAR range images, and the outputs may be fused together to project the outputs into three-dimensional (3D) LiDAR point clouds. This 2D and/or 3D information output by the DNN may be provided to an autonomous vehicle drive stack to enable safe planning and control of the autonomous vehicle."
11907717,"A technique for block data transfer is disclosed that reduces data transfer and memory access overheads and significantly reduces multiprocessor activity and energy consumption. Threads executing on a multiprocessor needing data stored in global memory can request and store the needed data in on-chip shared memory, which can be accessed by the threads multiple times. The data can be loaded from global memory and stored in shared memory using an instruction which directs the data into the shared memory without storing the data in registers and/or cache memory of the multiprocessor during the data transfer."
11907846,One embodiment of the present invention sets forth a technique for performing spatial propagation. The technique includes generating a first directed acyclic graph (DAG) by connecting spatially adjacent points included in a set of unstructured points via directed edges along a first direction. The technique also includes applying a first set of neural network layers to one or more images associated with the set of unstructured points to generate (i) a set of features for the set of unstructured points and (ii) a set of pairwise affinities between the spatially adjacent points connected by the directed edges. The technique further includes generating a set of labels for the set of unstructured points by propagating the set of features across the first DAG based on the set of pairwise affinities.
11908064,"One embodiment of a computer-implemented method for processing ray tracing operations in parallel includes receiving a plurality of rays and a corresponding set of material shading instructions for each ray included in the plurality of rays for processing, wherein each ray represents a path from a light source to at least one point within a three-dimensional (3D) environment, and each corresponding set of material shading instructions is based at least in part on one or more material properties associated with at least one surface of at least one object included in the 3D environment; assigning each ray included in the plurality of rays to a different processing core included in a plurality of processing cores; and for each ray included in the plurality of rays, causing the processing core assigned to the ray to execute the corresponding set of material shading instructions on the ray to generate a color."
11908104,"In order to more accurately white balance an image, weightings can be determined for pixels of an image when computing an illuminant color value of the image and/or a scene. The weightings can be based at least in part on the Signal-to-Noise Ratio (SNR) of the pixels. The SNR may be actual SNR or SNR estimated from brightness levels of the pixels. SNR weighting (e.g., SNR adjustment) may reduce the effect of pixels with high noise on the computed illuminant color value. For example, one or more channel values of the illuminant color value can be determined based on the weightings and color values of the pixels. One or more color gain values can be determined based on the one or more channel values of the illuminant color value and used to white balance the image."
11908203,"LiDAR (light detection and ranging) and RADAR (radio detection and ranging) systems are commonly used to generate point cloud data for 3D space around vehicles, for such functions as localization, mapping, and tracking. Improved techniques for processing the point cloud data that has been collected are provided. The improved techniques include mapping one or more point cloud data points into a depth map, the one or more point cloud data points being generated using one or more sensors; determining one or more mapped point cloud data points within a bounded area of the depth map, and detecting, using one or more processing units and for an environment surrounding a machine corresponding to the one or more sensors, a location of one or more entities based on the one or more mapped point cloud data points."
11909820,"A computer implemented method of executing applications in a cloud server system is presented. The method comprises receiving a file identifier from a client device. The method also comprises receiving a file associated with the file identifier from a first server. Further, the method comprises accessing an application associated with the file from memory of the cloud server. Also, the method comprises executing by the cloud server the application using the file received from the first server. Finally, the method comprises streaming results from the executing the application as a video stream destined for the client device."
11910576,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, an absorption chiller includes a generator vessel to enable removal of heat from fluid returned from at least one computing component of the datacenter."
11910577,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a hybrid coolant distribution unit (HCDU) provides first stage cooling of secondary coolant returning from at least one cold plate in a liquid to air heat exchanger (L2AHE) and provides second stage cooling in a liquid to liquid heat exchanger (L2LHE) for secondary coolant exiting an L2AHE using varying flow rates of a primary coolant based in part on a residual temperature that is determined for such secondary coolant exiting an L2AHE."
11915145,"In various examples, a two-dimensional (2D) and three-dimensional (3D) deep neural network (DNN) is implemented to fuse 2D and 3D object detection results for classifying objects. For example, regions of interest (ROIs) and/or bounding shapes corresponding thereto may be determined using one or more region proposal networks (RPNs)—such as an image-based RPN and/or a depth-based RPN. Each ROI may be extended into a frustum in 3D world-space, and a point cloud may be filtered to include only points from within the frustum. The remaining points may be voxelated to generate a volume in 3D world space, and the volume may be applied to a 3D DNN to generate one or more vectors. The one or more vectors, in addition to one or more additional vectors generated using a 2D DNN processing image data, may be applied to a classifier network to generate a classification for an object."
11915493,"A deep neural network(s) (DNN) may be used to detect objects from sensor data of a three dimensional (3D) environment. For example, a multi-view perception DNN may include multiple constituent DNNs or stages chained together that sequentially process different views of the 3D environment. An example DNN may include a first stage that performs class segmentation in a first view (e.g., perspective view) and a second stage that performs class segmentation and/or regresses instance geometry in a second view (e.g., top-down). The DNN outputs may be processed to generate 2D and/or 3D bounding boxes and class labels for detected objects in the 3D environment. As such, the techniques described herein may be used to detect and classify animate objects and/or parts of an environment, and these detections and classifications may be provided to an autonomous vehicle drive stack to enable safe planning and control of the autonomous vehicle."
11917307,"A method of decompression includes decompressing a compressed image according to a power curve to generate a partially decompressed image, wherein the compressed image is decompressed from a second bit depth that is lower than a first bit-depth at which the image was generated."
11918890,"While one type of input, either a mouse input or a joystick input, may be preferred for one type of a game, it may not be preferred, or even compatible, for another type of a game. Introduced herein is a game controller that employs a dedicated input, which is capable of the absolute accuracy of a mouse input or trackball input, but is also capable of measuring how far off center the input is (e.g., how far off center it has moved), and can also return to center when released, as is present in a joystick input. The introduced game controller integrates a touch sensing trackball to enjoy the benefits of both the mouse type input and joystick type input, in a single dedicated input, providing a user freedom to play any type of game without worrying about the compatibility of their game controllers."
11921502,"In various examples, systems and methods are disclosed that preserve rich spatial information from an input resolution of a machine learning model to regress on lines in an input image. The machine learning model may be trained to predict, in deployment, distances for each pixel of the input image at an input resolution to a line pixel determined to correspond to a line in the input image. The machine learning model may further be trained to predict angles and label classes of the line. An embedding algorithm may be used to train the machine learning model to predict clusters of line pixels that each correspond to a respective line in the input image. In deployment, the predictions of the machine learning model may be used as an aid for understanding the surrounding environment—e.g., for updating a world model—in a variety of autonomous machine applications."
11921997,"User interfaces and methods are disclosed. In some embodiments, a plurality of source artifacts is displayed. A selector is operable to indicate a selected set of the source artifacts. An output artifact is displayed having an output attribute that represents a combination of source attributes from the source artifacts in the selected set. An amount of contribution to the first output attribute by respective ones of the source artifacts in the first selected set is based on a coordinate of the selector relative to coordinates of the source attributes in the first selected set."
11922533,"A weighted average execution time associated with each execution stage of a plurality of execution stages used to process a plurality of frames in parallel is obtained. The processing of each of the plurality of frames is performed at each of the plurality of execution stages in a sequential order, starting with an initial execution stage and continuing with each subsequent execution stage. A first largest weighted average execution time associated with one of the plurality of execution stages is determined. A delay to the initial execution stage prior to processing a first next frame is applied. The delay is determined based on the first largest weighted average execution time."
11922556,"Apparatuses, systems, and techniques to render images. In at least one embodiment, at least one visibility parameter determined for a first image region is reused for a different second image region that neighbors the first image region (e.g., spatially and/or temporally)."
11922558,"In various examples, information may be received for a 3D model, such as 3D geometry information, lighting information, and material information. A machine learning model may be trained to disentangle the 3D geometry information, the lighting information, and/or material information from input data to provide the information, which may be used to project geometry of the 3D model onto an image plane to generate a mapping between pixels and portions of the 3D model. Rasterization may then use the mapping to determine which pixels are covered and in what manner, by the geometry. The mapping may also be used to compute radiance for points corresponding to the one or more 3D models using light transport simulation. Disclosed approaches may be used in various applications, such as image editing, 3D model editing, synthetic data generation, and/or data set augmentation."
11922567,"The present invention facilitates efficient and effective image processing. A network can comprise: a first system configured to perform a first portion of lighting calculations for an image and combing results of the first portion of lighting calculations for the image with results of a second portion of lighting calculations; and a second system configured to perform the second portion of lighting calculations and forward the results of the second portion of the lighting calculations to the first system. The first and second portion of lighting calculations can be associated with indirect lighting calculations and direct lighting calculations respectively. The first system can be a client in a local location and the second system can be a server in a remote location (e.g., a cloud computing environment). The first system and second system can be in a cloud and a video is transmitted to a local system."
11922568,"In various embodiments, a finite aperture omni-directional camera is modeled by aligning a finite aperture lens and focal point with the omni-directional part of the projection. For example, each point on an image plane maps to a direction in camera space. For a spherical projection, the lens can be orientated along this direction and the focal point is picked along this direction at focal distance from the lens. For a cylindrical projection, the lens can be oriented along the projected direction on the two dimensional (2D) xz-plane, as the projection is not omni-directional in the y direction. The focal point is picked along the (unprojected) direction so its projection on the xz-plane is at focal distance from the lens. The final outgoing ray can be constructed by sampling of point on this oriented lens and shooting a ray from there through the focal point."
11922571,"In various examples, to support training a deep neural network (DNN) to predict a dense representation of a 3D surface structure of interest, a training dataset is generated using a parametric mathematical modeling. A variety of synthetic 3D road surfaces may be generated by modeling a 3D road surface using varied parameters to simulate changes in road direction and lateral surface slope. In an example embodiment, a synthetic 3D road surface may be created by modeling a longitudinal 3D curve and expanding the longitudinal 3D curve to a 3D surface, and the resulting synthetic 3D surface may be sampled to form a synthetic ground truth projection image (e.g., a 2D height map). To generate corresponding input training data, a known pattern that represents which pixels may remain unobserved during 3D structure estimation may be generated and applied to a ground truth projection image to simulate a corresponding sparse projection image."
11923853,"A ring oscillator circuit with a frequency that is sensitive to the timing of a clock-to-Q (clk2Q) propagation delay of one or more flip-flops utilized in the ring oscillator. The clock2Q is the delay between the clock signal arriving at the clock pin on the flop and the Q output reflecting the state of the input data signal to the flop. Clk2q delay measurements are made based on measurement of the ring oscillator frequency, leading to more accurate estimates of clk2Q for different types of flip-flops and flip-flop combinations, which may in turn enable improvements in circuit layouts, performance, and area."
11925860,"This application discloses techniques for generating and querying projective hash maps. More specifically, projective hash maps can be used for spatial hashing of data related to N-dimensional points. Each point is projected onto a projection surface to convert the three-dimensional (3D) coordinates for the point to two-dimensional (2D) coordinates associated with the projection surface. Hash values based on the 2D coordinates are then used as an index to store data in the projective hash map. Utilizing the 2D coordinates rather than the 3D coordinates allows for more efficient searches to be performed to locate points in the 3D space. In particular, projective hash maps can be utilized by graphics applications for generating images, and the improved efficiency can, for example, enable a game streaming application on a server to render images transmitted to a user device via a network at faster frame rates."
11926346,"In various examples, a yield scenario may be identified for a first vehicle. A wait element is received that encodes a first path for the first vehicle to traverse a yield area and a second path for a second vehicle to traverse the yield area. The first path is employed to determine a first trajectory in the yield area for the first vehicle based at least on a first location of the first vehicle at a time and the second path is employed to determine a second trajectory in the yield area for the second vehicle based at least on a second location of the second vehicle at the time. To operate the first vehicle in accordance with a wait state, it may be determined whether there is a conflict between the first trajectory and the second trajectory, where the wait state defines a yielding behavior for the first vehicle."
11927449,"According to an aspect of an embodiment, operations may comprise receiving an approximate geographic location of a vehicle, accessing a map of a region within which the approximate geographic location of the vehicle is located, identifying a first region on the map within a first threshold distance of the approximate geographic location of the vehicle, identifying a second region on the map associated with one or more roads on the map, determining a search space on the map within which the vehicle is likely to be present, the search space representing an intersection of the first region and the second region, and determining a more accurate geographic location of the vehicle by performing a search within the search space."
11927502,"In various examples, sensor data recorded in the real-world may be leveraged to generate transformed, additional, sensor data to test one or more functions of a vehicle—such as a function of an AEB, CMW, LDW, ALC, or ACC system. Sensor data recorded by the sensors may be augmented, transformed, or otherwise updated to represent sensor data corresponding to state information defined by a simulation test profile for testing the vehicle function(s). Once a set of test data has been generated, the test data may be processed by a system of the vehicle to determine the efficacy of the system with respect to any number of test criteria. As a result, a test set including additional or alternative instances of sensor data may be generated from real-world recorded sensor data to test a vehicle in a variety of test scenarios—including those that may be too dangerous to test in the real-world."
11928764,"Apparatuses, systems, and techniques to animate objects in computer-generated graphics. In at least one embodiment, one or more neural networks are trained to identify one or more forces to be applied to one or more objects based, at least in part, on training data corresponding to two or more aspects of motion of the one or more objects."
11928772,"In a ray tracer, to prevent any long-running query from hanging the graphics processing unit, a traversal coprocessor provides a preemption mechanism that will allow rays to stop processing or time out early. The example non-limiting implementations described herein provide such a preemption mechanism, including a forward progress guarantee, and additional programmable timeout options that can be time or cycle based. Those programmable options provide a means for quality of service timing guarantees for applications such as virtual reality (VR) that have strict timing requirements."
11928822,"In various examples, live perception from sensors of a vehicle may be leveraged to detect and classify intersection contention areas in an environment of a vehicle in real-time or near real-time. For example, a deep neural network (DNN) may be trained to compute outputs—such as signed distance functions—that may correspond to locations of boundaries delineating intersection contention areas. The signed distance functions may be decoded and/or post-processed to determine instance segmentation masks representing locations and classifications of intersection areas or regions. The locations of the intersections areas or regions may be generated in image-space and converted to world-space coordinates to aid an autonomous or semi-autonomous vehicle in navigating intersections according to rules of the road, traffic priority considerations, and/or the like."
11928826,"In various examples, optical flow estimate (OFE) quality is improved when employing a hint-based algorithm in multi-level hierarchical motion estimation by using different scan orders at different resolution levels. A scan of an image performed with a scan order may initially leverage OFEs from a previous scan of the image, where the previous scan was performed using a different scan order. The OFEs leveraged from the previous scan are more likely to be of high accuracy until sufficient spatial hints are available to the hint-based algorithm for the scan to reduce the impact of potentially lower quality OFEs resulting from the different scan order of the previous scan."
11931909,"Apparatuses, systems, and techniques generate poses of an object based on data of the object observed from a first viewpoint and a second viewpoint. The poses can be evaluated to determine a portion of the data usable by an estimator to generate a pose of the object."
11934242,"Provided, in one aspect, is a data center. The data center, in this aspect, includes a data center enclosure, the data center enclosure designed for a given supply of power (Ps). The data center, according to this aspect, further includes N independent coolable clusters of data center racks located within the data center enclosure, wherein N is at least two, and further wherein the N independent coolable clusters each have an ostensible power demand (Pos) approximately equal to Ps/N, and each of the N independent coolable clusters has a respective actual power demand (Pac) adjustable at, above or below the ostensible power demand (Pos)."
11934311,"Various embodiments include a system for managing cache memory in a computing system. The system includes a sectored cache memory that provides a mechanism for sharing sectors in a cache line among multiple cache line allocations. Traditionally, different cache line allocations are assigned to different cache lines in the cache memory. Further, cache line allocations may not use all of the sectors of the cache line, leading to low utilization of the cache memory. With the present techniques, multiple cache lines share the same cache line, leading to improved cache memory utilization relative to prior techniques. Further, sectors of cache allocations can be assigned to reduce data bank conflicts when accessing cache memory. Reducing such data bank conflicts can result in improved memory access performance, even when cache lines are shared with multiple allocations."
11934520,"The disclosure provides systems and processes for applying neural networks to detect intrusions and other anomalies in communications exchanged over a data bus between two or more devices in a network. The intrusions may be detected in data being communicated to an embedded system deployed in vehicular or robotic platforms. The disclosed system and process are well suited for incorporation into autonomous control or advanced driver assistance system (ADAS) vehicles including, without limitation, automobiles, motorcycles, boats, planes, and manned and un-manned robotic devices. Data communicated to an embedded system can be detected over any of a variety of data buses. In particular, embodiments disclosed herein are well suited for use in any data communication interface exhibiting the characteristics of a lack of authentication or following a broadcast routing scheme—including, without limitation, a control area network (CAN) bus."
11934567,"A host may use address translation to convert virtual addresses to physical addresses for endpoints, which may then submit memory access requests for physical addresses. The host may incorporate the physical address and a signature of the physical address generated using a private key into a translated address field of a response to a translation request. An endpoint may treat the combination as a translated address by storing it in an entry of a translation cache, and accessing the entry for inclusion in a memory access request. The host may generate a signature of the translated address from the request using the private key, with the result being compared to the signature from the request. The memory access request may be verified when the compared values match, and the memory access may be performed using the translated address."
11934829,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
11934867,"Warp sharding techniques to switch execution between divergent shards on instructions that trigger a long stall, thereby interleaving execution between diverged threads within a warp instead of across warps. The technique may be applied to mitigate pipeline stalls in applications with low warp occupancy and high divergence. Warp data cache locality may also be improved by concentrating memory accesses within a warp rather than spreading them across warps."
11934872,"A system is provided for monitoring and controlling program flow in an event-triggered system. A program (e.g., application, algorithm, routine, etc.) may be organized into operational units (e.g., nodes executed by one or more processors), each of which tasked with executing one or more respective events (e.g., tasks) within the larger program. At least some of the events of the larger program may be successively executed in a flow, one after another, using triggers sent directly from one node to the next. In addition, the system of the present disclosure may include a manager that may exchange communications with the nodes to monitor or assess a status of the system (e.g., determine when a node has completed an event) or to control or trigger a node to initiate an event."
11934955,"Systems and methods for more accurate and robust determination of subject characteristics from an image of the subject. One or more machine learning models receive as input an image of a subject, and output both facial landmarks and associated confidence values. Confidence values represent the degrees to which portions of the subject's face corresponding to those landmarks are occluded, i.e., the amount of uncertainty in the position of each landmark location. These landmark points and their associated confidence values, and/or associated information, may then be input to another set of one or more machine learning models which may output any facial analysis quantity or quantities, such as the subject's gaze direction, head pose, drowsiness state, cognitive load, or distraction state."
11934959,"Apparatuses, systems, and techniques are presented to synthesize consistent images or video. In at least one embodiment, one or more neural networks are used to generate one or more second images based, at least in part, on one or more point cloud representations of one or more first images."
11935177,"Disclosed are apparatuses, systems, and techniques to render images with global illumination using efficient ray tracing, light source identification, and reservoir resampling that deploys temporal and spatial reservoirs."
11935179,"A fully-connected neural network may be configured for execution by a processor as a fully-fused neural network by limiting slow global memory accesses to reading and writing inputs to and outputs from the fully-connected neural network. The computational cost of fully-connected neural networks scale quadratically with its width, whereas its memory traffic scales linearly. Modern graphics processing units typically have much greater computational throughput compared with memory bandwidth, so that for narrow, fully-connected neural networks, the linear memory traffic is the bottleneck. The key to improving performance of the fully-connected neural network is to minimize traffic to slow “global” memory (off-chip memory and high-level caches) and to fully utilize fast on-chip memory (low-level caches, “shared” memory, and registers), which is achieved by the fully-fused approach. A real-time neural radiance caching technique for path-traced global illumination is implemented using the fully-fused neural network for caching scattered radiance components of global illumination."
11935194,"Systems and methods are provided to perform constrained BSDF sampling in relation to various algorithms, and specifically in relation to ray tracing algorithms. In some embodiments, a method is provided to generate samples by: determining a spherical polygon on a unit hemisphere; determining, on a unit circle, a projected area corresponding to the spherical polygon on the unit hemisphere; determining a parameterization of the projected area of the spherical polygon on the unit circle; generating samples in the projected area based on the parameterization; and generating samples in the spherical polygon. The unit circle is abase of the unit hemisphere, and the projection of the projected area is along a vector perpendicular to the unit circle. The generated samples in the spherical polygon correspond to the samples in the projected area. The method may further include evaluating a rendering equation based on the generated samples in the spherical polygon."
11936379,"Embodiments include a memory device with an improved calibration circuit. Memory device input/output pins include delay lines for adjusting the delay in each memory input/output signal path. The delay adjustment circuitry includes digital delay lines for adjusting this delay. Further, each digital delay line is calibrated via a digital delay line locked loop which enables adjustment of the delay through the digital delay line in fractions of a unit interval across variations due to differences in manufacturing process, operating voltage, and operating temperature. The disclosed techniques calibrate the digital delay lines by measuring both the high phase and the low phase of the clock signal. As a result, the disclosed techniques compensate for duty cycle distortion by combining the calibration results from both phases of the clock signal. The disclosed techniques thereby result in lower calibration error relative to approaches that measure only one phase of the clock signal."
11936507,"A transceiver circuit includes a receiver front end utilizing a ring oscillator, and a transmitter front end utilizing a pass-gate circuit in a first feedback path across a last-stage driver circuit. The transceiver circuit provides low impedance at low frequency and high impedance at high frequency, and desirable peaking behavior."
11937028,"Configurations for rack connection systems are disclosed. In at least one embodiment, installation locations for one or more cables are determined and one or more indicators corresponding to installation locations are activated."
11938406,"In various examples, compute resources may be allocated for highlight generation in cloud gaming systems. Systems and methods are disclosed that distribute, between and among various devices, processing including user interface generation and overlay, analysis of game streams for actionable events, generation of highlights, storage of highlights, and sharing of highlights. The distribution of processing or compute resources within the cloud gaming system may be dependent on system information of various devices and/or networks. Recordings, snapshots, and/or other highlights may be generated within the cloud gaming system using the determined distribution of compute resources."
11940493,A circuit for improving control over asynchronous signal crossings during circuit scan tests includes multiple scan registers and a decoder configured to translate a combined output of the scan registers into multiple one-hot controls to the local clock gates of scan registers disposed in multiple different clock domains. Programmable registers are provided to selectively enable and disable the local clock gates of the different clock domains.
11940947,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
11941719,"Various embodiments enable a robot, or other autonomous or semi-autonomous device or system, to receive data involving the performance of a task in the physical world. The data can be provided as input to a perception network to infer a set of percepts about the task, which can correspond to relationships between objects observed during the performance. The percepts can be provided as input to a plan generation network, which can infer a set of actions as part of a plan. Each action can correspond to one of the observed relationships. The plan can be reviewed and any corrections made, either manually or through another demonstration of the task. Once the plan is verified as correct, the plan (and any related data) can be provided as input to an execution network that can infer instructions to cause the robot, and/or another robot, to perform the task."
11941743,"A system and method for generating a set of samples stratified across two-dimensional elementary intervals of a two-dimensional space is disclosed within the application. A computer-implemented technique for generating the set of samples includes selecting an elementary interval associated with a stratification of the two-dimensional space, initializing at least one data structure that indicates valid regions within the elementary interface based on other samples previously placed within the two-dimensional space, and generating a sample in a valid region of the elementary interval utilizing the at least one data structure to identify the valid region prior to generating the sample. In some embodiments, the data structures comprise a pair of binary trees. The process can be repeated for each elementary interval of a selected stratification to generate the set of stratified two-dimensional samples."
11941745,"Disclosed approaches may leverage the actual spatial and reflective properties of a virtual environment—such as the size, shape, and orientation of a bidirectional reflectance distribution function (BRDF) lobe of a light path and its position relative to a reflection surface, a virtual screen, and a virtual camera—to produce, for a pixel, an anisotropic kernel filter having dimensions and weights that accurately reflect the spatial characteristics of the virtual environment as well as the reflective properties of the surface. In order to accomplish this, geometry may be computed that corresponds to a projection of a reflection of the BRDF lobe below the surface along a view vector to the pixel. Using this approach, the dimensions of the anisotropic filter kernel may correspond to the BRDF lobe to accurately reflect the spatial characteristics of the virtual environment as well as the reflective properties of the surface."
11941752,"A remote device utilizes ray tracing to compute a light field for a scene to be rendered, where the light field includes information about light reflected off surfaces within the scene. This light field is then compressed utilizing one or more video compression techniques that implement temporal reuse, such that only differences between the light field for the scene and a light field for a previous scene are compressed. The compressed light field data is then sent to a client device that decompresses the light field data and uses such data to obtain the light field for the scene at the client device. This light field is then used by the client device to compute global illumination for the scene. The global illumination may be used to accurately render the scene at the mobile device, resulting in a realistic scene that is presented by the mobile device."
11941819,"A neural network may be used to determine corner points of a skewed polygon (e.g., as displacement values to anchor box corner points) that accurately delineate a region in an image that defines a parking space. Further, the neural network may output confidence values predicting likelihoods that corner points of an anchor box correspond to an entrance to the parking spot. The confidence values may be used to select a subset of the corner points of the anchor box and/or skewed polygon in order to define the entrance to the parking spot. A minimum aggregate distance between corner points of a skewed polygon predicted using the CNN(s) and ground truth corner points of a parking spot may be used simplify a determination as to whether an anchor box should be used as a positive sample for training."
11941873,"In various examples, sensor data may be received that represents a field of view of a sensor of a vehicle located in a physical environment. The sensor data may be applied to a machine learning model that computes both a set of boundary points that correspond to a boundary dividing drivable free-space from non-drivable space in the physical environment and class labels for boundary points of the set of boundary points that correspond to the boundary. Locations within the physical environment may be determined from the set of boundary points represented by the sensor data, and the vehicle may be controlled through the physical environment within the drivable free-space using the locations and the class labels."
11941887,"The present disclosure provides various approaches for smart area monitoring suitable for parking garages or other areas. These approaches may include ROI-based occupancy detection to determine whether particular parking spots are occupied by leveraging image data from image sensors, such as cameras. These approaches may also include multi-sensor object tracking using multiple sensors that are distributed across an area that leverage both image data and spatial information regarding the area, to provide precise object tracking across the sensors. Further approaches relate to various architectures and configurations for smart area monitoring systems, as well as visualization and processing techniques. For example, as opposed to presenting video of an area captured by cameras, 3D renderings may be generated and played from metadata extracted from sensors around the area."
11941899,"Apparatuses, systems, and techniques generate poses of an object based on image data of the object obtained from a first viewpoint of the object and a second viewpoint of the object. The poses can be evaluated to determine a portion of the image data usable by an estimator to generate a pose of the object."
11944903,"In various embodiments of the present disclosure, playstyle patterns of players are learned and used to generate virtual representations (“bots”) of users. Systems and methods are disclosed that use game session data (e.g., metadata) from a plurality of game sessions of a game to learn playstyle patterns of users, based on user inputs of the user in view of variables presented within the game sessions. The game session data is applied to one or more machine learning models to learn playstyle patterns of the user for the game, and associated with a user profile of the user. Profile data representative of the user profile is then used to control or instantiate bots of the users, or of categories of users, according to the learned playstyle patterns."
11947742,"A cheat detection methodology is disclosed that relates to identifying cheaters making super-human movements in interactive programs. For example, users trying to outcompete their opponents in video games using large aim assists and aim bots that perform actions that are not feasibly human. The disclosed methodology substantially reduces or even eliminates the benefit that various cheating solutions offer. In one aspect, the disclosure provides a method of monitoring cheating in interactive programs. In one example, the method includes: (1) obtaining motion data corresponding to a user input device interacting with an interactive program, (2) segmenting data submovements from the motion data, (3) determining one or more attributes of the data submovements, and (4) detecting, based on the one or more attributes, the data submovements that are a deviation of human submovements."
11947804,A system includes a hardware circuitry having a device coupled with one or more external memory devices. The device is to detect an input/output (I/O) request associated with an external memory device of the one or more external memory devices. The device is to record a first timestamp in response to detecting the IO request transmitted to the external memory device. The device is further to detect an indication from the external memory device of a completion of the IO request associated with the external memory device and record a second timestamp in response to detecting the indication. The device is also to determine a latency associated with the IO request based on the first timestamp and the second timestamp.
11948078,"The disclosure provides a framework or system for learning visual representation using a large set of image/text pairs. The disclosure provides, for example, a method of visual representation learning, a joint representation learning system, and an artificial intelligence (AI) system that employs one or more of the trained models from the method or system. The AI system can be used, for example, in autonomous or semi-autonomous vehicles. In one example, the method of visual representation learning includes: (1) receiving a set of image embeddings from an image representation model and a set of text embeddings from a text representation model, and (2) training, employing mutual information, a critic function by learning relationships between the set of image embeddings and the set of text embeddings."
11948246,"Apparatuses, systems, and techniques to render computer graphics. In at least one embodiment, a first one or more lights are selected from among lights in a virtual scene to be rendered as a frame of graphics, and a second one or more lights are selected from among lights used to render one or more pixels in at least one of a prior frame or the current frame. A pixel of the current frame is rendered using the first and second one or more lights, and a light is selected for reuse in rendering a subsequent frame from among the first and second one or more lights."
11948315,"In various examples, two or more cameras in an automotive surround view system generate two or more input images to be stitched, or combined, into a single stitched image. In an embodiment, to improve the quality of a stitched image, a feedback module calculates two or more scores representing errors between the stitched image and one or more input images. If a computed score indicates structural errors in the stitched image, the feedback module calculates and applies one or more geometric transforms to apply to the one or more input images. If a computed score indicates color errors in the stitched image, the feedback module calculates and applies one or more photometric transforms to apply to the one or more input images."
11950396,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a modular unit is swappable or hot-swappable and has a heat exchanger, a variable speed fan, and at least one flow controller to pass fluid through microchannels of a cold plate, so that the fluid extracts heat from at least one computing device and so that fluid through a heat exchanger enables dissipation of heat by forced air from a variable speed fan."
11953957,"Systems and methods for cooling a computer environment are disclosed. In at least one embodiment, one or more neural networks can be used to adjust one or more flow control valves, of a liquid cooling system for a data center, to control a variation in liquid flow rate across the data center."
11954037,"A computing system includes a volatile memory, a cache coupled with the volatile memory, and a processing device coupled with the cache and at least one of a storage device or a network port. The processing device is to: generate a plurality of virtual addresses that are sequentially numbered for data that is to be at least one of processed or transferred in response to an input/output (I/O) request; allocate, for the data, a continuous range of physical addresses of the volatile memory; generate a set of hash-based values based on mappings between the plurality of virtual addresses and respective physical addresses of the continuous range of physical addresses; identify a unique cache line of the cache that corresponds to each respective hashed-based value of the set of hash-based values; and cause the data to be directly stored in the unique cache lines of the cache."
11954487,"Disclosed are apparatuses, systems, and techniques to perform and facilitate fast and efficient modular computational operations, such as modular division and modular inversion, using shared platforms, including hardware accelerator engines."
11954496,"In various examples, systems and methods for reducing written requirements in a system on chip (SoC) are described herein. For instance, a total number of iterations may be determined for processing data, such as data representing an array. In some circumstances, a set of iterations may include a first number of iterations that is less than a second number of iterations. As such, and during execution of the set of iterations, a predicate flag corresponding to an excess iteration of the set of iterations may be generated, where the excess iteration corresponds to an iteration that is part of a number of excess iterations that is associated with a difference between the first number of iterations and the second number of iterations. Based on the predicate flag, one or more first values corresponding to the iteration may be prevented from being written to memory."
11954518,"Apparatuses, systems, and techniques to optimize processor resources at a user-defined level. In at least one embodiment, priority of one or more tasks are adjusted to prevent one or more other dependent tasks from entering an idle state due to lack of resources to consume."
11954791,"Approaches in accordance with various embodiments provide for fluid simulation with substantially reduced time and memory requirements with respect to conventional approaches. In particular, various embodiments can perform time and energy efficient, large scale fluid simulation on processing hardware using a method that does not solve for the Navier-Stokes equations to enforce incompressibility. Instead, various embodiments generate a density tensor and rigid body map tensor for a large number of particles contained in a sub-domain. Collectively, the density tensor and rigid body map may represent input channels of a network with three spatial-dimensions. The network may apply a series of operations to the input channels to predict an updated position and updated velocity for each particle at the end of a frame. Such approaches can handle tens of millions of particles within a virtually unbounded simulation domain, as compared to classical approaches that solve for the Navier-Stokes equations."
11954830,"High dynamic range (HDR) support is provided for legacy application programs, such as games that are configured to display standard dynamic range (SDR) frames. HDR frames may be synthesized without modifying the legacy application program. The buffer creation process of the legacy application program is intercepted and modified before creation of the SDR format buffer so that the buffer is configured to use an HDR format. A location of an intermediate buffer storing HDR rendered data is determined by intercepting and analyzing graphics driver calls in a command stream produced by the legacy application program. The HDR rendered data is combined with user interface content extracted from the SDR frames. Additionally, any post processing effects used by the legacy application program to produce the SDR frames may be predicted and applied to the HDR rendered data to synthesize the HDR frames for display on a modern HDR display device."
11954862,"A neural network system leverages dual attention, specifically both spatial attention and channel attention, to jointly estimate heart rate and respiratory rate of a subject by processing images of the subject. A motion neural network receives images of the subject and estimates heart and breath rates of the subject using both spatial and channel domain attention masks to focus processing on particular feature data. An appearance neural network computes a spatial attention mask from the images of the subject and may indicate that features associated with the subject's face (as opposed to the subject's hair or shoulders) to accurately estimate the heart and/or breath rate. Channel-wise domain attention is learned during training and recalibrates channel-wise feature responses to select the most informative features for processing. The channel attention mask is learned during training and can be used for different subjects during deployment."
11954914,"In various examples, systems and methods are described that generate scene flow in 3D space through simplifying the 3D LiDAR data to “2.5D” optical flow space (e.g., x, y, and depth flow). For example, LiDAR range images may be used to generate 2.5D representations of depth flow information between frames of LiDAR data, and two or more range images may be compared to generate depth flow information, and messages may be passed—e.g., using a belief propagation algorithm—to update pixel values in the 2.5D representation. The resulting images may then be used to generate 2.5D motion vectors, and the 2.5D motion vectors may be converted back to 3D space to generate a 3D scene flow representation of an environment around an autonomous machine."
11956306,"Systems and techniques for performing multicast-reduction operations. In at least one embodiment, a network device receives first network data associated with a multicast operation to be collectively performed by at least a plurality of endpoints. The network device reserves resources to process second network data to be received from the endpoints, and sends the first network data to a plurality of additional network devices. The network device receives the second network data, and processes the second network data using the reserved resources."
11956342,"A system includes a link having one or more lanes associated with transmitting data and one or more lanes associated with transmitting a clock signal. The system includes a device coupled with the link, the device to receive a signal via the one or more lanes associated with transmitting the clock signal and determine a number of pulses associated with the signal over a period. The device is further to determine the number of pulses associated with the signal fail to satisfy a predetermined condition relating to a specified number of pulses for the period and initiate a power-down sequence in response to determining the number of pulses that fail to satisfy the predetermined condition relating to the specified number of pulses for the period."
11956931,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, fins are provided within a cold plate and are adjustable to control an amount of surface area of the fins to be exposed to a fluid and to be cooled by the fluid based, at least in part, upon a temperature associated with the fluid or with at least one computing device."
11958529,A framework for offline learning from a set of diverse and suboptimal demonstrations operates by selectively imitating local sequences from the dataset. At least one embodiment recovers performant policies from large manipulation datasets by decomposing the problem into a goal-conditioned imitation and a high-level goal selection mechanism.
11960026,"In various examples, a deep neural network(s) (e.g., a convolutional neural network) may be trained to detect moving and stationary obstacles from RADAR data of a three dimensional (3D) space. In some embodiments, ground truth training data for the neural network(s) may be generated from LIDAR data. More specifically, a scene may be observed with RADAR and LIDAR sensors to collect RADAR data and LIDAR data for a particular time slice. The RADAR data may be used for input training data, and the LIDAR data associated with the same or closest time slice as the RADAR data may be annotated with ground truth labels identifying objects to be detected. The LIDAR labels may be propagated to the RADAR data, and LIDAR labels containing less than some threshold number of RADAR detections may be omitted. The (remaining) LIDAR labels may be used to generate ground truth data."
11960433,"Apparatuses, systems, and techniques to route data transfers between hardware devices. In at least one embodiment, a path over which to transfer data from a first hardware component of a computer system to a second hardware component of a computer system is determined based, at least in part, on one or more characteristics of different paths usable to transfer the data."
11960570,"A multi-level contrastive training strategy for training a neural network relies on image pairs (no other labels) to learn semantic correspondences at the image level and region or pixel level. The neural network is trained using contrasting image pairs including different objects and corresponding image pairs including different views of the same object. Conceptually, contrastive training pulls corresponding image pairs closer and pushes contrasting image pairs apart. An image-level contrastive loss is computed from the outputs (predictions) of the neural network and used to update parameters (weights) of the neural network via backpropagation. The neural network is also trained via pixel-level contrastive learning using only image pairs. Pixel-level contrastive learning receives an image pair, where each image includes an object in a particular category."
11961001,"A neural network structure is separated into an odd neural network including only the odd layers and an even neural network including only the even layers. In order to allow for parallel execution, for forward propagation a second input is generated from the original input, while for backward propagation a second error gradient is generated. Parallel execution may accelerate the forward and backward propagation operations without significant change in accuracy of the model. Additionally, restructuring a single neural network into two or more parallel neural networks may reduce the total time needed for training."
11961176,"Disclosed approaches provide for interactions of secondary rays of light transport paths in a virtual environment to share lighting contributions when determining lighting conditions for a light transport path. Interactions may be shared based on similarities in characteristics (e.g., hit locations), which may define a region in which interactions may share lighting condition data. The region may correspond to a texel of a texture map and lighting contribution data for interactions may be accumulated to the texel spatially and/or temporally, then used to compute composite lighting contribution data that estimates radiance at an interaction. Approaches are also provided for reprojecting lighting contributions of interactions to pixels to share lighting contribution data from secondary bounces of light transport paths while avoiding potential over blurring."
11961243,"A geometric approach may be used to detect objects on a road surface. A set of points within a region of interest between a first frame and a second frame are captured and tracked to determine a difference in location between the set of points in two frames. The first frame may be aligned with the second frame and the first pixel values of the first frame may be compared with the second pixel values of the second frame to generate a disparity image including third pixels. One or more subsets of the third pixels that have a value above a first threshold may be combined, and the third pixels may be scored and associated with disparity values for each pixel of the one or more subsets of the third pixels. A bounding shape may be generated based on the scoring."
11961308,"Systems and methods for detecting blockages in images are described. An example method may include receiving a plurality of images captured by a camera installed on an apparatus. The method may include identifying one or more candidate blocked regions in the plurality of images. Each of the candidate blocked regions may contain image data caused by blockages in the camera's field-of-view. The method may further include assigning scores to the one or more candidate blocked regions based on relationships among the one or more candidate blocked regions in the plurality of images. In response to a determination that one of the scores is above a predetermined blockage threshold, the method may include generating an alarm signal for the apparatus."
11962301,"Technologies for low jitter and low power ring oscillators with multi-phase signal reassembly are described. A ring oscillator circuit includes a ring oscillator with a set of M delay stages, each stage outputs a phase signal, where M is a positive integer greater than one. The ring oscillator circuit includes a phase selector circuit coupled to the ring oscillator. The phase selector circuit can receive M phase signals from the ring oscillator and generate N phase signals based on the M phase signals, where N is a positive integer less than M."
11962306,"Methods and apparatus are described for detecting anomalies in a clock signal. Example methods include sensing a clock signal that exhibits alternating phases during normal operation; responsive to sensing the start of a first phase, generating a pulse; and if the pulse terminates before sensing the end of the first phase, asserting a clock stopped detection signal. Example clock anomaly detection apparatus includes a clock signal input for coupling to a clock signal that, during normal operation, oscillates between first and second clock states. An anomaly detection output is asserted if the clock signal remains in the first clock state longer than a first phase expected duration or remains in the second clock state longer than a second phase expected duration."
11962312,"A glitch detection device includes an oscillator to generate multiple local clocks of multiple different phases and a sampling circuit to oversample, using the multiple local clocks, a system clock to generate multiple samples of the system clock. The device further includes digital logic that in turn includes a glitch detector to monitor a variation in pulse width of the system clock based on counting the multiple samples and to report a glitch in response to detecting a variation in the pulse width that exceeds a threshold value. The digital logic further includes a loop filter coupled between the glitch detector and the oscillator. The loop filter variably adjusts the oscillator based on a frequency of each of the multiple samples to control an output frequency of each of the multiple different phases of the oscillator."
11962638,"Systems and methods related to transferring (e.g., large) files over a network are disclosed. In at least one embodiment, a client-server framework establishes a QUIC connection between a server application and a client application. Source files are processed by the server application to divide the source files into a number of chunks. Differential file transfer can be implemented between the client application and the server application by comparing metadata for chunks of the source file with metadata of local chunks of a destination file already stored in a local storage associated with the client application. Missing chunks can be requested from the server application and transferred to the client application using HTTP/3 messages."
11963339,"Systems and methods for cooling a data center are disclosed. In at least one embodiment, a radiator is associated with one or more racks of a datacenter and has a first portion to function as an air-to-liquid heat exchanger having a primary cooling loop to absorb first heat away from the one or more racks and has a second portion to function as a liquid-to-liquid heat exchanger to enable at least one secondary cooling loop to exchange second heat with the primary cooling loop."
11966228,"In various examples, a current claimed set of points representative of a volume in an environment occupied by a vehicle at a time may be determined. A vehicle-occupied trajectory and at least one object-occupied trajectory may be generated at the time. An intersection between the vehicle-occupied trajectory and an object-occupied trajectory may be determined based at least in part on comparing the vehicle-occupied trajectory to the object-occupied trajectory. Based on the intersection, the vehicle may then execute the first safety procedure or an alternative procedure that, when implemented by the vehicle when the object implements the second safety procedure, is determined to have a lesser likelihood of incurring a collision between the vehicle and the object than the first safety procedure."
11966348,"Methods of operating a serial data bus divide series of data bits into sequences of one or more bits and encode the sequences as N-level symbols, which are then transmitted at multiple discrete voltage levels. These methods may be utilized to communicate over serial data lines to improve bandwidth and reduce crosstalk and other sources of noise."
11966480,"Apparatuses, systems, and techniques for supporting fairness of multiple context sharing cryptographic hardware. An accelerator circuit includes a copy engine (CE) with AES-GCM hardware configured to perform both encryption and authentication of data transfers for multiple applications or multiple data streams in a single application or belonging to a single user. The CE splits a data transfer of a specified size into a set of partial transfers. The CE sequentially executes the set of partial transfers using a context for a period of time (e.g., a timeslice) for an application. The CE stores in a secure memory for the application one or more data for encryption or decryption (e.g., a hash key, a block counter, etc.) computed from a last partial transfer. The one or more data for encryption or decryption are retrieved and used when data transfers for the application is resumed by the CE."
11966673,"In various examples, a sensor model may be learned to predict virtual sensor data for a given scene configuration. For example, a sensor model may include a deep neural network that supports generative learning—such as a generative adversarial network (GAN). The sensor model may accept an encoded representation of a scene configuration as an input using any number of data structures and/or channels (e.g., concatenated vectors, matrices, tensors, images, etc.), and may output virtual sensor data. Real-world data and/or virtual data may be collected and used to derive training data, which may be used to train the sensor model to predict virtual sensor data for a given scene configuration. As such, one or more sensor models may be used as virtual sensors in any of a variety of applications, such as in a simulated environment to test features and/or functionality of one or more autonomous or semi-autonomous driving software stacks."
11966737,"Systems and methods for an efficient and robust multiprocessor-coprocessor interface that may be used between a streaming multiprocessor and an acceleration coprocessor in a GPU are provided. According to an example implementation, in order to perform an acceleration of a particular operation using the coprocessor, the multiprocessor: issues a series of write instructions to write input data for the operation into coprocessor-accessible storage locations, issues an operation instruction to cause the coprocessor to execute the particular operation; and then issues a series of read instructions to read result data of the operation from coprocessor-accessible storage locations to multiprocessor-accessible storage locations."
11966765,"Systems and methods are disclosed for throttling memory bandwidth accessed by virtual machines (VMs). A technique for dynamically throttling the virtual computer processing units (vCPUs) assigned to a VM (tenant) controls the memory access rate of the VM. When the memory is shared by multiple VMs in a cloud-computing environment, one VM increasing its memory access rate may cause another VM to suffer memory access starvation. This behavior violates the principle of VM isolation in cloud computing. In contrast to conventional systems, a software solution for dynamically throttling the vCPUs may be implemented within a hypervisor and is therefore portable across CPU families and doesn't require specialized server-class CPU capabilities or limit the system configuration."
11966835,"A sparse convolutional neural network accelerator system that dynamically and efficiently identifies fine-grained parallelism in sparse convolution operations. The system determines matching pairs of non-zero input activations and weights from the compacted input activation and weight arrays utilizing a scalable, dynamic parallelism discovery unit (PDU) that performs a parallel search on the input activation array and the weight array to identify reducible input activation and weight pairs."
11966838,"In various examples, a machine learning model—such as a deep neural network (DNN)—may be trained to use image data and/or other sensor data as inputs to generate two-dimensional or three-dimensional trajectory points in world space, a vehicle orientation, and/or a vehicle state. For example, sensor data that represents orientation, steering information, and/or speed of a vehicle may be collected and used to automatically generate a trajectory for use as ground truth data for training the DNN. Once deployed, the trajectory points, the vehicle orientation, and/or the vehicle state may be used by a control component (e.g., a vehicle controller) for controlling the vehicle through a physical environment. For example, the control component may use these outputs of the DNN to determine a control profile (e.g., steering, decelerating, and/or accelerating) specific to the vehicle for controlling the vehicle through the physical environment."
11967022,"In various examples, to support training a deep neural network (DNN) to predict a dense representation of a 3D surface structure of interest, a training dataset is generated using a parametric mathematical modeling. A variety of synthetic 3D road surfaces may be generated by modeling a 3D road surface using varied parameters to simulate changes in road direction and lateral surface slope. In an example embodiment, a synthetic 3D road surface may be created by modeling a longitudinal 3D curve and expanding the longitudinal 3D curve to a 3D surface, and the resulting synthetic 3D surface may be sampled to form a synthetic ground truth projection image (e.g., a 2D height map). To generate corresponding input training data, a known pattern that represents which pixels may remain unobserved during 3D structure estimation may be generated and applied to a ground truth projection image to simulate a corresponding sparse projection image."
11967024,"A technique is described for extracting or constructing a three-dimensional (3D) model from multiple two-dimensional (2D) images. In an embodiment, a foreground segmentation mask or depth field may be provided as an additional supervision input with each 2D image. In an embodiment, the foreground segmentation mask or depth field is automatically generated for each 2D image. The constructed 3D model comprises a triangular mesh topology, materials, and environment lighting. The constructed 3D model is represented in a format that can be directly edited and/or rendered by conventional application programs, such as digital content creation (DCC) tools. For example, the constructed 3D model may be represented as a triangular surface mesh (with arbitrary topology), a set of 2D textures representing spatially-varying material parameters, and an environment map. Furthermore, the constructed 3D model may be included in 3D scenes and interacts realistically with other objects."
11967396,"A multi-rank system includes multiple circuit ranks communicating over a common data line to multiple data receivers, each corresponding to one or more of the ranks and each having a corresponding reference voltage generator and clock timing adjustment circuit, such that a rank to communicate on the shared data line is switched without reconfiguring outputs of either the reference voltage generators or the clock timing adjustment circuits."
11968040,"Various embodiments and implementations of graph-neural-network (GNN)-based decoding applications are disclosed. The GNN-based decoding schemes are broadly applicable to different coding schemes, and capable of operating on both binary and non-binary codewords, in different implementations. Advantageously, the inventive GNN-based decoding is scalable, even with arbitrary block lengths, and not subject to typical limits with respect to dimensionality. Decoding performance of the inventive GNN-based techniques demonstrably matches or outpaces BCH and LDPC (both regular and 5G NR) decoding algorithms, while exhibiting improvements with respect to number of iterations required and scalability of the GNN-based approach. These inventive concepts are implemented, according to various embodiments, as methods, systems, and computer program products."
11971774,"A datacenter power management system and method is disclosed. A plurality of computing units are enabled to operate at a second frequency, higher than a first frequency, in response to determining from respective power coefficients for these computing units, that a power level at this higher frequency remains below a power budget."
11971790,"The disclosure describes a method of monitoring the dynamic power consumption of ReRAM crossbars and determines the occurrence of faults when a changepoint is detected in the monitored power-consumption time series. Statistical features are computed before and after the changepoint and train a predictive model using machine-learning techniques. In this way, the computationally expensive fault localization and error-recovery steps are carried out only when a high fault rate is estimated. With the proposed fault-detection method and the predictive model, the test time is significantly reduced while high classification accuracy for well-known AI/ML datasets using a ReRAM-based computing system (RCS) can still be ensured."
11972188,"To ensure proper operation (e.g., speed and/or function) of standard cells fabricated within an integrated circuit a minimum potential difference between the high and low power supply rails needs to be maintained. IR drop refers to a reduction in the potential difference between the power supply rails and is caused when the switching activity of cells that share a power supply rail is greater than can be provided at a particular time. Before fabrication, placement of the cells is reorganized within bounding box regions. Power density across the power rails within each bounding box is normalized based on spatial and temporal power density characteristics of each cell. The reorganization is IR aware and has minimal impact on timing and IR drop is mitigated because distributing current consumption between the supply rails reduces current spikes and IR drops."
11972281,"A first intermediate representation of a first portion of a source code implementing an application and a second intermediate representation of a second portion of the source code is received by a processing device. The first intermediate representation and the second intermediate representation is merged, at run-time, into a merged intermediate representation, wherein the first intermediate representation includes a reference to a function in the second intermediate representation. An execution flow transfer instruction within the merged intermediate representation is identified based on a run-time value of a parameter of the application. The execution flow transfer instruction references the function. A set of executable instructions implementing the function is identified within the merged intermediate representation. The execution flow transfer instruction is replaced with a copy of the set of executable instructions implementing the function."
11972354,"Artificial neural networks (ANNs) are computing systems that imitate a human brain by learning to perform tasks by considering examples. By representing an artificial neural network utilizing individual paths each connecting an input of the ANN to an output of the ANN, a complexity of the ANN may be reduced, and the ANN may be trained and implemented in a much faster manner when compared to an implementation using fully connected ANN graphs."
11973060,"A TSV of a first semiconductor die may extend from a semiconductor substrate of the first semiconductor die through at least one metallization layer of the die to connect to a metallization layer to supply power to the second semiconductor die. By extending the TSV, resistance may be reduced, allowing for enhanced power delivery to the second semiconductor die. Resistance may be further reduced by allowing for the TSV to connect to a thicker metallization layer than would otherwise be possible. Also, in some embodiments, the TSV may connect to a metallization layer that is suitable for supplying power to both semiconductor dies. The first semiconductor die may be a top die or a bottom die in a face-to-face arrangement. Disclosed concepts may be extended to any number of dies included in a die stack that includes the face-to-face arrangement."
11973501,"A multi-rank circuit system includes multiple transmitters each switchably coupled to a first end of a shared input/output (IO) channel and a unified receiver coupled to a second end of the shared IO channel. The unified receiver is coupled to apply a preconfigured analog reference voltage to set a differential output of the unified receiver, and further configured to apply a variable digital code to adjust the differential output according to a particular one of the transmitters that is switched to the shared IO channel."
11974416,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, one or more flow controllers is associated with a cold plate and with a thermosyphon condenser that is elevated with respect to a cold plate so that two-phase fluid is enabled for gravity-assisted downflow in a liquid phase to a cold plate for absorption of heat and is enabled for buoyancy-driven upflow through a riser tube into a thermosyphon condenser for dissipation of heat of at least one computing device."
11976939,"In various examples, operations include obtaining, from a machine learning model, feature classifications that correspond to features of objects depicted in images of a geographical area in which the images are provided to the machine learning model. The operations may also include annotating the images with three-dimensional representations that are based on the obtained feature classifications. Further, the operations may include generating map data corresponding to the geographical area based on the annotated images."
11977386,Techniques to generate driving scenarios for autonomous vehicles characterize a path in a driving scenario according to metrics such as narrowness and effort. Nodes of the path are assigned a time for action to avoid collision from the node. The generated scenarios may be simulated in a computer.
11977388,"The performance of a neural network is improved by applying quantization to data at various points in the network. In an embodiment, a neural network includes two paths. A quantization is applied to each path, such that when an output from each path is combined, further quantization is not required. In an embodiment, the neural network is an autoencoder that includes at least one skip connection. In an embodiment, the system determines a set of quantization parameters based on the characteristics of the data in the primary path and in the skip connection, such that both network paths produce output data in the same fixed point format. As a result, the data from both network paths can be combined without requiring an additional quantization."
11977452,"A method for a storage system to process input and output operations. The method includes receiving writes over time to an address at a base virtual volume, storing each of the writes in a physical storage at a new location that is without existing data, tagging each stored write with a different generation number to distinguish between different versions of data written to the address at the base virtual volume, receiving a read of the address at the base virtual volume, and, in response to the read of the address at the base virtual volume, returning one of the stored writes that is tagged with a newer generation number than a remainder of the stored writes."
11977489,"Apparatuses, systems, and techniques for memory management are disclosed. In at least one embodiment, memory management is provided for a heterogenous system, for example, a system including a CPU and a GPU, in which redundant or unnecessary memory transfers are reduced."
11977766,"A hierarchical network enables access for a stacked memory system including or more memory dies that each include multiple memory tiles. The processor die includes multiple processing tiles that are stacked with the one or more memory die. The memory tiles that are vertically aligned with a processing tile are directly coupled to the processing tile and comprise the local memory block for the processing tile. The hierarchical network provides access paths for each processing tile to access the processing tile's local memory block, the local memory block coupled to a different processing tile within the same processing die, memory tiles in a different die stack, and memory tiles in a different device. The ratio of memory bandwidth (byte) to floating-point operation (B:F) may improve 50× for accessing the local memory block compared with conventional memory. Additionally, the energy consumed to transfer each bit may be reduced by 10×."
11977888,"A method, computer readable medium, and processor are described herein for inline data inspection by using a decoder to decode a load instruction, including a signal to cause a circuit in a processor to indicate whether data loaded by a load instruction exceeds a threshold value. Moreover, an indication of whether data loaded by a load instruction exceeds a threshold value may be stored."
11978181,"Apparatuses, systems, and techniques to process luminance and/or radiance values of one or more images from one or more cameras using one or more neural networks to perform a machine vision task. In at least one embodiment, one or more neural networks determine detection difficulty levels of objects within the one or more images and performs a machine vision task based on the determined detection difficulty levels of objects within images associated with that ask."
11978258,"Apparatuses, systems, and techniques to identify out-of-distribution input data in one or more neural networks. In at least one embodiment, a technique includes training one or more neural networks to infer a plurality of characteristics about input information based, at least in part, on the one or more neural networks being independently trained to infer each of the plurality of characteristics about the input information."
11978266,"In various examples, estimated field of view or gaze information of a user may be projected external to a vehicle and compared to vehicle perception information corresponding to an environment outside of the vehicle. As a result, interior monitoring of a driver or occupant of the vehicle may be used to determine whether the driver or occupant has processed or seen certain object types, environmental conditions, or other information exterior to the vehicle. For a more holistic understanding of the state of the user, attentiveness and/or cognitive load of the user may be monitored to determine whether one or more actions should be taken. As a result, notifications, AEB system activations, and/or other actions may be determined based on a more complete state of the user as determined based on cognitive load, attentiveness, and/or a comparison between external perception of the vehicle and estimated perception of the user."
11978496,A method includes generating a differential voltage from a first reference voltage generator; receiving the differential voltage at a second reference voltage generator; dividing the differential voltage at the second reference voltage generator into multiple available reference voltage levels; and selecting one of the available reference voltage levels to apply to a circuit.
11981349,"Embodiments of the present disclosure relate to behavior planning for autonomous vehicles. The technology described herein selects a preferred trajectory for an autonomous vehicle based on an evaluation of multiple hypothetical trajectories by different components within a planning system. The various components provide an optimization score for each trajectory according to the priorities of the component and scores from multiple components may form a final optimization score. This scoring system allows the competing priorities (e.g., comfort, minimal travel time, fuel economy) of different components to be considered together. In examples, the trajectory with the best combined score may be selected for implementation. As such, an iterative approach that evaluates various factors may be used to identify an optimal or preferred trajectory for an autonomous vehicle when navigating an environment."
11983536,"Systems and methods herein address power for one or more processing units, using one of a plurality of power profiles during execution of a group of real-time instructions, the one of the plurality of power profiles determined based in part on a relationship determined between the one of the plurality of power profiles and a power profile of the group of real-time instructions, the relationship limited by a threshold, and the plurality of power profiles are associated with a plurality of groups of reference instructions."
11983566,"Apparatuses, systems, and techniques for scheduling deep learning tasks in hardware are described. One accelerator circuit includes multiple fixed-function circuits that each processes a different layer type of a neural network. A scheduler circuit receives state information associated with a respective layer being processed by a respective fixed-function circuit and dependency information that indicates a layer dependency condition for the respective layer. The scheduler circuit determines that the layer dependency condition is satisfied using the state information and the dependency information and enables the fixed-function circuit to process the current layer at the respective fixed-function circuit."
11983815,"In various examples, a deep three-dimensional (3D) conditional generative model is implemented that can synthesize high resolution 3D shapes using simple guides—such as coarse voxels, point clouds, etc.—by marrying implicit and explicit 3D representations into a hybrid 3D representation. The present approach may directly optimize for the reconstructed surface, allowing for the synthesis of finer geometric details with fewer artifacts. The systems and methods described herein may use a deformable tetrahedral grid that encodes a discretized signed distance function (SDF) and a differentiable marching tetrahedral layer that converts the implicit SDF representation to an explicit surface mesh representation. This combination allows joint optimization of the surface geometry and topology as well as generation of the hierarchy of subdivisions using reconstruction and adversarial losses defined explicitly on the surface mesh."
11983928,"Apparatuses, systems, and techniques for managing lost objects in an intelligent video analytics system. A first set of application modules is executed for an object tracking application configured to track, based on images depicting an environment, a state of objects included in the environment. The first set of application modules is associated with a first object tracker type. A request is received to configure the object tracking application to execute a second set of application modules associated with a second object tracker type. The second set of application modules includes one or more application modules that are different from application modules of the first set of application modules. The object tracking application is configured to execute the second set of application modules in accordance with the request. The second set of application modules is executed for the object tracking application to track, based on the images depicting the environment, the state of the objects included in the environment."
11985220,"An integrated circuit for a receiving link device includes a processing device to detect, using an equalizer of the receiving link device, that a receiver (RX) pre-cursor value is outside of a threshold value based on a target RX tap value. The processing device further generates, based on the detecting, a plurality of tap messages having a plurality of up or down commands to one of decrease or increase a corresponding transmitter (TX) pre-cursor value of a transmitting link device. The processing device further causes the plurality of tap messages to be provided to a local transmitter to be transmitted to the transmitting link device. The plurality of tap messages is to cause the transmitting link device to adjust the corresponding TX pre-cursor value."
11985221,"Disclosed are apparatuses, systems, and techniques to perform and facilitate secure ladder computational operations whose iterative execution depends on secret values associated with input data. Disclosed embodiments use masking factors that re-blind secret data without exposing the unmasked secret data between iterations of the ladder computations. Some disclosed embodiments use Montgomery multiplication techniques to facilitate secret data masking by efficiently avoiding modular division operations. Disclosed embodiments significantly reduce the vulnerability of ladder computations to adversarial side-channel attacks."
11985801,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, flow controllers are associated with cold plates and have direct and bypass ports, so that when direct ports are disabled for removal of a first cold plate, bypass ports are enabled to bypass a first cold plate and to enable a second cold plate to be continuously cooled by a datacenter cooling system."
11988401,"Systems and methods for cooling in a datacenter are disclosed. In at least one embodiment, a thermal load bank (TLB) system to test a hybrid datacenter cooling system includes one or more thermal features to generate heat within a TLB system and includes one or more hybrid cooling features to provide air and liquid cooling responses to such heat generated by one or more thermal features."
11988518,"A computer-implemented method may comprise: receiving sensor data from a sensor of an autonomous vehicle; determining a presence of a lane closure object located on a lane element; determining a change of the lane closure object, selected from the presence of the lane closure object or absence of the lane closure object on the lane element; generating a change candidate based on the change in the lane closure object; obtaining a plurality of the change candidates during a time period or the autonomous vehicle being on a preceding lane element on the route; analyzing the plurality of change candidates for the change being the presence of the lane closure object or the absence of the lane closure object on the lane element; generating a final change candidate based on the change; and providing the final change candidate for updating a high definition map of the route having the lane element."
11989067,A portable computing device comprises: a base portion that includes a keyboard; and a display portion that is movably coupled to the base portion and includes: a heat sink with cooling fins; one or more heat-generating electronic devices that are thermally coupled to the heat sink; and at least one cooling fan configured to direct cooling air across the cooling fins.
11989262,"Approaches presented herein provide for unsupervised domain transfer learning. In particular, three neural networks can be trained together using at least labeled data from a first domain and unlabeled data from a second domain. Features of the data are extracted using a feature extraction network. A first classifier network uses these features to classify the data, while a second classifier network uses these features to determine the relevant domain. A combined loss function is used to optimize the networks, with a goal of the feature extraction network extracting features that the first classifier network is able to use to accurately classify the data, but prevent the second classifier from determining the domain for the image. Such optimization enables object classification to be performed with high accuracy for either domain, even though there may have been little to no labeled training data for the second domain."
11989642,"In various examples, historical trajectory information of objects in an environment may be tracked by an ego-vehicle and encoded into a state feature. The encoded state features for each of the objects observed by the ego-vehicle may be used—e.g., by a bi-directional long short-term memory (LSTM) network—to encode a spatial feature. The encoded spatial feature and the encoded state feature for an object may be used to predict lateral and/or longitudinal maneuvers for the object, and the combination of this information may be used to determine future locations of the object. The future locations may be used by the ego-vehicle to determine a path through the environment, or may be used by a simulation system to control virtual objects—according to trajectories determined from the future locations—through a simulation environment."
11989948,"Apparatuses, systems, and techniques to perform non-maximum suppression (NMS) with a bit-reduced radix sort to remove redundant bounding boxes are described. In at least one embodiment, one or more circuits perform i) a bit-reduced radix sort operation to sort a list of confidence scores associated with a set of bounding boxes corresponding to one or more objects within one or more digital images and ii) a non-maximum suppression (NMS) operation on the sorted list to remove one or more redundant bounding boxes from the set."
11990713,"Apparatuses, systems, and methods to move end connectors. In at least one embodiment, a linkage system to move an end connector between at least a first position and a second position is driven by an actuator in a first direction to drive movement of the end connector in a second direction, perpendicular to the first direction."
11991865,"Systems and methods for cooling a computer environment are disclosed. In at least one embodiment, a cooling assembly can be used to monitor and control fluid quality associated with one or more servers."
11995023,"Apparatuses, systems, and techniques to route data transfers between hardware devices. In at least one embodiment, a path over which to transfer data from a first hardware component of a computer system to a second hardware component of a computer system is determined based, at least in part, on one or more characteristics of different paths usable to transfer the data."
11995378,"The disclosure is directed to a process that can predict and prevent an audio artifact from occurring. The process can monitor the systems, processes, and execution threads on a larger system/device, such as a mobile or in-vehicle device. Using a learning algorithm, such as deep neural network (DNN), the information collected can generate a prediction of whether an audio artifact is likely to occur. The process can use a second learning algorithm, which also can be a DNN, to generate recommended system adjustments that can attempt to prevent the audio glitch from occurring. The recommendations can be for various systems and components on the device, such as changing the processing system frequency, the memory frequency, and the audio buffer size. After the audio artifact has been prevented, the system adjustments can be reversed fully or in steps to return the system to its state prior to the system adjustments."
11995551,"A neural network includes at least a first network layer that includes a first set of filters and a second network layer that includes a second set of filters. Notably, a filter was removed from the first network layer. A bias associated with a different filter included in the second set of filters compensates for a different bias associated with the filter that was removed from the first network layer."
11995759,"In examples, the number of rays used to sample lighting conditions of a light source in a virtual environment with respect to particular locations in the virtual environment may be adapted to scene conditions. An additional ray(s) may be used for locations that tend to be associated with visual artifacts in rendered images. A determination may be made on whether to cast an additional ray(s) to a light source for a location and/or a quantity of rays to cast. To make the determination variables such as visibilities and/or hit distances of ray-traced samples of the light source may be analyzed for related locations in the virtual environment, such as those in a region around the location (e.g., within an N-by-N kernel centered at the location). Factors may include variability in visibilities and/or hit distances, differences between visibilities and/or hit distances relative to the location, and magnitudes of hit distances."
11995854,"One embodiment of a method includes predicting one or more three-dimensional (3D) mesh representations based on a plurality of digital images, wherein the one or more 3D mesh representations are refined by minimizing at least one difference between the one or more 3D mesh representations and the plurality of digital images."
11995883,"Approaches are presented for training and using scene graph generators for transfer learning. A scene graph generation technique can decompose a domain gap into individual types of discrepancies, such as may relate to appearance, label, and prediction discrepancies. These discrepancies can be reduced, at least in part, by aligning the corresponding latent and output distributions using one or more gradient reversal layers (GRLs). Label discrepancies can be addressed using self-pseudo-statistics collected from target data. Pseudo statistic-based self-learning and adversarial techniques can be used to manage these discrepancies without the need for costly supervision from a real-world dataset."
11995895,"In various examples, image areas may be extracted from a batch of one or more images and may be scaled, in batch, to one or more template sizes. Where the image areas include search regions used for localization of objects, the scaled search regions may be loaded into Graphics Processing Unit (GPU) memory and processed in parallel for localization. Similarly, where image areas are used for filter updates, the scaled image areas may be loaded into GPU memory and processed in parallel for filter updates. The image areas may be batched from any number of images and/or from any number of single- and/or multi-object trackers. Further aspects of the disclosure provide approaches for associating locations using correlation response values, for learning correlation filters in object tracking based at least on focused windowing, and for learning correlation filters in object tracking based at least on occlusion maps."
11997306,A method dynamically selects one of a first sampling order and a second sampling order for a ray trace of pixels in a tile where the selection is based on a motion vector for the tile. The sampling order may be a bowtie pattern or an hourglass pattern.
11997830,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, an integrated power and coolant distribution unit (PCDU) is provided to determine a change in a power state or a coolant state of at least one server and to enable a coolant response from an overhead cooling unit (OCU) to dissipate heat from secondary coolant of a secondary cooling loop."
12001592,"Apparatuses, systems, and techniques for handling faults by a direct memory access (DMA) engine. When a DMA engine detects an error associated with an encryption or decryption operation, the DMA engine reports the error to a CPU, which may be executing an untrusted software directing a DMA operation, and the secure processor. The DMA engine waits for clearance from the secure processor before responding to further directions from the potentially untrusted software."
12001725,A combined on-package and off-package memory system uses a custom base-layer within which are fabricated one or more dedicated interfaces to off-package memories. An on-package processor and on-package memories are also directly coupled to the custom base-layer. The custom base-layer includes memory management logic between the processor and memories (both off and on package) to steer requests. The memories are exposed as a combined memory space having greater bandwidth and capacity compared with either the off-package memories or the on-package memories alone. The memory management logic services requests while maintaining quality of service (QoS) to satisfy bandwidth requirements for each allocation. An allocation may include any combination of the on and/or off package memories. The memory management logic also manages data migration between the on and off package memories.
12001958,"In various examples, past location information corresponding to actors in an environment and map information may be applied to a deep neural network (DNN)—such as a recurrent neural network (RNN)—trained to compute information corresponding to future trajectories of the actors. The output of the DNN may include, for each future time slice the DNN is trained to predict, a confidence map representing a confidence for each pixel that an actor is present and a vector field representing locations of actors in confidence maps for prior time slices. The vector fields may thus be used to track an object through confidence maps for each future time slice to generate a predicted future trajectory for each actor. The predicted future trajectories, in addition to tracked past trajectories, may be used to generate full trajectories for the actors that may aid an ego-vehicle in navigating the environment."
12002189,"The technology disclosed herein involves using a machine learning model (e.g., CNN) to expand lower dynamic-range image content (e.g., SDR images) into higher dynamic-range image content (e.g., HDR images). The machine learning model can take as input the lower dynamic-range image and can output multiple expansion maps that are used to make the expanded image appear more natural. The expansion maps may be used by image operators to smooth color banding and to dim overexposed regions or user interface elements in the expanded image. The expanded content (e.g., HDR image content) may then be provided to one or more devices for display or storage."
12003253,"Apparatuses, systems, and techniques to compute cyclic redundancy checks use a graphics processing unit (GPU) to compute cyclic redundancy checks. For example, in at least one embodiment, an input data sequence is distributed among GPU threads for parallel calculation of an overall CRC value for the input data sequence according to various novel techniques described herein."
12003633,"Disclosed are apparatuses, systems, and techniques to perform and facilitate secure ladder computational operations whose iterative execution depends on secret values associated with input data. Disclosed embodiments balance execution of various iterations in a way that is balanced for different secret values, significantly reducing vulnerability of ladder computations to adversarial side-channel attacks."
12005363,"In various examples, applications may be executed on remote computing devices to composite and broadcast gameplay with video and audio data. Systems and methods are disclosed that distribute, between and among various computing devices, processing of tasks including rendering of gameplay, composition of various types of data, and broadcasting of composited data. The tasks may be executed on computing devices that are remote to a client device, such as a virtual machine, GPU, server, and/or other computing device in the cloud, all of which are connected through a network. Customized composited content may be generated within the system, without latency and dropped frames, by distributing tasks such as compositing and rendering of gameplay to computing devices that have high performance capability and are specialized for handling memory- and time-intensive tasks."
12005855,"Systems and methods for machine learning based seatbelt position detection and classification. A number of fiducial markers are placed on a vehicle seatbelt. A camera or other sensor is placed within the vehicle, to capture images or other data relating positions of the fiducial markers when the seatbelt is in use. One or more models such as machine learning models may then determine the spatial positions of the fiducial markers from the captured image information, and determine the worn state of the seatbelt. In particular, the system may determine whether the seatbelt is being worn in one or more improper states, such as not being worn or being worn in an unsafe or dangerous manner, and if so, the system may alert the vehicle to take corrective action. In this manner, the system provides constant and real-time monitoring of seatbelts to improve seatbelt usage and safety."
12008475,"Machine learning systems that implement neural networks typically operate in an inference mode or a training mode. In the training mode, inference operations are performed to help guide the training process. Inference mode operation typically involves forward propagation and intensive access to certain sparse matrices, encoded as a set of vectors. Back propagation and intensive access to transposed versions of the same sparse matrices provide training refinements. Generating a transposed version of a sparse matrix can consume significant additional memory and computation resources. In one embodiment, two additional encoding vectors are generated, providing efficient operations on sparse matrices and also on transposed representations of the same sparse matrices. In a neural network the efficient operations can reduce the amount of memory needed for backpropagation and reduce power consumption."
12009816,A level-shifting circuits utilizing storage cells for shifting signals low-to-high or high-to-low include control drivers with moving supply voltages. The moving supply voltages may power positive or negative supply terminals of the control drivers. The control drivers drive gates of common-source configured devices coupled to storage nodes of the storage cell.
12010819,"Systems and methods for operating a datacenter are disclosed. In at least one embodiment, a power delivery system includes one or more fuel cells to provide a source of electrical power for a datacenter, where waste heat produced by a fuel cell is to be captured and provided to an absorption chiller to produce a cooled liquid for use in a cooling system for this datacenter."
12012125,"In various examples, an integrated circuit includes first and second portions. The first portion includes a timer that starts when the first portion transmits at least one error signal to the second portion. The timer may reset when data corresponding to at least one fault has been cleared from the first portion. The first portion transmits a timeout error signal when the timer indicates at least a predetermined amount of time has elapsed. The second portion receives the at least one error signal and the timeout error signal when the timeout error signal has been sent. The second portion may notify an external system after the timeout error signal is received."
12013244,"In various examples, live perception from sensors of a vehicle may be leveraged to generate potential paths for the vehicle to navigate an intersection in real-time or near real-time. For example, a deep neural network (DNN) may be trained to compute various outputs—such as heat maps corresponding to key points associated with the intersection, vector fields corresponding to directionality, heading, and offsets with respect to lanes, intensity maps corresponding to widths of lanes, and/or classifications corresponding to line segments of the intersection. The outputs may be decoded and/or otherwise post-processed to reconstruct an intersection—or key points corresponding thereto—and to determine proposed or potential paths for navigating the vehicle through the intersection."
12013844,"Approaches in accordance with various embodiments can perform spatial hash map updates while ensuring the atomicity of the updates for arbitrary data structures. A hash map can be generated for a dataset where entries in the hash map may correspond to multiple independent values, such as pixels of an image to be rendered. Update requests for independent values may be received on multiple concurrent threads, but change requests for independent values corresponding to a hash map entry can be aggregated from a buffer and processed iteratively in a single thread for a given hash map entry. In the case of multi-resolution spatial hashing where data can be stored at various discretization levels, this operation can be repeated to propagate changes from one level to another."
12014460,"Robust temporal gradients, representing differences in shading results, can be computed between current and previous frames in a temporal denoiser for ray-traced renderers. Backward projection can be used to locate matching surfaces, with the relevant parameters of those surfaces being carried forward and used for patching. Backward projection can be performed for each stratum in a current frame, a stratum representing a set of adjacent pixels. A pixel from each stratum is selected that has a matching surface in the previous frame, using motion vectors generated during the rendering process. A comparison of the depth of the normals, or the visibility buffer data, can be used to determine whether a given surface is the same in the current frame and the previous frame, and if so then parameters of the surface from the previous frame G-buffer is used to patch the G-buffer for the current frame."
12014547,"In various examples, natural language processing may be performed on text generated by a game to extract one or more in-game events from the game. The system (e.g., a client device and/or server) may receive the text in the form of one or more strings generated by a game application. The system may then extract one or more in-game events from the text using natural language processing. The game may include the text in a message it sends to the system (e.g., using an Application Programming Interface (API)) and/or in a game log entry or notification. The text may be generated based at least on the game determining one or more conditions are satisfied in the gameplay (e.g., victory, points scored, milestones, eliminations, item acquisition, etc.). The text may be mapped to event templates, which may then be used to extract parameters of events therefrom."
12016154,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, an in-row cooling unit is located within a row of racks and between racks so that it can use an interchangeable heat exchanger (IHE) to receive a primary coolant and can use one or more flow controllers to provide a first part of the primary coolant to cool a secondary coolant that is to be distributed to at least one cold plate, and to provide a second part of the primary coolant to cool air to be circulated through at least one server tray or rack."
12017352,"Apparatuses, systems, and techniques to map coordinates in task space to a set of joint angles of an articulated robot. In at least one embodiment, a neural network is trained to map task-space coordinates to joint space coordinates of a robot by simulating a plurality of robots at various joint angles, and determining the position of their respective manipulators in task space."
12019498,"An optimized power saving technique is described for a processor, such as, for example, a graphic processing unit (GPU), which includes one or more processing cores and at least one data link interface. According to the technique, the processor is operable in a low power mode in which power to the at least one processing core is off and power to the at least one data link interface is on. This technique provides reduced exit latencies compared to currently available approaches in which the core power is turned off."
12019967,"The disclosure provides a general solution for determining connections between terminals of various types of circuits using machine learning (ML). A ML method that uses reinforcement learning (RL), such as deep RL, to determine and optimize routing of circuit connections using a game process is provided. In one example a method of determining routing connection includes: (1) receiving a circuit design having known terminal groups, (2) establishing terminal positions for the terminal groups in a routing environment, and (3) determining, by the RL agent, routes of nets between the known terminal groups employing a model that is independent of a number of the nets of the circuit. A method of creating a model for routing nets using RL, a method of employing a game for training a RL agent to determine routing connections, and a RL agent for routing connections of a circuit are also disclosed."
12020035,"This specification describes a programmatic multicast technique enabling one thread (for example, in a cooperative group array (CGA) on a GPU) to request data on behalf of one or more other threads (for example, executing on respective processor cores of the GPU). The multicast is supported by tracking circuitry that interfaces between multicast requests received from processor cores and the available memory. The multicast is designed to reduce cache (for example, layer 2 cache) bandwidth utilization enabling strong scaling and smaller tile sizes."
12020076,"In various embodiments, a dispatch application performs multiply-accumulate (“MAC”) computations across parallel processing elements. In operation, the dispatch application determines a first quantity of iterations associated with a given MAC computation. The dispatch application determines a maximum number of tasks that can execute concurrently across a set of parallel processing elements. Subsequently, the dispatch application causes the maximum number of tasks to be executed concurrently across the set of parallel processing elements in order to perform the MAC computation. During execution, each task performs a substantially similar number of the first quantity of iterations. Relative to conventional tile-based approaches to performing MAC computations across parallel processing elements, the dispatch application can more evenly distribute iterations across the different parallel processing elements. Accordingly, the dispatch application can reduce the amount of parallel processing element idle time when performing MAC computations."
12020367,"Enhanced techniques applicable to a ray tracing hardware accelerator for traversing a hierarchical acceleration structure are disclosed. The traversal efficiency of such hardware accelerators are improved, for example, by transforming a ray, in hardware, from the ray's coordinate space to two or more coordinate spaces at respective points in traversing the hierarchical acceleration structure. In one example, the hardware accelerator is configured to transform a ray, received from a processor, from the world space to at least one alternate world space and then to an object space in hardware before a corresponding ray-primitive intersection results are returned to the processor. The techniques disclosed herein facilitate the use of additional coordinate spaces to orient acceleration structures in a manner that more efficiently approximate the space occupied by the underlying primitives being ray-traced."
12022633,"A graphics subsystem includes a printed circuit board (PCB), a blower, and a heat sink. A graphics processing unit (GPU) is integrated into the PCB. The PCB is shortened to occupy a portion of the width of the graphics subsystem. The heat sink is coupled to the PCB and/or GPU similarly occupies just a portion of the width of the graphics subsystem. The blower is disposed adjacent to the PCB and heat sink and configured to occupy the full height of the graphics subsystem. The blower is further configured to intake air from both the top side of the graphics subsystem and the bottom side of the graphics subsystem. In this configuration, the blower provides an elevated air flow rate in order to facilitate cooling of the PCB and/or GPU."
12022634,"Systems and methods for cooling a server case are disclosed. In at least one embodiment, a fan switches between an axial operation mode and a centrifugal operation mode to change a direction of an air flow within this server case."
12026626,"Apparatuses, systems, and techniques to classify content. In at least one embodiment, a mixture of neural networks each trained to generate labels for various types of input are used to automatically generate appropriate content labels given an input."
12026822,"In various examples, the actual spatial properties of a virtual environment are used to produce, for a pixel, an anisotropic filter kernel for a filter having dimensions and weights that accurately reflect the spatial characteristics of the virtual environment. Geometry of the virtual environment may be computed based at least in part on a projection of a light source onto a surface through an occluder, in order to determine a footprint that reflects a contribution of the light source to lighting conditions of the pixel associated with a point on the surface. The footprint may define a size, orientation, and/or shape of the anisotropic filter kernel and corresponding filter weights. The anisotropic filter kernel may be applied to the pixel to produce a graphically-rendered image of the virtual environment."
12026830,"In order to perform denoising on a three-dimensional (3D) spherical measurement of light (such as spherical irradiance probe information or the results of a 3D gonioreflectometry capture), the 3D spherical measurement of light is converted to a two-dimensional (2D) measurement by creating multiple copies of the 3D spherical measurement of light, determining a two-dimensional sub-domain (e.g., a rectangular sub-domain) for each of the multiple copies, and stitching the plurality of two-dimensional sub-domains together in a toroidal configuration. Denoising may then be performed on this 2D measurement via a machine learning implementation or other means. This may result in more accurate 3D spherical light probes that require fewer light measurement samples to generate accurate light measurements."
12026845,"Apparatuses, systems, and techniques are presented to generate augmented images. In at least one embodiment, one or more neural networks are used to modify one or more first objects in an image based at least in part upon a modification to be made to one or more second objects in the image."
12026955,"In various examples, live perception from sensors of an ego-machine may be leveraged to detect objects and assign the objects to bounded regions (e.g., lanes or a roadway) in an environment of the ego-machine in real-time or near real-time. For example, a deep neural network (DNN) may be trained to compute outputs—such as output segmentation masks—that may correspond to a combination of object classification and lane identifiers. The output masks may be post-processed to determine object to lane assignments that assign detected objects to lanes in order to aid an autonomous or semi-autonomous machine in a surrounding environment."
12027198,"Embodiments include a memory device with an improved circuit to mitigate degradation of memory devices due to aging. Memory device input/output pins include delay elements for adjusting the delay in each memory input/output signal path to synchronize the input/output signal paths with one another. Certain data patterns, including a long series of logic zero values or a long series of logic one values, can cause asymmetric degradation of transistors included in the delay elements. This asymmetric degradation can reduce the operating frequency of the memory device, leading to lower performance. The disclosed embodiments change the polarity of signals passing through the delay elements to mitigate the effects of asymmetric degradation resulting from these data patterns. As a result, the performance of memory devices is improved relative to prior approaches."
12031824,"A vehicle computing system validates location data received from a Global Navigation Satellite System receiver with other sensor data. In one embodiment, the system calculates velocities with the location data and the other sensor data. The system generates a probabilistic model for velocity with a velocity calculated with location data and variance associated with the location data. The system determines a confidence score by applying the probabilistic model to one or more of the velocities calculated with other sensor data. In another embodiment, the system implements a machine learning model that considers features extracted from the sensor data. The system generates a feature vector for the location data and determines a confidence score for the location data by applying the machine learning model to the feature vector. Based on the confidence score, the system can validate the location data. The validated location data is useful for navigation and map updates."
12032380,"In various examples, a trigger signal may be received that is indicative of a vehicle maneuver to be performed by a vehicle. A recommended vehicle trajectory for the vehicle maneuver may be determined in response to the trigger signal being received. To determine the recommended vehicle trajectory, sensor data may be received that represents a field of view of at least one sensor of the vehicle. A value of a control input and the sensor data may then be applied to a machine learning model(s) and the machine learning model(s) may compute output data that includes vehicle control data that represents the recommended vehicle trajectory for the vehicle through at least a portion of the vehicle maneuver. The vehicle control data may then be sent to a control component of the vehicle to cause the vehicle to be controlled according to the vehicle control data."
12032840,"Various embodiments include a computer memory system that dynamically adjusts a memory device performance feature, such as dynamic assist control, dynamic turbo mode, and/or the like, to improve the performance of memory devices in the memory system. The memory system enables or disables the memory device performance feature based on the operating voltage relative to a threshold voltage. If the operating voltage crosses the threshold voltage in one direction, then the memory device system enables the memory device performance feature. If the operating voltage crosses the threshold voltage in another direction, then the memory system disables the memory device performance feature. Various techniques enable the memory device performance feature to be employed even with complex integrated circuits that may include tens of thousands of devices that employ the memory device performance feature."
12033060,"Neural networks, in many cases, include convolution layers that are configured to perform many convolution operations that require multiplication and addition operations. Compared with performing multiplication on integer, fixed-point, or floating-point format values, performing multiplication on logarithmic format values is straightforward and energy efficient as the exponents are simply added. However, performing addition on logarithmic format values is more complex. Conventionally, addition is performed by converting the logarithmic format values to integers, computing the sum, and then converting the sum back into the logarithmic format. Instead, logarithmic format values may be added by decomposing the exponents into separate quotient and remainder components, sorting the quotient components based on the remainder components, summing the sorted quotient components using an asynchronous accumulator to produce partial sums, and multiplying the partial sums by the remainder components to produce a sum. The sum may then be converted back into the logarithmic format."
12033301,"Apparatuses, systems, and techniques to enhance video are disclosed. In at least one embodiment, one or more neural networks are used to create a higher resolution video using upsampled frames from a lower resolution video."
12033667,"In various examples, durations of relatively high user activity within a gameplay session may be determined from user input events using a running user activity measurement. Once a duration is identified, it may be further analyzed to merge the duration with one or more other durations and/or to determine or predict whether the duration would be of sufficient interest for further action. A user interest score for an identified duration may be computed based on a set of the user input events that occur in the duration and used to determine and/or predict whether the duration would be of sufficient interest for further action. In some cases, an action may be performed based on determining the user interest score is greater than a statistical value that is computed from user interest scores of multiple identified durations."
12034576,"A receiver receives communications over a communication channel, which may distort an incoming communication signal. In order to counter this distortion, the frequency response of the receiver is manipulated by adjusting several parameters. Each parameter controls at least a portion of the frequency response of the receiver. The optimal values for the parameters are determined by modifying an initial set of values for the parameters through one or more stochastic hill climbing operations until a performance metric associated with the receiver reaches a local optimum. The modified values are displaced through one or more mutation operations. The stochastic hill climbing operations may subsequently be performed on the mutated values to generate the final values for the parameters."
12034967,"Apparatuses, systems, and techniques to interpolate one or more intermediate images from two or more images is disclosed. In at least one embodiment, a processor includes one or more circuits to interpolate one or more intermediate images from two or more images based, at least in part, on one or more inconsistent flow vectors corresponding to the two or more images."
12039343,"Diagnostics and boot up for AV hardware and software of a computer system of an autonomous vehicle may be performed based at least on receiving a shutdown or power off indication, then a computing state of the computer system may be suspended with the computer system entering a low-power mode. The suspended computing state can be rapidly restored without requiring a reboot and diagnostics for key-on. To ensure the integrity of the saved computing state, the computer system may exit the low-power mode, rerun the diagnostics, reload the programs, and then reenter the low-power mode. Restoring the suspended computing state may be triggered by a user inserting an ignition key, pressing a button to turn on the vehicle, opening a door to the vehicle, remotely unlocking the vehicle, remotely starting the vehicle, etc."
12039350,"The disclosure relates to the transfer of visuals (e.g., window visuals) over virtual frames that may be stored in any number of video frames of one or more video streams. The visuals may be split into two-dimensional (2D) pages of a virtual frame, with each of the 2D pages being a fraction of the size of video frames of the video stream(s). The virtual frame may be encoded to the video frames of the video stream(s) and later reconstructed in accordance with a page table."
12039362,"In various examples, a timer component that generates an event when an interrupt request has not yet been cleared within at least a predetermined amount of time."
12039423,"The disclosure provides a vehicle, a machine vision system, and a robot. In one example, the vehicle includes one or more processing units to implement a machine-learning model and to identify one or more objects depicted in one or more images using the machine-learning model, the machine-learning model being trained using a training dataset that includes a plurality of images procedurally synthesized according to one or more training image definitions."
12039436,"Various examples of the present disclosure include a stereoscopic deep neural network (DNN) that produces accurate and reliable results in real-time. Both LIDAR data (supervised training) and photometric error (unsupervised training) may be used to train the DNN in a semi-supervised manner. The stereoscopic DNN may use an exponential linear unit (ELU) activation function to increase processing speeds, as well as a machine learned argmax function that may include a plurality of convolutional layers having trainable parameters to account for context. The stereoscopic DNN may further include layers having an encoder/decoder architecture, where the encoder portion of the layers may include a combination of three-dimensional convolutional layers followed by two-dimensional convolutional layers."
12039633,"Devices, systems, and techniques to incorporate lighting effects into computer-generated graphics. In at least one embodiment, a graphical frame depicting a virtual scene comprising is rendered by generating a record indicative of one or more lights in the virtual scene, and using the record to render a pixel. A second record, indicative of other lights in the virtual scene, is selected to combine with the first record, based at least in part on similarity between surfaces associated with the respective records. The combined record is used to render a pixel in a second graphical frame."
12039663,"In various examples, to support training a deep neural network (DNN) to predict a dense representation of a 3D surface structure of interest, a training dataset is generated using a parametric mathematical modeling. A variety of synthetic 3D road surfaces may be generated by modeling a 3D road surface using varied parameters to simulate changes in road direction and lateral surface slope. In an example embodiment, a synthetic 3D road surface may be created by modeling a longitudinal 3D curve and expanding the longitudinal 3D curve to a 3D surface, and the resulting synthetic 3D surface may be sampled to form a synthetic ground truth projection image (e.g., a 2D height map). To generate corresponding input training data, a known pattern that represents which pixels may remain unobserved during 3D structure estimation may be generated and applied to a ground truth projection image to simulate a corresponding sparse projection image."
12039694,"Apparatuses, systems, and techniques to enhance video are disclosed. In at least one embodiment, one or more neural networks are used to create a higher resolution video using upsampled frames from a lower resolution video."
12044732,"Silicon test structures are described that enable separate measurement of n-channel metal-oxide semiconductor (NMOS) and p-channel metal-oxide semiconductor (PMOS) transistor delays. NMOS and PMOS specific non-inverting stages may be used to construct a multi-stage ring oscillator. Each of the non-inverting stages generates either a rising or falling primary transition that is determined by either NMOS or PMOS transistors, respectively. The opposing transition for a particular non-inverting stage is triggered by propagation of the primary transition to a subsequent non-inverting stage (producing a “reset” pulse). A frequency of the ring oscillator is determined by the primary transition and one transistor type (NMOS or PMOS). Specifically, the frequency is determined by the propagation delay of the primary transition through the entire ring oscillator."
12045307,"Today neural networks are used to enable autonomous vehicles and improve the quality of speech recognition, real-time language translation, and online search optimizations. However, operation of the neural networks for these applications consumes energy. Quantization of parameters used by the neural networks reduces the amount of memory needed to store the parameters while also reducing the power consumed during operation of the neural network. Matrix operations performed by the neural networks require many multiplication calculations, so reducing the number of bits that are multiplied reduces the energy that is consumed. Quantizing smaller sets of the parameters using a shared scale factor improves accuracy compared with quantizing larger sets of the parameters. Accuracy of the calculations may be maintained by quantizing and scaling the parameters using fine-grained per-vector scale factors. A vector includes one or more elements within a single dimension of a multi-dimensional matrix."
12045666,"Apparatuses, systems, and techniques to collect performance data for one or more computations tasks executed by a plurality of nodes of a computational pipeline and enable optimization of distribution of task execution among the plurality of nodes."
12045924,"Graphics processing unit (GPU) performance and power efficiency is improved using machine learning to tune operating parameters based on performance monitor values and application information. Performance monitor values are processed using machine learning techniques to generate model parameters, which are used by a control unit within the GPU to provide real-time updates to the operating parameters. In one embodiment, a neural network processes the performance monitor values to generate operating parameters in real-time."
12045952,"Apparatuses, systems, and techniques to enhance video are disclosed. In at least one embodiment, one or more neural networks are used to create a higher resolution video using upsampled frames from a lower resolution video."
12046006,"According to an aspect of an embodiment, operations may comprise receiving a LIDAR scan of a scene from a LIDAR of a vehicle with the scene comprising a board, detecting the board in the LIDAR scan, fitting a plane through LIDAR coordinates corresponding to the detected board, projecting the plane from the LIDAR coordinates to a first set of camera coordinates, detecting the board in a camera image from a camera of the vehicle at a second set of camera coordinates, and calibrating the LIDAR of the vehicle and the camera of the vehicle by determining a transform between the first set of camera coordinates and the second set of camera coordinates."
12047067,"Stacked voltage domain level shifting circuits for shifting signals low-to-high or high-to-low include a storage cell powered by a mid-range supply rail of the stacked voltage domain level shifting circuit, and control drivers powered by moving supply voltages generated by the storage cell, wherein the control drivers coupled to drive gates of common-source configured devices coupled to storage nodes of the storage cell."
12047595,"Systems and methods herein address reference frame selection in video streaming applications using one or more processing units to decode a frame of an encoded video stream that uses an inter-frame depicting an object and an intra-frame depicting the object, the intra-frame being included in a set of intra-frames based at least in part on at least one attribute of the object as depicted in the intra-frame being different from the at least one attribute of the object as depicted in other intra-frames of the set of intra-frames."
12050548,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
12050893,"Systems and methods related to generating machine code using a coroutine suspension mechanism are disclosed below. An asynchronous programming model utilizing coroutines may be implemented in a compiler for a high-level programming language. The compiler is configured to include functionality related to an intrinsic function for a suspend operation of a coroutine. In accordance with an aspect of the disclosure, a method is disclosed for generating machine code that includes the coroutine mechanism. The method includes: receiving source code for a program in a high-level programming language, and compiling the source code with a compiler to generate machine code for a target processor. The source code includes a caller and a coroutine called by the caller. The compiler is configured to detect an intrinsic function for a suspend operation in the source code for the coroutine. The compiler inserts low-level code in the machine code in accordance with an ABI."
12051332,"In various examples, a path perception ensemble is used to produce a more accurate and reliable understanding of a driving surface and/or a path there through. For example, an analysis of a plurality of path perception inputs provides testability and reliability for accurate and redundant lane mapping and/or path planning in real-time or near real-time. By incorporating a plurality of separate path perception computations, a means of metricizing path perception correctness, quality, and reliability is provided by analyzing whether and how much the individual path perception signals agree or disagree. By implementing this approach—where individual path perception inputs fail in almost independent ways—a system failure is less statistically likely. In addition, with diversity and redundancy in path perception, comfortable lane keeping on high curvature roads, under severe road conditions, and/or at complex intersections."
12054164,"Systems and methods for detecting hardware faults in computer-based feedback control systems. Multiple instances of the system control program(s) are run on system processors. System sensor data are input to each instance, and the control commands output by each instance are compared. As instantiations of the same programs receive largely the same sensor data, differences between output commands may indicate the presence of one or more hardware faults."
12055412,"Systems and methods for vehicle-based determination of HD map update information. Sensor-equipped vehicles may determine locations of various detected objects relative to the vehicles. Vehicles may also determine the location of reference objects relative to the vehicles, where the location of the reference objects in an absolute coordinate system is also known. The absolute coordinates of various detected objects may then be determined from the absolute position of the reference objects and the locations of other objects relative to the reference objects. Newly-determined absolute locations of detected objects may then be transmitted to HD map services for updating."
12055995,"Apparatuses, systems, and techniques to predict a probability of an error or anomaly in processing units, such as those of a data center. In at least one embodiment, the probability of an error occurring in a processing unit is identified using multiple trained machine learning models, in which the trained machine learning models each outputs, for example, the probability of an error occurring within a different predetermined time period."
12056494,"Apparatuses, systems, and techniques to identify instructions for advanced execution. In at least one embodiment, a processor performs one or more instructions that have been identified by a compiler to be speculatively performed in parallel."
12056806,"Systems and methods of the present disclosure relate to fine grained interleaved rendering applications in path tracing for cloud computing environments. For example, a renderer and a rendering process may be employed for ray or path tracing and image-space filtering that interleaves the pixels of a frame into partial image fields and corresponding reduced-resolution images that are individually processed in parallel. Parallelization techniques described herein may allow for high quality rendered frames in less time, thereby reducing latency (or lag, in gaming applications) in high performance applications."
12056854,"Embodiments of the present invention provide end-to-end frame time synchronization designed to improve smoothness for displaying images of 3D applications, such as PC gaming applications. Traditionally, an application that renders 3D graphics functions based on the assumption that the average render time will be used as the animation time for a given frame. When this condition is not met, and the render time for a frame does not match the average render time of prior frames, the frames are not captured or displayed at a consistent rate. This invention enables feedback to be provided to the rendering application for adjusting the animation times used to produce new frames, and a post-render queue is used to store completed frames for mitigating stutter and hitches. Flip control is used to sync the display of a rendered frame with the animation time used to generate the frame, thereby producing a smooth, consistent image."
12057113,"In various examples, systems and methods of the present disclosure combine open and closed dialog systems into an intelligent dialog management system. A text query may be processed by a natural language understanding model trained to associate the text query with a domain tag, intent classification, and/or input slots. Using the domain tag, the natural language understanding model may identify information in the text query corresponding to input slots needed for answering the text query. The text query and related information may then be passed to a dialog manager to direct the text query to the proper domain dialog system. Responses retrieved from the domain dialog system may be provided to the user via text output and/or via a text to speech component of the dialog management system."
12057974,"A receiver includes a decision feed forward equalization (DFFE) system that generates, based on a digital signal that includes at least one intersymbol interference (ISI) value introduced by a communication channel, a detected signal including a set of detected symbol values. The DFFE system cancels the at least one ISI value from the detected signal using the set of estimated transmitted symbols and a set of tap coefficients to obtain a compensated signal and a set of compensated symbol values."
12059625,"In various examples, data representing user interactions with a plurality of games are analyzed to generate an aggregate playstyle profile for each game. The aggregate playstyle profiles of games participated in a by a user may be used to recommend one or more other games with a similar aggregate playstyle profile. In embodiments, an individual user's playstyle patterns may be used to determine games having similar playstyle profiles to eh user's playstyle patterns. In this way, game recommendations are more tailored to a particular type of gameplay, and not only to particular genres of games or games that are currently the most popular."
12059628,"In various examples, metadata of either a live stream game instance or a pre-recorded game instance may be included in a stream data from a game stream and used to enable access to play an instance of a game. A viewer of the stream may desire to participate in an instance of the game, and the system may use the metadata to determine authentication for the viewer with respect to a game platform hosting the game, access restrictions for the viewer with respect to the game, identification information for the streamer of the instance of the game, and/or game modification information for the particular instance of the game within the stream. This information may be used to seamlessly transition the viewer from a passive role in viewing the stream of the instance of the game on a streaming platform to actively participating in the instance of the game or another instance of the game on a gaming platform."
12067223,Annotations can be correlated to components of a document image so that the annotations track movements of the document image. A transparent overlay is generated to include the annotations and is linked to various components of the document image. Movement of the underlying document image is tracked and then adjustments in components positions are applied to associated annotations to maintain a contextual relationship between the annotations and the components of the document image.
12067405,"Configurations for communication interfaces are disclosed. In at least one embodiment, a processor includes one or more circuits to determine a firmware configuration for one or more server components and to transmit the firmware configuration at startup."
12067409,"The disclosure relates to the transfer of per-pixel transparency information using video codecs that do not provide an alpha channel (alternatively referred to as “transparency-agnostic video codecs”). For example, alpha information of visual elements may be transcoded into the supported channels of a video stream to generate additional samples of a supported color space, which are representative of the alpha information. After being encoded by a “transparency-agnostic video codec” and transmitted, the received alpha information may then be extracted from the supported channels of the video stream to render the received visuals with corresponding per-pixel transparency."
12067667,"Disclosed approaches provide for interactions of light transport paths in a virtual environment to share directional radiance when rendering a scene. Directional radiance that may be shared includes outgoing directional radiance of interactions, incoming directional radiance of interactions, and/or information derived therefrom. The shared directional radiance may be used for various purposes, such as computing lighting contributions at one or more interactions of a light transport path, and/or for path guiding. Directional radiance of an interaction may be shared with another interaction when the interaction is sufficiently similar (e.g., in radiance direction) to serve as an approximation of a sample for the other interaction. Sharing directional radiance may provide for online learning of directional radiance, which may build finite element approximations of light fields at the interactions."
12067669,A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to properly handle numerically challenging computations at or near edges and/or vertices of primitives and/or ensure that a single intersection is reported when a ray intersects a surface formed by primitives at or near edges and/or vertices of the primitives.
12069836,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a cold plate is coupled to a condenser section of a heat pipe and to a primary computing device, with the heat pipe coupled to an auxiliary computing device at an evaporator section of the heat pipe, so that the cold plate draws heat from the primary computing device and from the heat pipe."
12069840,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a first interfacing flow controller includes a sensor and is associated with a first server tray of a rack, so that a first interfacing flow controller can receive sensor inputs and can communicate with a second interfacing flow controller by a communication line there between, where a second interfacing flow controller can be associated with a coolant distribution unit (CDU) to cause a balance of coolant flow to be provided from a CDU to one or more second server trays based in part on a change in a coolant flow to a first server tray as indicated by such sensor inputs."
12072442,"In various examples, detected object data representative of locations of detected objects in a field of view may be determined. One or more clusters of the detected objects may be generated based at least in part on the locations and features of the cluster may be determined for use as inputs to a machine learning model(s). A confidence score, computed by the machine learning model(s) based at least in part on the inputs, may be received, where the confidence score may be representative of a probability that the cluster corresponds to an object depicted at least partially in the field of view. Further examples provide approaches for determining ground truth data for training object detectors, such as for determining coverage values for ground truth objects using associated shapes, and for determining soft coverage values for ground truth objects."
12072703,"In various examples, at least partial control of a vehicle may be transferred to a control system remote from the vehicle. Sensor data may be received from a sensor(s) of the vehicle and the sensor data may be encoded to generate encoded sensor data. The encoded sensor data may be transmitted to the control system for display on a virtual reality headset of the control system. Control data may be received by the vehicle and from the control system that may be representative of a control input(s) from the control system, and actuation by an actuation component(s) of the vehicle may be caused based on the control input."
12072815,"Various embodiments include a network for transmitting data words from a source node to a destination node. The source node optionally inverts the logic levels of each data word so that the number of logic ‘1’ bits in each data word is less than or equal to half of the data bits. The destination node recovers the original data words by passing the data words not inverted by the source node and inverting the data words that were inverted by the source node. As the packet is transmitted through the network, each node encodes and/or decodes the data words by generating an output transition for each logic ‘1’ bit of the input data word. Because no more than half the bits of the input data word are logic ‘1’ bits, the node generates output transitions for no more than one half of the data bits."
12072954,"Apparatuses, systems, and techniques to perform federated training of neural networks while maintaining control over dissemination of local models of neural networks from which aspects of local training data might be extracted. In at least one embodiment, a neural network is trained on local training data and a local model is provided to be aggregated with other local models into a global model that is in turn used for further local model training, wherein a provided local model or training is adjusted to reduce an ability to extract aspects of local training data therefrom."
12073325,"In various examples, a deep neural network (DNN) is trained—using image data alone—to accurately predict distances to objects, obstacles, and/or a detected free-space boundary. The DNN may be trained with ground truth data that is generated using sensor data representative of motion of an ego-vehicle and/or sensor data from any number of depth predicting sensors—such as, without limitation, RADAR sensors, LIDAR sensors, and/or SONAR sensors. The DNN may be trained using two or more loss functions each corresponding to a particular portion of the environment that depth is predicted for, such that—in deployment—more accurate depth estimates for objects, obstacles, and/or the detected free-space boundary are computed by the DNN."
12073504,"A bounding volume is used to approximate the space an object occupies. If a more precise understanding beyond an approximation is required, the object itself is then inspected to determine what space it occupies. Often, a simple volume (such as an axis-aligned box) is used as bounding volume to approximate the space occupied by an object. But objects can be arbitrary, complicated shapes. So a simple volume often does not fit the object very well. That causes a lot of space that is not occupied by the object to be included in the approximation of the space being occupied by the object. Hardware-based techniques are disclosed herein, for example, for efficiently using multiple bounding volumes (such as axis-aligned bounding boxes) to represent, in effect, an arbitrarily shaped bounding volume to better fit the object, and for using such arbitrary bounding volumes to improve performance in applications such as ray tracing."
12073604,"In various examples, the present disclosure relates to using temporal filters for automated real-time classification. The technology described herein improves the performance of a multiclass classifier that may be used to classify a temporal sequence of input signals—such as input signals representative of video frames. A performance improvement may be achieved, at least in part, by applying a temporal filter to an output of the multiclass classifier. For example, the temporal filter may leverage classifications associated with preceding input signals to improve the final classification given to a subsequent signal. In some embodiments, the temporal filter may also use data from a confusion matrix to correct for the probable occurrence of certain types of classification errors. The temporal filter may be a linear filter, a nonlinear filter, an adaptive filter, and/or a statistical filter."
12075061,Systems and methods herein address reference frame selection in video streaming applications using one or more processing units to identify a frame of a sequence of frames as a blurred frame based at least in part on a first variance of motion (VoM) of the frame being less than or equal to an adaptive threshold that is based in part on a moving average of variance of motion (MAoV) determined using one or more reference frames.
12075589,"Configurations for interface panels are disclosed. In at least one embodiment, an interface panel includes removable receptacles to provide communication to rack components."
12077190,"In various examples, systems and methods are disclosed for weighting one or more optional paths based on obstacle avoidance or other safety considerations. In some embodiments, the obstacle avoidance considerations may be computed using a comparison of trajectories representative of safety procedures at present and future projected time steps of an ego-vehicle and other actors to ensure that each actor is capable of implementing their respective safety procedure while avoiding collisions at any point along the trajectory. This comparison may include filtering out a path(s) of an actor at a time step(s)—e.g., using a one-dimensional lookup—based on spatial relationships between the actor and the ego-vehicle at the time step(s). Where a particular path—or point along the path—does not satisfy a collision-free standard, the path may be penalized more negatively with respect to the obstacle avoidance considerations, or may be removed from consideration as a potential path."
12078678,"Manufacturers perform tests on chips before the chips are shipped to customers. However, defects can occur on a chip after the manufacturer testing and when the chips are used in a system or device. The defects can occur due to aging or the environment in which the chip is employed and can be critical; especially when the chips are used in systems such as autonomous vehicles. To verify the structural integrity of the IC during the lifetime of the product, an in-system test (IST) is disclosed. The IST enables self-testing mechanisms for an IC in working systems. The IST mechanisms provide structural testing of the ICs when in a functional system and at a manufacturer's level of testing. Unlike ATE tests that are running on a separate environment, the IST provides the ability to go from a functional world view to a test mode."
12079028,"Methods and structures are described for detecting clock anomalies, including anomalies in which the clock oscillates at a faster than expected rate or exhibits a shorter than expected clock phase instance. Example methods include starting a timer responsive to the start of a clock phase, wherein the timer duration is shorter than an expected duration of the clock phase. If the clock phase ends before the timer expires, a fast clock detection signal is asserted. Example structures include fast clock detection logic coupled to a clock signal. The logic includes a timer, circuitry to start the timer responsive to the clock signal entering a monitored phase, and error detection circuitry to assert a fast clock detection output if the monitored phase ends before the timer expires. In some embodiments, the timer duration may be based on a measured duration of a previous clock phase."
12079097,"Techniques for testing semiconductor devices include a semiconductor device having a plurality of components, a test bus, and a test data transfer unit. The test data transfer unit receives, from a host computer, configuration information for performing a test of the semiconductor device, reads, via a high-speed data transfer link, test data associated with the test from memory of the host computer using direct memory access, sends the test data to the plurality of components via the test bus, causes one or more operations to be performed on the semiconductor device to effect at least a portion of the test, and after the one or more operations have completed, retrieves test results of the at least a portion of the test from the test bus and stores, via the high-speed data transfer link, the test results in the memory of the host computer using direct memory access."
12081812,"A performance metrics of a receiver is obtained using frames of an application hosted by a server that are received via a network. The one or more performance metrics include information indicative of a current occupancy of a frame buffer corresponding to the receiver and information indicative of a target occupancy of the frame buffer corresponding to the receiver. The frame buffer of the receiver is used to queue frames of the application for display. A frame rate associated with rendering at least one next frame of the application is adjusted using the one or more performance metrics of the receiver to control population of the frame buffer. Subsequent frames of the application hosted by the server are rendered using the adjusted frame rate. Upon rendering the subsequent frames, the server sends the subsequent frames to the receiver for display."
12082382,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a control unit within a rack has a pump or compressor unit to cause two-phase fluid to circulate through a cold plate associated with a computing device and to circulate through a heat exchanger associated with a rear door of a rack, so as to dissipate heat from a computing device through a heat exchanger by a control unit within a rack."
12086095,Technologies for enabling downstream components to update upstream states in streaming pipelines are described. One method of a first computing device receives a remote promise object assigned to a first serialized object from a second computing device in the data center over a network fabric. The remote promise object uniquely identifies a first contiguous block of the first serialized object stored in a memory associated with the second computing device. The method obtains contents of the first contiguous block and sends contents of a second serialized object back to the second computing device to release the remote promise object.
12086208,"In various examples, sets of testing data may be selected and applied to an MLM such that differences in performance of the MLM in the testing between the sets indicates and may be used to determine whether and/or an extent by which the MLM is trained to rely on artifacts. Training data for the MLM may be generated using a first value of a parameter that defines a value of a characteristic of the training data. For testing, first testing data may be selected that corresponds to a second value of the parameter that shifts the value in a first direction and second testing data may be selected that corresponds to a third value of the parameter that shifts the value in a second direction (e.g., opposite the first direction). Various possible actions may be taken based on results of analyzing the differences in performance."
12087077,"In various examples, sensor data—such as masked sensor data—may be used as input to a machine learning model to determine a confidence for object to person associations. The masked sensor data may focus the machine learning model on particular regions of the image that correspond to persons, objects, or some combination thereof. In some embodiments, coordinates corresponding to persons, objects, or combinations thereof, in addition to area ratios between various regions of the image corresponding to the persons, objects, or combinations thereof, may be used to further aid the machine learning model in focusing on important regions of the image for determining the object to person associations."
12089378,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a server tray or box includes a surface with a flow-through fixture or manifold that extends on both sides of the surface, that includes an inward coupling, an outward coupling, a flow controller, and a state sensor, the state sensor to monitor a flow-through fixture or manifold, where a flow controller of a flow-through fixture or manifold can change a flow of a coolant through a flow-through fixture or manifold and can selectively trap a portion of a coolant within a flow-through fixture or manifold."
12092742,"Embodiments relate to methods for efficiently encoding sensor data captured by an autonomous vehicle and building a high definition map using the encoded sensor data. The sensor data can be LiDAR data which is expressed as multiple image representations. Image representations that include important LiDAR data undergo a lossless compression while image representations that include LiDAR data that is more error-tolerant undergo a lossy compression. Therefore, the compressed sensor data can be transmitted to an online system for building a high definition map. When building a high definition map, entities, such as road signs and road lines, are constructed such that when encoded and compressed, the high definition map consumes less storage space. The positions of entities are expressed in relation to a reference centerline in the high definition map. Therefore, each position of an entity can be expressed in fewer numerical digits in comparison to conventional methods."
12092820,"Virtual reality (VR) displays are computer displays that present images or video in a manner that simulates a real experience for the viewer. In many cases, VR displays are implemented as head-mounted displays (HMDs) which provide a display in the line of sight of the user. Because current HMDs are composed of a display panel and magnifying lens with a gap therebetween, proper functioning of the HMDs limits their design to a box-like form factor, thereby negatively impacting both comfort and aesthetics. The present disclosure provides a different configuration for a virtual reality display which allows for improved comfort and aesthetics, including specifically at least one coherent light source, at least one holographic waveguide coupled to the at least one coherent light source to receive light therefrom, and at least one spatial light modulator coupled to the at least one holographic waveguide to modulate the light."
12093208,"Technologies for enabling remote direct memory access (RDMA) transport of serialized objects in streaming pipelines are described. One method of a first computing device that stores a serialized object in a first memory can generate a remote descriptor associated with the serialized object. The remote descriptor uniquely identifies the location of the serialized object and a reference count token. The first computing device sends the remote descriptor to a second computing device in the data center over a network fabric. The second computing device uses the remote descriptor to obtain the contiguous block from the first memory for storage at a second memory associated with the second computing device. The value of the reference count token can be updated by receiving a message from the second computing device, and the remote descriptor can be released responsive to the value of the reference count token satisfying a threshold value."
12093209,Technologies for batching remote descriptors of serialized objects in streaming pipelines are described. One method of a first computing device generates a streaming batch of remote descriptors. Each remote descriptor uniquely identifies a contiguous block of a serialized object. The first computing device sends at least one of the remote descriptors to a second computing device before the streaming batch is completed. At least some contents of a contiguous block are obtained for storage at a second memory associated with the second computing device before the streaming batch is completed.
12093539,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
12093699,"A storage system (400) includes a storage processor (420-1) such as a storage card resident in a host server (410-1) and coupled to the storage device (450-1). The storage processor (420-1) may be configured to create a virtual volume (428-1), store content derived from an image (492) downloaded from a URL storage corresponding to the virtual volume (428-1), and present the virtual volume (428-1) to the host server as a boot LUN. A management infrastructure (480) can be used to create a library (490) of images (492, 494) corresponding to different storage system characteristics and used to selected which URL is provided to the storage processor (420-1)."
12093824,"In various examples, a deep neural network (DNN) is trained to accurately predict, in deployment, distances to objects and obstacles using image data alone. The DNN may be trained with ground truth data that is generated and encoded using sensor data from any number of depth predicting sensors, such as, without limitation, RADAR sensors, LIDAR sensors, and/or SONAR sensors. Camera adaptation algorithms may be used in various embodiments to adapt the DNN for use with image data generated by cameras with varying parameters—such as varying fields of view. In some examples, a post-processing safety bounds operation may be executed on the predictions of the DNN to ensure that the predictions fall within a safety-permissible range."
12094572,"The present disclosure provides methods, systems, and computer program products that use deep learning models to classify candidate mutations detected in sequencing data, particularly suboptimal sequencing data. The methods, systems, and programs provide for increased efficiency, accuracy, and speed in identifying mutations from a wide range of sequencing data."
12099407,"An error reporting system utilizes a parity checker to receive data results from execution of an original instruction and a parity bit for the data. A decoder receives an error correcting code (ECC) for data resulting from execution of a shadow instruction of the original instruction, and data error correction is initiated on the original instruction result on condition of a mismatch between the parity bit and the original instruction result, and the decoder asserting a correctable error in the original instruction result."
12099439,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
12099453,"Embodiments of the present disclosure relate to application partitioning for locality in a stacked memory system. In an embodiment, one or more memory dies are stacked on the processor die. The processor die includes multiple processing tiles and each memory die includes multiple memory tiles. Vertically aligned memory tiles are directly coupled to and comprise the local memory block for a corresponding processing tile. An application program that operates on dense multi-dimensional arrays (matrices) may partition the dense arrays into sub-arrays associated with program tiles. Each program tile is executed by a processing tile using the processing tile's local memory block to process the associated sub-array. Data associated with each sub-array is stored in a local memory block and the processing tile corresponding to the local memory block executes the program tile to process the sub-array data."
12099848,"Apparatuses, systems, and techniques to receive, by a processor of a computer system, one or more operations for a kernel; automatically generate, by the processor, one or more operators that perform the one or more operations on elements of one or more input data structures; and automatically generate, by the processor, the kernel that comprises the one or more operators."
12100112,"A content management system may maintain a scene description that represents a 3D virtual environment and a publish/subscribe model in which clients subscribe to content items that correspond to respective portions of the shared scene description. When changes are made to content, the changes may be served to subscribing clients. Rather than transferring entire descriptions of assets to propagate changes, differences between versions of content may be exchanged, which may be used construct updated versions of the content. Portions of scene description may reference other content items and clients may determine whether to request and load these content items for lazy loading. Content items may be identified by Uniform Resource Identifiers (URIs) used to reference the content items. The content management system may maintain states for client connections including for authentication, for the set of subscriptions in the publish/subscribe model, and for their corresponding version identifiers."
12100113,"In order to determine accurate three-dimensional (3D) models for objects within a video, the objects are first identified and tracked within the video, and a pose and shape are estimated for these tracked objects. A translation and global orientation are removed from the tracked objects to determine local motion for the objects, and motion infilling is performed to fill in any missing portions for the object within the video. A global trajectory is then determined for the objects within the video, and the infilled motion and global trajectory are then used to determine infilled global motion for the object within the video. This enables the accurate depiction of each object as a 3D pose sequence for that model that accounts for occlusions and global factors within the video."
12101338,"Various approaches are disclosed for protecting vehicle buses from cyber-attacks. Disclosed approaches provide for an embedded system having a hypervisor that provides a virtualized environment supporting any number of guest OSes. The virtualized environment may include a security engine on an internal communication channel between the guest OS and an external vehicle bus of a vehicle to analyze network traffic to protect the guest OS from other guest OSes or other network components, and to protect those network components from the guest OS. Each guest OS may have its own security engine customized for the guest OS to account for what is typical or expected traffic for the guest OS (e.g., using machine learning, anomaly detection, etc.). Also disclosed are approaches for corrupting a message being transmitted on a vehicle bus to prevent devices from acting on the message."
12101907,"Systems and methods for cooling a mobile datacenter are disclosed. In at least one embodiment, a cooling loop is located on a mobile unit and includes at least one cold plate within a pod on a mobile unit and includes a dry cooler external to a pod on a mobile unit so as to enable coolant to be provided to a cold plate and to enable such coolant to be provided to a dry cooler for removal of heat from at least one computing device to an ambient environment."
12105960,"Various embodiments include techniques for performing self-synchronizing remote memory operations in a multiprocessor computing system. During a remote memory operation in the multiprocessor computing system, a source processing unit transmits multiple segments of data to a destination processing. For each segment of data, the source processing unit transmits a remote memory operation to the destination processing unit that includes associated metadata that identifies the memory location of a corresponding synchronization object. The remote memory operation along with the metadata is transmitted as a single unit to the destination processing unit. The destination processing unit splits the operation into the remote memory operation and the memory synchronization operation. As a result, the source processing unit avoids the need to perform a separate memory synchronization operation, thereby reducing inter-processor communications and increasing performance of remote memory operations."
12106423,"Techniques applicable to a ray tracing hardware accelerator for traversing a hierarchical acceleration structure with reduced false positive ray intersections are disclosed. The reduction of false positives may be based upon one or more of selectively performing a secondary higher precision intersection test for a bounding volume, identifying and culling bounding volumes that degenerate to a point, and parametrically clipping rays that exceed certain configured distance thresholds."
12109701,"A robot is controlled using a combination of model-based and model-free control methods. In some examples, the model-based method uses a physical model of the environment around the robot to guide the robot. The physical model is oriented using a perception system such as a camera. Characteristics of the perception system may be are used to determine an uncertainty for the model. Based at least in part on this uncertainty, the system transitions from the model-based method to a model-free method where, in some embodiments, information provided directly from the perception system is used to direct the robot without reliance on the physical model."
12111177,"According to an aspect of an embodiment, operations may comprise receiving sensor data from one or more vehicles, determining, by combining the received sensor data, a high definition map comprising a point cloud, and labeling one or more objects in the point cloud. The operations may also comprise generating training data by receiving a new image captured by one of the vehicles, receiving a pose of the vehicle when the new image was captured, determining an object having a label in the point cloud that is observable from the pose of the vehicle, determining a position of the object in the new image, and labeling the new image by assigning the label of the object to the new image, the labeled new image comprising the training data. The operations may also comprise training a deep learning model using the training data."
12111179,"In various examples, a method to manage map data includes storing a map of a geographic area using an immutable tree. The immutable tree comprises a plurality of nodes stored using a distributed hash table. The plurality of nodes include a plurality of map tiles. At least two map tiles of the plurality of map tiles cover different geographic subregions of the geographic area of the map. The method includes hosting one or more binary large objects (BLOBs) that correspond to the plurality of map tiles in an origin data plane. The method includes making the one or more BLOBs available for distribution to one or more client devices using a content delivery network (CDN)."
12111381,"One or more embodiments of the present disclosure may relate to communicating RADAR (RAdio Detection And Ranging) data to a distributed map system that is configured to generate map data based on the RADAR data. In these or other embodiments, certain compression operations may be performed on the RADAR data to reduce the amount of data that is communicated from the ego-machines to the map system."
12111842,"An initiating node (C) in a storage platform (100) receives a modification request (312, 314) for changing an object (O). The initiating node (C), using system configuration information (127), identifies an owner node (A) and a backup node (B) for the object (O) and sends change data (324, 334) to the owner node (A) and the backup node (B). The owner node (A) modifies the object (O) with the data (324) from the initiating node (C) and sends an update request (352) that does not include the data (324) to the backup node (B). The backup node (B) modifies a backup object (O′) with data (334) from the initiating node (C)."
12112147,"Systems and methods are disclosed that relate to graphically representing different components (e.g., software modules, libraries, interfaces, or other blocks of code) that may be included in an application, linking the components in an ordered sequence to embody the application, and deploying the application to perform a task. The components may be displayed and represented as graphical components in a graphical application editor, or any other development environment. The graphical application editor may perform various operations with respect to the graphical components and the components respectively represented by and corresponding therewith. The operations may include facilitation of linking implemented instances of the graphical component objects together and/or developing the application by linking the underlying code associated with the graphical component objects according to the linking of the graphical component objects."
12112148,"Embodiments of the present disclosure relate to applications and platforms for configuring machine learning models for training and deployment using graphical components in a development environment. For example, systems and methods are disclosed that relate to determining one or more machine learning models and one or more processing operations corresponding to the one or more machine learning models. Further, a model component may be generated using the one or more machine learning models, the one or more processing operations, and one or more extension libraries in which the one or more extension libraries indicate one or more deployment parameters related to the one or more machine learning models. The model component may accordingly provide data that may be used to be able to use and deploy the one or more machine learning models."
12112247,"In various examples, object detections of a machine learning model are leveraged to automatically generate new ground truth data for images captured at different perspectives. The machine learning model may generate a prediction of a detected object at the different perspective, and an object tracking algorithm may be used to track the object through other images in a sequence of images where the machine learning model may not have detected the object. New ground truth data may be generated as a result of the object tracking algorithms outputs, and the new ground truth data may be used to retrain or update the machine learning model, train a different machine learning model, or increase the robustness of a ground truth data set that may be used for training machine learning models from various perspectives."
12112395,"The present invention facilitates efficient and effective utilization of unified virtual addresses across multiple components. In one exemplary implementation, an address allocation process comprises: establishing space for managed pointers across a plurality of memories, including allocating one of the managed pointers with a first portion of memory associated with a first one of a plurality of processors; and performing a process of automatically managing accesses to the managed pointers across the plurality of processors and corresponding memories. The automated management can include ensuring consistent information associated with the managed pointers is copied from the first portion of memory to a second portion of memory associated with a second one of the plurality of processors based upon initiation of an accesses to the managed pointers from the second one of the plurality of processors."
12112422,"A differentiable ray casting technique may be applied to a model of a three-dimensional (3D) scene (scene includes lighting configuration) or object to optimize one or more parameters of the model. The one or more parameters define geometry (topology and shape), materials, and lighting configuration (e.g., environment map, a high-resolution texture that represents the light coming from all directions in a sphere) for the model. Visibility is computed in 3D space by casting at least two rays from each ray origin (where the two rays define a ray cone). The model is rendered to produce a model image that may be compared with a reference image (or photograph) of a reference 3D scene to compute image space differences. Visibility gradients in 3D space are computed and backpropagated through the computations to reduce differences between the model image and the reference image."
12112428,"In various examples, shader bindings may be recorded in a shader binding table that includes shader records. Geometry of a 3D scene may be instantiated using object instances, and each may be associated with a respective set of the shader records using a location identifier of the set of shader records in memory. The set of shader records may represent shader bindings for an object instance under various predefined conditions. One or more of these predefined conditions may be implicit in the way the shader records are arranged in memory (e.g., indexed by ray type, by sub-geometry, etc.). For example, a section selector value (e.g., a section index) may be computed to locate and select a shader record based at least in part on a result of a ray tracing query (e.g., what sub-geometry was hit, what ray type was traced, etc.)."
12112445,"Generation of three-dimensional (3D) object models may be challenging for users without a sufficient skill set for content creation and may also be resource intensive. One or more style transfer networks may be used for part-aware style transformation of both geometric features and textural components of a source asset to a target asset. The source asset may be segmented into particular parts and then ellipsoid approximations may be warped according to correspondence of the particular parts to the target assets. Moreover, a texture associated with the target asset may be used to warp or adjust a source texture, where the new texture can be applied to the warped parts."
12114469,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a flow controller adapter of a cooling manifold is to interchangeably receive a flow controller of a plurality of flow controllers, wherein a flow controller adapter is associated with a rack-side flow controller and with a tube there between and is configured to be movable within cooling manifold to allow different positions for mating a flow controller with a server-side flow controller of server tray or box."
12117298,"According to an aspect of an embodiment, operations may comprise obtaining a pose graph that comprises a plurality of nodes. The operations may also comprise dividing the pose graph into a plurality of pose subgraphs, each pose subgraph comprising one or more respective pose subgraph interior nodes and one or more respective pose subgraph boundary nodes. The operations may also comprise generating one or more boundary subgraphs based on the plurality of pose subgraphs, each of the one or more boundary subgraphs comprising one or more respective boundary subgraph boundary nodes and comprising one or more respective boundary subgraph interior nodes. The operations may also comprise obtaining an optimized pose graph by performing a pose graph optimization. The pose graph optimization may comprise performing a pose subgraph optimization of the plurality of pose subgraphs and performing a boundary subgraph optimization of the plurality of boundary subgraphs."
12118353,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
12118382,"Apparatuses, systems, and techniques to parallelize operations in one or more programs with data copies from global memory to shared memory in each of the one or more programs. In at least one embodiment, a program performs operations on shared data and then asynchronously copies shared data to shared memory, and continues performing additional operations in parallel while the shared data is copied to shared memory until an indicator provided by an application programming interface to facilitate parallel computing, such as CUDA, informs said program that shared data has been copied to shared memory."
12118454,"Neural networks, in many cases, include convolution layers that are configured to perform many convolution operations that require multiplication and addition operations. Compared with performing multiplication on integer, fixed-point, or floating-point format values, performing multiplication on logarithmic format values is straightforward and energy efficient as the exponents are simply added. However, performing addition on logarithmic format values is more complex. Conventionally, addition is performed by converting the logarithmic format values to integers, computing the sum, and then converting the sum back into the logarithmic format. Instead, logarithmic format values may be added by decomposing the exponents into separate quotient and remainder components, sorting the quotient components based on the remainder components, summing the sorted quotient components to produce partial sums, and multiplying the partial sums by the remainder components to produce a sum. The sum may then be converted back into the logarithmic format."
12118643,"Apparatuses, systems, and techniques to perform a K-nearest-neighbor query. In at least one embodiment, a set of bounding boxes corresponding to a set of primitives is generated that allows the query to be solved using light transport simulation acceleration features of a GPU."
12120122,"Disclosed are apparatuses, systems, and techniques that improve efficiency and decrease latency of processing of authorization requests by cloud-based access servers that evaluate access rights to access various cloud-based services. The techniques include but are not limited to generating and processing advanced authorization requests that anticipate future authorization requests that may be generated by cloud-based services. The techniques further include processing of frequently accessed policies and policy data dependencies and preemptive generation and processing of authorization requests that are replicated from existing authorization requests."
12120152,"Disclosed are apparatuses, systems, and techniques that improve efficiency and decrease latency of processing of authorization requests by a cloud service. The techniques include obtaining, from an access server, a snapshot associated with processing an authorization request to evaluate an access to a resource of the cloud service and generating, using the snapshot, preemptive authorization requests by modifying the authorization request with a new user identity or a new resource identity. The techniques further include receiving, from the cloud service, a subsequent authorization request to evaluate an authorization of a user to access a particular resource of the cloud service, determining that the subsequent authorization request corresponds to one of preemptive authorization requests, and providing, to the cloud service, an authorization response for the user to access the resource, based on evaluation of this preemptive authorization request."
12121801,"In various examples, a user may access or acquire an application to download to the user's local computing device. Upon accessing the application, a local instance of the application may begin downloading to the computing device, and the user may be given the option to play a cloud-hosted instance of the application. If the user selects to play a hosted instance of the application, the cloud-hosted instance of the application may begin streaming while the local instance of the application downloads to the user's computing device in the background. Application state data may be stored and associated with the user during gameplay such that, once the local instance of the application has downloaded, the user may switch from the hosted instance of the application to the local instance to begin playing locally, with the application state information accounted for."
12121823,"In various examples, game session audio data—e.g., representing speech of users participating in the game—may be monitored and/or analyzed to determine whether inappropriate language is being used. Where inappropriate language is identified, the portions of the audio corresponding to the inappropriate language may be edited or modified such that other users do not hear the inappropriate language. As a result, toxic behavior or language within instances of gameplay may be censored—thereby enhancing the user experience and making online gaming environments safer for more vulnerable populations. In some embodiments, the inappropriate language may be reported—e.g., automatically—to the game developer or game application host in order to suspend, ban, or otherwise manage users of the system that have a proclivity for toxic behavior."
12122053,"Apparatuses, systems, and techniques to identify at least one physical characteristic of materials from computer simulations of manipulations of materials. In at least one embodiment, physical characteristics are determined by comparing measured statistics of observed manipulations to simulations of manipulations using a simulator trained with a likelihood-free inference engine."
12122392,"State information can be determined for a subject that is robust to different inputs or conditions. For drowsiness, facial landmarks can be determined from captured image data and used to determine a set of blink parameters. These parameters can be used, such as with a temporal network, to estimate a state (e.g., drowsiness) of the subject. To improve robustness, an eye state determination network can determine eye state from the image data, without reliance on intermediate landmarks, that can be used, such as with another temporal network, to estimate the state of the subject. A weighted combination of these values can be used to determine an overall state of the subject. To improve accuracy, individual behavior patterns and context information can be utilized to account for variations in the data due to subject variation or current context rather than changes in state."
12124308,"Apparatuses, systems, and techniques to optimize processor performance. In at least one embodiment, a method increases an operation voltage of one or more processors, based at least in part, on one or more error rates of the one or more processors."
12124346,"In various examples, one or more components or regions of a processing unit—such as a processing core, and/or component thereof—may be tested for faults during deployment in the field. To perform testing while in deployment, the state of a component subject to test may be retrieved and/or stored during the test to maintain state integrity, the component may be clamped to communicatively isolate the component from other components of the processing unit, a test vector may be applied to the component, and the output of the component may be compared against an expected output to determine if any faults are present. The state of the component may be restored after testing, and the clamp removed, thereby returning the component to its operating state without a perceivable detriment to operation of the processing unit in deployment."
12124378,"In a ray tracer, a cache for streaming workloads groups ray requests for coherent successive bounding volume hierarchy traversal operations by sending common data down an attached data path to all ray requests in the group at the same time or about the same time. Grouping the requests provides good performance with a smaller number of cache lines."
12124832,"Devices and methods to update semiconductor components are disclosed. In at least one embodiment, a device updates semiconductor components independent of a semiconductor component operational state."
12125277,"Apparatuses, systems, and techniques for real-time persistent object tracking for intelligent video analytics systems. A state of a first object included in an environment may be tracked based on a first set of images depicting the environment. The first set of images may be generated during a first time period. It may be determined that the first object is not detected in the environment depicted in a second set of images. The second set of images may be generated during a second time period that is subsequent to the first time period. One or more predicted future states of the first object may be obtained in view of the state of the first object in the environment depicted in the first set of images. A second object may be detected in the environment depicted in a third set of images generated during a third time period that is subsequent to the second time period. A determination may be made as to whether a current state of the second object corresponds to at least one of the one or more predicted future states of the first object. In response to a determination that a current state of the second object corresponds to at least one of the predicted future states of the first object, an identifier associated with the second object is updated to correspond to an identifier associated with the first object."
12126791,"Systems and methods of compressing video data are disclosed. The proposed systems provide a computer-implemented process configured to classify a person's behavior(s) during a video and encode the behaviors as a representation of the video. When playback of the video is requested, a reconstruction of the video is generated by a video synthesizer based on a reference image of the person and the sequence of codes corresponding to their behavior during the video. Storage and transmission of the video can then be limited to the reference image and the behavioral codes rather than the video file itself, significantly reducing memory and bandwidth requirements."
12127374,"Systems and methods for a datacenter cooling system are disclosed. In at least one embodiment, reconfigurable terminations are provided for fluid loops in a datacenter cooling system with individual ones of such reconfigurable terminations are to be configured in a first state to enable non-cooling fluid runs through individual ones of such fluid loops, taken individually and in combination, during commissioning of a datacenter cooling system, and are to be configured in a second state to enable cooling fluid runs to cool at least one cold plate after commissioning of a datacenter cooling system."
12127381,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, one or more outlet reservoirs are associated with a stabilizing subsystem and a rack so that one or more outlet reservoirs can receive two-phase fluid that is outlet from a plurality of cold plates of a rack and so that a stabilizing subsystem can stabilize a quality factor of a two-phase fluid to a predetermined quality factor before heat is removed from a two-phase fluid and it is cycled to such cold plates."
12129901,"Various embodiments of the present disclosure relate to a leaf spring for coupling a heat sink to an integrated circuit, where the leaf spring includes a central portion that has an aperture, a first spring arm that is formed on a first side of the central portion and includes a first through-hole for a first fastener, and a second spring arm that is formed on a second side of the central portion and includes a second through-hole for a second fastener. In various embodiments, a first bending axis passes through the first side and is substantially perpendicular to a longitudinal axis of the leaf spring that passes through the first through-hole and the second through-hole, and a second bending axis passes through the second side and is substantially perpendicular to the longitudinal axis of the leaf spring."
12130687,A computer-implemented method of controlling power consumption in a multi-processor computing device comprises: determining whether a first processor is operating in a high-power regime or a low-power regime; selecting a first set of control rules that includes a first subset of control rules that apply when the first processor is operating in the high-power regime and a second subset of control rules that apply when the first processor is operating in the low-power regime; determining one or more power settings for the first processor based on the first set of control rules; and causing the first processor to perform one or more operations based on the one or more power settings.
12130750,"Computer systems often employ virtual address translation hierarchies in which virtual memory addresses are mapped to physical memory. Use of the virtual address translation hierarchy speeds up the virtual address translation when the required mapping is stored in one of the higher levels of the hierarchy. To reduce a number of misses occurring in the virtual address translation hierarchy, huge memory pages may be selectively employed, which map larger continuous regions of virtual memory to continuous regions of physical memory, thereby increasing the coverage of each entry in the virtual address translation hierarchy. The present disclosure provides hardware support for optimizing this huge memory page selection."
12131556,"In various examples, object fence corresponding to objects detected by an ego-vehicle may be used to determine overlap of the object fences with lanes on a driving surface. A lane mask may be generated corresponding to the lanes on the driving surface, and the object fences may be compared to the lanes of the lane mask to determine the overlap. Where an object fence is located in more than one lane, a boundary scoring approach may be used to determine a ratio of overlap of the boundary fence, and thus the object, with each of the lanes. The overlap with one or more lanes for each object may be used to determine lane assignments for the objects, and the lane assignments may be used by the ego-vehicle to determine a path or trajectory along the driving surface."
12131775,A static random access memory (SRAM) or other bit-storing cell arrangement includes memory cells and a hierarchical bitline structure including local bitlines for subsets of the memory banks and a global bitline spanning the subsets. A keeper circuit for the global bitline is replaced by bias circuitry on output transistors of the memory cells.
12131800,"PUF cells utilizing a dual-interlocking scheme demonstrating improved noise immunity and stability across different V/T conditions and different uses over time in noisy environments. The PUF cell may be advantageously utilized in conjunction with error detection techniques that screen out unstable cells. A set of such PUF cells utilized to generate a device-specific bit pattern, for example a master key."
12132590,"Data bits are encoded in one or both of an eleven bit seven pulse amplitude modulated three-level (PAM-3) symbol (11b7s) format and a three bit two symbol (3b2s) format on a plurality of data channels, one or more auxiliary data channels, and an error correction channel. One or more of a cyclic redundancy check (CRC) value, a poison value, and a severity value are encoded as 11b7s and/or 3b2s PAM-3 symbols on an error correction channel."
12135607,"Data bits are encoded in one or both of an eleven bit seven pulse amplitude modulated three-level (PAM-3) symbol (11b7s) format and a three bit two symbol (3b2s) format on a plurality of data channels and on an error correction channel. One or more of a cyclic redundancy check (CRC) value, a poison value, and a severity value are encoded as 11b7s and/or 3b2s PAM-3 symbols on the error correction channel."
12135781,"While a compiler compiles source code to create an executable binary, code is added into the compiled source code that, when executed, identifies and stores in a metadata table base and bounds information associated with memory allocations. Additionally, additional code is added into the compiled source code that enables hardware to determine a safety of memory access requests during an implementation of the compiled source code by performing an out-of-bounds (OOB) check in hardware using the base and bounds information stored in the metadata table. This enables the identification and avoidance of unsafe memory operations during the implementation of the executable by a GPU."
12136249,"In various examples, contrast values corresponding to pixels of one or more images generated using one or more sensors of a vehicle may be computed to detect and identify objects that trigger glare mitigating operations. Pixel luminance values are determined and used to compute a contrast value based on comparing the pixel luminance values to a reference luminance value that is based on a set of the pixels and the corresponding luminance values. A contrast threshold may be applied to the computed contrast values to identify glare in the image data to trigger glare mitigating operations so that the vehicle may modify the configuration of one or more illumination sources so as to reduce glare experienced by occupants and/or sensors of the vehicle."
12137055,"A switching system having input ports and output ports and comprising an input queued (IQ) switch with virtual channels. Typically, only one virtual channel can, at a given time, access a given output port. Typically, the IQ switch includes an arbiter apparatus that controls the input ports and output ports to ensure that an input port transmits at most one cell at a time, and/or that an output port receives a cell over only one virtual channel, and/or an output port receives at most one cell at a time."
12138805,"Apparatuses, systems, and techniques to grasp objects with a robot. In at least one embodiment, a neural network is trained to determine a grasp pose of an object within a cluttered scene using a point cloud generated by a depth camera."
12141005,A cooling system for a datacenter device is disclosed. Fins are provided between a first plate and a second plate to dissipate a first amount of heat to an environment in a first configuration of the fins. The first plate is movable relative to the second plate to expose a surface area of the fins to the environment in a second configuration of the fins.
12141082,"A parallel processing unit comprises a plurality of processors each being coupled to a memory access hardware circuitry. Each memory access hardware circuitry is configured to receive, from the coupled processor, a memory access request specifying a coordinate of a multidimensional data structure, wherein the memory access hardware circuit is one of a plurality of memory access circuitry each coupled to a respective one of the processors; and, in response to the memory access request, translate the coordinate of the multidimensional data structure into plural memory addresses for the multidimensional data structure and using the plural memory addresses, asynchronously transfer at least a portion of the multidimensional data structure for processing by at least the coupled processor. The memory locations may be in the shared memory of the coupled processor and/or an external memory."
12141225,"Neural networks, in many cases, include convolution layers that are configured to perform many convolution operations that require multiplication and addition operations. Compared with performing multiplication on integer, fixed-point, or floating-point format values, performing multiplication on logarithmic format values is straightforward and energy efficient as the exponents are simply added. However, performing addition on logarithmic format values is more complex. Conventionally, addition is performed by converting the logarithmic format values to integers, computing the sum, and then converting the sum back into the logarithmic format. Instead, logarithmic format values may be added by decomposing the exponents into separate quotient and remainder components, sorting the quotient components based on the remainder components, summing the sorted quotient components using an asynchronous accumulator to produce partial sums, and multiplying the partial sums by the remainder components to produce a sum. The sum may then be converted back into the logarithmic format."
12141229,One embodiment sets forth a technique for performing one or more matrix multiplication operations based on a first matrix and a second matrix. The technique includes receiving data associated with the first matrix from a first traversal engine that accesses nonzero elements included in the first matrix via a first tree structure. The technique also includes performing one or more computations on the data associated with the first matrix and the data associated with the second matrix to produce a plurality of partial results. The technique further includes combining the plurality of partial results into one or more intermediate results and storing the one or more intermediate results in a first buffer memory.
12141268,"Apparatuses, systems, and techniques to generate a trusted execution environment including multiple accelerators. In at least one embodiment, a parallel processing unit (PPU), such as a graphics processing unit (GPU), operates in a secure execution mode including a protect memory region. Furthermore, in an embodiment, a cryptographic key is utilized to protect data during transmission between the accelerators."
12141451,"Embodiments of the present disclosure relate to memory page access instrumentation for generating a memory access profile. The memory access profile may be used to co-locate data near the processing unit that accesses the data, reducing memory access energy by minimizing distances to access data that is co-located with a different processing unit (i.e., remote data). Execution thread arrays and memory pages for execution of a program are partitioned across multiple processing units. The partitions are then each mapped to a specific processing unit to minimize inter-partition traffic given the processing unit physical topology."
12141582,"Various techniques for accelerating dynamic programming algorithms are provided. For example, a fused addition and comparison instruction, a three-operand comparison instruction, and a two-operand comparison instruction are used to accelerate a Needleman-Wunsch algorithm that determines an optimized global alignment of subsequences over two entire sequences. In another example, the fused addition and comparison instruction is used in an innermost loop of a Floyd-Warshall algorithm to reduce the number of instructions required to determine shortest paths between pairs of vertices in a graph. In another example, a two-way single instruction multiple data (SIMD) floating point variant of the three-operand comparison instruction is used to reduce the number of instructions required to determine the median of an array of floating point values."
12141689,"Systems and methods for generating a representative value of a data set by first compressing a portion of values in the data set to determine a first common value and further compressing a subset of the portion of values to determine a second common value. The representative value is generated by taking the difference between the first common value and the second common value, wherein the representative value corresponds to a mathematical relationship between the first and second common values and each value within the subset of the portion of values. The representative value requires less storage than the first and second common values."
12141941,"Systems and methods are disclosed that improve output quality of any neural network, particularly an image generative neural network. In the real world, details of different scale tend to transform hierarchically. For example, moving a person's head causes the nose to move, which in turn moves the skin pores on the nose. Conventional generative neural networks do not synthesize images in a natural hierarchical manner: the coarse features seem to mainly control the presence of finer features, but not the precise positions of the finer features. Instead, much of the fine detail appears to be fixed to pixel coordinates which is a manifestation of aliasing. Aliasing breaks the illusion of a solid and coherent object moving in space. A generative neural network with reduced aliasing provides an architecture that exhibits a more natural transformation hierarchy, where the exact sub-pixel position of each feature is inherited from underlying coarse features."
12141946,"During the rendering of an image, specific pixels in the image are identified where antialiasing would be helpful. Antialiasing is then performed on these identified pixels, where anti-aliasing is a technique used to add greater realism to a digital image by smoothing jagged edges. This reduces a cost of performing antialiasing by reducing a number of pixels within an image on which antialiasing is performed."
12141986,"Various types of image analysis benefit from a multi-stream architecture that allows the analysis to consider shape data. A shape stream can process image data in parallel with a primary stream, where data from layers of a network in the primary stream is provided as input to a network of the shape stream. The shape data can be fused with the primary analysis data to produce more accurate output, such as to produce accurate boundary information when the shape data is used with semantic segmentation data produced by the primary stream. A gate structure can be used to connect the intermediate layers of the primary and shape streams, using higher level activations to gate lower level activations in the shape stream. Such a gate structure can help focus the shape stream on the relevant information and reduces any additional weight of the shape stream."
12142016,"Systems and methods are disclosed for fused processing of a continuous mathematical operator. Fused processing of continuous mathematical operations, such as pointwise non-linear functions without storing intermediate results to memory improves performance when the memory bus bandwidth is limited. In an embodiment, a continuous mathematical operation including at least two of convolution, upsampling, pointwise non-linear function, and downsampling is executed to process input data and generate alias-free output data. In an embodiment, the input data is spatially tiled for processing in parallel such that the intermediate results generated during processing of the input data for each tile may be stored in a shared memory within the processor. Storing the intermediate data in the shared memory improves performance compared with storing the intermediate data to the external memory and loading the intermediate data from the external memory."
12142344,"Various embodiments include a memory device that is capable of performing memory access operations with reduced power consumption relative to prior approaches. The memory device receives early indication as to whether a forthcoming memory access operation is a read operation or a write operation. The memory device enables various circuits and disables other circuits depending on whether this early indication identifies an upcoming memory access operation as a read operation or a write operation. As a result, circuits that are not needed for an upcoming memory access operation are disabled earlier during the memory access operation relative to prior approaches. Disabling such circuits earlier during the memory access operation reduces power consumption without reducing memory device performance."
12142580,"Devices and methods for physical chip security are disclosed. In at least one embodiment, a security module is secured to a board to restrict physical access to an integrated circuit mounted on the security module and provides one or more contacts enabling data access to the integrated circuit."
12145617,"In various examples, a 3D surface structure such as the 3D surface structure of a road (3D road surface) may be observed and estimated to generate a 3D point cloud or other representation of the 3D surface structure. Since the representation may be sparse, one or more densification techniques may be applied to densify the representation of the 3D surface structure. For example, the relationship between sparse and dense projection images (e.g., 2D height maps) may be modeled with a Markov random field, and Maximum a Posterior (MAP) inference may be performed using a corresponding joint probability distribution to estimate the most likely dense values given the sparse values. The resulting dense representation of the 3D surface structure may be provided to an autonomous vehicle drive stack to enable safe and comfortable planning and control of the autonomous vehicle."
12148088,"A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include opaque and alpha triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to determine primitives intersected by the ray, and return intersection information to a streaming multiprocessor for further processing. The hardware-based traversal coprocessor is configured to omit reporting of one or more primitives the ray is determined to intersect. The omitted primitives include primitives which are provably capable of being omitted without a functional impact on visualizing the virtual scene."
12148099,"A method, computer readable medium, and system are disclosed for overlaying a cell onto a polygon meshlet. The polygon meshlet may include a grouping of multiple geometric shapes such as triangles, and the cell may include a square-shaped boundary. Additionally, every polygon (e.g., a triangle or other geometric shape) within the polygon meshlet that has at least one edge fully inside the cell is removed to create an intermediate meshlet. A selected vertex is determined from all vertices (e.g., line intersections) of the intermediate meshlet that are located within the cell, based on one or more criteria, and all the vertices of the intermediate meshlet that are located within the cell are replaced with the selected vertex to create a modified meshlet. The modified meshlet is then rendered (e.g., as part of a process to generate a scene to be viewed)."
12149259,"A memory device and a system that implements a single symbol correction, double symbol detection (SSC-DSD+) error correction scheme are provided. The scheme is implemented by calculating four syndrome symbols in accordance with a Reed-Solomon (RS) codeword; determining three location bytes in accordance with three corresponding pairs of syndrome symbols in the four syndrome symbols; and generating an output based on a comparison of the three location bytes. The output may include: corrected data responsive to determining that the three location bytes match; an indication of a detected-and-corrected error (DCE) responsive to determining that two of the three location bytes match; or an indication of a detected-yet-uncorrected error (DUE) responsive to determining that none of the three location bytes match. A variant of the SSC-DSD+ decoder may be implemented using a carry-free subtraction operation to perform sanity checking."
12149588,"Storage processing units or SPUs (120) operate backend storage (150) to provide scalable storage services, redundancy, and disaster recovery to an enterprise. Each SPU (120) may reside in a host server (110) and may include an processor domain (490) with backup power (440) and isolation from a host domain (480) to allow the SPU (120) to operate after the host (110) fails or otherwise stops providing power. A cloud-based management system (180) may assess the storage needs of the enterprise, identify a storage style suited to the enterprise, and direct the SPUs (120) to create virtual volumes (122, 124, 128) having characteristics according to the storage style identified. The cloud based management system (180) may eliminate the need for the enterprise to have expertise in storage management."
12149708,"In various examples, machine learning of encoding parameter values for a network is performed using a video encoder. Feedback associated with streaming video encoded by a video encoder over a network may be applied to an MLM(s). Using such feedback, the MLM(s) may predict a value(s) of an encoding parameter(s). The video encoder may then use the value to encode subsequent video data for the streaming. By using the video encoder in training, the MLM(s) may learn based on actual encoded parameter values of the video encoder. The MLM(s) may be trained via reinforcement learning based on video encoded by the video encoder. A rewards metric(s) may be used to train the MLM(s) using data generated or applied to the physical network in which the MLM(s) is to be deployed and/or a simulation thereof. Penalty metric(s) (e.g., the quantity of dropped frames) may also be used to train the MLM(s)."
12150284,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a number of multi-dimensional column-based heat dissipation features enable cooling by a cooling media flowing there through so that an individual heat dissipation column having a first dimension and a second dimension may be supported, with the first dimension being normal relative to an axial flow path of the cooling media, with the second dimension being parallel or offset from parallel relative to the axial flow path and with the second dimension being more than the first dimension."
12153688,"Apparatuses, systems, and techniques to perform a cryptographic operation using multiple iterations, wherein each iteration includes two or more stages operating in parallel on inputs derived from a common value, one of the stages computing real data and other stages computing dummy data."
12153783,"User interfaces, methods and structures are described for intuitively and fluidly creating new artifacts from existing artifacts and for exploring latent spaces in a visual manner. In example embodiments, source artifacts are displayed along with a selector. The selector is operable to indicate a selected set of the source artifacts by establishing a selection region that includes portions of one or more of the source artifacts displayed. Source vectors are associated with the source artifacts in the selected set. One or more resultant vectors are determined based on the source vectors, and an output artifact is generated based on the one or more resultant vectors."
12154188,"In various examples, a neural network may be trained for use in vehicle re-identification tasks—e.g., matching appearances and classifications of vehicles across frames—in a camera network. The neural network may be trained to learn an embedding space such that embeddings corresponding to vehicles of the same identify are projected closer to one another within the embedding space, as compared to vehicles representing different identities. To accurately and efficiently learn the embedding space, the neural network may be trained using a contrastive loss function or a triplet loss function. In addition, to further improve accuracy and efficiency, a sampling technique—referred to herein as batch sample—may be used to identify embeddings, during training, that are most meaningful for updating parameters of the neural network."
12154213,"Apparatuses, systems, and techniques to generate blue noise masks for real-time image rendering and enhancement. In at least one embodiment, a vector-valued noise mask is generated and applied to one or more images to generate one or more enhanced images for image processing (e.g., real-time image rendering). In at least one embodiment, the noise mask includes vector values per pixel and is able to handle the temporal domain (e.g., add time to the spatial domain) to improve image quality when rendering images over multiple frames."
12154214,"An alternate root tree or graph structure for ray and path tracing enables dynamic instancing build time decisions to split any number of geometry acceleration structures in a manner that is developer transparent, nearly memory storage neutral, and traversal efficient. The resulting traversals only need to partially traverse the acceleration structure, which improves efficiency. One example use reduces the number of false positive instance acceleration structure to geometry acceleration structure transitions for many spatially separated instances of the same geometry."
12154293,"In various examples, live perception from wide-view sensors may be leveraged to detect features in an environment of a vehicle. Sensor data generated by the sensors may be adjusted to represent a virtual field of view different from an actual field of view of the sensor, and the sensor data—with or without virtual adjustment—may be applied to a stereographic projection algorithm to generate a projected image. The projected image may then be applied to a machine learning model—such as a deep neural network (DNN)—to detect and/or classify features or objects represented therein. In some examples, the machine learning model may be pre-trained on training sensor data generated by a sensor having a field of view less than the wide-view sensor such that the virtual adjustment and/or projection algorithm may update the sensor data to be suitable for accurate processing by the pre-trained machine learning model."
12156384,"Systems and methods for evaluating cooling characteristics are disclosed. In at least one embodiment, a thermal testing rig for a data center can include one or more pluggable heat-generating elements to direct a heat flux in an upward direction towards one or more thermal distribution elements."
12158977,"Devices and methods to obtain values usable to verify the geographic location of a device. In at least one embodiment, a device comprises a positioning circuit and a cryptoprocessor. The device obtains geographic coordinates of the device's location, using the positioning circuit. The device stores, in the cryptoprocessor, information indicating the state of the device and the geographic coordinates. The device uses the cryptoprocessor to obtain values usable to validate the geographic location of the device."
12159342,"Ray tracing hardware accelerators supporting motion blur and moving/deforming geometry are disclosed. For example, dynamic objects in an acceleration data structure are encoded with temporal and spatial information. The hardware includes circuitry that test ray intersections against moving/deforming geometry by applying such temporal and spatial information. Such circuitry accelerates the visibility sampling of moving geometry, including rigid body motion and object deformation, and its associated moving bounding volumes to a performance similar to that of the visibility sampling of static geometry."
12159344,"One embodiment of a computer-implemented method for processing ray tracing operations in parallel includes receiving a plurality of rays and a corresponding set of importance sampling instructions for each ray included in the plurality of rays for processing, wherein each ray represents a path from a light source to at least one point within a three-dimensional (3D) environment, and each corresponding set of importance sampling instruction is based at least in part on one or more material properties associated with at least one surface of at least one object included in the 3D environment; assigning each ray included in the plurality of rays to a different processing core included in a plurality of processing cores; and for each ray included in the plurality of rays, causing the processing core assigned to the ray to execute the corresponding set of importance sampling instructions on the ray to generate a direction for a secondary ray that is produced when the ray intersects a surface of an object within the 3D environment."
12159417,"In various examples, an ego-machine may analyze sensor data to identify and track features in the sensor data using. Geometry of the tracked features may be used to analyze motion flow to determine whether the motion flow violates one or more geometrical constraints. As such, tracked features may be identified as dynamic features when the motion flow corresponding to the tracked features violates the one or more static constraints for static features. Tracked features that are determined to be dynamic features may be clustered together according to their location and feature track. Once features have been clustered together, the system may calculate a detection bounding shape for the clustered features. The bounding shape information may then be used by the ego-machine for path planning, control decisions, obstacle avoidance, and/or other operations."
12159694,"A machine learning framework is described for performing generation of candidate molecules for, e.g., drug discovery or other applications. The framework utilizes a pre-trained encoder-decoder model to interface between representations of molecules and embeddings for those molecules in a latent space. A fusion module is located between the encoder and decoder and is used to fuse an embedding for an input molecule with embeddings for one or more exemplary molecules selected from a database that is constructed according to a design criteria. The fused embedding is decoded using the decoder to generate a candidate molecule. The fusion module is trained to reconstruct a nearest neighbor to the input molecule from the database based on the sample of exemplary molecules. An iterative approach may be used during inference to dynamically update the database to include newly generated candidate molecules."
12160307,"A system can include an optical transmitter having transmitter components and an optical receiver having receiver components and photodetectors. The optical transmitter is configured to receive optical wavelengths of radiation from a multiple wavelength generate, such as a laser, and generate transmitted wavelengths including data wavelengths and excess wavelengths. Each photodetector is configured to receive at least one transmitted wavelength. The photodetectors can include a common photodetector operatively coupled to at least two receiver components and configured to obtain a set of unmodulated carrier frequencies (e.g., a pair of unmodulated carrier frequencies) from the at least two receiver components, and determine clock information therefrom. The clock information can be determined by obtaining a heterodyne frequency from the set of unmodulated carrier frequencies. The heterodyne frequency can be used to synchronize the optical transmitter and the optical receiver."
12160498,"Processors, systems and methods are described that synchronize clocks of devices on a second network that uses a second network protocol to a source clock on a first network that uses a first network protocol. Processors, systems and methods are described to cause a first time synchronization message corresponding to a first network communication protocol to be converted to a second time synchronization message corresponding to a second network communication protocol to enable synchronization."
12160981,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a first three-way flow controller is associated with a single-phase fluid and a second three-way flow controller is associated with a two-phase fluid, with a first three-way flow controller to enable a first flow path of a single-phase fluid from a coolant distribution unit to a cold plate or to enable a second flow path to a heat exchanger to cool a two-phase fluid to be used in a cold plate, and with a second three-way flow controller to enable a third flow path of a two-phase fluid to a cold plate or to enable a fourth flow path to a heat exchanger."
12162418,"In various examples, systems and methods are disclosed that accurately identify driver and passenger in-cabin activities that may indicate a biomechanical distraction that prevents a driver from being fully engaged in driving a vehicle. In particular, image data representative of an image of an occupant of a vehicle may be applied to one or more deep neural networks (DNNs). Using the DNNs, data indicative of key point locations corresponding to the occupant may be computed, a shape and/or a volume corresponding to the occupant may be reconstructed, a position and size of the occupant may be estimated, hand gesture activities may be classified, and/or body postures or poses may be classified. These determinations may be used to determine operations or settings for the vehicle to increase not only the safety of the occupants, but also of surrounding motorists, bicyclists, and pedestrians."
12164059,"A deep neural network(s) (DNN) may be used to detect objects from sensor data of a three dimensional (3D) environment. For example, a multi-view perception DNN may include multiple constituent DNNs or stages chained together that sequentially process different views of the 3D environment. An example DNN may include a first stage that performs class segmentation in a first view (e.g., perspective view) and a second stage that performs class segmentation and/or regresses instance geometry in a second view (e.g., top-down). The DNN outputs may be processed to generate 2D and/or 3D bounding boxes and class labels for detected objects in the 3D environment. As such, the techniques described herein may be used to detect and classify animate objects and/or parts of an environment, and these detections and classifications may be provided to an autonomous vehicle drive stack to enable safe planning and control of the autonomous vehicle."
12164599,"Volumetric quantification can be performed for various parameters of an object represented in volumetric data. Multiple views of the object can be generated, and those views provided to a set of neural networks that can generate inferences in parallel. The inferences from the different networks can be used to generate pseudo-labels for the data, for comparison purposes, which enables a co-training loss to be determined for the unlabeled data. The co-training loss can then be used to update the relevant network parameters for the overall data analysis network. If supervised data is also available then the network parameters can further be updated using the supervised loss."
12165258,"One or more machine learning models (MLMs) may learn implicit 3D representations of geometry of an object and of dynamics of the object from performing an action on the object. Implicit neural representations may be used to reconstruct high-fidelity full geometry of the object and predict a flow-based dynamics field from one or more images, which may provide a partial view of the object. Correspondences between locations of an object may be learned based at least on distances between the locations on a surface corresponding to the object, such as geodesic distances. The distances may be incorporated into a contrastive learning loss function to train one or more MLMs to learn correspondences between locations of the object, such as a correspondence embedding field. The correspondences may be used to evaluate state changes when evaluating one or more actions that may be performed on the object."
12167169,A digital avatar system can process video streams and generate synthetic video with a digital avatar. The digital avatar provides the appearance of a participant from the video stream talking and one or more of performing various behaviors or actions consistent with the participant's behavior when they are live streamed. A digital avatar system can detect triggering events during a live stream and automatically switch to an avatar mode.
12169677,A genetic algorithm is utilized to generate routing candidates to which a reinforcement learning model is applied to correct the design rule constraint violations incrementally. A design rule checker provides feedback on the violations to the reinforcement learning model and the model learns how to fix the violations. A layout device placer based upon a simulated annealing method may also be utilized.
12169882,"Embodiments of the present disclosure relate to learning dense correspondences for images. Systems and methods are disclosed that disentangle structure and texture (or style) representations of GAN synthesized images by learning a dense pixel-level correspondence map for each image during image synthesis. A canonical coordinate frame is defined and a structure latent code for each generated image is warped to align with the canonical coordinate frame. In sum, the structure associated with the latent code is mapped into a shared coordinate space (canonical coordinate space), thereby establishing correspondences in the shared coordinate space. A correspondence generation system receives the warped coordinate correspondences as an encoded image structure. The encoded image structure and a texture latent code are used to synthesize an image. The shared coordinate space enables propagation of semantic labels from reference images to synthesized images."
12170757,"Disclosed are apparatuses, systems, and techniques for real-time codec encoding of video files using hardware-assisted accelerators that utilize a combination of parallel and sequential processing, in which at least a part of intra-frame block prediction is performed with parallel processing."
12172667,"In various examples, a 3D surface structure such as the 3D surface structure of a road (3D road surface) may be observed and estimated to generate a 3D point cloud or other representation of the 3D surface structure. Since the estimated representation may be sparse, a deep neural network (DNN) may be used to predict values for a dense representation of the 3D surface structure from the sparse representation. For example, a sparse 3D point cloud may be projected to form a sparse projection image (e.g., a sparse 2D height map), which may be fed into the DNN to predict a dense projection image (e.g., a dense 2D height map). The predicted dense representation of the 3D surface structure may be provided to an autonomous vehicle drive stack to enable safe and comfortable planning and control of the autonomous vehicle."
12174034,"A computer-implemented method may comprise: receiving sensor data from a sensor of an autonomous vehicle; determining a presence of a lane closure object located on a lane element; determining a change of the lane closure object, selected from the presence of the lane closure object or absence of the lane closure object on the lane element; generating a change candidate based on the change in the lane closure object; obtaining a plurality of the change candidates during a time period or the autonomous vehicle being on a preceding lane element on the route; analyzing the plurality of change candidates for the change being the presence of the lane closure object or the absence of the lane closure object on the lane element; generating a final change candidate based on the change; and providing the final change candidate for updating a high definition map of the route having the lane element."
12174602,"A thermal load system for testing a datacenter liquid cooling system is disclosed. The system includes a server box having at least one thermal feature associated with at least one cooling feature and at least one flow controller, where the at least one thermal feature and the at least one flow controller are adjustable to cause cooling stress on the datacenter liquid cooling system."
12175350,"In at least one embodiment, differentiable neural architecture search and reinforcement learning are combined under one framework to discover network architectures with desired properties such as high accuracy, low latency, or both. In at least one embodiment, an objective function for search based on generalization error prevents the selection of architectures prone to overfitting."
12175588,"One embodiment of a method for rendering one or more graphics images includes tracing one or more rays through a graphics scene; storing one or more hit points based on one or more coordinate frames associated with one or more voxels of a grid, where the one or more rays intersect one or more surfaces of geometry in the one or more voxels; and rendering one or more graphics images based on the one or more hit points that are stored."
12175703,"Apparatuses, systems, and techniques to determine a pose and relative dimensions of an object from an image. In at least one embodiment, a pose and relative dimensions of an object are determined from an image based at least in part on, for example, features of the image."
12175711,"Optical center is determined on a column-by-column and row-by-row basis by identifying brightest pixels in respective columns and rows. The brightest pixels in each column are identified and a line is fit to those pixels. Similarly, brightest pixels in each row are identified and a second line is fit to those pixels. The intersection of the two lines is the optical center."
12175739,"Apparatuses, systems, and techniques to perform non-maximum suppression (NMS) in parallel to remove redundant bounding boxes. In at least one embodiment, two or more parallel circuits to perform two or more portions of a NMS algorithm in parallel to remove one or more redundant bounding boxes corresponding to one or more objects within one or more digital images."
12177961,"According to various embodiments, a processing subsystem includes: a processor mounted on a first printed circuit board that is oriented parallel to a first plane; a heat sink thermally coupled to the processor; a second printed circuit board that is communicatively coupled to the first printed circuit board and oriented parallel to a second plane, wherein the second plane is not parallel with the first plane; and at least one cooling fan that is positioned to direct a cooling fluid through the heat sink in a direction parallel to the first plane."
12179119,"The disclosure provides a cheating detection strategy for interactive programs, which detects programmatically-generated motion from actual human-generated motion based on a comparison of actual motion data to inferred motion data. The cheating detection strategy uses visual and input information to ensure that the input matches the output to detect and avoid cheating tools positioned in between the input and the output. In one example, the disclosure provide a method of monitoring cheating in interactive programs that includes: (1) receiving actual motion data from a user input device, wherein the actual motion data corresponds to interacting with the interactive program, (2) receiving image data of the interactive program that includes image sequences of the interactive program to display on a screen, (3) comparing the actual motion data to inferred motion data determined from the image sequences, and (4) determining possible cheating based on the comparing."
12179795,"A trajectory for an autonomous machine may be evaluated for safety based at least on determining whether the autonomous machine would be capable of occupying points of the trajectory in space-time while still being able to avoid a potential future collision with one or more objects in the environment through use of one or more safety procedures. To do so, a point of the trajectory may be evaluated for conflict based at least on a comparison between points in space-time that correspond to the autonomous machine executing the safety procedure(s) from the point and arrival times of the one or more objects to corresponding position(s) in the environment. A trajectory may be sampled and evaluated for conflicts at various points throughout the trajectory. Based on results of one or more evaluations, the trajectory may be scored, eliminated from consideration, or otherwise considered for control of the autonomous machine."
12182694,"In various examples, physical sensor data may be generated by a vehicle in a real-world environment. The physical sensor data may be used to train deep neural networks (DNNs). The DNNs may then be tested in a simulated environment—in some examples using hardware configured for installation in a vehicle to execute an autonomous driving software stack—to control a virtual vehicle in the simulated environment or to otherwise test, verify, or validate the outputs of the DNNs. Prior to use by the DNNs, virtual sensor data generated by virtual sensors within the simulated environment may be encoded to a format consistent with the format of the physical sensor data generated by the vehicle."
12182927,"Recurrent blurring may be used to render frames of a virtual environment, where the radius of a filter for a pixel is based on a number of successfully accumulated frames that correspond to that pixel. To account for rejections of accumulated samples for the pixel, ray-traced samples from a lower resolution version of a ray-traced render may be used to increase the effective sample count for the pixel. Parallax may be used to control the accumulation speed along with an angle between a view vector that corresponds to the pixel. A magnitude of one or more dimensions of a filter applied to the pixel may be based on an angle of a view vector that corresponds to the pixel to cause reflections to elongate along an axis under glancing angles. The dimension(s) may be based on a direction of a reflected specular lobe associated with the pixel."
12182940,"Apparatuses, systems, and techniques to identify a shape or camera pose of a three-dimensional object from a two-dimensional image of the object. In at least one embodiment, objects are identified in an image using one or more neural networks that have been trained on objects of a similar category and a three-dimensional mesh template."
12183037,"An autoencoder may be trained to predict 3D pose labels using simulation data extracted from a simulated environment, which may be configured to represent an environment in which the 3D pose estimator is to be deployed. Assets may be used to mimic the deployment environment such as 3D models or textures and parameters used to define deployment scenarios and/or conditions that the 3D pose estimator will operate under in the environment. The autoencoder may be trained to predict a segmentation image from an input image that is invariant to occlusions. Further, the autoencoder may be trained to exclude areas of the input image from the object that correspond to one or more appendages of the object. The 3D pose may be adapted to unlabeled real-world data using a GAN, which predicts whether output of the 3D pose estimator was generated from real-world data or simulated data."
12183050,"Apparatuses, systems, and techniques to use data obtained from an inferred object to determine whether to re-infer the same inferred object. In at least one embodiment, data obtained from inferencing a tracked object among a set of images is used to adjust a set of conditions."
12183063,"In examples, image data representative of an image of a field of view of at least one sensor may be received. Source areas may be defined that correspond to a region of the image. Areas and/or dimensions of at least some of the source areas may decrease along at least one direction relative to a perspective of the at least one sensor. A downsampled version of the region (e.g., a downsampled image or feature map of a neural network) may be generated from the source areas based at least in part on mapping the source areas to cells of the downsampled version of the region. Resolutions of the region that are captured by the cells may correspond to the areas of the source areas, such that certain portions of the region (e.g., portions at a far distance from the sensor) retain higher resolution than others."
12184843,"Disclosed are techniques for compressing data of an image using multiple processing cores. The techniques include obtaining, using a first (second, etc.) processing core, a first (second, etc.) plurality of reconstructed blocks approximating source pixels of a first (second, etc.) portion of an image and filtering, using the first processing core, the first plurality of reconstructed blocks. The filtering includes enabling application of one or more filters to a first plurality of regions that include pixels of the first plurality of reconstructed blocks but not pixels of the second plurality of reconstructed blocks. The filtering further includes disabling application of the one or more filters to a second plurality of regions that include pixels of the first plurality of reconstructed blocks and pixels of the second plurality of reconstructed blocks."
12185495,"A cold plate that is configurable and for a datacenter liquid cooling system is disclosed. The cold plate includes a first section, a second section, and an intermediate layer, which is changeable and has first channels to enable flow of a coolant through the intermediate layer, and has second channels or at least one adapted second channel to concentrate the coolant or the flow of the coolant to at least one area within the configurable cold plate corresponding to at least a heat generating feature of an associated computing device."
12187187,"The present disclosure relates to determining a first illumination level corresponding to an area based at least on a first illumination detection obtained using a first illumination detector corresponding to a machine. A second illumination level corresponding to the area may be determined based at least on a second illumination detection obtained using a second illumination detector corresponding to the machine. Based at least on the first illumination level and the second illumination level, a scene illumination state of the area may be determined. Based at least on the scene illumination state, one or more lights of the machine may be controlled."
12188779,"In various examples, a method includes computing a current keyframe, the current keyframe being representative of an area around an autonomous vehicle at a current time based on map data. The method includes transforming a preceding keyframe to a coordinate frame of the autonomous vehicle at a first time prior to completing computation of the current keyframe to generate a first world model frame. The method includes transforming the preceding keyframe to the coordinate frame of the autonomous vehicle at a second time after the first time and prior to completing computation of the current keyframe to generate a second world model frame."
12189018,"One or more embodiments of the present disclosure relate to generating RADAR (RAdio Detection And Ranging) point clouds based on RADAR data obtained from one or more RADAR sensors disposed on one or more ego-machines. In these or other embodiments, the RADAR point clouds may be communicated to a distributed map system that is configured to generate map data based on the RADAR point clouds. In some embodiments of the present disclosure, certain compression operations may be performed on the RADAR point clouds to reduce the amount of data that is communicated from the ego-machines to the map system."
12189065,"A method includes obtaining first user input identifying at least one LIDAR point in a set of LIDAR points associated with an object in an image, and obtaining second user input identifying the object in the image. The method may also include generating a constraint on a relationship between a LIDAR sensor used to capture the set of LIDAR points and a camera used to capture the image. The method may additionally include reducing a cost associated with the LIDAR point being inconsistent with the object in the image subject to the constraint."
12189558,"In various examples, methods may include receiving first data transmitted from a second component and second data transmitted from the second component during a first time period. The first data may be transmitted via a first data lane and the second data may be transmitted via a second data lane. The method may include receiving de-skew symbols at an interval from the second component via the first data lane and via the second data lane during the first time period. The method may include compensating for a first skew introduced to a first propagation of the first data across the first data lane and a second skew introduced to a second propagation of the second data across the second data lane using the de-skew symbols received during the first time period."
12189561,"A multi-format graphics process unit (GPU) docking board is disclosed. The multi-format GPU docking board includes a first switch to enable communication between a first format (GPU) board and a second format GPU board, and a second switch to enable communication between a central processing unit (CPU) and the first format GPU board and between the CPU and the second format GPU board."
12190434,"In various examples, a virtual light meter may be implemented along with ray tracing techniques in order to determine incident light values—e.g., incoming irradiance, incident radiance, etc.—for adjusting auto exposure values of rendered frames. For example, one or more rays may be used to sample incident light over a sampling pattern—such as a hemispherical sampling pattern—for any position in a virtual game environment. As a result, the incident light values may be sampled near a subject of interest in a scene or frame such that exposure values are consistent or stable regardless of the composition of the rendered frames."
12190435,"Enhanced techniques applicable to a ray tracing hardware accelerator for traversing a hierarchical acceleration structure are disclosed. For example, traversal efficiency is improved by combining programmable traversals based on ray operations with per-node static configurations that modify traversal behavior. The per-node static configurations enable creators of acceleration data structures to optimize for potential traversals without necessarily requiring detailed information about ray characteristics and ray operations used when traversing the acceleration structure. Moreover, by providing for selective exclusion of certain nodes using per-node static configurations, less memory is needed to express an acceleration structure that includes, for example, different geometric levels of details corresponding to a single object."
12190448,"In various examples, to support training a deep neural network (DNN) to predict a dense representation of a 3D surface structure of interest, a training dataset is generated using a simulated environment. For example, a simulation may be run to simulate a virtual world or environment, render frames of virtual sensor data (e.g., images), and generate corresponding depth maps and segmentation masks (identifying a component of the simulated environment such as a road). To generate input training data, 3D structure estimation may be performed on a rendered frame to generate a representation of a 3D surface structure of the road. To generate corresponding ground truth training data, a corresponding depth map and segmentation mask may be used to generate a dense representation of the 3D surface structure."
12191868,"A glitch detection device includes an oscillator to generate multiple local clocks of multiple different phases and a sampling circuit to oversample, using the multiple local clocks, a system clock to generate multiple samples of the system clock. The device further includes a glitch detector to monitor a variation in pulse width of the system clock based on counting the multiple samples and to report a glitch in response to detecting a variation in the pulse width that exceeds a threshold value."
12192547,"In various examples, systems and methods are disclosed relating to aligning images into frames of a first video using at least one first temporal attention layer of a neural network model. The first video has a first spatial resolution. A second video having a second spatial resolution is generated by up-sampling the first video using at least one second temporal attention layer of an up-sampler neural network model, wherein the second spatial resolution is higher than the first spatial resolution."
12192720,"Apparatuses, systems, and techniques are presented to reduce noise in audio. In at least one embodiment, one or more neural networks are used to determine a noise signal in one or more speech signals."
12193194,"Systems and methods for a datacenter cooling system are disclosed. In at least one embodiment, a thermal test vehicle (TTV) includes an air-cooled heat element associated with a plurality of fins to enable air cooling of a TTV and includes a liquid-cooled heat trace associated with a cold plate to enable liquid cooling of a TTV, where an air-cooled heat element and a liquid-cooled heat trace generate heat to enable separate or concurrent testing of air cooling and liquid cooling in a datacenter cooling system."
12193196,"Systems and methods for cooling a computer environment are disclosed. In at least one embodiment, one or more neural networks can be used to determine one or more temperature control settings associated with one or more servers."
12194383,"Apparatuses, systems, and techniques to determine position information for a gameplay session. In at least one embodiment, the position information is determined by at least matching features extracted from a mini-map to feature extracted from a map and determining a transformation matrix to be applied to a position within the mini-map."
12194632,"In at least one embodiment, under the control of a robotic control system, a gripper on a robot is positioned to grasp a 3-dimensional object. In at least one embodiment, the relative position of the object and the gripper is determined, at least in part, by using a camera mounted on the gripper."
12197272,"A system includes a device having a controller a plurality of finite state machines (FSMs). The device is to detect that one or more FSMs of the plurality of FSMs fails to satisfy a non-idle duration criterion during an operation, where the one or more FSM that fail to satisfy the non-idle duration criterion are associated with one or more errors. The device is to determine a location of the one or more FSMs that fail to satisfy the non-idle duration criterion. The device is to record the location of the one or more FSMs and the one or more errors, restore the one or more FSM to an idle state, and transmit an indication that the one or more FSMs failed to satisfy the non-idle duration criterion."
12197281,"A transceiver configured to communicate a burst of data bits and meta-data bits for the data bits includes data channels, auxiliary data channels, and at least one error correction channel. The transceiver includes an encoder that applies 11b7s encoding to a first number of the data bits to generate first PAM-3 symbols on some or all of the communication channels, and that applies 3b2s encoding to a second number of the data bits to generate second PAM-3 symbols on at least some of the communication channels."
12197954,"The present technology augments the GPU compute model to provide system-provided data marshalling characteristics of graphics pipelining to increase efficiency and reduce overhead. A simple scheduling model based on scalar counters (e.g., semaphores) abstract the availability of hardware resources. Resource releases can be done programmatically, and a system scheduler only needs to track the states of such counters/semaphores to make work launch decisions. Semantics of the counters/semaphores are defined by an application, which can use the counters/semaphores to represent the availability of free space in a memory buffer, the amount of cache pressure induced by the data flow in the network, or the presence of work items to be processed."
12198251,"Techniques applicable to a ray tracing hardware accelerator for traversing a hierarchical acceleration structure with reduced false positive ray intersections are disclosed. The reduction of false positives may be based upon one or more of selectively performing a secondary higher precision intersection test for a bounding volume, identifying and culling bounding volumes that degenerate to a point, and parametrically clipping rays that exceed certain configured distance thresholds."
12198252,"Techniques applicable to a ray tracing hardware accelerator for traversing a hierarchical acceleration structure with reduced false positive ray intersections are disclosed. The reduction of false positives may be based upon one or more of selectively performing a secondary higher precision intersection test for a bounding volume, identifying and culling bounding volumes that degenerate to a point, and parametrically clipping rays that exceed certain configured distance thresholds."
12198253,"A hardware-based traversal coprocessor provides acceleration of tree traversal operations searching for intersections between primitives represented in a tree data structure and a ray. The primitives may include opaque and alpha triangles used in generating a virtual scene. The hardware-based traversal coprocessor is configured to determine primitives intersected by the ray, and return intersection information to a streaming multiprocessor for further processing. The hardware-based traversal coprocessor is configured to provide a deterministic result of intersected triangles regardless of the order that the memory subsystem returns triangle range blocks for processing, while opportunistically eliminating alpha intersections that lie further along the length of the ray than closer opaque intersections."
12198255,"Methods and systems are described in some examples for changing the traversal of an acceleration data structure in a highly dynamic query-specific manner, with each query specifying test parameters, a test opcode and a mapping of test results to actions. In an example ray tracing implementation, traversal of a bounding volume hierarchy by a ray is performed with the default behavior of the traversal being changed in accordance with results of a test performed using the test opcode and test parameters specified in the ray data structure and another test parameter specified in a node of the bounding volume hierarchy. In an example implementation a traversal coprocessor is configured to perform the traversal of the bounding volume hierarchy."
12198256,"Techniques are disclosed for improving the throughput of ray intersection or visibility queries performed by a ray tracing hardware accelerator. Throughput is improved, for example, by releasing allocated resources before ray visibility query results are reported by the hardware accelerator. The allocated resources are released when the ray visibility query results can be stored in a compressed format outside of the allocated resources. When reporting the ray visibility query results, the results are reconstructed based on the results stored in the compressed format. The compressed format storage can be used for ray visibility queries that return no intersections or terminate on any hit ray visibility query. One or more individual components of allocated resources can also be independently deallocated based on the type of data to be returned and/or results of the ray visibility query."
12198450,"In various examples, systems and methods are disclosed herein for a vehicle command operation system that may use technology across multiple modalities to cause vehicular operations to be performed in response to determining a focal point based on a gaze of an occupant. The system may utilize sensors to receive first data indicative of an eye gaze of an occupant of the vehicle. The system may utilize sensors to receive second data indicative of other data from the occupant. The system may then calculate a gaze vector based on the data indicative of the eye gaze of the occupant. The system may determine a focal point based on the gaze vector. In response to determining the focal point, the system causes an operation to be performed in the vehicle based on the second data."
12199619,A receiver includes a multi-phase clock generator to generate phases of a clock signal and a global phase interpolator (PI) circuit coupled to the multi-phase clock generator and to clock and data recovery (CDR) circuitry. The global PI circuit generates initial-adjusted phases from the phases of the clock signal based on a control signal received from the CDR circuitry. A first local PI receives the initial-adjusted phases of the clock signal and applies a first fixed phase shift to the initial-adjusted phases to generate first final-adjusted phases of the clock signal that are useable to sample a first level of multiple levels of a pulse-amplitude-modulated (PAM) data stream.
12200909,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a fluid reservoir in a form-factor of at least one rack is provided, the fluid reservoir to store fluid, the fluid to be passed to a cold plate or an immersive-cooled server, and the fluid to be cooled by a secondary cooling loop or an air-cooling system."
12200913,A cooling system for a datacenter is disclosed. The datacenter cooling system includes a cooling manifold having a first controllable fluid coupler to receive a coolant from a cooling loop external to the rack and one or more second controllable fluid couplers to distribute the coolant to one or more server cooling manifolds within server trays of a rack within the datacenter.
12202147,"A technique for training a neural network, including generating a plurality of input vectors based on a first plurality of task demonstrations associated with a first robot performing a first task in a simulated environment, wherein each input vector included in the plurality of input vectors specifies a sequence of poses of an end-effector of the first robot, and training the neural network to generate a plurality of output vectors based on the plurality of input vectors. Another technique for generating a task demonstration, including generating a simulated environment that includes a robot and at least one object, causing the robot to at least partially perform a task associated with the at least one object within the simulated environment based on a first output vector generated by a trained neural network, and recording demonstration data of the robot at least partially performing the task within the simulated environment."
12202432,"Systems and methods are disclosed related to restraint device (e.g., seatbelt) localization. In one embodiment, the disclosure relates to systems and methods for seatbelt detection and modeling. A vehicle may be occupied by one or more occupants wearing one or more seatbelts. A camera or other sensor is placed within the vehicle to capture images of the one or more occupants. A system analyzes the images to detect and model seatbelts depicted in the images. Specifically, the system may scan the images and areas of the images that may correspond to seatbelts. The system may assemble candidate areas of the images that may correspond to seatbelts, and refine the candidate areas based on various constraints. The system may build models based on the refined candidate areas that indicate the seatbelts. The system may visualize the models indicating the seatbelts using the images."
12202518,"In various examples, a safety decomposition architecture for autonomous machine applications is presented that uses two or more individual safety assessments to satisfy a higher safety integrity level (e.g., ASIL D). For example, a behavior planner may be used as a primary planning component, and a collision avoidance feature may be used as a diverse safety monitoring component—such that both may redundantly and independently prevent violation of safety goals. In addition, robustness of the system may be improved as single point and systematic failures may be avoided due to the requirement that two independent failures—e.g., of the behavior planner component and the collision avoidance component—occur simultaneously to cause a violation of the safety goals."
12204475,"In various examples, a VPU and associated components may be optimized to improve VPU performance and throughput. For example, the VPU may include a min/max collector, automatic store predication functionality, a SIMD data path organization that allows for inter-lane sharing, a transposed load/store with stride parameter functionality, a load with permute and zero insertion functionality, hardware, logic, and memory layout functionality to allow for two point and two by two point lookups, and per memory bank load caching capabilities. In addition, decoupled accelerators may be used to offload VPU processing tasks to increase throughput and performance, and a hardware sequencer may be included in a DMA system to reduce programming complexity of the VPU and the DMA system. The DMA and VPU may execute a VPU configuration mode that allows the VPU and DMA to operate without a processing controller for performing dynamic region based data movement operations."
12204897,"Apparatuses, systems, and techniques to perform computational operations in response to one or more compute uniform device architecture (CUDA) programs. In at least one embodiment, one or more computational operations are to cause one or more other computational operations to wait until a portion of matrix multiply-accumulate (MMA) operations have been performed."
12205210,"In various examples, a virtually animated and interactive agent may be rendered for visual and audible communication with one or more users with an application. For example, a conversational artificial intelligence (AI) assistant may be rendered and displayed for visual communication in addition to audible communication with end-users. As such, the AI assistant may leverage the visual domain—in addition to the audible domain—to more clearly communicate with users, including interacting with a virtual environment in which the AI assistant is rendered. Similarly, the AI assistant may leverage audio, video, and/or text inputs from a user to determine a request, mood, gesture, and/or posture of a user for more accurately responding to and interacting with the user."
12205534,"Certain display types—such as organic light emitting diode (OLED) displays—may be more prone to burn-in or ghosting due to the varied luminance degradation rates of pixel cells of the display—especially in applications or content types that require display of prolonged, continuous, static textures. To account for this, aging of pixel cells (e.g., R, G, B, and/or W pixel cells) of a display may be tracked such that more aged pixel cells may be compensated for by reducing pixel values of one or more (e.g., each) other pixel cells of the display. As a result, the effect of burn-in or ghosting may be mitigated by tracking luminance degradation over time and compensating for the luminance degradation across some or all of the pixel cells of the display."
12206748,"A method includes receiving, using a processing device, a first condition associated with an operation at a data center, where the operation at the data center pertains to a first location at the data center, the first location corresponding to a first parameter value. The method further includes providing the first condition as an input to a machine learning model. The method also includes performing one or more reinforcement learning techniques using the machine learning model to cause the machine learning model to output an indication of a final location associated with the operation, where the final location corresponds to a final parameter value that is closer to a target than the first parameter value corresponding to the first location at the data center."
12206845,"In various examples, a deep neural network (DNN) based pre-filter for content streaming applications is used to dynamically adapt scene entropy (e.g., complexity) in response to changing network or system conditions of an end-user device. For example, where network and/or system performance issues or degradation are identified, the DNN may be implemented as a frame pre-filter to reduce the complexity or entropy of the frame prior to streaming—thereby allowing the frame to be streamed at a reduced bit rate without requiring a change in resolution. The DNN-based pre-filter may be tuned to maintain image detail along object, boundary, and/or surface edges such that scene navigation—such as by a user participating in an instance of an application—may be easier and more natural to the user."
12208732,"Systems and methods for a self-adjusting vehicle mirror. The mirror automatically locates the face of the driver or another passenger, and orients the mirror to provide the driver/passenger face with a desired view from the mirror. The mirror may continue to reorient itself as the driver or passenger shifts position, to continuously provide a desired field of view even as he or she changes position over time. In certain embodiments, the mirror system of the disclosure can be a self-contained system, with the mirror, mirror actuator, camera, and computing device all contained within the mirror housing as a single integrated unit."
12209881,"A semi-public blockchain maintained on one or more nodes in a map cloud platform comprises data for maintaining a global map of a predetermined geographic area. The blockchain also comprises a plurality of data records, where each data record is associated with an update to a global map. When a message associated with a map update to the global map is received, the nodes of the blockchain determine a consensus by evaluating the map update, where the evaluating comprises performing a plurality of proofs including a proof of location, a proof of iterations, a proof of physical delivery and a proof of safety. When consensus is attained and the map update is validated, a data record associated with the map update is generated and added to the blockchain with a timestamp and a link to prior data records in the blockchain."
12210770,"Systems, computer program products, and methods are described herein for automated data retrieval from an integrated circuit (IC). An example system receives an alert indicating a trigger event associated with the IC; extracts, using a scan island (e.g., a partition of the IC that is isolated for data retrieval), data from a plurality of scan chains and a plurality of random-access memories (RAMs) associated with the IC in response to receiving the alert; stores the data in an external non-volatile storage media; and reboots the IC upon storing the data in the external non-volatile storage media. In this way, embodiments of the present invention offer a scalable and secure method for real-time data extraction and processing in the event of an integrated circuit malfunction, improving diagnostics while ensuring cost-effectiveness and data security."
12210867,"Apparatuses, systems, and techniques for a compiled shader program caches in a cloud computing environment."
12210888,"The present disclosure relates to streaming individual application windows and/or other desktop elements of a remote desktop. Data used to represent irrelevant desktop areas may be replaced with lower entropy data that may be highly compressed in a video stream and/or with data representative of other visual content. The video stream may also include desktop metadata (e.g., locations for desktop visuals, etc.) used to render the desktop elements on the local desktop. The desktop visuals of an application window may be rendered in a proxy window on the local desktop."
12211005,"A cloud-centric platform is used for generating virtual three-dimensional (3D) content, that allows users to collaborate online and that can be connected to different software tools (applications). Using the platform, virtual environments (e.g., scenes, worlds, universes) can be created, accessed, and interacted with simultaneously by multiple collaborative content creators using varying content creation or development applications."
12211080,One embodiment sets forth a technique for performing matrix operations. The technique includes traversing a tree structure to access one or more non-empty regions within a matrix. The tree structure includes a first plurality of nodes and a second plurality of nodes corresponding to non-empty regions in the matrix. The first plurality of nodes includes a first node representing a first region and one or more second nodes that are children of the first node and represent second region(s) with an equal size formed within the first region. The second plurality of nodes include a third node representing a third region and one or more fourth nodes that are children of the third node and represent fourth region(s) with substantially equal numbers of non-zero matrix values formed within the third region. The technique also includes performing matrix operation(s) based on the non-empty region(s) to generate a matrix operation result.
12211216,"Disclosed are apparatuses, systems, and techniques that may perform efficient deployment of machine learning for detection and classification of moving objects in streams of images. A set of machine learning models with different input sizes may be used for parallel processing of various regions of interest in multiple streams of images. Both the machine learning models as well as the inputs into these models may be selected dynamically based on a size of the regions of interest."
12211236,"Disclosed are apparatuses, systems, and techniques to render images depicting light interacting with media that have volume attenuation, using optimized spectral rendering that emulates rendering of the media in tristimulus color rendering schemes."
12211308,"Interactions with virtual systems may be difficult when users inadvertently fail to provide sufficient information to proceed with their requests. Certain types of inputs, such as auditory inputs, may lack sufficient information to properly provide a response to the user. Additional information, such as image data, may enable user gestures or poses to supplement the auditory inputs to enable response generation without requesting additional information from users."
12211609,"Apparatuses, systems, and techniques are presented to generate ultrasound images. In at least one embodiment, use one or more neural networks are used to generate one or more ultrasound images of one or more objects based, at least in part, upon one or more acoustic properties of the one or more objects."
12212480,"In various examples, latency of human interface devices (HIDs) may be accounted for in determining an end-to-end latency of a system. For example, when an input is received at an HID, an amount of time for the input to reach a connected device may be computed by the HID and included in a data packet transmitted by the HID device to the connected device. The addition of the peripheral latency to the end-to-end latency determination may provide a more comprehensive latency result for the system and, where the peripheral latency of an HID is determined to have a non-negligible contribution to the end-to-end latency, a new HID component may be implemented, a configuration setting associated with the HID component may be updated, and/or other actions may be taken to reduce the contribution of the peripheral latency to the overall latency of the system."
12213281,"A cold plate that is configurable and for a datacenter liquid cooling system is disclosed. The cold plate includes a first section, a second section, and an intermediate layer, which is changeable and has first channels to enable flow of a coolant through the intermediate layer, and has second channels or at least one adapted second channel to concentrate the coolant or the flow of the coolant to at least one area within the configurable cold plate corresponding to at least a heat generating feature of an associated computing device."
12216608,"A controller device includes a memory storing instructions. An interface bus is coupled to sensors and configured to operate with a multi-target interface protocol. A processor is coupled to the memory and the interface bus. The processor broadcasts initialization data, according to the multi-target interface protocol, to the sensors. The processor generates, from the initialization data, using at least one cryptographic function, an authentication tag for each sensor. Each authentication tag is specific to a corresponding sensor of the sensors. The processor also unicasts, according to the multi-target interface protocol, each authentication tag to the corresponding sensor of the sensors."
12216969,"Apparatuses, systems, and techniques apply to a force-based (e.g., primal) formulation for object simulation. In at least one embodiment, updates to the force-based formulation is determined by solving for constraints that are to be satisfied when simulating rigid bodies (e.g., contact rich scenarios)."
12217002,"Apparatuses, systems, and techniques to parse textual data using parallel computing devices. In at least one embodiment, text is parsed by a plurality of parallel processing units using a finite state machine and logical stack to convert the text to a tree data structure. Data is extracted from the tree by the plurality of parallel processors and stored."
12217151,A graph neural network to predict net parasitics and device parameters by transforming circuit schematics into heterogeneous graphs and performing predictions on the graphs. The system may achieve an improved prediction rate and reduce simulation errors.
12217326,"Apparatuses, systems, and techniques for buffer identification of an application for post-processing. The apparatuses, systems, and techniques includes generating a buffer statistic data structure for a buffer of a plurality of buffers associated with a frame of an application; updating the buffer statistic data structure with metadata of the draw call responsive to detecting a draw call to the buffer; and determining, based on the buffer statistic data structure, a score reflecting a likelihood of the buffer being associated with a specified buffer type."
12217331,"Disclosed are apparatuses, systems, and techniques that enable compressed grid-based graph representations for efficient implementations of graph-mapped computing applications. The techniques include but are not limited to selecting a reference grid having a plurality of blocks, assigning nodes of the graph to blocks of the grid, and generating a graph representation that maps directions, relative to the reference grid, of nodal connections of the graph."
12217386,"Apparatuses, systems, and techniques are presented to generate images. In at least one embodiment, at least a first optical flow network (OFN) and at least a first reconstruction network (RN) can be used to generate one or more images based, at least in part, upon the OFN and the RN using a shared loss function."
12219057,"Apparatuses, systems, and techniques to generate a trusted execution environment including multiple accelerators. In at least one embodiment, a parallel processing unit (PPU), such as a graphics processing unit (GPU), operates in a secure execution mode including a protect memory region. Furthermore, in an embodiment, a cryptographic key is utilized to protect data during transmission between the accelerators."
12219173,"In various examples, the decoding and upscaling capabilities of a client device are analyzed to determine encoding parameters and operations used by a content streaming server to generate encoded video streams. The quality of the upscaled content of the client device may be monitored by the streaming servers such that the encoding parameters may be updated based on the monitored quality. In this way, the encoding operations of one or more streaming servers may be more effectively matched to the decoding and upscaling abilities of one or more client devise such that an increased number of client devices may be served by the streaming servers."
12219301,"Apparatuses, systems, and techniques to receive, at one or more processors associated with an image signal processing (ISP) pipeline for a camera, an image generated using an image sensor of the camera, wherein the image comprises a plurality of channels associated with color information of the image; process, by the one or more processors, the plurality of channels of the image to generate a plurality of luminance and/or radiance values; generate, by the one or more processors, an updated version of the image using the plurality of luminance and/or radiance values; and output the updated version of the image."
12219691,A printed circuit board assembly comprises: a printed circuit board (PCB); an integrated circuit (IC) package that is mounted on the PCB and includes a first surface and a bare IC die disposed on the first surface; and a vapor chamber coupled to the first surface of the IC package.
12222820,A storage platform (100) improves data flow when modifying mirrored volumes. A backup storage component (120 A) that receives a service request keeps a copy of change data when redirecting the service request to a primary storage component (120B) that owns the volume that the service request targets. The primary storage (120B) component does not need to return the change data to the backup storage component (120A) when the primary storage component (120B) instructs the backup storage component (120 A) to apply the modification request to the backup copy of the volume.
12223201,"A hierarchical network enables access for a stacked memory system including or more memory dies that each include multiple memory tiles. The processor die includes multiple processing tiles that are stacked with the one or more memory die. The memory tiles that are vertically aligned with a processing tile are directly coupled to the processing tile and comprise the local memory block for the processing tile. The hierarchical network provides access paths for each processing tile to access the processing tile's local memory block, the local memory block coupled to a different processing tile within the same processing die, memory tiles in a different die stack, and memory tiles in a different device. The ratio of memory bandwidth (byte) to floating-point operation (B:F) may improve 50× for accessing the local memory block compared with conventional memory. Additionally, the energy consumed to transfer each bit may be reduced by 10×."
12223303,"Apparatuses, systems, and methods for verifying fingerprints associated with components to be installed on printed circuit boards (PCBs). In at least one embodiment, one or more processors determine whether a component fingerprint associated with a component to be installed on the PCB corresponds to an expected fingerprint, the component fingerprint based, at least in part, on a firmware version associated with the component."
12223429,"In various examples, a two-dimensional (2D) and three-dimensional (3D) deep neural network (DNN) is implemented to fuse 2D and 3D object detection results for classifying objects. For example, regions of interest (ROIs) and/or bounding shapes corresponding thereto may be determined using one or more region proposal networks (RPNs)—such as an image-based RPN and/or a depth-based RPN. Each ROI may be extended into a frustum in 3D world-space, and a point cloud may be filtered to include only points from within the frustum. The remaining points may be voxelated to generate a volume in 3D world space, and the volume may be applied to a 3D DNN to generate one or more vectors. The one or more vectors, in addition to one or more additional vectors generated using a 2D DNN processing image data, may be applied to a classifier network to generate a classification for an object."
12223593,"A high-definition map system receives sensor data from vehicles travelling along routes and combines the data to generate a high definition map for use in driving vehicles, for example, for guiding autonomous vehicles. A pose graph is built from the collected data, each pose representing location and orientation of a vehicle. The pose graph is optimized to minimize constraints between poses. Points associated with surface are assigned a confidence measure determined using a measure of hardness/softness of the surface. A machine-learning-based result filter detects bad alignment results and prevents them from being entered in the subsequent global pose optimization. The alignment framework is parallelizable for execution using a parallel/distributed architecture. Alignment hot spots are detected for further verification and improvement. The system supports incremental updates, thereby allowing refinements of sub-graphs for incrementally improving the high-definition map for keeping it up to date."
12223949,"A robotic system is provided for performing rearrangement tasks guided by a natural language instruction. The system can include a number of neural networks used to determine a selected rearrangement of the objects in accordance with the natural language instruction. A target object predictor network processes a point cloud of the scene and the natural language instruction to identify a set of query objects that are to-be-rearranged. A language conditioned prior network processes the point cloud, natural language instruction, and the set of query objects to sample a distribution of rearrangements to generate a number of sets of pose offsets for the set of query objects. A discriminator network then processes the samples to generate scores for the samples. The samples may be refined until a score for at least one of the sample generated by the discriminator network is above a threshold value."
12225665,A circuit system and method of manufacturing a printed circuit board includes providing an integrated circuit package mounted on a first side of a printed circuit board and a power regulator connected to power terminals of the integrated circuit package through a cutout in the printed circuit board. The power regulator draws power from the printed circuit board by way of side pins around a periphery of the cutout.
12229566,"Apparatuses, systems, and techniques to execute one or more application programming interfaces (APIs) to perform one or more operations for one or more accelerators within a heterogeneous processor. In at least one embodiment, one or more processors are to perform one or more instructions in response to one or more APIs to indicate one or more functions to be performed in response to one or more errors from one or more accelerators within a heterogeneous processor."
12229869,"One embodiment of a method rendering one or more graphics images includes tracing a ray cone through a three-dimensional (3D) graphics scene, generating a refracted ray cone based on the ray cone and a two-dimensional (2D) coordinate frame, and rendering a graphics image based on the refracted ray cone."
12229970,"In examples, when attempting to interpolate or extrapolate a frame based on motion vectors of two adjacent frames, there can be more than one pixel value mapped to a given location in the frame. To select between conflicting pixel values for the given location, similarities between the motion vectors of source pixels that cause the conflict and global flow may be evaluated. For example, a level of similarity for a motion vector may be computed using a similarity metric based at least on a difference between an angle of a global motion vector and an angle of the motion vector. The similarity metric may also be based at least on a difference between a magnitude of the global motion vector and a magnitude of the motion vector. The similarity metric may weigh the difference between the angles in proportion to the magnitude of the global motion vector."
12230040,"State information can be determined for a subject that is robust to different inputs or conditions. For drowsiness, facial landmarks can be determined from captured image data and used to determine a set of blink parameters. These parameters can be used, such as with a temporal network, to estimate a state (e.g., drowsiness) of the subject. To improve robustness, an eye state determination network can determine eye state from the image data, without reliance on intermediate landmarks, that can be used, such as with another temporal network, to estimate the state of the subject. A weighted combination of these values can be used to determine an overall state of the subject. To improve accuracy, individual behavior patterns and context information can be utilized to account for variations in the data due to subject variation or current context rather than changes in state."
12230245,"Systems and methods provide for text normalization or inverse text normalization using a hybrid language system that combines rule-based processing with neural or learned processing. For example, a hybrid rule-based and neural approach identifies semiotic tokens within a textual input and generates a set of potential plain-text conversions of the semiotic tokens. The plain-text conversions are weighted and evaluated by a trained language model that rescores the plain-text conversion based on context to identify a highest scoring plain-text conversion for further processing within a language system pipeline."
12231133,"A time-to-digital converter (TDC) circuit includes self-referenced delay cell circuits each including: a first inverter coupled with a second inverter, the first inverter receiving a positive time signal representative of an incoming up signal; a third inverter coupled with a fourth inverter, the third inverter receiving a negative time signal representative of an incoming down signal; a first bank of capacitors coupled to a first node between the first/second inverters; and a second bank of capacitors coupled to a second node between the third/fourth inverters. Control logic generates first control signals, each with an up value, to selectively control the first bank of capacitors. Control logic generates second control signals, each with a down value, to selectively control the second bank of capacitors. The up values vary relative to the down values across the first control signals and the second control signals."
12233854,"In various examples, perception-based parking assistance systems and methods for an ego-machine are presented. Example embodiments may determine a location of a real-world parking strip relative to an ego-machine and an associated parking rule for the parking strip. A virtual parking strip and one or more virtual parking signs may be generated based at least in part on one or more detected features in an environment of the ego-machine and a tracked motion of the ego machine, and the virtual parking strip may be used to track parking strip locations and associated parking rules. The virtual parking strips and associated rules may be relied upon by an ego-machine to determine parking locations and/or to navigate into a suitable parking spot."
12235353,"In various examples, a hazard detection system fuses outputs from multiple sensors over time to determine a probability that a stationary object or hazard exists at a location. The system may then use sensor data to calculate a detection bounding shape for detected objects and, using the bounding shape, may generate a set of particles, each including a confidence value that an object exists at a corresponding location. The system may then capture additional sensor data by one or more sensors of the ego-machine that are different from those used to capture the first sensor data. To improve the accuracy of the confidences of the particles, the system may determine a correspondence between the first sensor data and the additional sensor data (e.g., depth sensor data), which may be used to filter out a portion of the particles and improve the depth predictions corresponding to the object."
12235673,"Apparatuses, systems, and techniques including APIs to enable one or more fifth generation new radio (5G-NR) network components to write, read, send, transmit, load, or otherwise obtain packaging, synchronization, and/or management information. For example, a processor comprising one or more circuits to perform an application programming interface (API) to cause fifth generation new radio (5G-NR) packaging, synchronization, or management information to be indicated to one or more accelerators."
12235765,"Various embodiments include techniques for storing data in a repurposed cache memory in a computing system. The disclosed techniques include a system level cache controller that processes a memory operation for a processing unit. The controller and the processing unit communicate over a network-on-chip. To process the memory operation, the controller selects a repurposed cache memory from a pool of active cache memories associated with processing units that are inoperable and/or are in a low-power state. To select the repurposed cache memory, the controller generates a candidate vector that identifies the position of the requesting processing unit relative to the controller. The candidate vector enables the controller in selecting a repurposed cache memory that is, for example, on the shortest path between the processing unit and the controller. These techniques result in a lower latency, and improved memory performance, relative to prior conventional techniques."
12236204,"In various examples, a technique for slot filling includes receiving a natural language sentence from a user and identifying a first mention span included in the natural language sentence. The technique also includes determining, using a first machine learning model, that the first mention span is associated with a first slot class included in a set of slot classes based on a set of slot class descriptions corresponding to the set of slot classes."
12236218,"In various examples, techniques for performing software code verification are described. Systems and methods are disclosed for generating, using intermediate code and user input, a call graph that represents source code for software. For instance, the call graph represents at least functions (e.g., internal functions, external functions, etc.) associated with the software, calls (e.g., direct calls, call pointers, etc.) between the functions, and register information associated with the functions (e.g., variables used by the functions, assembly code used by the functions, etc.). The systems and methods may further use the call graph to perform software code verification by verifying rules from design specifications for the software and/or rules from various certification standards."
12236351,"Apparatuses, systems, and techniques are described to determine locations of objects using images including digital representations of those objects. In at least one embodiment, a gaze of one or more occupants of a vehicle is determined independently of a location of one or more sensors used to detect those occupants."
12236564,"In various examples, apparatuses, systems, and techniques to perform offline image signal processing of source image data to generate target image data. In at least one embodiment, data collection using exposure and calibration setting of an image sensor is performed to generate source image data, which is then processed by using offline image signal processing to generate target data."
12237878,"The disclosure provides a signaling link that overcomes or at least reduces the limitations of RC-dominated signaling wires, improving both the bandwidth and the power consumption of signaling circuits. Both an AC and a DC signaling link are disclosed. In one example, a signaling link is provided that includes: (1) a transmitter including a passive equalizer, (2) an over-terminated receiver, and (3) a lossy channel having a first end connected to the passive equalizer and a second end connected to the receiver, wherein the lossy channel has a channel characteristic impedance that is lower than a terminating impedance of the passive equalizer and a termination impedance of the receiver."
12238271,"In one embodiment, a system receives pixel data from a pair of regions of an image generated by an imaging device, the pair of regions includes a first region and a second region, where the first region includes a first plurality of pixels and the second region includes a second plurality of pixels. The system determines a plurality of pixel pairs, where a pixel pair includes a first pixel from the first plurality of pixels and a second pixel from the second plurality of pixels. The system calculates a plurality of contrasts based on the plurality of pixel pairs. The system determines a contrast distribution based on the plurality of contrasts. The system calculates a value representative of a capability of the imaging device to detect contrast based on the contrast distribution. The system determines a reduction in contrast detectability of the imaging device based on the value."
12238335,"Disclosed are systems and techniques for efficient real-time codec encoding of video files. In one embodiment, the techniques include obtaining a first plurality of motion vectors of a first resolution, generating a second plurality of motion vectors of a second resolution, and calculating a first cost of the motion vector using a first cost function of a first size. The techniques include selecting a subset of motion vectors of the second plurality of motion vectors, calculating a second cost using a second cost function of a second size, and generating a plurality of combined motion vectors based on the subset of motion vectors. The techniques include calculating a third cost using the second cost function of the second size, selecting a final motion vector, and generating, based on the selected final motion vector, a block of predicted pixels that approximates a block of source pixels of an image frame."
12238895,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a cold plate includes an evaporator to remove heat from at least one computing device using a two-phase fluid and using a buffer to perform flow stabilization represented by different volumes or different flow rates of a two-phase fluid that is enabled to flow between an evaporator and a condensing or compressor unit located external to a cold plate."
12240112,"Apparatuses, systems, and techniques provide a policy that can be executed to cause a machine to move. In at least one embodiment, a first policy layer is provided to cause the machine to execute a first motion that causes the machine to accelerate to reach an unbiased state. A second policy layer is provided to cause the machine to execute a second motion without influencing the unbiased state to be reached by machine. The policy can comprise the first and second policy layers."
12243118,"Apparatuses, systems, and techniques to indicate contextual information to be used by available logical processors. In at least one embodiment, one or more circuits are to perform an application programming interface (API) to indicate a first set of contextual information to be used by a first subset of available processors."
12243152,"In various examples, information may be received for a 3D model, such as 3D geometry information, lighting information, and material information. A machine learning model may be trained to disentangle the 3D geometry information, the lighting information, and/or material information from input data to provide the information, which may be used to project geometry of the 3D model onto an image plane to generate a mapping between pixels and portions of the 3D model. Rasterization may then use the mapping to determine which pixels are covered and in what manner, by the geometry. The mapping may also be used to compute radiance for points corresponding to the one or more 3D models using light transport simulation. Disclosed approaches may be used in various applications, such as image editing, 3D model editing, synthetic data generation, and/or data set augmentation."
12243501,"In various examples, computing system display settings may be configured automatically based at least on display illumination patterns. For example, a system(s) may determine one or more locations of one or more displays associated with a computing device based at least on image data depicting a user of the computing device. In some instances, the image data may be captured during a period of time in which the display(s) may be operating at one or more respective frequencies. During this period of time, the system(s) may cause the display(s) to operate at the respective frequency(ies), and the image data may depict one or more reflections of the display(s) off one or more portions of the user. The system(s) may then determine the location(s) of the display(s) based at least on correlating one or more frequencies associated with the reflection(s) to the respective frequency(ies) of the displays."
12244938,"Apparatuses, systems, and techniques for white balancing an image are presented. In at least one embodiment, a chromaticity-based weighting function is determined based at least on an estimated scene brightness of the image and applied to exclude or minimize the impact of large colored portions or objects within an image when estimating an illuminant color."
12245360,"A power arrangement and cooling system for electronic devices includes a processing unit electrically interconnected and disposed to a first side of a printed circuit board and a power converter electrically interconnected and disposed on a second side of the printed circuit board. The power converter includes a thermally conductive material layer that transfers heat generated by the power converter during operation away from the power converter toward a heatsink that is disposed adjacent the second side of the printed circuit board. Heat generated by the processing unit is absorbed by a heatsink disposed adjacent the first side of the printed circuit board. Power for the processing unit is provided, by the power converter, through a thickness of the printed circuit board."
12245405,"A system comprising an adapter plate to couple a plurality of different types of cooling manifolds to one or more racks in a datacenter is disclosed. Additionally, a system comprising an adapter plate to adaptively couple a cooling manifold to a plurality of different types of server racks is disclosed."
12246718,"Embodiments of the present disclosure relate to encoding of junction area information in map data. In particular, the encoding may include organizing vehicle paths that traverse through a junction area according to path groups and organizing contentions that influence behavior of vehicles traveling along the vehicle paths according to contention groups. In addition, the encoding may include generating direction data structures that associate respective path groups with one or more of the contention groups. In these or other embodiments, the map data that corresponds to the junction area may be updated with direction data structures."
12248203,"In an embodiment, a modular augmented reality display is provided that incorporates prescription eyewear that can be used separately by the wearer. In an embodiment, an image is generated from a removable display attached to the eyewear and directed into the edge of a prescription lens, which acts as a waveguide. The image is internally reflected within the prescription lens, and is directed to the wearer by an image combiner embedded within the prescription lens. In an embodiment, the augmented reality display includes a wearable belt pouch that includes a battery and support electronics connected to the eyewear so that the weight on the eyewear is reduced."
12248319,"In various examples, systems and methods are disclosed that preserve rich spatial information from an input resolution of a machine learning model to regress on lines in an input image. The machine learning model may be trained to predict, in deployment, distances for each pixel of the input image at an input resolution to a line pixel determined to correspond to a line in the input image. The machine learning model may further be trained to predict angles and label classes of the line. An embedding algorithm may be used to train the machine learning model to predict clusters of line pixels that each correspond to a respective line in the input image. In deployment, the predictions of the machine learning model may be used as an aid for understanding the surrounding environment—e.g., for updating a world model—in a variety of autonomous machine applications."
12248392,"In various examples, a diagnostic circuit is connected to a target system to automatically trigger the target system to enter a diagnostic mode. The diagnostic circuit receives diagnostic data from the target system when the target system performs a diagnostic operation in the diagnostic mode."
12248788,"Distributed shared memory (DSMEM) comprises blocks of memory that are distributed or scattered across a processor (such as a GPU). Threads executing on a processing core local to one memory block are able to access a memory block local to a different processing core. In one embodiment, shared access to these DSMEM allocations distributed across a collection of processing cores is implemented by communications between the processing cores. Such distributed shared memory provides very low latency memory access for processing cores located in proximity to the memory blocks, and also provides a way for more distant processing cores to also access the memory blocks in a manner and using interconnects that do not interfere with the processing cores' access to main or global memory such as hacked by an L2 cache. Such distributed shared memory supports cooperative parallelism and strong scaling across multiple processing cores by permitting data sharing and communications previously possible only within the same processing core."
12248881,"According to an aspect of an embodiment, a method may include obtaining multiple sets of camera images and light detection and ranging (LIDAR) point clouds along a track within a geographic sector of a map. The method may include applying a learning model to the camera images to characterize objects within the camera images within classes of objects to generate segmented images. The method may additionally include mapping the sets of camera images and the LIDAR point clouds to three dimensional points of the geographic sector of the map. The method may also include projecting the three dimensional points onto the segmented images to obtain corresponding classes for the three dimensional points of the geographic sector of the map."
12249022,"A Displaced Micro-mesh (DMM) primitive enables high complexity geometry for ray and path tracing while minimizing the associated builder costs and preserving high efficiency. A structured, hierarchical representation implicitly encodes vertex positions of a triangle micro-mesh based on a barycentric grid, and enables microvertex displacements to be encoded efficiently (e.g., as scalars linearly interpolated between minimum and maximum triangle surfaces). The resulting displaced micro-mesh primitive provides a highly compressed representation of a potentially vast number of displaced microtriangles that can be stored in a small amount of space. Improvements in ray tracing hardware permit automatic processing of such primitive for ray-geometry intersection testing by ray tracing circuits without requiring intermediate reporting to a shader."
12249048,One embodiment of the present invention sets forth a technique for generating data. The technique includes sampling from a first distribution associated with the score-based generative model to generate a first set of values. The technique also includes performing one or more denoising operations via the score-based generative model to convert the first set of values into a first set of latent variable values associated with a latent space. The technique further includes converting the first set of latent variable values into a generative output.
12249163,"In various examples, object fence corresponding to objects detected by an ego-vehicle may be used to determine overlap of the object fences with lanes on a driving surface. A lane mask may be generated corresponding to the lanes on the driving surface, and the object fences may be compared to the lanes of the lane mask to determine the overlap. Where an object fence is located in more than one lane, a boundary scoring approach may be used to determine a ratio of overlap of the boundary fence, and thus the object, with each of the lanes. The overlap with one or more lanes for each object may be used to determine lane assignments for the objects, and the lane assignments may be used by the ego-vehicle to determine a path or trajectory along the driving surface."
12249589,"Apparatus for flattening a warped ball grid array (BGA) package, including a first plate having a first surface and opposite second surface and a second plate having a first surface and opposite second surface. The first surface of the first plate and the first surface of the second plate oppose each other with a gap there-between. The gap houses the warped BGA package there-in, the warped BGA package including a package substrate with solder balls attached to a device mounting surface of the package substrate to form a BGA thereon. The gap adjustable by changing the position of the first plate or of the second plate such that a pushing force is applicable to the warped BGA package. A method of manufacturing a flattened BGA package and computer having a circuit that include the flatted BGA package are also disclosed."
12249619,"An integrated circuit including a chip substrate having an upper isolation layer with a pad thereon and a coil located below the pad, where, in a dimension perpendicular to a surface of the chip substrate, a perimeter of the coil overlaps with a perimeter of the pad."
12254410,"A method and system are disclosed for training a model that implements a machine-learning algorithm. The technique utilizes latent descriptor vectors to change a multiple-valued output problem into a single-valued output problem and includes the steps of receiving a set of training data, processing, by a model, the set of training data to generate a set of output vectors, and adjusting a set of model parameters and component values for at least one latent descriptor vector in the plurality of latent descriptor vectors based on the set of output vectors. The set of training data includes a plurality of input vectors and a plurality of desired output vectors, and each input vector in the plurality of input vectors is associated with a particular latent descriptor vector in a plurality of latent descriptor vectors. Each latent descriptor vector comprises a plurality of scalar values that are initialized prior to training the model."
12254554,"Embodiments of the present disclosure are directed to apparatuses, systems, and techniques of offloading shader program compilation at a computing system. A detection is made that a set of shader programs are to be compiled for an application executing at a computing system using a first set of processing devices. A second set of processing devices to compile the set of shader programs is identified. Each of the second set of processing devices is different from any processing device of the first set of processing devices. The set of shader programs is provided for compilation using the second set of processing devices in view of state data associated with the computing system to obtain a set of complied shader programs. The set of compiled shader programs is executed using the first set of processing devices."
12254556,"One embodiment of a method for rendering one or more graphics images includes tracing one or more rays through a graphics scene; computing one or more surface normals associated with intersections of the one or more rays with one or more surfaces, where computing each surface normal includes: computing a plurality of intermediate surface normals associated with a plurality of adjacent voxels of a grid, and interpolating the plurality of intermediate surface normals; and rendering one or more graphics images based on the one or more surface normals."
12255675,"A simultaneous bi-directional (SBD) transceiver includes a main transmit driver, a replica transmit driver, and a series-series-bridged (SSB) tri-impedance network. A pre-driver stage includes parallel delay paths for the main transmit driver and the replica transmit driver, enabling the delay for signals received by the main transmit driver and the replica transmit driver to be independently configured."
12255778,"Systems and methods are described for collecting configuration data associated with one or more devices of a network, in association with a configuration of the network. The systems and methods include validating the configuration of the network. Validating the configuration includes determining a stability status associated with the network and the configuration. The systems and methods include generating a data record corresponding to the configuration of the network and storing the data record to a data repository. The data record includes the configuration data and results associated with validating the configuration of the network. The systems and methods include generating a second configuration and simulating the second network based on the second configuration. The second configuration includes the one or more devices, one or more second devices included in the data repository, or both."
12260017,"Machine learning systems and methods that determine gaze direction by using face orientation information, such as facial landmarks, to modify eye direction information determined from images of the subject's eyes. System inputs include eye crops of the eyes of the subject, as well as face orientation information such as facial landmarks of the subject's face in the input image. Facial orientation information, or facial landmark information, is used to determine a coarse prediction of gaze direction as well as to learn a context vector of features describing subject face pose. The context vector is then used to adaptively re-weight the eye direction features determined from the eye crops. The re-weighted features are then combined with the coarse gaze prediction to determine gaze direction."
12260486,"A Displaced Micro-mesh (DMM) primitive enables high complexity geometry for ray and path tracing while minimizing the associated builder costs and preserving high efficiency. A structured, hierarchical representation implicitly encodes vertex positions of a triangle micro-mesh based on a barycentric grid, and enables microvertex displacements to be encoded efficiently (e.g., as scalars linearly interpolated between minimum and maximum triangle surfaces). The resulting displaced micro-mesh primitive provides a highly compressed representation of a potentially vast number of displaced microtriangles that can be stored in a small amount of space. Improvements in ray tracing hardware permit automatic processing of such primitive for ray-geometry intersection testing by ray tracing circuits without requiring intermediate reporting to a shader."
12260574,"Operations may comprise obtaining a plurality of light detection and ranging (LIDAR) scans of a region. The operations may also comprise identifying a plurality of LIDAR poses that correspond to the plurality of LIDAR scans. In addition, the operations may comprise identifying, as a plurality of keyframes, a plurality of images of the region that are captured during capturing of the plurality of LIDAR scans. The operations may also comprise determining, based on the plurality of LIDAR poses, a plurality of camera poses that correspond to the keyframes. Further, the operations may comprise identifying a plurality of two-dimensional (2D) keypoints in the keyframes. The operations also may comprise generating one or more three-dimensional (3D) keypoints based on the plurality of 2D keypoints and the respective camera poses of the plurality of keyframes."
12263403,"In various examples, potentially highlight-worthy video clips are identified from a gameplay session that a gamer might then selectively share or store for later viewing. The video clips may be identified in an unsupervised manner based on analyzing game data for durations of predicted interest. A classification model may be trained in an unsupervised manner to classify those video clips without requiring manual labeling of game-specific image or audio data. The gamer can select the video clips as highlights (e.g., to share on social media, store in a highlight reel, etc.). The classification model may be updated and improved based on new video clips, such as by creating new video-clip classes."
12265416,"Circuitry and a method of operating a clock monitoring circuit for monitoring a clock signal is disclosed. The method comprises charging a first capacitor connected to a connection between a first pair of transistors and a voltage reference, charging a second capacitor connected to a connection between a second pair of transistors and to the voltage reference, sinking a current from the first and second pair of transistors with a constant current sink, and asserting a clock slow detect (CSD) signal when a voltage at the constant current sink drops below a threshold indicating durations of phases of the clock signal lengthen."
12265463,"One or more embodiments relate to executing a software testing tool to identify function calls—internal and/or external—of software code and their corresponding errors. Once identified-such as during an information gathering operation-the error codes may be returned in place of actual outputs of the function during testing, and the downstream processing of the software as a result of the errors may be evaluated. As such, an automatic software testing tool may be implemented that not only identifies functions calls and corresponding errors, but also evaluates performance of the software in view of the various different error types associated with the function calls."
12266144,"Apparatuses, systems, and techniques to identify orientations of objects within images. In at least one embodiment, one or more neural networks are trained to identify an orientations of one or more objects based, at least in part, on one or more characteristics of the object other than the object's orientation."
12266148,"In various examples, sensor data representative of an image of a field of view of a vehicle sensor may be received and the sensor data may be applied to a machine learning model. The machine learning model may compute a segmentation mask representative of portions of the image corresponding to lane markings of the driving surface of the vehicle. Analysis of the segmentation mask may be performed to determine lane marking types, and lane boundaries may be generated by performing curve fitting on the lane markings corresponding to each of the lane marking types. The data representative of the lane boundaries may then be sent to a component of the vehicle for use in navigating the vehicle through the driving surface."
12266350,"Systems and methods are directed toward evaluating auditory inputs against a range of tolerance to provide feedback regarding pronunciation. An auditory input may be evaluated using a trained machine learning system and evaluated for similarity against a target word. Similarity may be scored and then evaluated to determine whether the similarity falls within a range of tolerance, wherein the range of tolerance may be adjusted or modified for particular uses. A score within the range of tolerance is indicative of a word that has been pronounced such that it would be perceptible."
12267210,"Technologies for optimizing post-FEC bit error rate performance of a Forward Error Correction (FEC) system are described. A controller is coupled to an FEC circuit and a receiver circuit. The controller receives FEC symbol error data from the FEC circuit and determines, using the FEC symbol error data, a post-FEC correlated performance metric indicative of an estimated post-FEC BER of the FEC circuit. The controller adjusts, based on the post-FEC correlated performance metric, at least one of a FEC parameter of the FEC circuit or a link parameter of the receiver circuit to decrease the estimated post-FEC BER. This improves the post-FEC BER performance of the FEC circuit."
12269488,"In various examples, an end-to-end perception evaluation system for autonomous and semi-autonomous machine applications may be implemented to evaluate how the accuracy or precision of outputs of machine learning models—such as deep neural networks (DNNs)—impact downstream performance of the machine when relied upon. For example, decisions computed by the system using ground truth output types may be compared to decisions computed by the system using the perception outputs. As a result, discrepancies in downstream decision making of the system between the ground truth information and the perception information may be evaluated to either aid in updating or retraining of the machine learning model or aid in generating more accurate or precise ground truth information."
12271194,"In various examples, motifs, watermarks, and/or signature inputs are applied to a deep neural network (DNN) to detect faults in underlying hardware and/or software executing the DNN. Information corresponding to the motifs, watermarks, and/or signatures may be compared to the outputs of the DNN generated using the motifs, watermarks and/or signatures. When a the accuracy of the predictions are below a threshold, or do not correspond to the expected predictions of the DNN, the hardware and/or software may be determined to have a fault—such as a transient, an intermittent, or a permanent fault. Where a fault is determined, portions of the system that rely on the computations of the DNN may be shut down, or redundant systems may be used in place of the primary system. Where no fault is determined, the computations of the DNN may be relied upon by the system."
12271676,"Embodiments of the present disclosure relate to parallel mask rule checking on evolving mask shapes in optical proximity correction (OPC) flows for integrated circuit designs. Systems and methods are disclosed that perform mask (manufacturing) rule checks (MRC) in parallel, sharing information to maintain symmetry when violations are corrected. In an embodiment the shared information is also used to minimize changes to the geometric area of proposed mask shapes resulting from the OPC. In contrast to conventional systems, MRC is performed for multiple edges in parallel, sharing information between the different edges to encourage symmetry. In an embodiment, all edges may be adjusted in parallel to reduce mask-edge traversal bias."
12271765,"Various embodiments include a parallel processing computer system that enables parallel instances of a program to synchronize at disparate addresses in memory. When the parallel program instances need to exchange data, the program instances synchronize based on a mask that identifies the program instances that are synchronizing. As each program instance reaches the point of synchronization, the program instance blocks and waits for all other program instances to reach the point of synchronization. When all program instances have reached the point of synchronization, at least one program instance executes a synchronous operation to exchange data. The program instances then continue execution at respective and disparate return addresses."
12272040,"Apparatuses, systems, and techniques to perform effective tone management for image data. In an embodiment, a set of contrast gain curves are generated corresponding to a set of tonal ranges of an input image. An output image may then be generated by at least applying corresponding contrast gain curves to tonal ranges of the input image."
12272148,"Approaches presented herein provide for semantic data matching, as may be useful for selecting data from a large unlabeled dataset to train a neural network. For an object detection use case, such a process can identify images within an unlabeled set even when an object of interest represents a relatively small portion of an image or there are many other objects in the image. A query image can be processed to extract image features or feature maps from only one or more regions of interest in that image, as may correspond to objects of interest. These features are compared with images in an unlabeled dataset, with similarity scores being calculated between the features of the region(s) of interest and individual images in the unlabeled set. One or more highest scored images can be selected as training images showing objects that are semantically similar to the object in the query image."
12272152,"In various examples, live perception from sensors of a vehicle may be leveraged to generate object tracking paths for the vehicle to facilitate navigational controls in real-time or near real-time. For example, a deep neural network (DNN) may be trained to compute various outputs—such as feature descriptor maps including feature descriptor vectors corresponding to objects included in a sensor(s) field of view. The outputs may be decoded and/or otherwise post-processed to reconstruct object tracking and to determine proposed or potential paths for navigating the vehicle."
12272385,"In various examples, users may access a tool that automatically generates video montages from video clips of the user's gameplay according to parameterized recipes. As a result, a user may select—or allow the system to select—clips corresponding to gameplay of the user and customize one or more parameters (e.g., transitions, music, audio, graphics, etc.) of a recipe, and a video montage may be generated automatically according to a montage script output using the recipe. As such, a user may have a video montage generated with little user involvement, and without requiring any skill or expertise in video editing software. In addition, even for experienced video editors, automatic video montage generation may be a useful alternative to save the time and effort of manually curating video montages."
12273220,"Apparatuses, systems, and techniques to perform signal processing operations in a fifth generation (“5G”) radio signal. In at least one embodiment, one or more processors equalize, in parallel, one or more 5G radio signals."
12273260,"Approaches in accordance with various illustrative embodiments provide for the management of active connections in a network environment. In particular, various embodiments implement keep alive functionality in components such as network processing units (NPUs) of network devices such as routers and switches, instead of host processors for those devices. When a status message is received, such as a hello message, the NPU can set or refresh a hit bit in a table entry for a given connection with a peer device. If a subsequent status message is not received within a keep alive interval of the last received status message, then the NPU can determine that the connection with the peer device is stale and can inform the host processor that the connection is no longer available for routing network traffic. The status messages are terminated in the NPU and prevented from being received and processed by the host processor."
12273632,"A method of compression includes compressing a captured image from a first bit-depth at which it was captured to a second bit-depth that is less than the first bit-depth. The compression comprises applying, according to a power curve, a first compression amount to a first region of the captured image having a first pixel value; and applying, according to the power curve, a second compression amount to a second part of the captured image having a higher second pixel value, wherein the first compression amount is lower than the second compression amount."
12275146,"A machine-learning control system is trained to perform a task using a simulation. The simulation is governed by parameters that, in various embodiments, are not precisely known. In an embodiment, the parameters are specified with an initial value and expected range. After training on the simulation, the machine-learning control system attempts to perform the task in the real world. In an embodiment, the results of the attempt are compared to the expected results of the simulation, and the parameters that govern the simulation are adjusted so that the simulated result matches the real-world attempt. In an embodiment, the machine-learning control system is retrained on the updated simulation. In an embodiment, as additional real-world attempts are made, the simulation parameters are refined and the control system is retrained until the simulation is accurate and the control system is able to successfully perform the task in the real world."
12277043,"A system can include a memory and a processing device, operatively coupled to the memory, to perform operations including receiving a header block of an ordered set of blocks. The header block includes a header block payload and a first digest. The operations further include authenticating, based on the header block payload, the header block, and receiving a first data block of the ordered set of blocks. The first data block includes a first data block payload and a second digest. The operations further include authenticating, based on the first digest, the first data block, and processing the first data block payload."
12277376,"To ensure proper operation (e.g., speed and/or function) of standard cells fabricated within an integrated circuit a minimum potential difference between the high and low power supply rails needs to be maintained. IR drop refers to a reduction in the potential difference between the power supply rails and is caused when the switching activity of cells that share a power supply rail is greater than can be provided at a particular time. Before fabrication, placement of the cells is reorganized within bounding box regions. Power density across the power rails within each bounding box is normalized based on spatial and temporal power density characteristics of each cell. The reorganization is IR aware and has minimal impact on timing and IR drop is mitigated because distributing current consumption between the supply rails reduces current spikes and IR drops."
12277406,"Traditionally, a software application is developed, tested, and then published for use by end users. Any subsequent update made to the software application is generally in the form of a human programmed modification made to the code in the software application itself, and further only becomes usable once tested, published, and installed by end users having the previous version of the software application. This typical software application lifecycle causes delays in not only generating improvements to software applications, but also to those improvements being made accessible to end users. To help avoid these delays and improve performance of software applications, deep learning models may be made accessible to the software applications for use in providing inferenced data to the software applications, which the software applications may then use as desired. These deep learning models can furthermore be improved independently of the software applications using manual and/or automated processes."
12279401,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, multiple parallel refrigerant paths are associated with one or more flow controllers to cool multiple computing devices associated therewith, so that one or more flow controllers can distribute equal measures of a liquid phase of refrigerant, relative to a vapor phase of a refrigerant, to such parallel refrigerant paths based in part on a cooling requirement from at least one of such multiple computing devices."
12282526,"Apparatuses, systems, and techniques to determine a matrix multiplication algorithm for a matrix multiplication operation. In at least one embodiment, a matrix multiplication operation is analyzed to determine an appropriate matrix multiplication algorithm to perform the matrix multiplication algorithm."
12282676,"A cluster storage system takes snapshots that are consistent across all storage nodes. The storage system can nearly instantaneously promote a set of consistent snapshots to their respective base volumes to restore the base volumes to be the same as the snapshots. Given these two capabilities, users can restore the system to a recovery point of the user's choice, by turning off storage service I/O, promoting the snapshots constituting the recovery point, rebooting their servers, and resuming storage service I/O."
12283028,"Apparatuses, systems, and techniques to generate blue noise masks for real-time image rendering and enhancement. In at least one embodiment, a noise mask is generated and applied to one or more images to generate one or more enhanced images for image processing (e.g., real-time image rendering). In at least one embodiment, the noise mask is able to handle the temporal domain (e.g., add time to the spatial domain) to improve image quality when rendering images over multiple frames."
12283187,"In various examples, audio alerts of emergency response vehicles may be detected and classified using audio captured by microphones of an autonomous or semi-autonomous machine in order to identify travel directions, locations, and/or types of emergency response vehicles in the environment. For example, a plurality of microphone arrays may be disposed on an autonomous or semi-autonomous machine and used to generate audio signals corresponding to sounds in the environment. These audio signals may be processed to determine a location and/or direction of travel of an emergency response vehicle (e.g., using triangulation). Additionally, to identify siren types—and thus emergency response vehicle types corresponding thereto—the audio signals may be used to generate representations of a frequency spectrum that may be processed using a deep neural network (DNN) that outputs probabilities of alert types being represented by the audio data."
12286115,"In various examples, a three-dimensional (3D) intersection structure may be predicted using a deep neural network (DNN) based on processing two-dimensional (2D) input data. To train the DNN to accurately predict 3D intersection structures from 2D inputs, the DNN may be trained using a first loss function that compares 3D outputs of the DNN—after conversion to 2D space—to 2D ground truth data and a second loss function that analyzes the 3D predictions of the DNN in view of one or more geometric constraints—e.g., geometric knowledge of intersections may be used to penalize predictions of the DNN that do not align with known intersection and/or road structure geometries. As such, live perception of an autonomous or semi-autonomous vehicle may be used by the DNN to detect 3D locations of intersection structures from 2D inputs."
12288098,"Approaches presented herein provide for the optimization of tasks performed for an operation such as the rendering of an image. A Frame Interceptor (FI) can generate a resource dependency graph (RDG) by intercepting API calls during the rendering process and determining dependencies. FI can analyze the RDG to identify potential optimizations, such as may correspond to reordering or parallel execution of certain tasks. FI can automatically test optimizations to determine whether sufficient improvement is obtained. This testing can be performed in real time by replacing the originally intercepted API calls with the newly ordered API calls generated by FI. FI can then issue a report that indicates information such as the changes made, the time taken to render the image, and potentially the fact that the images were determined to be identical."
12288277,"In various examples, high-precision semantic image editing for machine learning systems and applications are described. For example, a generative adversarial network (GAN) may be used to jointly model images and their semantic segmentations based on a same underlying latent code. Image editing may be achieved by using segmentation mask modifications (e.g., provided by a user, or otherwise) to optimize the latent code to be consistent with the updated segmentation, thus effectively changing the original, e.g., RGB image. To improve efficiency of the system, and to not require optimizations for each edit on each image, editing vectors may be learned in latent space that realize the edits, and that can be directly applied on other images with or without additional optimizations. As a result, a GAN in combination with the optimization approaches described herein may simultaneously allow for high precision editing in real-time with straightforward compositionality of multiple edits."
12288363,"In various examples, sensor configuration for autonomous or semi-autonomous systems and applications is described. Systems and methods are disclosed that may use image feature correspondences between camera images along with an assumption that image features are locally planar to determine parameters for calibrating an image sensor with a LiDAR sensor and/or another image sensor. In some examples, an optimization problem is constructed that attempts to minimize a geometric loss function, where the geometric loss function encodes the notion that corresponding image features are views of a same point on a locally planar surface (e.g., a surfel or mesh) that is constructed from LiDAR data generated using a LiDAR sensor. In some examples, performing such processes to determine the calibration parameters may remove structure estimation from the optimization problem."
12288403,"In various examples, estimated field of view or gaze information of a user may be projected external to a vehicle and compared to vehicle perception information corresponding to an environment outside of the vehicle. As a result, interior monitoring of a driver or occupant of the vehicle may be used to determine whether the driver or occupant has processed or seen certain object types, environmental conditions, or other information exterior to the vehicle. For a more holistic understanding of the state of the user, attentiveness and/or cognitive load of the user may be monitored to determine whether one or more actions should be taken. As a result, notifications, AEB system activations, and/or other actions may be determined based on a more complete state of the user as determined based on cognitive load, attentiveness, and/or a comparison between external perception of the vehicle and estimated perception of the user."
12288404,"A game-agnostic event detector can be used to automatically identify game events. Game-specific configuration data can be used to specify types of pre-processing to be performed on media for a game session, as well as types of detectors to be used to detect events for the game. Event data for detected events can be written to an event log in a form that is both human- and process-readable. The event data can be used for various purposes, such as to generate highlight videos or provide player performance feedback. The event data may be determined based upon output from detectors such as optical character recognition (OCR) engines, and the regions may be upscaled and binarized before OCR processing."
12288570,"Systems and methods of compressing video content as encoded data and selectively reconstructing portions of the content are disclosed. The proposed systems provide a computer-implemented process configured to classify a person's behavior(s) during a video and encode the behaviors as a representation of the video. When playback of the video is requested, a video navigation assistant will allow the end-user to select specific segments of the video based on topics discussed in the video and the codes that were generated to represent the video. The user is then able to move through segments of the video in a sequence that aligns with their viewing preferences."
12291219,Systems and methods are disclosed that relate to testing processing elements of an integrated processing system. A first system test may be performed on a first processing element of an integrated processing system. The first system test may be based at least on accessing a test node associated with the first processing element. The first system test may be accessed using a first local test controller. A second system test may be performed on a second processing element of the integrated processing system. The second system test may be based at least on accessing a second test node associated with the second processing element. The second system test may be accessed using a second local test controller.
12292495,"One or more embodiments of the present disclosure relate to generation of map data. In these or other embodiments, the generation of the map data may include determining whether objects indicated by the sensor data are static objects or dynamic objects. Additionally or alternatively, sensor data may be removed or included in the map data based on determinations as to whether it corresponds to static objects or dynamic objects."
12298825,"The disclosure provides a cooling solution that evaluates the thermal environment of a computer component based on transient thermal responses of the computer component. The transient thermal responses are generated by measuring the temperature rise of the computer component over a designated amount of time for multiple “good” assemblies and multiple “bad” assemblies to determine a duration and allowable temperature rise needed to set a pass/fail criteria for different failure modes of cooling devices. A cooling device may not be operating as designed due to damage, needed maintenance, missing thermal interface material (TIM), improper installation, etc. From the transient thermal responses, a thermal problem, such as a malfunctioning fan, can be determined and a corrective action can be performed."
12298845,"Various embodiments include a memory device that recovers from write errors and read errors more quickly relative to prior memory devices. Certain patterns of write data and read data may result on poor signal quality on the memory interface between memory controllers and memory devices. The disclosed memory device, synchronously with the memory controller, scrambles read data before transmitting the data to the memory controller and descrambles received from the memory controller. The scrambling and descrambling results in a different pattern on the memory interface even for the same read data or write data. Therefore, when a write operation or a read operation fails, and the operation is replayed, the pattern transmitted on the memory interface is different when the operation is replayed. As a result, the memory device more easily recovers from data patterns that cause poor signal quality on the memory interface."
12299454,Described approaches provide for effectively and scalably using multiple GPUs to build and probe hash tables and materialize results of probes. Random memory accesses by the GPUs to build and/or probe a hash table may be distributed across GPUs and executed concurrently using global location identifiers. A global location identifier may be computed from data of an entry and identify a global location for an insertion and/or probe using the entry. The global location identifier may be used by a GPU to determine whether to perform an insertion or probe using an entry and/or where the insertion or probe is to be performed. To coordinate GPUs in materializing results of probing a hash table a global offset to the global output buffer may be maintained in memory accessible to each of the GPUs or the GPUs may compute global offsets using an exclusive sum of the local output buffer sizes.
12299577,"Aspects of the present invention are directed to computer-implemented techniques for improving the training of artificial neural networks using a reduced precision (e.g., float16) data format. Embodiments of the present invention rescale tensor values prior to performing matrix operations (such as matrix multiplication or matrix addition) to prevent overflow and underflow. To preserve accuracy throughout the performance of the matrix operations, the scale factors are defined using a novel data format to represent tensors, wherein a matrix is represented by the tuple X, where X=(a, v[.]), wherein a is a float scale factor and v[.] are scaled values stored in the float16 format. The value of any element X[i] according to this data format would be equal to a*v[i]."
12299800,"One common robotic task is the rearrangement of physical objects situated in an environment. This typically involves a robot manipulator picking up a target object and placing the target object in some target location, such as a shelf, cabinet or cubby, and requires the skills of picking, placing and generating complex collision-free motions, oftentimes in a cluttered environment. The present disclosure provides collision detection for object rearrangement using a three-dimensional (3D) scene representation."
12299801,"Devices, systems, and techniques to incorporate lighting effects into computer-generated graphics. In at least one embodiment, a virtual scene comprising a plurality of lights is rendered by subdividing the virtual area and stored, in a record corresponding to a subdivision of the virtual area, information indicative of one or more lights in the virtual area selected based on a stochastic model. Pixels near a subdivision are rendered based on the light information stored in the subdivision."
12299855,"Approaches presented herein can reduce temporal lag that may be introduced in a generated image sequence that utilizes temporal accumulation for denoising in dynamic scenes. A fast historical frame can be generated along with a full historical frame generated for a denoising process, with the fast historical frame being accumulated using an exponential moving average with a significantly higher blend weight. This fast history frame can be used to determine a clamping window that can be used to clamp a corresponding full historical value before, or after, reprojection. The fast historical blend weight can be adjusted to control the amount of noise versus temporal lag in an image sequence. In some embodiments, differences between fast and full historical values can also be used to determine an amount of spatial filtering to be applied."
12299892,"In various examples, live perception from sensors of a vehicle may be leveraged to detect and classify intersection contention areas in an environment of a vehicle in real-time or near real-time. For example, a deep neural network (DNN) may be trained to compute outputs—such as signed distance functions—that may correspond to locations of boundaries delineating intersection contention areas. The signed distance functions may be decoded and/or post-processed to determine instance segmentation masks representing locations and classifications of intersection areas or regions. The locations of the intersections areas or regions may be generated in image-space and converted to world-space coordinates to aid an autonomous or semi-autonomous vehicle in navigating intersections according to rules of the road, traffic priority considerations, and/or the like."
12299962,"Systems and methods described relate to the synthesis of content using generative models. In at least one embodiment, a score-based generative model can use a stochastic differential equation with critically-damped Langevin diffusion to learn to synthesize content. During a forward diffusion process, noise can be introduced into a set of auxiliary (e.g., “velocity”) values for an input image to learn a score function. This score function can be used with the stochastic differential equation during a reverse diffusion denoising process to remove noise from the image to generate a reconstructed version of the input image. A score matching objective for the critically-damped Langevin diffusion process can require only the conditional distribution learned from the velocity data. A stochastic differential equation based integrator can then allow for efficient sampling from these critically-damped Langevin diffusion models."
12301623,"In various examples, communications having insecure protocols are dynamically hardened. For example, communications that are formatted in an outdated or otherwise insecure version of a protocol (e.g., sent by a device aged out of a service window) may be isolated within a network, converted to an updated protocol format, or any combination thereof. These systems and methods may be implemented on a general purpose network device (e.g., a hub of a Local Area Network (LAN))."
12301785,"Systems and methods of selectively compressing video data are disclosed. The proposed systems provide a computer-implemented process configured to classify a person's behavior(s) during a video and encode the behaviors as a representation of the video. The encoding will be tailor-generated based on the specific display configuration of the target device at which playback is expected to occur. Target device displays with lower resolution and video quality characteristics will trigger an encoding of the video data that has less complexity than target device displays with higher resolution and video quality characteristics. When playback of the video is requested at the target device, a reconstruction of the video is generated by a video synthesizer based on a reference image of the person and the encoding rather than the original video file, significantly reducing memory, processing, power, and bandwidth requirements."
12306220,"The disclosure provides a voltage detecting circuit that detects voltage increases and voltage decreases using a diode drop and voltage thresholds. The voltage detecting circuit, referred to as a voltage variation detector, uses the diode to maintain a differential between the voltage being monitored and a voltage threshold. When the diode is reversed bias, the voltage variation detector generates a detecting signal indicating the monitored voltage crossed the voltage threshold. In one example a voltage variation detector is disclosed that includes: (1) a transistor stack that corresponds to a voltage threshold, (2) a transistor diode, and (3) an inverter that receives an input signal and provides an detection signal that controls one or more gates of the transistor stack, wherein the transistor stack and the transistor diode provide the input signal and the detection signal indicates when the voltage crosses the voltage threshold."
12306298,"In various examples, techniques for sensor-fusion based object detection and/or free-space detection using ultrasonic sensors are described. Systems may receive sensor data generated using one or more types of sensors of a machine. In some examples, the systems may then process at least a portion of the sensor data to generate input data, where the input data represents one or more locations of one or more objects within an environment. The systems may then input at least a portion of the sensor data and/or at least a portion of the input data into one or more neural networks that are trained to output one or more maps or other output representations associated with the environment. In some examples, the map(s) may include a height, an occupancy, and/or height/occupancy map generated, e.g., from a birds-eye-view perspective. The machine may use these outputs to perform one or more operations."
12306691,"Apparatuses, systems, and techniques to power balance multiple chips. In at least one embodiment, a system includes a plurality of processors having substantially equal performance capability and different power consumption capability, where a cumulative power consumption of the processors is not to exceed a system power threshold if each processor is operated at substantially peak performance."
12307571,"A method, computer readable medium, and system are disclosed for implementing automatic level-of-detail for physically-based materials. The method includes the steps of identifying a declarative representation of a material to be rendered, creating a reduced complexity declarative representation of the material by applying one or more term rewriting rules to the declarative representation of the material, and returning the reduced complexity declarative representation of the material."
12307684,"Disclosed are apparatuses, systems, and techniques that may perform methods of pyramid optical flow processing with efficient identification and handling of object boundary pixels. In pyramid optical flow, motion vectors for pixels of image layers having a coarse resolution may be used as hints for identification of motion vectors for pixels of image layers having a higher resolution. Pixels that are located near apparent boundaries between foreground and background objects may receive multiple hints from lower-resolution image layers, for more accurate identification of matching pixels across different image levels of the pyramid."
12307785,"In various examples, lane location criteria and object class criteria may be used to determine a set of objects in an environment to track. For example, lane information, freespace information, and/or object detection information may be used to filter out or discard non-essential objects (e.g., objects that are not in an ego-lane or adjacent lanes) from objects detected using an object detection algorithm. Further, objects corresponding to non-essential object classes may be filtered out to generate a final filtered set of objects to be tracked that may be of a lower quantity than the actual number of detected objects. As a result, object tracking may only be executed on the final filtered set of objects, thereby decreasing compute requirements and runtime of the system without sacrificing object tracking accuracy and reliability with respect to more pertinent objects."
12307788,"In various examples, a multi-sensor fusion machine learning model—such as a deep neural network (DNN)—may be deployed to fuse data from a plurality of individual machine learning models. As such, the multi-sensor fusion network may use outputs from a plurality of machine learning models as input to generate a fused output that represents data from fields of view or sensory fields of each of the sensors supplying the machine learning models, while accounting for learned associations between boundary or overlap regions of the various fields of view of the source sensors. In this way, the fused output may be less likely to include duplicate, inaccurate, or noisy data with respect to objects or features in the environment, as the fusion network may be trained to account for multiple instances of a same object appearing in different input representations."
12309070,"Aggregation of small payloads from multiple packets may improve bandwidth efficiency of a network, particularly a high-performance compute cluster with thousands of network endpoints and distributed data. Aggregation is context-based and a packet header is reduced because the common components that are shared by the aggregated messages are included once within the header. Execution contexts are explicitly created and destroyed by application programs. Each participating endpoint stores context-specific properties until the context is destroyed, so that the properties are not included in the header. Aggregation may be performed at different hierarchical levels by switches and/or endpoints."
12314175,"Various embodiments include techniques for managing cache memory in a computing system. The computing system includes a sectored cache memory that provides a mechanism for software applications to directly invalidate data items stored in the cache memory on a sector-by-sector basis, where a sector is smaller than a cache line. When all sectors in a cache line have been invalidated, the cache line is implicitly invalidated, freeing the cache line to be reallocated for other purposes. In cases where the data items to be invalidated can be aligned to sector boundaries, the disclosed techniques effectively use status indicators in the cache tag memory to track which sectors, and corresponding data items, have been invalidated by the software application. Thus, the disclosed techniques thereby enable a low-overhead solution for invalidating individual data items that are smaller than a cache line without additional tracking data structures or consuming additional memory transfer bandwidth."
12314451,"Apparatuses, systems, and methods for communication interfaces of a programmable part. In at least one embodiment, one or more communication interfaces are secured to a top side of a programmable part to provide programmable access to the programmable part after installation on a printed circuit board (PCB), the one or more communication interfaces to be selectively disabled based, at least in part, on a status of the programmable part."
12314854,"Systems and methods for determining the gaze direction of a subject and projecting this gaze direction onto specific regions of an arbitrary three-dimensional geometry. In an exemplary embodiment, gaze direction may be determined by a regression-based machine learning model. The determined gaze direction is then projected onto a three-dimensional map or set of surfaces that may represent any desired object or system. Maps may represent any three-dimensional layout or geometry, whether actual or virtual. Gaze vectors can thus be used to determine the object of gaze within any environment. Systems can also readily and efficiently adapt for use in different environments by retrieving a different set of surfaces or regions for each environment."
12315064,"Systems and methods relate to the determination of accurate motion vectors, for rendering situations such as a noisy Monte Carlo integration where image object surfaces are at least partially translucent. To optimize the search for “real world” positions, this invention defines the background as first path vertices visible through multiple layers of refractive interfaces. To find matching world positions, the background is treated as a single layer morphing in a chaotic way, permitting the optimized algorithm to be executed only once. Further improving performance over the prior linear gradient descent, the present techniques can apply a cross function and numerical optimization, such as Newton's quadratic target or other convergence function, to locate pixels via a vector angle minimization. Determined motion vectors can then serve as input for services including image denoising."
12315070,"Apparatuses, systems, and techniques to ray trace caustics in a scene using feedback of photon information between frames. In at least one embodiment, photon tracing determines photon footprints in an individual frame as a result of individual photons interacting with one or more caustic-casting objects in that frame, and uses those photon footprints to facilitate photon tracing in subsequent frames."
12315131,"In order to determine contour edges within a provided image, a plurality of image cells (e.g., groupings of pixels) are created within the image. For each image cell, a numerical value for each of the pixels is compared to a predetermined threshold value to determine comparison values for each pixel. A total numerical value for each image cell may then be determined utilizing the comparison values and numerical values for each pixel within each image cell. An associated contour cell (indicating present contour edges) is then determined for each image cell by comparing the total numerical value for the image cell to a contour cell index. These operations may be performed in parallel by a graphics processing unit (GPU) for each image cell, which may improve a performance of contour edge determination for the image. The stitching of contour edges may also be performed using the GPU, which may provide additional performance improvements for image contour extraction."
12315589,"The disclosure provides improvements for transmitting data between different voltage domains of an IC, such as a chip. The disclosure introduces a data transfer circuit that uses a multi-voltage RAM, referred to herein as MVRAM, for transmitting data across the different voltage domains. The MVRAM has multiple memory cells with write ports and read ports on different clock and voltage domains. Accordingly, a write operation can occur completely on the write domain voltage and the read operation can occur completely on the read domain voltage. In one example, the data transfer circuit includes: (1) write logic operating at a first operating voltage, (2) read logic operating at second operating voltage, and (3) a MVRAM with write ports that operate under the first operating voltage and read ports that operate under the second operating voltage."
12316397,"Apparatuses, systems, and techniques to cause one or more directions of travel to be indicated to a user in order to improve wireless signal strength. In at least one embodiment, one or more directions of travel are indicated to a device in order to improve wireless signal strength, based on, for example, wireless signal strength values obtained by said device at one or more locations."
12316863,"Disclosed are systems and techniques for efficient real-time codec encoding of video files. In one embodiments, the techniques include receiving one or more intra-prediction modes, each having a corresponding cost; calculating a first cost of a chroma-from-luma intra-prediction mode; calculating a second cost of the chroma-from-luma intra-prediction mode; and calculating a final cost based on the first cost and the second cost. The techniques also include selecting a final intra-prediction mode; generating, based on the selected final intra-prediction mode, a block of predicted pixels that approximates a block of source pixels of an image frame; and encoding a first alpha value in a bitstream."
12318935,One embodiment of a method for controlling a robot includes receiving sensor data associated with an environment that includes an object; applying a machine learning model to a portion of the sensor data associated with the object and one or more trajectories of motion of the robot to determine one or more path lengths of the one or more trajectories; generating a new trajectory of motion of the robot based on the one or more trajectories and the one or more path lengths; and causing the robot to perform one or more movements based on the new trajectory.
12321230,"Implicit Memory Tagging (IMT) mechanisms utilizing alias-free memory tags that enable hardware-assisted memory tagging without incurring storage overhead above those incurred by conventional tagging mechanisms, while providing enhanced data integrity and memory security. The IMT mechanisms enhance the utility of error correcting codes (ECCs) to test memory tags in addition to the traditional utility of ECCs for detecting and correcting data errors and enable a finer granularity of memory tagging than many conventional approaches."
12321743,"A method, computer readable medium, and processor are disclosed for performing matrix multiply and accumulate (MMA) operations. The processor includes a datapath configured to execute the MMA operation to generate a plurality of elements of a result matrix at an output of the datapath. Each element of the result matrix is generated by calculating at least one dot product of corresponding pairs of vectors associated with matrix operands specified in an instruction for the MMA operation. A dot product operation includes the steps of: generating a plurality of partial products by multiplying each element of a first vector with a corresponding element of a second vector; aligning the plurality of partial products based on the exponents associated with each element of the first vector and each element of the second vector; and accumulating the plurality of aligned partial products into a result queue utilizing at least one adder."
12321783,"In various examples, each hosted application may be modeled with a corresponding application-specific resource consumption model that predicts a measure of that application's anticipated resource utilization at some future time based on an input representation of one or more features of the current state of an instance of the hosted application. For cloud gaming, those features may include the current level being played, current obstacles, user results playing the level or obstacles, metadata quantifying one or more aspects of the level or obstacles, game progress, etc. As such, application-specific models may be used to predict resource demands at a future time and schedule resource allocations accordingly. The present techniques may be used to manage and reallocate resources for applications such as game streaming applications, remote desktop applications, simulation applications (e.g., an autonomous or semi-autonomous vehicle simulation), virtual reality (VR) and/or augmented reality (AR) streaming applications, and/or other application types."
12321825,"Embodiments of the present disclosure relate to a technique for training neural networks, such as a generative adversarial neural network (GAN), using a limited amount of data. Training GANs using too little example data typically leads to discriminator overfitting, causing training to diverge and produce poor results. An adaptive discriminator augmentation mechanism is used that significantly stabilizes training with limited data providing the ability to train high-quality GANs. An augmentation operator is applied to the distribution of inputs to a discriminator used to train a generator, representing a transformation that is invertible to ensure there is no leakage of the augmentations into the images generated by the generator. Reducing the amount of training data that is needed to achieve convergence has the potential to considerably help many applications and may the increase use of generative models in fields such as medicine."
12322063,"Apparatuses, systems, and techniques to enhance video are disclosed. In at least one embodiment, one or more neural networks are used to create a higher resolution video using upsampled frames from a lower resolution video."
12322068,"Apparatuses, systems, and techniques are presented to generate digital content. In at least one embodiment, one or more neural networks are used to generate a three-dimensional voxel representation of a scene based, at least in part, upon a plurality of two-dimensional images of the scene."
12322114,"In various examples, image data may be received that represents an image. Corner detection may be used to identify pixels that may be candidate corner points. The image data may be converted from a higher dimensional color space to a converted image in a lower dimensional color space, and boundaries may be identified within the converted image. A set of the candidate corner points may be determined that are within a threshold distance to one of the boundaries, and the set of the candidate corner points may be analyzed to determine a subset of the candidate corner points representative of corners of polygons. Using the subset of the candidate corner points, one or more polygons may be identified, and a filter may be applied to the polygons to identify a polygon as corresponding to a fiducial marker boundary of a fiducial marker."
12322126,"In various examples, methods and systems are provided for estimating depth values for images (e.g., from a monocular sequence). Disclosed approaches may define a search space of potential pixel matches between two images using one or more depth hypothesis planes based at least on a camera pose associated with one or more cameras used to generate the images. A machine learning model(s) may use this search space to predict likelihoods of correspondence between one or more pixels in the images. The predicted likelihoods may be used to compute depth values for one or more of the images. The predicted depth values may be transmitted and used by a machine to perform one or more operations."
12322177,"In various examples, one or more Machine Learning Models (MLMs) are used to identify content items in a video stream and present information associated with the content items to viewers of the video stream. Video streamed to a user(s) may be applied to an MLM(s) trained to detect an object(s) therein. The MLM may directly detect particular content items or detect object types, where a detection may be narrowed to a particular content item using a twin neural network, and/or an algorithm. Metadata of an identified content item may be used to display a graphical element selectable to acquire the content item in the game or otherwise. In some examples, object detection coordinates from an object detector used to identify the content item may be used to determine properties of an interactive element overlaid on the video and presented on or in association with a frame of the video."
12322471,"Mechanisms to mitigate signal race conditions in circuits that utilize multiple voltage domains. The mechanisms are applicable in signal fanout scenarios where leakage becomes problematic to signal timing, such machine memory devices, e.g., volatile single port or multi-port memory devices such as SRAMs (volatile static random access memory) or other bit-storing cell arrangements that include memory cells and a hierarchical bitline structure including local bitlines for subsets of the memory banks and a global bitline spanning the subsets."
12323341,"In various examples, each user of a hosted application may be modeled with a corresponding user-specific resource consumption model that predicts a measure of that user's anticipated (e.g., processing, memory or storage, and/or networking) resource utilization at some future time based on an input representation of one or more features of the user's current session, application (e.g., game) setup, skill or experience level, social media activity, some time series representing feature(s) for a series of interactions, the time of day, and/or other characteristics. As such, user-specific models may be used to predict resource demands at a future time and schedule resource allocations accordingly. The present techniques may be used to manage and reallocate resources for applications such as game streaming applications, remote desktop applications, simulation applications (e.g., an autonomous or semi-autonomous vehicle simulation), virtual reality (VR) and/or augmented reality (AR) streaming applications, and/or other application types."
12323717,"In various examples, lens shading image correction systems and applications using non-radial correction of residual radial shading error are provided. In some embodiments, lens shading image correction may be implemented using calibration parameters corresponding to radial lens shading correction, and calibration parameters corresponding to non-radial lens shading correction. In some embodiments, sensor data comprising an image frame may be captured using a sensor. Radial lens shading correction may be applied to the image frame to produce a residual shading profile, and non-radial lens shading correction may be applied to the residual shading profile to produce a calibrated image frame. Parameters for radial lens shading correction may be computed from a lens shading profile associated with the sensor, and parameters for non-radial lens shading correction may be computed based a residual shading profile produced from the radial lens shading correction."
12326820,"In various examples, a memory model may support multicasting where a single request for a memory access operation may be propagated to multiple physical addresses associated with multiple processing elements (e.g., corresponding to respective local memory). Thus, the request may cause data to be read from and/or written to memory for each of the processing elements. In some examples, a memory model exposes multicasting to processes. This may include providing for separate multicast and unicast instructions or shared instructions with one or more parameters (e.g., indicating a virtual address) being used to indicate multicasting or unicasting. Additionally or alternatively, whether a request(s) is processed using multicasting or unicasting may be opaque to a process and/or application or may otherwise be determined by the system. One or more constraints may be imposed on processing requests using multicasting to maintain a coherent memory interface."
12327071,"Simulation of complex agents, such as robots with many articulation links, can be performed utilizing a pre-computed a response matrix for each link. When an impulse is applied to a link for this agent, the response matrix for a root node can be used to determine an impact of that impulse on the root node, as well as changes in velocity for any direct child node. This process can be performed recursively for each link down to the leaf links of a hierarchical agent structure. These response matrices can be solved recursively from root to leaf while only visiting each hierarchical link once. Such an approach can be used to solve a full set of constraints acting on the agent in an amount of time per solver iteration that is on the order of the number of links, or O(N) time per solver iteration."
12327413,"In various examples, color statistic(s) from ground projections are used to harmonize color between reference and target frames representing an environment. The reference and target frames may be projected onto a representation of the ground (e.g., a ground plane) of the environment, an overlapping region between the projections may be identified, and the portion of each projection that lands in the overlapping region may be taken as a corresponding ground projection. Color statistics (e.g., mean, variance, standard deviation, kurtosis, skew, correlation(s) between color channels) may be computed from the ground projections (or a portion thereof, such as a majority cluster) and used to modify the colors of the target frame to have updated color statistics that match those from the ground projection of the reference frame, thereby harmonizing color across the reference and target frames."
12328456,"Systems and methods for improved media stream processing. In at least one embodiment, a media stream is assigned to either a hardware processing engine or software processing engine based on a performance state of an application server and one or more parameters of the media stream."
12328851,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a liquid-to-air heat exchanger is associated with a fan wall and a refrigerant-based cooling system to provide air cooling and refrigerant-based cooling to cool secondary coolant or fluid received from at least one cold plate."
12330050,"In examples, a device's native input interface (e.g., a soft keyboard) may be invoked using interaction areas associated with image frames from an application, such as a game. An area of an image frame(s) from a streamed game video may be designated (e.g., by the game and/or a game server) as an interaction area. When an input event associated with the interaction area is detected, an instruction may be issued to the client device to invoke a user interface (e.g., a soft keyboard) of the client device and may cause the client device to present a graphical input interface. Inputs made to the presented graphical input interface may be accessed by the game streaming client and provided to the game instance."
12332079,"In various examples, a network of servers, such as a content delivery network, is used to provide a lightweight approach to hosting and serving HD map data to vehicles. The lightweight approach may allow for modifying various map components, such as tiles, layers, and/or segments. Modifying may include adding, removing, and/or updating the various components. A request to modify a first version of a High definition (HD) map may be received. Map data may be recorded that represents a second version of the HD map. A second request associated with the HD map may be received from a vehicle. Based on this second request, second map data representative of at least a portion of a layer may be identified on at least one server of the network of servers. The second map data may then be transmitted to the vehicle by the network of servers."
12332349,"In various examples, techniques for sensor-fusion based object detection and/or free-space detection using ultrasonic sensors are described. Systems may receive sensor data generated using one or more types of sensors of a machine. In some examples, the systems may then process at least a portion of the sensor data to generate input data, where the input data represents one or more locations of one or more objects within an environment. The systems may then input at least a portion of the sensor data and/or at least a portion of the input data into one or more neural networks that are trained to output one or more maps or other output representations associated with the environment. In some examples, the map(s) may include a height, an occupancy, and/or height/occupancy map generated, e.g., from a birds-eye-view perspective. The machine may use these outputs to perform one or more operations."
12332436,"In an embodiment, an augmented reality display provides an expanded eye box and enlarged field of view through the use of holographic optical elements. In at least one example, an incoupling element directs an image into a waveguide, which transmits the image to a set of outcoupling gratings. In one example, a set of holographic optical elements opposite the outcoupling elements reflect the image to the user with an enlarged field of view while maintaining an expanded eye box."
12332614,"In various examples, systems and methods are disclosed that perform sensor fusion using rule-based and learned processing methods to take advantage of the accuracy of learned approaches and the decomposition benefits of rule-based approaches for satisfying higher levels of safety requirements. For example, in-parallel and/or in-serial combinations of early rule-based sensor fusion, late rule-based sensor fusion, early learned sensor fusion, or late learned sensor fusion may be used to solve various safety goals associated with various required safety levels at a high level of accuracy and precision. In embodiments, learned sensor fusion may be used to make more conservative decisions than the rule-based sensor fusion (as determined using, e.g., severity (S), exposure (E), and controllability (C) (SEC) associated with a current safety goal), but the rule-based sensor fusion may be relied upon where the learned sensor fusion decision may be less conservative than the corresponding rule-based sensor fusion."
12332961,"Statistical analysis can be used to attempt to identify potentially malicious references, such as trap URLs. When a URL is utilized for a request, that request can be intercepted before analysis before that URL is resolved to an address. Portions of this URL, as well as the entire URL, can be compared against one or more lists of known URLs using a probabilistic matching process to determine whether there are any matches that are very close but not quite exact. Any determined match with high probability above a suspicion threshold can be flagged as being suspicious, or associated with a potentially malicious site. An action can then be taken, such as to block that URL or prompt a user for confirmation of intent."
12333311,"A new level(s) of hierarchy—Cooperate Group Arrays (CGAs)—and an associated new hardware-based work distribution/execution model is described. A CGA is a grid of thread blocks (also referred to as cooperative thread arrays (CTAs)). CGAs provide co-scheduling, e.g., control over where CTAs are placed/executed in a processor (such as a GPU), relative to the memory required by an application and relative to each other. Hardware support for such CGAs guarantees concurrency and enables applications to see more data locality, reduced latency, and better synchronization between all the threads in tightly cooperating collections of CTAs programmably distributed across different (e.g., hierarchical) hardware domains or partitions."
12333638,"Apparatuses, systems, and techniques are presented to reconstruct one or more images. In at least one embodiment, one or more neural networks are used to generate one or more images of one or more objects based, at least in part, on input indicating motion of the one or more objects."
12333639,"In various examples, animations may be generated using audio-driven body animation synthesized with voice tempo. For example, full body animation may be driven from an audio input representative of recorded speech, where voice tempo (e.g., a number of phonemes per unit time) may be used to generate a 1D audio signal for comparing to datasets including data samples that each include an animation and a corresponding 1D audio signal. One or more loss functions may be used to compare the 1D audio signal from the input audio to the audio signals of the datasets, as well as to compare joint information of joints of an actor between animations of two or more data samples, in order to identify optimal transition points between the animations. The animations may then be stitched together—e.g., using interpolation and/or a neural network trained to seamlessly stitch sequences together—using the transition points."
12333642,"A ray (e.g., a traced path of light, etc.) is generated from an originating pixel within a scene being rendered. Additionally, one or more shadow map lookups are performed for the originating pixel to estimate an intersection of the ray with alpha-tested geometry within the scene. A shadow map stores the distance of geometry as seen from the point of view of the light, and alpha-tested geometry includes objects within the scene being rendered that have a determined texture and opacity. Further, the one or more shadow map lookups are performed to determine a visibility value for the pixel (e.g., that identifies whether the originating pixel is in a shadow) and a distance value for the pixel (e.g., that identifies how far the pixel is from the light). Further still, the visibility value and the distance value for the pixel are passed to a denoiser."
12333688,"Apparatuses, systems, and techniques are presented to train and utilize one or more neural networks. A denoising diffusion generative adversarial network (denoising diffusion GAN) reduces a number of denoising steps during a reverse process. The denoising diffusion GAN does not assume a Gaussian distribution for large steps of the denoising process and applies a multi-model model to permit denoising with fewer steps. Systems and methods further minimize a divergence between a diffused real data distribution and a diffused generator distribution over several timesteps. Accordingly, various embodiments may enable faster sample generation, in which the samples are generated from noise using the denoising diffusion GAN."
12335458,"Systems and methods are presented for reliable transmission of time-sensitive data. In particular, various embodiments provide for the generation of compressed sequential data, where individual instances of a sequence represent differentials from prior instances in that sequence. In order to reduce an amount of data that needs to be transmitted, instances of data (such as individual video frames) can be provided using a prior video frame as a reference, sending only data for those pixel locations where the pixel value differs from the reference frame. A reference frame can include a previously-received and successfully-decoded frame, in order to minimize the impact of dropped, incomplete, or corrupted frames. In order to further reduce data transmission requirements, a reference frame can be selected which is determined to be optimal for the current frame, such as may represent a least amount of data to be transmitted for a given frame."
12339135,"A system accesses a three-dimensional map of a geographic region and generates a two-dimensional projection of the road based on the three-dimensional map. The two-dimensional projection comprises a plurality of points along the road and each point is assigned a score measuring a navigability of the point. Based on the navigability score of each point and history of vehicle positions on the road, the system identifies a plurality of navigable points on the two-dimensional projection of the road. Based on the plurality of navigable points, the system determines a navigable surface corresponding to a physical area over which a vehicle may safely navigate and navigable surface boundaries surrounding that area. The navigable surface area and boundaries on the two-dimensional projection are converted into a three-dimensional representation, which the system uses to generate an updated three-dimensional map of the geographic region."
12339700,"Circuits that include one or more transmission lines to propagate a signal through a serially-arranged plurality of repeaters, and one or more control circuits to propagate control pulses to the repeaters, wherein a timing and duration of the control pulses is configured to operate the repeaters in current-mode signaling (CMS) mode during a state transition of the signal at the repeaters and to operate the repeaters in voltage-mode signaling (VMS) mode otherwise."
12339899,"Approaches presented herein provide for the generation and maintenance of a minimally-sized octree (or other spatial representation) for an arbitrary or dynamic dataset. An octree representation allows for efficient real-time querying of dynamic content, where such a spatial database can scale from a single machine to multiple machines. Objects in a scene can be stored to the spatial database using a set of spatial primitives. When a first object (or set of objects) in a scene is determined, an initial octree and root can be determined based at least in part upon the size and location of the object(s). An additional object may be added that is outside the existing root of the octree. A new bounding volume is generated that surrounds this new object, and the bounding volume is grown in alternating directions until the bounding volume also includes the other objects in the environment, and this new volume boundary becomes the new root of an updated octree for this environment."
12340259,"Various embodiments include a parallel processing computer system that provides multiple memory synchronization domains in a single parallel processor to reduce unneeded synchronization operations. During execution, one execution kernel may synchronize with one or more other execution kernels by processing outstanding memory references. The parallel processor tracks memory references for each domain to each portion of local and remote memory. During synchronization, the processor synchronizes the memory references for a specific domain while refraining from synchronizing memory references for other domains. As a result, synchronization operations between kernels complete in a reduced amount of time relative to prior approaches."
12340484,"Apparatuses, systems, and techniques for texture synthesis from small input textures in images using convolutional neural networks. In at least one embodiment, one or more convolutional layers are used in conjunction with one or more transposed convolution operations to generate a large textured output image from a small input textured image while preserving global features and texture, according to various novel techniques described herein."
12341890,"Approaches in accordance with various embodiments allow for zero-touch enrollment of devices with respective manager systems. In at least one embodiment, a device at startup can contact a central directory service (CDS) for information about an associated manager. The CDS can authenticate the device using device information included in the request, and can send a challenge token to the device in response. The challenge token can include information for the manager, protected with multiple layers of security that should only be able to be decrypted by the authenticated device. The device can decrypt this challenge token to determine the manager information, and can convert this challenge token to a bearer token. The device can then send a request to the determined manager that includes the bearer token, which the manager can use to authenticate the device. The manager can then send the device appropriate configuration information."
12342448,"A circuit board includes chip die mounted on a three dimensional rectangular structure, a three dimensional triangular prism structure, or a combination thereof. A ball grid array for the chip die mounted on any such three dimensional structure is interposed between the three dimensional structure and the circuit board itself."
5619658," Apparatus and a method by which the flow of commands to an input/output device may be halted when the device is unable to respond to a command decoded to its address space. The apparatus includes circuitry for ascertaining whether the input/output device is able to respond to a command decoded by the decoding circuit, a circuit for storing the data and address of a command transferred to the input/output device to which the input/output device is unable to respond, and circuitry for generating a signal to disable immediately the flow of commands to the input/output device and an interrupt to assure that the unimplemented command is handled in an expeditious manner. "
5623692," Hardware input/output address translation apparatus adapted for use in a multitasking computer system including hardware responsive to commands from an unprivileged application program addressed to an input/output address for translating the input/output address to a physical address space of an input/output device and transferring the command to the physical address of an input/output device, and additional hardware responsive to commands from an unprivileged application program addressed to an input/output address for selecting from safe translations of input/output addresses to physical address spaces of input/output devices for the hardware for translating the input/output address to a physical address space of an input/output device. "
5638535," A flow control circuit for a computer system including a first-in first-out buffer including a register for storing a value indicating the number of stages of the FIFO which are available to store data, circuitry for detecting whether an input/output device is able to process data more rapidly than the FIFO is emptied, and circuitry for providing an value greater than the number of stages actually available for storage in the FIFO if the input/output device is able to process data more rapidly than the FIFO is emptied. "
5640591," Hardware input/output address translation apparatus adapted for use in a multitasking computer system including a circuit which responds to commands from an unprivileged application program addressed to an input/output address for translating the input/output address to a physical address of an input/output device and transferring the command to the physical address of an input/output device, a translation table which responds to commands from an unprivileged application program addressed to an input/output address for selecting from safe translations of input/output addresses to physical address spaces of input/output devices for the first hardware means, each selection of a safe translation being accomplished using an arbitrary name originally provided by the unprivileged application program; and a database of data structures which individually include a physical address of an input/output device and can be copied and named by application programs to provide safe translation for storage in the translation table. "
5652793," A hardware encoding circuit which generates a code value unique to a particular computer, stores a password unique to an application program and to the particular computer, tests the stored password against a verification value generated by the hardware encoding program each time the application program is run, and generates an error signal if the stored password and the verification value do not match. "
5659750," Hardware input/output control apparatus for use in a computer system which control apparatus is joined to a plurality of input/output devices, and includes circuitry which responds to commands from unprivileged application programs addressed to input/output devices joined to the hardware input/output apparatus for selecting a context to be placed on an addressed input/output device to function with an application program sending the command. Context switching is effected in response to commands from unprivileged application programs without involving the operating system or trusted code. "
5680592," Apparatus for emulating input/output devices on an ISA bus using input/output devices on a local bus which includes circuitry for snooping on the bus to capture commands sent to input/output devices the functions of which are to be emulated, circuitry for storing those commands, circuitry for generating new commands in response to the commands which are stored, and circuitry for generating output signals in response to the new commands which output signals replace the output signals produced by the input/output devices on an ISA bus. "
5685011," Hardware input/output address translation apparatus adapted for use in a multitasking computer system including hardware responsive to commands from an unprivileged application program addressed to an input/output address for translating the input/output address to a physical address space of an input/output device and transferring the command to the physical address of an input/output device, hardware responsive to commands from an unprivileged application program addressed to an input/output address for selecting from safe translations of input/output addresses to physical address spaces of input/output devices for the first hardware means, and apparatus for handling a failure to provide an address translation. "
5687357," Apparatus and a method by which an application program writing a series of commands to a single destination on an input/output bus increments the addresses to which the commands are addressed as the commands are written so that the commands may be transferred utilizing the burst mode of the input/output bus, and the device receiving the data decodes a large number of sequential addresses to the same destination so that the input/output device transfers all of the commands in the sequence of addresses to the single destination. "
5696990," A system which uses an arrangement of FIFO buffers which include circuitry to assure that no data written to a FIFO buffer by an application program will overflow the FIFO buffer. Each FIFO buffer includes a flow control register which stores a value which indicates the amount of space available in the FIFO to which data may be written. In order to allow for situations in which data is available at a FIFO buffer which cannot be immediately utilized for some reason, an overflow storage area is provided for storing data transferred to the FIFO buffer in excess of the number of stages of the FIFO circuit which are available to store data. The flow control circuitry also includes circuitry for assuring that data which is placed in the overflow storage area is handled in the appropriate sequence. "
5721947," A computer system including a central processing unit, a system input/output bus, an input/output device, and an input/output control unit joined to the system input/output bus for translating addresses on the system input/output bus to physical input/output device addresses. "
5733194," An arrangement which provides hardware at the game port to provide a direct analog-to-digital conversion of input signals provided by the directional input signals of a joystick without involving the central processing unit in the determination. By determining at the game port the input values, the central processing unit need not have its interrupts disabled, and games may easily function with other application programs in a multi-tasking operating system. "
5734369, An ordered dithering process by using different sets of dithering patterns for different color components of the source pixel color instead of using the same set of patterns. The sets of dithered patterns are designed in a way that variations in intensity due to dithering of some color components are partially or fully compensated by variations in intensity due to dithering of other color components. 
5740406," An input circuit for an input/output device adapted for use in a computer system in which a command includes information indicating an application program which initiated the command, the input circuit including a first-in first-out (FIFO) buffer circuit having a plurality of stages, each stage providing storage for commands from application programs including both data and an address for the data, circuitry for determining from a command an application program which has initiated a command, and circuitry for assuring that commands from only one application program reside in the FIFO buffer at any time. "
5740464," Hardware input/output address translation apparatus adapted for use in a multitasking computer system including hardware responsive to commands from an unprivileged application program addressed to an input/output address for translating the input/output address to a physical address space of an input/output device and transferring the command to the physical address of an input/output device, and additional hardware responsive to commands from an unprivileged application program addressed to an input/output address for selecting from safe translations of input/output addresses to physical address spaces of input/output devices for the hardware for translating the input/output address to a physical address space of an input/output device. "
5754866," Apparatus for transferring commands over a system transmission path between first and second components in a digital data system including a first-in first-out circuit having a plurality of stages arranged in the system transmission path, circuitry for generating a first signal to indicate that a component to which a command in the FIFO circuit is directed is unable to handle an operation commanded, and a delay circuit responsive to the first signal for causing the generation of an interrupt request signal after a preselected time. "
5758182," A DMA controller which responds without operating system intervention to virtual addresses provided by application programs, and a memory management unit for providing translations between physical addresses of input/output devices and addresses on a system input/output bus for data transferred by the DMA controller. "
5764861," Hardware input/output control apparatus for use in a computer system which control apparatus is joined to a plurality of input/output devices, and includes circuitry which responds to commands from unprivileged application programs addressed to input/output devices joined to the hardware input/output apparatus for selecting a context to be placed on an addressed input/output device to function with an application program sending the command. "
5768628," An arrangement which utilizes the system memory to store the wave tables used in the generation of high quality sound, and a direct memory access controller to rapidly transfer the portions of the wave tables stored in memory using the system bus so that a sound card may manipulate high quality sounds from wave tables stored directly in system memory without overloading the system bus and without the need for substantial additional memory on the sound card. "
5793379," A method of processing a digital input image having a plurality of scan lines of pixel data into an interpolated digital output image by interpolating the pixel data in each scan line of the digital input image and replicating the pixel data in the slow scan direction to provide a plurality of scan lines interpolated in the fast scan direction, calculating slow scan direction interpolation coefficients for scan lines to be interpolated in the interpolated output image, storing the interpolated scan lines using the storage typically used for the display image, interpolating selected scan lines which have been stored using selected existing scan lines to produce scan lines interpolated in the slow scan direction of the interpolated output image, and writing scan lines interpolated in the slow scan direction in place of scan lines selected for interpolation in the output image. "
5805175," An arrangement which provides for storing a single lookup/bypass bit with each pixel stored in a frame buffer to indicate whether the color format used to display that pixel on the output display is to use the lookup tables, and for storing an indication apart from the frame buffer which to indicate the decode format for the pixels stored in the frame buffer and retrieved for display by programs providing graphics output in different color formats. The arrangement allows fifteen bit color formats to be stored in standard sized frame buffers without the addition of memory devices. "
5805930," A digital system which uses an arrangement of one or more parallel FIFO buffers in which each FIFO buffer handles data from only one application program at any time. In order to assure that no data written to a FIFO buffer by an application program will overflow the FIFO buffer, each FIFO buffer includes a flow control register which must be read by the processing unit running the application before writing data to an input/output device. The register stores a value which indicates the amount of space available in the FIFO buffer to which data may be written. Reading this register tells the application program how much data may be written without running the risk of overflowing the data storage area which the input/output device has available. "
5887190, An input/output control unit which provides a large amount of input/output address space divisible into areas each of which is a multiple of the system memory management unit page size and thus may be allotted to only one of the individual application programs using a computer system by an input/output device driver. The control unit is able to determine from command addresses provided by the application programs both the application program which is involved in the operation and the address area which has been allotted solely to that application program. This use of these addresses in the input/output address space which have been allotted solely to one application program allows the application programs to write directly to the input/output devices while still maintaining the integrity of the system. 
5909595," A method of controlling the routing of input/output operations including providing a series of commands expressing connections between sources of data, processing elements, and destinations for data to carry out an input/output operation; compiling a data structure for the input/output operation from the series of commands, the data structure including context defining connections between each of the sources of data, processing elements, and destinations for data; and using the data structure to set connecting context to make connection expressed between each of the sources of data, processing elements, and destinations for data whenever the input/output operation is to be accomplished. "
5918050," A computer system including a central processing unit, a system input/output bus, an input/output device, and an input/output control unit accessed at a physical input/output address for translating addresses and data in commands from applications programs to physical input/output device addresses and for changing the context of an input/output device for which an address translation is furnished. "
5924126," An input circuit for an input/output device adapted for use in a computer system including a first section having a storage circuit holding physical addresses of input/output devices which are translations of selected input/output bus addresses, and a comparator circuit for testing an address in a command from application programs including both data and an address for the data with the recently accessed addresses to obtain a translation from the storage circuit; and a second section including a hash table including translations of physical addresses to be placed in the storage circuit. "
5968148," An arrangement which utilizes the system memory to store the wave tables used in the generation of high quality sound, and a direct memory access controller to rapidly transfer the portions of the wave tables stored in memory using the system bus so that a sound card may manipulate high quality sounds from wave tables stored directly in system memory without overloading the system bus and without the need for substantial additional memory on the sound card. "
6023738," A direct memory access (DMA) arrangement having a DMA circuit which is positioned with an input/output device, the DMA circuit including a first register for storing a reference value pointing to a first data structure established by an application program which includes details of a transfer buffer in memory in which data is stored for transfer to the I/O device, two additional registers for storing an address and a range at which the data is stored within the transfer buffer in memory, and a fourth register for storing a reference value pointing to a second data structure which includes details describing a notification area of memory at which a notification from the DMA circuit that a transfer of data has been completed may be stored. "
6061066," A circuit for providing a perspective correct transformation of attribute values at positions defining a planar polygon in world space to attribute values at pixels describing the polygon in screen space including a first circuit for determining a series of presetup values defined by coordinates of vertices of the polygon which are constant throughout the polygon, a second circuit for computing setup values for each attribute which are constant throughout the polygon from the presetup values, a third circuit for computing from the setup values for each attribute a result for the attribute which is constant at any pixel describing the polygon, a fourth circuit for determining a reciprocal of a result of a depth attribute computed by the third circuit, and a fifth circuit for combining the values of the result computed by the third circuit for each attribute and the reciprocal value for each pixel of the polygon. "
6065071," Apparatus and a method by which the flow of DMA-transferable data from an application program to an input/output device using a direct memory access circuit may be halted when the device is unable to respond to DMA-transferable data sent to it. The apparatus includes circuitry for ascertaining whether the input/output device is able to respond to DMA-transferable data transferred to the input/output device, a circuit for storing the DMA-transferable data transferred to the input/output device to which the input/output device is unable to respond, and circuitry for generating a signal to disable immediately the flow of DMA-transferable data to the input/output device and an interrupt to assure that the DMA-transferable data is handled in an expeditious manner. "
6075544," A circuit for accelerating processing of pixel data being provided to a frame buffer comprising circuitry for determining that pixel values vary linearly over a scan line of a polygon to be rendered, linear interpolation circuitry for providing pixel values using a process of linear interpolation between accurately determined pixel values, and a circuit for collecting pixel values to be written to a frame buffer until a significant number of pixel values may be written together. "
6081854," An input circuit for an input/output device adapted for use in a computer system in which a command includes information indicating an application program which initiated the command, the input circuit including a first-in first-out (FIFO) buffer circuit having a plurality of stages, each stage providing storage for commands from application programs including both data and an address for the data, a direct memory access circuit for transferring data between a buffer established in system memory by an application program and the FIFO buffer circuit, computer implemented software means for establishing a transfer buffer in system memory, circuitry for determining from a command which application program has initiated the command, and circuitry for assuring that commands from only one application program reside in the FIFO buffer circuit at any time. "
6092124," A direct memory access (DMA) circuit which is physically positioned with an input/output device, the DMA circuit storing a first reference value pointing to a data structure which describes a buffer portion of system memory in which data is stored for transfer to the I/O device, a value determining a position within the buffer portion of system memory beginning at which a next sequence of data is to be placed, and a value determining a position within the buffer portion of system memory from which a next sequences of data is to be copied to the I/O device, the DMA circuit including circuitry for reading data from the buffer portion of system memory beginning at the position from which a next sequences of data is to be copied and for writing the data read to the I/O device. "
6181352, A graphics accelerator pipeline including a combiner stage capable of producing output values during each clock interval of the pipeline which map a plurality of textures to a single pixel or an individual texture to two pixels. 
6191794," A method which derives for each triangle to be rendered the values of the texture map coordinates in world space and the screen space two dimensional coordinates across the polygon, utilizes the values to provide two bounding boxes, compares the values of sides of the bounding boxes, and uses these comparisons to select a texture map of a scale which will provide an accurate color representation of a texture value for the pixels of the polygon. "
6194923," An off-chip driver circuit having a set of input terminals and an output terminal, a pull-up transistor having a controllable path connected between a first power supply and the output terminal of the off-chip driver circuit, a pull-down transistor having a controllable path connected between a second power supply and the output terminal of the off-chip driver circuit, a first controllable path for applying a first voltage at one of the input terminals to a control terminal of the pull-up transistor, the first controllable path functioning in response to voltages at the output terminal below a first value, a second controllable path for applying a second voltage greater than the first voltage to the control terminal of the pull-up transistor, the second controllable path functioning in response to voltages at the output terminal above the first value. "
6198488, A graphics pipeline system is provided for graphics processing. Such system includes a transform module adapted for being coupled to a vertex attribute buffer for receiving vertex data. The transform module serves to transform the vertex data from object space to screen space. Coupled to the transform module is a lighting module which is positioned on the single semiconductor platform for performing lighting operations on the vertex data received from the transform module. Also included is a rasterizer coupled to the lighting module and positioned on the single semiconductor platform for rendering the vertex data received from the lighting module. 
6226012," A method which evaluates each sequence of pixels provided in a polygon to determine whether the pixels vary linearly, selects sequences of adjacent pixels which vary linearly, determines a processing factor for the sequence of pixels, processes only every one of a selected number of pixels of the sequence, and interpolates the data for pixels of the sequence between the processed pixels after the processed pixels have been processed. "
6239808," In a computer display system, a method for mapping textures to three dimensional surfaces divided into a one or more polygons including the steps of determining pixels to be utilized in describing a polygon, selecting a texture map having a scale chosen to reproduce accurately a texture value for pixels for a polygon, determining a plurality of texture coordinates of a pixel at a plurality of positions surrounding a center of the pixel, determining texture values at each of the determined positions, and blending the texture values at the points to produce a texture value for the pixel. "
6275243, A graphics accelerator including an address remapping memory which straddles slow address spaces and fast address spaces. 
6282587," A direct memory access (DMA) circuit which is physically positioned with an input/output device, the DMA circuit storing a first reference value pointing to a data structure which describes a buffer portion of system memory in which data is stored for transfer to the I/O device, a value determining a position within the buffer portion of system memory beginning at which a next sequence of data is to be placed, and a value determining a position within the buffer portion of system memory from which a next sequences of data is to be copied to the I/O device, the DMA circuit including circuitry for reading data from the buffer portion of system memory beginning at the position from which a next sequences of data is to be copied and for writing the data read to the I/O device. "
6288418," An integrated circuit including a plurality of connectors for communicating with circuitry within the integrated circuit, a plurality of input/output pads for connecting to external circuitry, a plurality of multiplexors joined to the connectors and the input/output pads, means for providing an external control signal for each multiplexor for joining the plurality of connectors for communicating with circuitry within the integrated circuit to correct input/output pads for connecting to external circuitry for operating the integrated circuit. "
6292854," An arrangement which utilizes the system memory to store the wave tables used in the generation of high quality sound, and a direct memory access controller to rapidly transfer the portions of the wave tables stored in memory using the system bus so that a sound card may manipulate high quality sounds from wave tables stored directly in system memory without overloading the system bus and without the need for substantial additional memory on the sound card. "
6297833," A graphics accelerator pipeline including a rasterizer stage, a texture stage, and a combiner stage capable of producing realistic output images by mapping irregular textures to surfaces. "
6300953, A method and apparatus for grouping texture data to increase storage throughput. Texels are addressed and stored according to adjacency to enable retrieval of a plurality of texels (a cache entry) with only a single address space request. Individual texel position is then derived using a simple adjacency formula. The preferred method and apparatus are compatible with both tiled data and linear data storage formats. 
6323860," A method performed in a graphics processor postpones the processing of one or more changes in render state until after one or more tiles that are affected by a primitive are identified (e.g. by use of a bounding box around the primitive to identify tiles within the bounding box, or by visiting an area enclosed by vertex tiles and edge tiles of the primitive to identify tiles covered by the primitive). The method may be performed by: storing value(s) of render state(s) on receipt, receiving one or more primitives affected by the render state(s), identifying from among a number of render state(s) whose values are being stored one or more render state(s) whose values have changed since last update to a tile covered by a received primitive, and associating with the covered tile the changed render states. Such a deliberate delay in association of changed render states eliminates the need to process render state(s) for tiles that are not identified as being covered by a received primitive, and render states that have not changed for such tiles, thus saving processing power and memory bandwidth. Identification of a render state that has changed since the last update to a tile can be accomplished in any manner, e.g. (1) by storage of a sequence signal (such as a time stamp) that indicates the order in which render states (and optionally primitives) are received, and are updated to a tile, or (2) by comparison of render state values that were previously updated to a tile, with the most current render state values, or (3) by some combination of (1) and (2). "
6333744," A graphics pipeline including a rasterizing stage producing diffuse color values; a plurality of texture stages producing texture values defining a particular texture; a combiner stage for combining four of a plurality of selectable input values including diffuse color values, texture values furnished by a plurality of texture stages, and proportions for combination of the selectable input values; the combiner stage being capable of providing a result equivalent to a sum of products of any two sets of input values, and a product of two input values. "
6342888,"A graphics pipeline system is provided for graphics processing. Such system includes a transform module adapted for receiving vertex data. The transform module serves to transform the vertex data from a first space to a second space. Further, the transform module of the graphics pipeline system is capable of carrying out a blending operation. Coupled to the transform module is a lighting module which is positioned on the single semiconductor platform for performing lighting operations on the vertex data received from the transform module. During use, the lighting module of the graphics pipeline system is capable of carrying out a fog operation."
6344852,"A system and method implemented in hardware are provided to optimize rendering of a computer graphics image, which may be displayed in an image frame comprising a number of tiles. The system and method determine each tile in the image frame touched by a geometry (e.g., a triangle). Graphics data for the geometry is selectively stored into a separate, corresponding portion of memory for each tile touched by the geometry. The graphics data stored in each portion of memory can be readily accessed and used to render a portion of the image in the respective tile of the image frame."
6352479,A multiplayer game system is implemented over the WWW using a plurality of game servers dynamically linked to and controlled by a WWW server. The WWW server dynamically links game players who log on to a web site hosted by the WWW server as a function of game playing statistics for each game player which are stored in the WWW server. The game servers generate the game player statistics for each player during and/or after game play and upload the game player statistics to the WWW server. The WWW server matches game players to appropriate games currently being played on the game servers based on the skill level required by the game and the corresponding skill levels of other current players of that game as represented by the game player statistics stored by the WWW server and dynamically generates links for the game player to the appropriate games. The user can then select which game to play by choosing one of the dynamically generated links.
6353439,"A system, method and computer program product are provided for a hardware implementation of a blending of &#8220;skinning,&#8221; during graphics processing in a graphics pipeline. During processing in the pipeline, a plurality of matrices and a plurality of weight values are received. Also received is vertex data to be processed. A sum of a plurality of products may then be calculated by the multiplication of the vertex data, one of the matrices, and at least of the weights. Such sum of products is then outputted for additional processing."
6362997,"A memory system is disclosed. The memory system comprises a circuit board and at least two memory devices mounted on the circuit board. Each of the at least two memory devices includes a plurality of pins for receiving and providing signals. At least a first portion of the pins of one of the at least two memory devices are coupled to at least a second portion of the pins of the other at least two memory devices such that a pair of the first portion coupled to a pin of the second portion forms a coupled load. The coupled load then appears as one load. Accordingly, in a system in accordance with the present invention, at least two memory devices are provided on a circuit board. Each of the at least two memory devices includes a plurality of pins. At least a portion of the pins of one of the two memory devices is in close proximity to and coupled to the at least a portion of the pins of the other of the at least two memory devices such that a pin and one memory device is coupled to a pin on the other memory device to form a coupled load. The coupled load then appears as one load. This is accomplished in a preferred embodiment by allowing the pins which are on opposite sides (front and back) of a printed circuit board to be represented as one load and then remapping one of the oppositely disposed pins to have the same functionality as the other oppositely disposed pin."
6374279,"A method and system are provided for efficiently implementing a dual finite impulse response (FIR) filter to vertically filter video data. A unique feedback mechanism enables multi-filter performance while implementing fewer actual filters and accompanying line delays than required in the available art. Advantageous placement of arithmetic elements is used to compensate for approximation error introduced by the feedback mechanism, resulting in substantially undiminished circuit performance in a more efficient circuit than currently available."
6380935,"A method performed in a graphics processor associates at least a portion (e.g. a triangle) of each primitive received from a CPU with each tile that is affected by the primitive (e.g. by storing the triangle in one or more tile-specific buffers, also called simply &#8220;tile buffer&#8221;). Moreover, the method stores packets that contain commands (also called &#8220;render commands&#8221;) for rendering the primitives (also called &#8220;command packets&#8221;) in a common buffer (called &#8220;broadcast buffer&#8221;), thereby to eliminate storage of the same commands in each tile buffer. The method repeats the just-described acts of associating primitives and storing command packets for each of a number of packets of primitives and commands that are generated by an application program for the display of a single frame. At a later time, the method uses the command packets from the broadcast buffer with primitives (or portions thereof) in each tile buffer tile, e.g. in one embodiment renders an image. The same render commands that are held in the broadcast buffer are used repeatedly, once for each tile buffer."
6417851,"A method and apparatus are provided for a lighting system for graphics processing. Included is a plurality of input buffers adapted for being coupled to a transform system for receiving vortex data therefrom. The input buffers include a first input buffer, a second input buffer and a third input buffer. An input of the first buffer, the second input buffer and the third input buffer are coupled to an output of the transform system. Further included is a multiplication logic unit having a first input coupled to an output of the first input buffer and a second input coupled to an output of the second input buffer. An arithmetic logic unit has a first input coupled to an output of the second input buffer. The arithmetic logic unit further has a second input coupled to an output of the multiplication logic unit. An output of the arithmetic logic unit is coupled to the output of the lighting system. Next provided is a first register unit having an input coupled to the output of the arithmetic logic unit and an output coupled to the first input of the arithmetic logic unit. A second register unit has an input coupled to the output of the arithmetic logic unit. Also, such second register has an output coupled to the first input and the second input of the multiplication logic unit. A lighting logic unit is also provided having a first input coupled to the output of the arithmetic logic unit, a second input coupled to the output of the first input buffer, and an output coupled to the first input of the multiplication logic unit. Finally, memory is coupled to at least one of the inputs of the multiplication logic unit and the output of the arithmetic logic unit. The memory has stored therein a plurality of constants and variables for being used in conjunction with the input buffers, the multiplication logic unit, the arithmetic logic unit, the first register unit, the second register unit, and the lighting logic unit for processing the vertex data."
6421059,"A system and method for rendering fonts into a memory is disclosed. The system and method comprises a data structure located within the memory. The data structure includes at least one font array. The method and system includes a graphics controller for accessing at least one font array in the memory and for rendering characters of at least one font array into the appropriate locations in the memory to be scanned onto a monitor. Accordingly, a system and method in accordance with the present invention provides for a plurality of font arrays to be provided within a memory of a computer system. The memory could be the frame buffer, system memory or any other memory within the computer system. The graphics controller includes a mechanism which allows for a font array to be accessed by the graphics controller. The graphics controller also includes a mechanism for allowing each font character to be rendered into the memory. In so doing, the number of transfers from the CPU is significantly reduced."
6437780,"A geometry tiler identifies tiles on a computer's screen that are covered by a graphics primitive by use of edges of the graphics primitive. Precise identification of tiles of various types (such as edge tiles covered by a segment) eliminates identification of one or more tiles that are merely located adjacent to the graphics primitive, but are not touched by the graphics primitive. For example, the geometry tiler can identify each of three types of tiles: vertex tiles, edge tiles and interior tiles. In one implementation, the geometry tiler identifies all tiles that are covered by a graphics primitive in the form of a convex polygon by: (a) determining attributes of at least one segment in the convex polygon, (b) determining iteration descriptors for each segment by using the attributes, (c) for each segment in the convex polygon, scanning the segment and identifying each edge tile that is covered by the segment, and (d) for each column of tiles in the screen, going from one edge tile in the column to another edge tile in the column and identifying each interior tile that is located within an area enclosed by the segments of the primitive. In one specific implementation, the geometry tiler simultaneously identifies edge tiles that are covered by two segments of the convex polygon that are located opposite to each other (such as a top segment and a bottom segment)."
6446186,"A method, apparatus and article of manufacture are provided for minimizing the number of look-ups in a page table entry (PTE) data structure during mapping of virtual addresses to physical addresses when the physical addresses consist of contiguous addresses. First, a primary virtual address in a PTE data structure is accessed for mapping physical memory. Next, it is determined whether a primary physical address corresponding to the accessed primary virtual address is associated with a physical page having at least one contiguous physical page. If it is determined that such contiguous physical page exists, information relating to both the primary virtual address and any virtual and physical contiguous addresses in the PTE data structure is retrieved in a single look-up."
6452595,"A graphics pipeline system is provided for graphics processing. Such system includes a transform module adapted for receiving vertex data. The transform module serves to transform the vertex data from a first space to a second space. Coupled to the transform module is a lighting module which is positioned on the single semiconductor platform for performing lighting operations on the vertex data received from the transform module. Also included is a rasterizer coupled to the lighting module and positioned on the single semiconductor platform for rendering the vertex data received from the lighting module. During use, an antialiasing feature is implemented to improve a quality of the graphics rendering."
6452603,"A circuit and process perform trilinear filtering using four texels (called &#8220;nearest texels&#8221;) that are nearest to a to-be-displayed pixel, and also using twelve additional texels (called &#8220;surrounding texels&#8221;) that surround the nearest texels. The nearest texels and the surrounding texels (together called &#8220;fine texels&#8221;) are all from only one level of detail L, while a filtered texel being generated is at another level of detail L+p, wherein p is a fractional level of detail. The filtered texel is used in rendering the to-be-displayed pixel, and can be identical to the texel obtained by trilinear filtering in the prior art. The circuit and process use fine texels to regenerate a quad of coarse texels that are used with a quad of the nearest texels to perform trilinear filtering. Alternatively, the circuit and process generate coefficients from the S and T coordinate fractions, and multiply the coefficients with the nearest texels and with summed texels (obtained by adding three surrounding texels and optionally the nearest texel), and add the products to obtain the filtered texel. In one implementation, a coarse texel regenerated from a number of fine texels is compared with another coarse texel pre-existing in a mipmap at the level of detail L+1, and in case of a match additional coarse texels are regenerated for the trilinear filtering in a single cycle. In case of no match, trilinear filtering is performed in two cycles using pre-existing coarse texels of the L+1 mipmap."
6462737,A graphics pipeline system is provided with an integrated clipping operation. First included is a transform module adapted for being coupled to a buffer to receive graphics data therefrom. Such transform module is positioned on a single semiconductor platform for transforming the graphics data from a first space to a second space. Also provided is a lighting module coupled to the transform module and positioned on the same single semiconductor platform as the transform module. The lighting module is adapted for performing lighting operations on the graphics data received from the transform module. A range clamp inversion function and a clipping operation are performed on the same single semiconductor platform as the transform module and the lighting module.
6469707,"A method and system for efficiently rendering and displaying the color intensity information of a pixel in a computer system is disclosed. The pixel includes a plurality of fragments. The method and system comprises providing a weighted average of a preselected number of the plurality of fragments for a pixel for a plurality of the color intensity information to a first portion of a register. The register is within a data structure in the computer system. The method and system also includes providing the color intensity information of a preselected number of fragments, except the one with the largest coverage to at least one additional portion of the register. The method and system further includes sending the information in the first portion and at least one additional portion to a memory in the computer system and sending the information in the first portion and at least one additional portion of the memory to a display. A method and system in accordance with the present invention allows one to eliminate the resolving step associated with the conventional A-buffer anti-aliasing scheme. Accordingly, it is cost-effective while maintaining image quality at a high level."
6477687,"Macrocells, e.g., Random Access Memory (&#8220;RAM&#8221;), are arranged in columns and disposed in a core of an integrated circuit (IC) chip. The macrocells can abut each other within the columns or can be separated from each other by standard cells which are disposed to fill gaps between the macrocells within the columns. Power/ground rails are disposed vertically along the sides of the columns. The power/ground rails run the full height of the core and couple to a power/ground ring disposed along the perimeter of the core. The power/ground rails also couple to the macrocells and the standard cells and provide power to those cells. The columns can form right angles with horizontal standard cell rows, thus enabling the standard cells to couple easily to the vertically disposed power/ground rails."
6480205,"Z-buffer rendering of three-dimensional scenes is made more efficient through a method for occlusion culling by which occluded geometry is removed prior to rasterization. The method uses hierarchical z-buffering to reduce the quantity of image and depth information that needs to be accessed. A separate culling stage in the graphics pipeline culls occluded geometry and passes visible geometry on to a rendering stage. The culling stage maintains its own z-pyramid in which z-values are stored at low precision (e.g., in 8 bits). The efficiency of hierarchical z-buffering is obtained through hierarchical evaluation of line and plane equations."
6489965,"A system, method and computer program product are provided for improving display characteristics in a computer graphics pipeline. Initially, color data is received from memory of the computer graphics pipeline. Thereafter, the saturation and/or sharpness of the color data is altered for improving display characteristics. Next, the color data is outputted for being displayed by a display device."
6496404,"A memory system is disclosed. The memory system comprises a circuit board and at least two memory devices mounted on the circuit board. Each of the at least two memory devices includes a plurality of pins for receiving and providing signals. At least a first portion of the pins of one of the at least two memory devices are coupled to at least a second portion of the pins of the other at least two memory devices such that a pair of the first portion coupled to a pin of the second portion forms a coupled load. The coupled load then appears as one load. Accordingly, in a system in accordance with the present invention, at least two memory devices are provided on a circuit board. Each of the at least two memory devices includes a plurality of pins. At least a portion of the pins of one of the two memory devices is in close proximity to and coupled to the at least a portion of the pins of the other of the at least two memory devices such that a pin and one memory device is coupled to a pin on the other memory device to form a coupled load. The coupled load then appears as one load. This is accomplished in a preferred embodiment by allowing the pins which are on opposite sides (front and back) of a printed circuit board to be represented as one load and then remapping one of the oppositely disposed pins to have the same functionality as the other oppositely disposed pin."
6502221,"A prototype development apparatus includes a logic board (LB) including a plurality of integrated circuit (IC) sites each adapted to receive an IC, logic traces coupled to each of the IC sites, and a plurality of logic board connector sites (LBCSs) configured to provide access to a number of the logic traces and each adapted to receive a connector. Additionally, a mezzanine board (MB) has a plurality of mezzanine board connector sites (MBCSs) each adapted to receive a connector and configured to provide access to a number of mezzanine traces interconnecting the LBCSs. The MB board is coupled to the LB and a portion of the logic traces are coupled to a portion of the mezzanine traces. In another embodiment the MB does not have any active components. This is because in this embodiment, the MB is configured to connect the pins of the connector sites according to a predetermined program. A method of prototyping a target circuit generates a netlist representative of the target circuit, divides the netlist into portions to be programmed into ICs on the LB and portions to be fabricated on the MB, such that the target circuit is configured from both the LB and the MB. Advantages of the present invention include providing a cost-effective technique for developing a prototype that combines the advantages of the custom prototype speed with the flexibility of the re-programmable emulators."
6504537,"A system, method and article of manufacture are provided for decomposing surfaces for rendering purposes during computer graphics processing. Initially, an interior mesh of primitives is defined in a surface to be rendered. Next, a plurality of surrounding meshes is defined along sides of the interior mesh. The exterior sides of the surrounding meshes each include a plurality of equally sized segments and at least one fractional segment that is a fraction of the equally sized segments. With this configuration, a pattern of triangles is used that permits the number of triangles to be varied continuously from frame to frame while accommodating incremental evaluation techniques such as forward differencing without visual artifacts such as popping."
6504542,"A method, apparatus and article of manufacture are provided for performing area rasterization using sense points. Upon receipt of a primitive, e.g. a triangle, line equation coefficients of line equations are determined for lines that define the primitive. Thereafter, a plurality of points is positioned on or near the primitive. Such points define an enclosed convex region. Next, the line equations are evaluated at the points. During operation, the points and convex region are moved based on the evaluation of the line equations for the purpose of identifying an area in the primitive for rendering pixels therein."
6515671,"A method, apparatus and article of manufacture are provided for managing vertex data in a vertex buffer. First, vertex data is received and stored in the vertex buffer. Thereafter, the vertex data is outputted from the vertex buffer to a processing module. During operation, a plurality of command bits is passed from the vertex buffer for determining a manner in which the vertex data is inputted and processed in the input buffer of the processing module. Such command bits are received from a command bit source. Further, a plurality of mode bits indicative of a status of a plurality of modes of process operations is passed. Such mode bits are received from a mode bit source. The mode bits are adapted for determining a manner in which the vertex data is processed in the processing module."
6532013,"A system, method and article of manufacture are provided for interweaving shading calculations and texture retrieval operations during texture sampling in a graphics pipeline. First, a shading calculation is performed in order to generate output. Next, texture information is retrieved, and another shading calculation is performed using the texture information in order to generate additional output. Texture information may be retrieved and shading calculations may then be repeated as desired. Thereafter, the generated output may be combined. As such, the repeated texture information retrieval and shading calculations may be carried out in an iterative, programmable manner."
6535209,"A computer graphics system splits vertex data into first and second streams and stores the streams in separate regions of memory. In a specific embodiment, the first stream includes positional data and the second stream includes non-positional color and texture data. A visibility subsystem uses only the first stream to perform visibility processing, thus reducing bandwidth requirement. The rendering system processes data from subsets, identified by the visibility subsystem, of both streams required to render the visible part of a scene."
6542971,"A buffering system attached to a memory for holding write-once, read-once data that is accessed by one or more peripheral devices. Data that is otherwise destined to be written to main memory is written, instead, into a storage buffer. The buffer is written using an address contained in a write pointer that is updated according to a predetermined pattern after the write operation. After updating the write pointer, if the address equals the read pointer, some or all of the buffer is flushed to the memory. Data is read from the buffer using an address contained in a read pointer that is updated according to the same predetermined pattern after the read operation. Any deviation from the pattern in either writing or reading the buffer causes the some or all of the buffer to be flushed to main memory and the read pointer to be updated accordingly."
6573900,"A method, apparatus and article of manufacture are provided for sequencing graphics processing in a transform or lighting operation. A plurality of mode bits are first received which are indicative of the status of a plurality of modes of process operations. A plurality of addresses are then identified in memory based on the mode bits. Such addresses are then accessed in the memory for retrieving code segments which each are adapted to carry out the process operations in accordance with the status of the modes. The code segments are subsequently executed within a transform or lighting module for processing vertex data."
6577309,"A graphics pipeline system is provided with a transform module positioned on a single semiconductor platform for transforming graphics data. Also included is a lighting module positioned on the same single semiconductor platform as the transform module for lighting the graphics data. In use, various operations may be performed utilizing the single semiconductor platform such as rendering, fog operations, blending, coloring operations, etc."
6577320,"A method is provided for processing multiple types of pixel component representations. The method first includes identifying a plurality of texels in a texture pattern grid that correspond to a pixel. Thereafter, information components of the pixel, i.e. R, G, B, and &agr; are multiplied if the information components of the pixel are in a postmultiplied representation. Further, a colorkeyed replacement operation is carried out if the information components of the pixel are in a colorkeyed representation and at least one of the texels substantially matches a colorkey. Next, a position is interpolated on the texture pattern grid between the texels that corresponds to the pixel. Finally, the information components of the pixel are filtered."
6593923,"A system, method and article of manufacture are provided for shadow mapping while rendering a primitive in a graphics pipeline. Initially, an offset operation is performed in order to generate a depth value while rendering a primitive. Further, a value of a slope associated with an edge of the primitive is identified. Thereafter, the depth value is conditionally clamped based on the value of the slope."
6597356,"An integrated graphics pipeline system is provided for graphics processing. Such system includes a tessellation module that is positioned on a single semiconductor platform for receiving data for tessellation purposes. Tessellation refers to the process of decomposing either a complex surface such as a sphere or surface patch into simpler primitives such as triangles or quadrilaterals, or a triangle into multiple smaller triangles. Also included on the single semiconductor platform is a transform module adapted to transform the tessellated data from a first space to a second space. Coupled to the transform module is a lighting module which is positioned on the single semiconductor platform for performing lighting operations on the data received from the transform module. Also included is a rasterizer coupled to the lighting module and positioned on the single semiconductor platform for rendering the data received from the lighting module."
6600488,"A system, method and article of manufacture are provided for decomposing surfaces for rendering purposes during computer graphics processing. Initially, an interior mesh of primitives is defined in a surface to be rendered. Next, a plurality of surrounding meshes is defined along sides of the interior mesh. The exterior sides of the surrounding meshes each include a plurality of equally sized segments and at least one fractional segment that is a fraction of the equally sized segments. With this configuration, a pattern of triangles is used that permits the number of triangles to be varied continuously from frame to frame while accommodating incremental evaluation techniques such as forward differencing without visual artifacts such as popping."
6614448,"A graphics processor displays pixels in an image at non-uniform resolution, using a maximum resolution in the interior of a surface in the image, and a lower resolution at edges. Higher color resolution in the interior eliminates color aliasing that would otherwise be caused if the interior were displayed at the lower resolution. Lower resolution at the edges is not noticeable to the human eye, and allows the graphics processor to use one or more low resolution color signals in generating the displayed image, thereby reducing hardware (e.g. memory locations required to store such signals, and lines required to route such signals). One such processor (not necessarily a graphics processor) includes a resolution reducer and a resolution enhancer that respectively reduce and enhance the resolution of a signal. Specifically, the resolution reducer reduces the resolution of a high resolution signal to generate a low resolution signal. The resolution enhancer enhances the low resolution signal to generate a signal (called &#8220;enhanced resolution signal&#8221;) having the same number of bits as the high resolution signal. One such resolution reducer simply drops a number of least significant bits to generate a low resolution signal, and the corresponding resolution enhancer passes, as the enhanced resolution signal, the low resolution signal and the above-described number of least significant bits of a high resolution signal. The enhanced resolution signal is not a significant aspect of one embodiment because in some embodiments the low resolution signal and the high resolution signal are used directly."
6618842,"A prototype development apparatus includes a logic board (LB) including a plurality of integrated circuit (IC) sites each adapted to receive an IC, logic traces coupled to each of the IC sites, and a plurality of logic board connector sites (LBCSs) configured to provide access to a number of the logic traces and each adapted to receive a connector. Additionally, a mezzanine board (MB) has a plurality of mezzanine board connector sites (MBCSs) each adapted to receive a connector and configured to provide access to a number of mezzanine traces interconnecting the LBCSs. The MB board is coupled to the LB and a portion of the logic traces are coupled to a portion of the mezzanine traces. In another embodiment the MB does not have any active components. This is because in this embodiment, the MB is configured to connect the pins of the connector sites according to a predetermined program. A method of prototyping a target circuit generates a netlist representative of the target circuit, divides the netlist into portions to be programmed into ICs on the LB and portions to be fabricated on the MB, such that the target circuit is configured from both the LB and the MB. Advantages of the present invention include providing a cost-effective technique for developing a prototype that combines the advantages of the custom prototype speed with the flexibility of the re-programmable emulators."
6624811,"A system, method and article of manufacture are provided for decomposing surfaces using guard curves for rendering purposes during computer graphics processing. Initially, a patch is received. Thereafter, a plurality of strip curves associated with the patch is defined in a first predetermined direction. As such, areas are defined by the strip curves which are adapted for being decomposed into a plurality of primitives. Next, at least one guard curve associated with the patch is generated. The guard curve is positioned along ends of the strip curves and in a second predetermined direction perpendicular with respect to the first predetermined direction."
6628290,"A method and graphics accelerator apparatus for pipelined generation of output values for a sequence of pixels, with generation of output values for each of at least two textured pixels during each pipeline clock interval. The apparatus includes a combiner stage capable of producing output values during each clock interval of the pipeline, wherein the output values are indicative of a blend of a plurality of textures with a single pixel when the combiner stage operates in a first mode, and the output values are indicative of a blend of an individual texture with two pixels when the combiner stage operates in a second mode."
6629188,"A cache memory apparatus for graphics and other systems. The cache memory apparatus includes a cache memory having a first number of cache lines, each cache line addressable by a cache line address; a first plurality of storage elements coupled to a first address bus; and a second plurality of storage elements coupled to the first plurality of storage elements. The first plurality of storage elements holds a second number of cache line addresses, and the second plurality of storage elements holds a third number of cache line addresses."
6636212,"A display is partitioned into a plurality of cells. Each of the plurality of cells includes a depth interval and a coverage for each of a plurality of surfaces having coverage within the cell. A depth interval and a coverage for a group of pixels having coverage within one or more of the cells is received. Visibility of the group of pixels, for each of the one or more cells, is determined based on comparisons of the depth interval of the group of pixels with the depth intervals of the plurality of surfaces."
6636215,"Roughly described, the invention is employed within a z-buffer-system having a host processor and graphics hardware that performs hierarchical z-buffering. The z-buffer system renders three-dimensional scenes having geometric primitives that are organized in bounding boxes or rooms-with-portals. As an image is being generated, some but not all z-pyramid values are written from the graphics system into memory that can be quickly accessed by the host processor. This enables the host processor to perform visibility tests that cull occluded bounding boxes or portals, thereby accelerating rendering by reducing the number of primitives that need to be sent to graphics hardware and processed."
6636227,A method and apparatus for grouping texture data to increase storage throughput. Texels are addressed and stored according to adjacency to enable retrieval of a plurality of texels (a cache entry) with only a single address space request. Individual texel position is then derived using a simple adjacency formula. The preferred method and apparatus are compatible with both tiled data and linear data storage formats.
6646639,"A system, method and computer program product are provided for avoiding reading z-values in a graphics pipeline. Initially, near z-values are stored which are each representative of a near z-value on an object in a region. Such region is defined by a tile and a coverage mask therein. Thereafter, the stored near z-values are compared with far z-values computed for other objects in the region. Such comparison indicates whether an object is visible in the region. Based on the comparison, z-values previously stored for image samples in the region are conditionally read from memory."
6647456,"At memory controller system is provided including a plurality of memory controller subsystems each coupled between memory and one of a plurality of computer components. Each memory controller subsystem includes at least one queue for managing pages in the memory. In use, each memory controller subsystem is capable of being loaded from the associated computer component independent of the state of the memory. Since high bandwidth and low latency are conflicting requirements in high performance memory systems, the present invention separates references from various computer components into multiple command streams. Each stream thus can hide precharge and activate bank preparation commands within its own stream for maximum bandwidth. A page context switch technique may be employed that allows instantaneous switching from one look ahead stream to another to allow low latency and high bandwidth while preserving"
6650325,"A method, apparatus and article of manufacture are provided for performing rasterization using alternating sense point traversal. Upon receipt of a primitive, i.e. a triangle, a plurality of points are positioned on or near the primitive. Such points define an enclosed convex region and may be located at corners of the convex region. In operation, the points and convex region are moved in an alternating manner for the purpose of identifying an area in the primitive for rendering pixels therein. In particular, the points are moved in a boustrophedonic manner."
6650330,"A method, apparatus and article of manufacture are provided for sequencing graphics processing in a transform or lighting operation. A plurality of mode bits are first received which are indicative of the status of a plurality of modes of process operations. A plurality of addresses are then identified in memory based on the mode bits. Such addresses are then accessed in the memory for retrieving code segments which each are adapted to carry out the process operations in accordance with the status of the modes. The code segments are subsequently executed within a transform or lighting module for processing vertex data."
6650331,A graphics pipeline system is provided with an integrated scissor operation. First provided is a transform module adapted for being coupled to a buffer to receive graphics data therefrom. Such transform module is positioned on a single semiconductor platform for transforming the graphics data from a first space to a second space. Associated therewith is a lighting module coupled to the transform module and positioned on the same single semiconductor platform as the transform module for performing lighting operations on the graphics data received from the transform module. A scissor operation is performed on the same single semiconductor platform as the transform module and the lighting module.
6657635,"Methods and systems for optimizing graphics data processing employ various binning flush algorithms to optimize the utilization of binning memory in a graphics system. Binning flush algorithms provide for processing all geometry and commands binned up to the point the binning memory becomes unavailable, and storing and restoring all necessary intermediate data generated during the partial tile rendering."
6664963,"A system, method and computer program product are provided for performing shader calculations in a graphics pipeline. Initially, a shading calculation is performed in order to generate output. Thereafter, an additional shading calculation is carried out. Such additional shading calculation includes converting the output of the shading calculation into a floating point format. Further, a dot product is calculated utilizing the converted output and texture coordinates. The dot product is then clamped. Next, the clamped dot product is stored in a plurality of color components."
6677953,A system and method are provided for a dedicated hardware-implemented viewport operation in a graphics pipeline. Included is a transform/lighting module for transforming and lighting vertex data. Also provided is viewport hardware coupled to the transform/lighting module for performing a viewport operation on the vertex data. A rasterizer is coupled to the viewport hardware for rendering the vertex data.
6690372,"A system, method and article of manufacture are provided for shadow mapping while rendering a primitive in a graphics pipeline. Initially, an offset operation is performed in order to generate a depth value while rendering a primitive. Further, a value of a slope associated with an edge of the primitive is identified. Thereafter, the depth value is conditionally clamped based on the value of the slope."
6691180,"A direct memory access (DMA) circuit which is physically positioned with an input/output device, the DMA circuit storing a first reference value pointing to a data structure which describes a buffer portion of system memory in which data is stored for transfer to the I/O device, a value determining a position within the buffer portion of system memory beginning at which a next sequence of data is to be placed, and a value determining a position within the buffer portion of system memory from which a next sequences of data is to be copied to the I/O device, the DMA circuit including circuitry for reading data from the buffer portion of system memory beginning at the position from which a next sequences of data is to be copied and for writing the data read to the I/O device."
6697063,"A rendering pipeline system for a computer environment uses screen space tiling (SST) to eliminate the memory bandwidth bottleneck due to frame buffer access and performs screen space tiling efficiently, while avoiding the breaking up of primitives. The system also reduces the buffering size required by SST. High quality, full-scene anti-aliasing is easily achieved because only the on-chip multi-sample memory corresponding to a single tile of the screen is needed. The invention uses a double-z scheme that decouples the scan conversion/depth-buffer processing from the more general rasterization and shading processing through a scan/z engine. The scan/z engine externally appears as a fragment generator but internally resolves visibility and allows the rest of the rendering pipeline to perform setup for only visible primitives and shade only visible fragments. The resulting reduced raster/shading requirements can lead to reduced hardware costs because one can process all parameters with generic parameter computing units instead of with dedicated parameter computing units. The invention processes both opaque and transparent geometries."
6697064,"A system, method and computer program product are provided for tracking a matrix during vertex processing. Initially, a request is received to track a matrix. Such matrix is identified in the request. The identified matrix is then tracked for vertex processing. In one aspect of the present embodiment, a version, type, and/or name of the matrix is identified in the request."
6704010,"A system, method and article of manufacture are provided for converting triangular patches into a form suitable for being rendered using a graphics pipeline adapted to render quadrilateral patches. First, a triangular patch is received. The received triangular patch is then divided into a plurality of quadrilateral patches. Such quadrilateral patches are suitable for being processed by a graphics pipeline specifically equipped to render quadrilateral patches."
6704025,"A system and method are provided for improved shadow mapping in a graphics pipeline. Raw depth values are initially collected from two depth layers in a scene to be rendered. Shadow-map depth values are then calculated utilizing the raw depth values. The scene is then shadow mapped utilizing the shadow-map depth values in order to improve the appearance of shadows in a rendered scene. The various steps are carried out by a hardware-implemented graphics pipeline, which may include texturing or shadowing mapping hardware."
6720975,"A system, method, and computer program product are provided for antialiasing during rendering in a graphics pipeline. Initially, a primitive of vertex data is received in a graphics pipeline. Next, a super-sampling operation is performed on the primitive of vertex data ufilizing the graphics pipeline. Further, a multi-sampling operation is performed on the primitive of vertex data utilizing the graphics pipeline."
6724394,"A system and associated method are provided for processing pixel data in a graphics pipeline. Included is a triangle module coupled to a rasterizer for calculating a plurality of equations using pixel data received from the rasterizer. Also provided is a shader core module coupled to the rasterizer for receiving the pixel data therefrom. The shader core module is further coupled to the triangle module for receiving the equations therefrom. The shader core module functions to execute floating point calculations and generating texture coordinates using the pixel data. Coupled to the shader core module is a texture module. The texture module is capable of looking up texture values using the texture coordinates. Associated therewith is a shader back end module coupled to the texture module and the triangle module. The shader back end module is capable of converting the texture values to an appropriate floating point representation and generating color values using the equations. Still yet, a combiner module is coupled to the shader core module and the shader back end module. Such combiner module combines the color values and the texture values."
6724395,"A system, method and article of manufacture are provided for anisotropic filtering during texture sampling. A description of a region, e.g. pixel footprint in a source image, to be texture sampled is initially received. Thereafter, the region is subdivided based on the description into a plurality of samples with a predetermined shape for mapping textures onto the samples. By subdividing the region in the source image into a plurality of samples having a predetermined shape, the region may be covered by samples that may be configured to be more suitable for an underlying process such as MIP mapping, thus allowing efficient texture sampling while reducing blurring, aliasing and other visual artifacts."
6725457,"A process of coordinating access to a shared resource by a plurality of execution units is provided. Channel control units are used to coordinate access to a shared resource. Each channel control unit reads semaphore values of a semaphore storage unit. In response to synchronization commands and semaphore values, the channel control unit manages the flow of execution instructions to the execution units in order to manage access to the shared resource."
6731298,"A system, method and article of manufacture are provided for computer graphics processing. First, pixel data is received including a depth-value. Thereafter, the depth-value is modified based on a depth-component of an algorithm. An operation is subsequently performed on the pixel data taking into account the modified depth-value."
6734861,"A system, method and article of manufacture are afforded for providing an interlock module in a graphics pipeline. initially, first information is received indicative of a first set of pixels that overlap a primitive. Such first set of pixels are currently being processed in the graphics pipeline. Also received is second information indicative of a second set of pixels that overlap the primitive. The second set of pixels are ready for being inputted in the graphics pipeline for processing. Thereafter, the first information and the second information are evaluated, and the second set of pixels is conditionally processed based on the evaluation."
6734874,"A method, apparatus and article of manufacture are provided for handling both scalar and vector components during graphics processing. To accomplish this, vertex data is received in the form of vectors after which vector operations are performed on the vector vertex data. Next, scalar operations may be executed on an output of the vector operations, thereby rendering vertex data in the form of scalars. Such scalar vertex data may then be converted to vector vertex data for performing vector operations thereon."
6738062,"A representation is provided for displacement mapping. Included are a coarse first mesh, and a fine second mesh with a topology substantially similar to a topology of the first mesh. The second mesh includes a plurality of scalar values which each represent an offset between various points on the first mesh and the second mesh."
6744433,"A system and method are provided for using information from at least one depth layer and for collecting information about at least one additional depth layer utilizing a graphics pipeline. Initially, constraining depth layers are provided which, in turn, define a plurality of depth constraints. Next, a plurality of tests is performed involving the constraining depth layers for collecting information about at least one additional depth layer. The information relating to the at least one depth layer may then be used to improve processing in the graphics pipeline. By the foregoing multiple tests, information relating to a plurality of depth layers may be collected during each of a plurality of rendering passes. Initially, information relating to the constraining depth layers and associated depth constraints is provided in the aforementioned manner. Thereafter, information relating to at least one additional depth layer is collected during additional rendering passes using multiple tests on each rendering pass. Once collected, such information relating to the constraining depth layers and the information relating to the at least one additional depth layer may be used to further improve processing in the graphics pipeline."
6750646,"An apparatus for environmental testing of a device under test (DUT), such as a printed circuit board. The apparatus generally includes a chamber for environmentally isolating the DUT with the DUT in situ and functional on another device (e.g., a motherboard). The DUT can be subjected to an environmental test condition inside the chamber while the other device is isolated from the environmental test condition. The chamber may have a connector for coupling the other device and the DUT, such that the DUT and the other device are in communication although in isolated environments."
6750862,"A method and system for performing enhanced lighting functions with respect to texture map data is operable within a computer controlled graphics display system and allows defined portions of a texture map to bypass prescribed lighting processes. Within a texture map, each texel data (u,v) is defined to contain color information and a control code (e.g., &#8220;texel light bit&#8221;). The texel light bit indicates to the lighting process whether or not texel color modulation is to occur to this texel data. In one embodiment, if the texel light bit is set, then no lighting modifications (e.g., color modulations) are performed with respect to the texel data. Also, if the texel light bit is not set, then normal lighting modifications are performed with respect to the texel data. In this way, the present invention allows texture map data to be lit in a non-uniform manner across a same graphics primitive. The present invention is particularly useful with respect to graphics objects (e.g., lights, indicator bulbs, glowing regions of the texture map) which should remain unaffected by external light sources (e.g., the sun, the moon, darkness of the night) within a three-dimensional graphic scene. By defining certain texel regions as having &#8220;texel lights&#8221;, the present invention then bypasses the external lighting conditions applied to the display scene for these regions."
6760032,"A system and method are provided for executing a cellular automata program in a hardware graphics pipeline. Initially, cell values are received in a hardware graphics pipeline. Next, the cell values are rendered to generate a condition value utilizing the hardware graphics pipeline. A cell value result for the subsequent generation is read from a rule map according to the condition value utilizing the hardware graphics pipeline. Still yet, additional cell values are stored based on the rule map value."
6760035,"A method to perform image transformations that are simplistic, conducive to miniaturization, and inexpensive to implement is provided. Transformations of an image stored in system memory are carried out by copying the image data, transforming the image data to a selected orientation, and outputting the transformed image for display, printing, or others. Throughout the transformation process, the image stored in system memory remains unchanged in the original orientation (T0-normal transformation). The transformation process is carried out by accessing in predetermined orders/sequences the image data copied from system memory to a frame buffer that is made up of N memory modules and arranged such that image data are stored serially with the image scan lines running the length of the frame buffer like that of a traditional frame buffer but with each memory module capable of being individually accessed. A line stride value S has been specifically derived to control the location of corresponding pixels of N adjacent rows of the image data so that these pixels appear in N different memory modules. In so doing, the start of each scan line (and consequently image data associated with the scan line) can be individually accessed by accessing a memory module. Such access makes it easier to manipulate the image data to perform different types of image transformations."
6765575,"Clip-less rasterization is provided by a plurality of operations. First, a primitive is received that is defined by a plurality of vertices. Each of such vertices includes a W-value. Thereafter, an area is identified based on the W-values. Such area is representative of a portion of a display to be drawn corresponding to the primitive."
6765584,"A system and method are provided for creating a vector map in a hardware graphic pipeline. Initially, one of a plurality of transforms is selected in a hardware graphic pipeline. Further, input is processed in order to generate a vector map utilizing the selected transform in the hardware graphics pipeline. Subsequently, a plurality of pixel color values is rendered utilizing the vector map."
6765901,"An Internet network protocol stack, along with special logic, is embedded with a modem, thereby enabling a modem to become Internet-ready. As a result, the modem offloads much of the network protocol processing from the main CPU and improves the overall performance of the communication system."
6768487,"Z-buffer rendering of three-dimensional scenes is made more efficient through a method for occlusion culling by which occluded geometry is removed prior to rasterization. The method uses hierarchical z-buffering to reduce the quantity of image and depth information that needs to be accessed. A separate culling stage in the graphics pipeline culls occluded geometry and passes visible geometry on to a rendering stage. The culling stage maintains its own z-pyramid in which z-values are stored at low precision (e.g., in 8 bits). The efficiency of hierarchical z-buffering is improved through hierarchical evaluation of line and plane equations."
6768493,"A system, method and article of manufacture are provided for efficient storage of texture data in memory for use with a computer graphics pipeline. Provided is a data structure including at least one compressed sub-block representing a group of texels in a predetermined image plane and at predetermined locations in a first and a second dimension in a texture map. A number of the sub-blocks is based on a depth of texture data in the texture map."
6774895,"A system, method and computer program product are provided for depth clamping in a hardware graphics pipeline. Initially, a depth value is identified. It is then determined as to whether a hardware graphics pipeline is operating in a depth clamping mode. If the hardware graphics pipeline is operating in the depth clamping mode, the depth value is clamped within a predetermined range utilizing the hardware graphics pipeline."
6778176,"A method, apparatus and article of manufacture are provided for sequencing graphics processing in a transform or lighting operation. A plurality of mode bits are first received which are indicative of the status of a plurality of modes of process operations. A plurality of addresses are then identified in memory based on the mode bits. Such addresses are then accessed in the memory for retrieving code segments which each are adapted to carry out the process operations in accordance with the status of the modes. The code segments are subsequently executed within a transform or lighting module for processing vertex data."
6778181,A graphics processing system is provided. The graphics processing system includes a front end module for receiving pixel data. A setup unit is coupled to the front end module and generates parameter coefficients. A raster unit is coupled to the setup unit and generates stepping information. A virtual texturing array engine textures and colors the pixel data based on the parameter coefficients and stepping information. Also provided is a pixel engine adapted for processing the textured and colored pixel data received from the virtual texturing array engine.
6778189,"A system, method and computer program product are provided for two-sided stencil testing during graphics processing. Initially, primitives are received to be processed in a graphics processing pipeline. In use, it is then determined whether the graphics processing pipeline is operating with same-sided stencil testing enabled. If same-sided stencil testing is not enabled, the primitives are passed without same-sided stencil testing and two-sided stencil testing. If, on other hand, same-sided stencil testing is enabled, it is determined whether the graphics processing pipeline is operating with two-sided stencil testing enabled. If the two-sided stencil testing is enabled and the same-sided stencil testing is enabled, two-sided stencil testing is performed on the primitives. If, on the other hand, the two-sided stencil testing is disabled and the same-sided stencil testing is enabled, same-sided stencil testing is performed on the primitives."
6778390,"An apparatus and method are described for cooling electronic components on a plug-in or other computer board placed within an enclosure. The inventive apparatus and system is capable of cooling a high power dissipating device, such as a Graphics Processing Unit and cooling individual ones of a plurality of other devices, such as memory chips, to within a specified temperature range. In one embodiment, cooling air is drawn from the edge of a plug-in card, over the GPU and is directed along and over arrays of memory chips. By directing the flow on and along the memory chips, a flow is established that maintains the chip-to-chip temperature difference to within a desired, uniform range. The invention allows for the incorporation of higher performance processors onto boards while maintaining memory chips within a temperature range that allows for predictable performance."
6779069,"Apparatus for a baseband-media interface is described. More particularly, in an embodiment, a baseband processor, a medium access controller and a baseband-media interface are provided with a input/output controller as an integrated circuit. In another instance, a baseband processor, a medium access controller and a baseband-media interface are provided on a printed circuit board and coupled to an input/output controller via a bus. The printed circuit board may be a system board or a peripheral card."
6779170,"Method and apparatus for providing logic emulation. Specifically, the present invention provides logic emulation by using waferscale integration."
6788312,"A system, method and computer program product are provided for improving image quality in a graphics pipeline. Initially, a difference is detected between a first pixel of a first frame to be outputted and a corresponding second pixel of a second frame outputted before the first frame. Such difference may be representative of motion which is capable of reducing image quality. A pixel output is then modified if such a difference is detected. This is accomplished utilizing texturing hardware in the graphics pipeline. Thereafter, the pixel output is outputted via a progressive or interlaced display system."
6797998,"A multi-configuration interface device for coupling different types of GPUs (graphics processor units) to a PCB (printed circuit board). The interface device comprises a GPU interface for a connection to the GPU and a PCB interface for a connection to the PCB. The GPU interface is implemented using a customizable attachment footprint for effectuating a connection to differing GPU types while maintaining the PCB interface for the connection to the PCB. The ball array for different GPUs can be configured to respectively support them. The interface device maintains a consistent PCB interface. Thus, as GPU characteristics change and evolve, or as different GPU versions are implemented, a consistent connection can be maintained for the PCB."
6806886,"A system, method and article of manufacture are provided for converting color data into floating point values in a graphics pipeline. First, color data is received. Next, the color data is separated into a plurality of components each including an integer. The components of color data are then converted into floating point values by dividing at least a portion of the components by predetermined numbers."
6809732,"A graphics subsystem having a programmable shader controllable by both state-based control information, such as DirectX 8 control information, and program instructions, such as DirectX 9 shader program instructions. The programmable shader translates state-based control information received from a host computer into native control information. The programmable shader translates into native control information program instructions fetched from memory locations identified by a received memory reference and program instructions received from the graphics subsystem. Native control information configures computation units of the programmable shader. The programmable shader optimizes the generated native control information by combining certain operations. The graphics subsystem detects memory references sent from the host computer and pre-fetches program instructions for transmission to the programmable shader. Native control information from multiple control sources is concurrently used in the programmable shader."
6812927,"A system and method are provided for reducing the number of depth clear operations in a hardware graphics pipeline. Initially, a frame count is stored into a frame buffer associated with the hardware graphics pipeline. The stored frame count is associated with a pixel. A depth clear operation is then performed based at least in part on the frame count utilizing the hardware graphics pipeline."
6820173,"A system, method and article of manufacture are provided for retrieving information from memory. Initially, processor requests for information from a first memory are monitored. A future processor request for information is then predicted based on the previous step. Thereafter, one or more speculative requests are issued for retrieving information from the first memory in accordance with the prediction. The retrieved information is subsequently cached in a second memory for being retrieved in response to processor requests without accessing the first memory. By allowing multiple speculative requests to be issued, throughput of information in memory is maximized."
6825840,"The present invention is related to rendering computer animated video and/or images generally, and to adjusting the origins of rays cast for object-edge positions. The present invention includes identifying a location of a vertex positioned on a perimeter of an object defined in the object scene by a plurality of vertices. The plurality of vertices include the vertex positioned on the perimeter of the object. A shading position that corresponds to, but is offset from, the vertex is then established. A shading value is then computed for the vertex by reference to the shading position. The shading value may be computed, for example, by casting a ray from the shading position."
6825843,"A method and apparatus for executing loop and branch program instructions in a programmable graphics shader. The programmable graphics shader converts a sequence of instructions comprising a portion of a shader program and selects a first set of fragments to be processed. Subsequent sequences of instructions are converted until all of the instructions comprising the shader program have been executed on the first set of fragments. Each remaining set of fragments is processed by the shader program until all of the fragments are processed in the same manner. Furthermore, the instructions can contain one or more loop or branch program instructions that are conditionally executed. Additionally, when instructions within a loop as defined by a loop instruction are being executed a current loop count is pipelined through the programmable graphics shader and used as an index to access graphics memory."
6825847,"A system and method are provided for the compression of pixel data for communicating the same with a frame buffer. Initially, a plurality of samples is received. It is first determined whether the samples are reducible, in that a single sample value can take the place of a plurality of sample values. If it is determined that the samples are capable of being reduced, the samples are reduced. Reduction is a first stage of compression. It is then determined whether the samples are capable of being compacted. The samples are then compacted if it is determined that the samples are capable of being compacted. Compaction is a second stage of compression. The samples are then communicated with a frame buffer, in compressed form, if possible, in uncompressed form if not. Subsequent reading of frame buffer data takes advantage of the smaller transfer size of compressed data. Compressed data is uncompacted and expanded as necessary for further processing or display. Where possible, data is processed reduced, rather than expanded, to minimize the amount of processing required and transfer bandwidth required. This system and method accelerate the rendering and display of computer-generated images."
6828980,"A system, method and computer program product are provided for computer graphics processing. Initially, a height parameter is determined. Thereafter, a depth-direction component of the height parameter is calculated. A depth-value of a pixel is then modified utilizing the computed depth-direction component of the height parameter."
6829689,"A method and system for arbitrating among memory access commands from clients seeking access to a DRAM or other memory, and an arbiter for use in implementing such method or system. When arbitrating among competing commands that include at least one command of the same read/write type as the current command, the arbiter selects a command of the same read/write type as the current command. In a wait mode, when arbitrating among a set of the commands that includes no command of the same read/write type as the current command, the arbiter prevents each command in the set from reaching the memory. Preferably, after operating in the wait mode for a limited time, the arbiter enters another arbitration mode in which it can select a command of the opposite read/write type as the current command. Preferably, the arbiter is implemented to be operable in any of multiple operating modes. Preferably, the arbiter monitors for occurrence of potential page fault conditions."
6844880,"A system, method and computer program product are provided for branching during programmable processing in a computer graphics pipeline. Initially, data is received. Programmable operations are then performed on the data in order to generate output. Such operations are programmable by a user utilizing instructions from a predetermined instruction set. When performing the programmable operations in the foregoing manner, programmable branching may take place between the programmable operations. Subsequently, the output is stored in memory. Also included is a system, method and computer program product for directly executing a function in the computer graphics pipeline. Initially, input data is received in the computer graphics pipeline. A mathematical function is directly performed on the input data in order to generate output data. It should be noted that the mathematical function is directly performed in the computer graphics pipeline without a texture look-up or aid from a central processing unit. Next, the output data is stored in memory on the computer graphics pipeline."
6848057,"A novel method and apparatus for providing a decoupled power management state. The present invention decouples the operating system's perspective of the power management state from that of the actual hardware state of a host resource. Namely, the resources of a host computer can still operate and provide functionality while the host operating system is “off”, while still providing power saving to the host system and user."
6850243,"A system, method and computer program product are provided for texture sampling in a graphics pipeline. Initially, texture information is retrieved using texture coordinates. Thereafter, the texture information is utilized to generate results. Next, the texture information and the results are utilized to generate further results. The foregoing operation may optionally be repeated, and the results outputted."
6853377,"The present invention is related to rendering computer animated video and/or images generally, and to improving the calculation of diffusely reflected light. The present invention includes a system and method of computing diffusely reflected light at one or more positions on surfaces in an object scene from object scene data. The present invention typically includes the step of and/or instructions for selecting a non-regular order for processing a plurality of positions on a surface—the plurality of positions having been predetermined. The present invention also includes the step of and/or instruction for processing the plurality of positions in the non-regular order. This processing typically includes computing diffusely reflected light at a position in the plurality of positions by reference to diffusely reflected light incident on the position when deriving the diffusely reflected light at the position by reference to diffusely reflected light at other positions computed by reference to diffusely reflected light incident on the other positions is inaccurate. Alternatively, deriving the diffusely reflected light at the position by reference to the diffusely reflected light at the other positions computed by reference to diffusely reflected light incident on the other positions when deriving the diffusely reflected light at the position by reference to the diffusely reflected light at the other positions is accurate."
6853382,"A memory system having a number of partitions each operative to independently service memory requests from a plurality of memory clients while maintaining the appearance to the memory client of a single partition memory subsystem. The memory request specifies a location in the memory system and a transfer size. A partition receives input from an arbiter circuit which, in turn, receives input from a number of client queues for the partition. The arbiter circuit selects a client queue based on a priority policy such as round robin or least recently used or a static or dynamic policy. A router receives a memory request, determines the one or more partitions needed to service the request and stores the request in the client queues for the servicing partitions. In one embodiment, an additional arbiter circuit selects memory requests from one of a subset of the memory clients and forwards the requests to a routing circuit, thereby providing a way for the subset of memory clients to share the client queues and routing circuit. Alternatively, a memory client can make requests directed to a particular partition in which case no routing circuit is required. For a read request that requires more than one partition to service, the memory system must collect the read data from read queues for the various partitions and deliver the collected data back to the proper client. Read queues can provide data in non-fifo order to satisfy an memory client that can receive data out-of-order."
6856320,"A memory system and methods of operating the same that drastically increase the efficiency in memory use and allocation in graphics systems. In a graphics system using a tiled architecture, instead of pre-allocating a fixed amount of memory for each tile, the invention dynamically allocates varying amounts of memory per tile depending on the demand. In one embodiment all or a portion of the available memory is divided into smaller pages that are preferably equal in size. Memory allocation is done by page based on the amount of memory required for a given tile."
6864893,"A method and apparatus for generating depth values in a programmable graphics system. Depth values are calculated under control of a pixel program using a variety of sources as inputs to programmable computation units (PCUs) in the programmable graphics systems. The PCUs are used to compute traditional interpolated depth values and modified depth values. Th PCUs are also used to compute arbitrary depth values which, unlike traditional interpolated depth values and modified depth values, are not dependent on the coordinates of the geometry primitive with which the arbitrary depth values are associated. Several sources are available as inputs to the PCUs. Clipping with optional clamping is performed using either interpolated depth values or calculated depth values, where calculated depth values are arbitrary depth values or modified depth values. Final depth values, used for depth testing, are selected from interpolated depth values and arbitrary depth values after clipping is performed."
6867780,"A system, method, and article of manufacture are provided for allowing direct memory access to graphics vertex data by a graphics accelerator module. First, vertex data is stored in memory. Next, an index is received which is representative of a portion of the vertex data in the memory. A location is then determined in the memory in which the portion of the vertex data is stored. Such portion of the vertex data may thereafter be directly retrieved from the determined location in the memory while bypassing a processor."
6870540,"A system, method and computer program product are provided for programmable pixel processing in a computer graphics pipeline. Initially, pixel data is received from a source buffer. Thereafter, programmable operations are performed on the pixel data in order to generate output. The operations are programmable in that a user may utilize instructions from a predetermined instruction set for generating the same. Such output is stored in a register."
6870542,"A graphics processing system performs filtering of oversampled data during a scanout operation. Sample values are read from an oversampled frame buffer and filtered during scanout; the filtered color values (one per pixel) are provided to a display device without an intervening step of storing the filtered data in a frame buffer. In one embodiment, the filtering circuit includes a memory interface configured to read data values corresponding to sample points from a frame buffer containing the oversampled data; and a filter configured to receive the data values provided by the memory interface, to compute a pixel value from the data values, and to transmit the pixel value for displaying by a display device, wherein the filter computes the pixel value during a scanout operation."
6874160,"A digital video recorder is described. In one embodiment, the digital video recorder includes a feature detector configured to derive a set of features from content within a television commercial. The digital video recorder also includes a television program identifier coupled to the feature detector. The television program identifier is configured to identify, using the set of features, a television program associated with the television commercial. The digital video recorder further includes a television program recorder coupled to the television program identifier. The television program recorder is configured to establish a recording session for the television program."
6876362,"An invention is provided for rendering using an omnidirectional light. A shadow cube texture map having six cube faces centered by a light source is generated. Each cube face comprises a shadow texture having depth data from a perspective of the light source. In addition, each cube face is associated with an axis of a three-dimensional coordinate system. For each object fragment rendered from the camera's perspective a light-to-surface vector is defined from the light source to the object fragment, and particular texels within particular cube faces are selected based on the light-to-surface vector. The texel values are tested against a depth value computed from the light to surface vector. The object fragment is textured as in light or shadow according to the outcome of the test."
6879207,"Circuits, methods, and apparatus for using redundant circuitry on integrated circuits in order to increase manufacturing yields. One exemplary embodiment of the present invention provides a circuit configuration wherein functional circuit blocks in a group of circuit blocks are selected by multiplexers. Multiplexers at the input and output of the group of circuit blocks steer input and output signals to and from functional circuit blocks, avoiding circuit blocks found to be defective or nonfunctional. Multiple groups of these circuit blocks may be arranged in series and in parallel. Alternate multiplexer configurations may be used in order to provide a higher level of redundancy. Other embodiments use all functional circuit blocks and sort integrated circuits based on the level of functionality or performance. Other embodiments provide methods of testing integrated circuits having one or more of these circuit configurations."
6894385,"An integrated circuit package is disclosed. The integrated circuit package includes a package substrate having a top and a bottom. Further, the integrated circuit package includes a plurality of bypass capacitors coupled to the bottom of the package substrate without a cavity. Moreover, the integrated circuit package includes an array of solder balls formed on the bottom of the package substrate. The array of solder balls facilitates surface mounting to a printed circuit board assembly. Also, the solder balls provide sufficient space between the printed circuit board assembly and the bypass capacitors. In an embodiment, the package substrate is an organic substrate."
6894687,"A system, method and article of manufacture are provided for aliasing vertex attributes during vertex processing. Initially, a plurality of identifiers are each mapped to one of a plurality of parameters associated with vertex data. Thereafter, the vertex data is processed by calling the parameters utilizing a vertex program capable of referencing the parameters using the identifiers."
6894689,"A system, method and computer program product are provided for avoiding reading z-values in a graphics pipeline. Initially, near z-values are stored which are each representative of a near z-value on an object in a region. Such region is defined by a tile and a coverage mask therein. Thereafter, the stored near z-values are compared with far z-values computed for other objects in the region. Such comparison indicates whether an object is visible in the region. Based on the comparison, z-values previously stored for image samples in the region are conditionally read from memory."
6897874,"A circuit for providing an overlay in a window on a computer output display including scaling circuitry, storage circuitry for receiving a plurality of lines of source data, input circuitry for loading the storage circuitry in a first prefill mode and in a second low water mark mode, and circuitry for selecting a mode for loading the storage circuitry responsive to the characteristics of the demand for data placed on the storage circuitry."
6900810,"A programmable geometry engine is described. One embodiment of the programmable geometry engine includes a programmable primitive engine configured to receive primitive commands that include information for processing vertex data using user-developed programs or subroutines. The programmable primitive engine also is configured to transmit program commands that include program pointers and data pointers. In addition, the programmable geometry engine includes a processing engine configured to receive the program commands. The processing engine is further configured to retrieve the user-developed programs or subroutines using the program pointers and to retrieve vertex data using the data pointers. Also, the processing engine is configured to process the vertex data based on instructions included in the user-developed programs or subroutines to produce processed vertex data and to transmit results to the programmable primitive engine."
6906716,"An integrated graphics pipeline system is provided for graphics processing. Such system includes a tessellation module that is positioned on a single semiconductor platform for receiving data for tessellation purposes. Tessellation refers to the process of decomposing either a complex surface such as a sphere or surface patch into simpler primitives such as triangles or quadrilaterals, or a triangle into multiple smaller triangles. Also included on the single semiconductor platform is a transform module adapted to transform the tessellated data from a first space to a second space. Coupled to the transform module is a lighting module which is positioned on the single semiconductor platform for performing lighting operations on the data received from the transform module. Also included is a rasterizer coupled to the lighting module and positioned on the single semiconductor platform for rendering the data received from the lighting module."
6911983,"Tile buffers in a graphics processing system are managed use “copy-on-write” semantics, in which tile data stored in a memory location is not transferred to another location until the tile data for one of the buffers is modified. Two memory spaces store tile data, and two logical buffers are used to access the memory spaces. For each tile, a tile association is maintained, indicating which of the two memory spaces is associated with each of the two logical buffers. To copy a tile of the first logical buffer to the second logical buffer, the tile association for the tile being copied is modified. Data for a tile is written to the memory space associated with a target logical buffer after ensuring that the tile association for the tile associates the target logical buffer with a different one of the two memory spaces from the other logical buffer."
6911984,"Tile data for drawing and desktop buffers in a desktop compositor system is managed using “copy-on-write” semantics, in which tile data stored in a memory location is not transferred to another location until the tile data for one of the buffers is modified. For each tile in drawing buffers and desktop buffers, an association is maintained with a location in a tile memory, and the number of buffer tiles associated with each location is tracked. To copy a tile from one buffer to another, the tile association for the tile in the destination buffer is modified. New data for a tile of a buffer is written to the tile memory location associated with the buffer after ensuring that the tile memory location is not associated with any other tiles of any of the buffers. As a result, memory bandwidth can be considerably reduced."
6919895,"A method and apparatus which includes a graphics accelerator, circuitry responsive to pixel texture coordinates to select texels and generate therefrom a texture value for any pixel the color of which is to be modified by a texture, a cache to hold texels for use by the circuitry to generate texture value for any pixel, a stage for buffering the acquisition of texel data, and control circuitry for controlling the acquisition of texture data, storing the texture data in the cache, and furnishing the texture data for blending with pixel data."
6919904,"A system, method and computer program product are provided for use in a graphics pipeline. Initially, a pixel is determined within a primitive that is to be texture mapped. Next, texture coordinates associated with the pixel are identified along with a plurality of sets of light values corresponding to vertices of the primitive. Texture information is then retrieved utilizing the texture coordinates. A plurality of interpolated light values is then calculated utilizing the sets of light values and texture coordinates. Such interpolated light values are then multiplied with the texture information."
6920484,"A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. In one embodiment, functions previously performed by a complex disk controller are now integrated into a storage processing unit (SPU) that can also be deployed on the same chipset, where the SPU serves as an overall file and disk management processor."
6924811,"A method of storing a texel in a texel cache comprising reading a t coordinate of the texel, the t coordinate comprising a plurality of bits, reading a s coordinate of the texel, the s coordinate comprising a plurality of bits, forming an offset by concatenating bits of the t coordinate with bits of the s coordinate and forming an index by concatenating bits of the t coordinate with bits of the s coordinate is discussed."
6927781,"A method of generating pixels in a graphics system including providing a plurality of sub-samples, and providing a source pixel. It is determined which of the plurality of sub-samples are covered by the source pixel, and which of the plurality of sub-samples are not covered. The sub-samples which are covered by the source pixel are filtered. The filtered sub-samples are blended with the source pixel to create a blended sub-sample, followed by the filtering of the sub-samples which are not covered by the source pixel together with the blended sub-sample."
6937290,"A method and circuit for generating a train of synthesized sync pulses in accordance with the Bresenham algorithm in response to an input clock having frequency Fi, such that the leading edges of the pulses occur at least nearly periodically, with time-averaged frequency at least nearly equal to (A/T)Fi, where A and T are integers, and such that the accumulated error, between the actual time interval between the first and last leading edges of Z consecutive ones of the pulses and the time ZT/(AFi), never exceeds 1/Fi. When Fi is equal to (T/A)Fo, where Fo is a predetermined output line frequency, an embodiment of the sync pulse generator includes an accumulator which stores a Count value, a comparator, and logic circuitry for generating the sync pulse train in response to a binary signal asserted by the comparator (and typically also control data that determines a configuration of the logic circuitry). The Count value is set to zero in response to a Frame Start event, and then increases by the above-noted integer value, A, once per input clock cycle. During each input clock cycle, the comparator compares the Count value in the accumulator with the above-noted integer value, T. In response to the comparator output indicating that the Count value has risen to a value greater than or equal to T, the Count value in the accumulator is reduced by the value T−A and the logic circuitry asserts the leading edge of a sync pulse. In typical cases in which the sync pulses are for use in clocking, generating, or synchronizing with a video signal (and the initial value is zero), the ratio T/A is equal to the number of input clock cycles per line of the video signal (i.e., the number of input clock cycles required to clock out a line of the video signal to a display device using an output clock having the output clock frequency)."
6938176,"A graphics processing device implementing a set of techniques for power management, preferably at both a subsystem level and a device level, and preferably including peak power management, a system including a graphics processing device that implements such a set of techniques for power management, and the power management methods performed by such a device or system. In preferred embodiments, the device includes at least two subsystems and hardware mechanisms that automatically seek the lowest power state for the device that does not impact performance of the device or of a system that includes the device. Preferably, the device includes a control unit operable in any selected one of multiple power management modes, and system software can intervene to cause the control unit to operate in any of these modes."
6940515,"A fixed function engine and method are described for processing a set of primitive commands. One embodiment of the fixed function engine includes a means for receiving one or more primitive commands, where each such primitive command includes information for processing vertex data using a user-developed program or subroutine. The fixed function engine also includes a means for determining a set of related primitive commands from the received primitive commands and a means for identifying a first primitive command to process from that set. In addition, the fixed function engine includes a means for transmitting a first program command, which is related to the first primitive command, to a processing engine for processing."
6942521,"An improved VGA connector that supports enhanced graphic performance by internally incorporating one or more functions of fusing, filtering, shielding, and the controlling of signal line impendances. The improved VGA connector is dimensionally interchangeable with many aspects of standard VGA connectors, and use standard pin-outs that mate with mating connectors. Integral DACs can be included to provide analog outputs."
6947047,"A programmable, pipelined graphics processor (e.g., a vertex processor) having at least two processing pipelines, a graphics processing system including such a processor, and a pipelined graphics data processing method allowing parallel processing and also handling branching instructions and preventing conflicts among pipelines. Preferably, each pipeline processes data in accordance with a program including by executing branch instructions, and the processor is operable in any one of a parallel processing mode in which at least two data values to be processed in parallel in accordance with the same program are launched simultaneously into multiple pipelines, and a serialized mode in which only one pipeline at a time receives input data values to be processed in accordance with the program (and operation of each other pipeline is frozen). During parallel processing mode operation, mode control circuitry recognizes and resolves branch instructions to be executed (before processing of data in accordance with each branch instruction starts) and causes the processor to operate in the serialized mode when (and preferably only for as long as) necessary to prevent any conflict between the pipelines due to branching. In other embodiments, the processor is operable in any one of a parallel processing mode and a limited serialized mode in which operation of each of a sequence of pipelines (or pipeline sets) pauses for a limited number of clock cycles. The processor enters the limited serialized mode in response to detecting a conflict-causing instruction that could cause a conflict between resources shared by the pipelines during parallel processing mode operation."
6947049,"A method and system for synchronizing updates of vertex data by a processor with a graphics accelerator module that is fetching vertex data is disclosed. The method and system comprises providing vertex array range (VAR) and writing vertex data into the VAR. The method and system includes providing a command into a command stream of the graphics accelerator module indicating that the vertex data has written into the VAR, and providing a fence condition based upon the command. A system and method in accordance with the present invention thus permits extremely high vertex processing rates via vertex arrays or vertex buffers even when the processor lacks the necessary data movement bandwidth. By passing indices in lieu of the vertex data, the processor is capable of keeping up with the rate at which a vertex engine of the graphics accelerator module can consume vertices. In operation, the processor passes vertex indices to the hardware and lets the hardware “pull” the actual vertex data via direct memory access (DMA)."
6947865,A processor power supply voltage controller. The controller includes a temperature sensor configured to sense a temperature of a processor and generate a temperature signal in accordance therewith. A regulator is coupled to provide a power supply voltage to the processor. The regulator is coupled to receive the temperature signal and control the power supply voltage to maintain a substantially stable crosstalk level within the processor.
6950107,"System and method for reserving a memory space for multithreaded processing is described. Memory space within a memory resource is allocated responsive to thread type. Examples of thread types for graphics processing include primitive, vertex and fragment types. Memory space allocated may be of a predetermined size for a thread type. Memory locations within a first memory space may be interleaved with memory locations within a second memory space."
6952206,"A system, method and computer program product are provided for accelerating graphics processing utilizing a graphics application program interface. Initially, graphics data is processed in a graphics system with components including a central processing unit, a geometry processing module, and a pixel processing module. In use, the graphics application program interface accepts one or more first occlusion queries followed by a second occlusion query. The second occlusion query is at least partially processed by the graphics system before a final result of any one of the first occlusion queries is computed by the graphics system."
6952217,"A method of self-programming a graphics processing unit (GPU) includes receiving a blit instruction defining a blit operation and storing a first control value in a control register, which determines the behavior of the GPU, using the blit operation. The blit instruction is read by the GPU from a command buffer asynchronously with the CPU. The blit operation is applied to a second control value to determine the first control value. The second control value can be stored in a memory, such as a second control register or a table of control values accessed by an index value. In one application, the second control value is a starting memory address for a display buffer, while in another application, second control value is a clip plane distance. The blit operation can include a copy operation, a colorkey operation, a logic operation, and/or a pattern copy operation on the first control value."
6954204,"A programmable graphics system and method for processing high precision graphics data represented in one or more data formats in one or more passes. Graphics program instructions executed by the system control the processing and format conversion of the data. The program instructions and the data are stored in a memory accessible by the system. Within the memory, contiguous memory entries can contain program instructions or data represented in different formats. The format used to represent a particular data element within the data, is specified in the state information maintained in the system and is used to configure format conversion units within the system. High precision data, such as floating color, is processed by the programmable graphics system and output via a digital to analog converter (DAC) for display."
6956579,"Systems and methods for private addressing in a multi-processor graphics processing subsystem having a number of memories and a number of graphics processors. Each of the memories includes a number of addressable storage locations, and storage locations in different memories may share a common global address. Storage locations are uniquely identifiable by private addresses internal to the graphics processing subsystem. One of the graphics processors is able to access a location in a particular memory by referencing its private address."
6957298,"A memory controller system is provided including a plurality of memory controller subsystems each coupled between memory and one of a plurality of computer components. Each memory controller subsystem includes at least one queue for managing pages in the memory. In use, each memory controller subsystem is capable of being loaded from the associated computer component independent of the state of the memory. Since high bandwidth and low latency are conflicting requirements in high performance memory systems, the present invention separates references from various computer components into multiple command streams. Each stream thus can hide activate bank preparation commands within its own stream for maximum bandwidth. A page context switch technique may be employed that allows instantaneous switching from one look ahead stream to another to allow low latency and high bandwidth while preserving maximum bank state from the previous stream."
6959110,"A multi-mode texture compression algorithm is provided for effective compression and decompression texture data during graphics processing. Initially, a request is sent to memory for compressed texture data. Such compressed texture data is then received from the memory in response to the request. At least one of a plurality of compression algorithms associated with the compressed texture data is subsequently identified. Thereafter, the compressed texture data is decompressed in accordance with the identified compression algorithm."
6961057,"A computer graphics system provides for processing image data including Z data for use in displaying three-dimensional images on a display unit. The system includes: a depth buffer providing for temporary storage of Z data; and a graphics processing unit having a graphics engine for generating image data including Z data, and a memory interface unit communicatively coupled to the graphics engine and communicatively coupled to the depth buffer via a depth buffer interface. The graphics processing unit is operative to compress at least a portion of the generated Z data, to write the compressed portion of Z data to the depth buffer via the depth buffer interface in a compressed format, to read portions of compressed Z data from the depth buffer via the depth buffer interface, and to decompress the compressed Z data read from the buffer. An advantage of the present invention is that effective Z data bandwidth through the depth buffer interface is maximized in order to facilitate fast depth buffer access operations."
6963340,"A graphics processor or display device including a microcontroller that functions as a sequencer, a computer system including at least one such graphics processor or display device, and a microcontroller for use in such a graphics processor or display device. In preferred embodiments, the microcontroller functions as a sequencer for controlling the timing of power up and/or power down operations by one or both of a graphics processor and a display device. The microcontroller is implemented to exclude any capacity to handle interrupts and so can provide guaranteed timing, and is preferably implemented to be small, simple, and programmable, and to store a small number of programs. Each program consists of instructions belonging to a small instruction set, such as a set consisting of set and clear instructions (for overriding or overwriting specified register bits) and wait, release, and stop instructions. When executing a program, the microcontroller typically overrides (in an ordered sequence) state and control bits that would otherwise be asserted."
6963344,A computer implemented method for utilizing graphics memory of a computer system to provide storage for video BIOS initialization. Video BIOS memory is accessed to execute video BIOS initialization routines. A portion of graphics memory is configured for access by the video BIOS initialization routines. Program execution data from the video BIOS initialization routines is then stored in the portion of graphics memory. The program execution data is stored prior to a completion of a video BIOS power on self test.
6963348,"Method and apparatus for display image adjustment is described. More particularly, handles associated with polygon vertices of a polygon rendered image are provided as a graphical user interface (GUI). These handles may be selected and moved by a user with a cursor pointing device to adjust a displayed image for keystoning, among other types of distortion. This GUI allows a user to adjust a projected image for position of a projector with respect to imaging surface, as well as for imaging surface contour, where such contour may be at least substantially planar, cylindrical, or spherical and where such contour may comprise multiple imaging surfaces. This advantageously may be done without special optics or special equipment. An original image is used as texture for rendering polygons, where the image is applied to the rendered polygons."
6967663,"Hybrid sampling of pixels of an image involves generating shading values at multiple shading sample locations and generating depth values at multiple depth sample locations, with the number of depth sample locations exceeding the number of shading sample locations. Each shading sample location is associated with one or more of the depth sample locations. Generation and filtering of hybrid sampled pixel data can be done within a graphics processing system, transparent to an application that provides image data."
6968424,"A method and system for implementing transparent compressed memory paging within a computer system. Data compression is performed in memory to increase resources available to the computer system and to reduce disk accesses. The compression is performed transparently to the operating system which requires no special software interfaces to make use of the reclaimed memory. In a first embodiment, data compression is performed in hardware to reclaim memory. This reclaimed memory is not made available to the operating system but is rather used as a hardware controlled disk cache to increase system performance. In this embodiment, a novel method is employed to reduce duplicate memory pages in the disk cache and the operating system memory. In another embodiment, the reclaimed memory is made available in a transparent way to the operating system. Variable compression ratios can lead to varying physical memory space available for the operating system. Therefore, if actual memory space becomes near exhausted, a process is automatically triggered that exclusively allocates blocks of physical memory to a driver thereby removing them from operating system usage. In the second embodiment, a special cache table is used for uncompressed physical memory pages."
6971907,"A communication connector, in accordance with one embodiment of the invention, includes an insulative housing having a cylindrical opening, a light source, and a first and second electrical interconnect. The insulative housing includes a body portion and a head portion. The cylindrical opening extends through the head portion and partially into the body portion of the insulative housing. The light source is disposed in the insulative housing proximate the head portion. The first electrical interconnect includes a terminal portion for fixedly connecting the communication connector to a device and a contact portion comprising a resilient conductive element disposed in the cylindrical opening for engaging a mating communication connector. The second electrical interconnect couples an indicator signal to the light source."
6972769,"A vertex texture cache unit enables vertex shader programs to arbitrarily access array data while minimizing pipeline stalls due to memory latency. The vertex texture cache unit receives vertex texture requests from multiple vertex processing engines, each executing multiple vertex shader programs. The vertex texture cache unit stores frequently accessed vertex texture map data in a cache memory. When a cache miss occurs, the vertex texture cache unit continues to process subsequent vertex texture requests while data is being retrieved from memory for the cache miss. Because the vertex texture cache unit may output vertex texture map data in a different order than the corresponding vertex texture requests are received, the vertex texture cache unit maintains the association between vertex texture map data and its set of attributes, so that the vertex texture map data is formatted correctly and returned to the appropriate vertex processing engine and vertex shader program."
6975319,"A system, method and article of manufacture are provided for calculating a level of detail (LOD) value for use during computer graphics processing. First, a plurality of geometrically arranged coordinates is identified. A distance value is computed based on the geometrically arranged coordinates. A LOD value is then calculated using the distance value for use during computer graphics processing. In one embodiment, a derivative value is estimated based on the geometrically arranged coordinates, and the distance value is computed based on the derivative value."
6975321,"A system and method are provided for generating multiple output packets in a single processing pass of a shader in a hardware graphics pipeline. Initially, graphics data is received, after which it is processed utilizing the shader of the hardware graphics pipeline to generate a plurality of output packets. The plurality of output packets is outputted from the shader of the hardware graphics pipeline in the single processing pass."
6975329,"A graphical processing unit (GPU) and methods for rendering a three-dimensional (3D) scene generated in a field of view having in-focus and out-of-focus regions on a two-dimensional (2D) screen region of pixels are described. One method includes initially rendering the scene to create color and depth texture maps and creating mip-map layers for the color texture map. The method further comprises subsequently rendering the scene by, for each pixel: creating a mip-map layer selection value as a function of a depth of the pixel from the depth texture map, generating a color value by interpolation using color values from at least one of the mip-map layers chosen according to the mip-map layer selection value, and setting a color of the pixel to the generated color texture."
6980208,"A system, method and computer program product are provided for performing depth testing and blending operations in a first mode and a second mode. In the first mode, a circuit processes a first number (m) of first pixels per clock cycle, each of the first pixels including both color values and depth values. In the second mode, the circuit processes a second number (n) of second pixels per clock cycle. Each of the second pixels includes the depth values and not the color values. Further, the second number (n) is greater than the first number (m)."
6980209,"A scalable pipelined pixel shader that processes packets of data and preserves the format of each packet at each processing stage. Each packet is an ordered array of data values, at least one of which is an instruction pointer. Each member of the ordered array can be indicative of any type of data. As a packet progresses through the pixel shader during processing, each member of the ordered array can be replaced by a sequence of data values indicative of different types of data (e.g., an address of a texel, a texel, or a partially or fully processed color value). Information required for the pixel shader to process each packet is contained in the packet, and thus the pixel shader is scalable in the sense that it can be implemented in modular fashion to include any number of identical pipelined processing stages and can execute the same program regardless of the number of stages. Preferably, each processing stage is itself scalable, can be implemented to include an arbitrary number of identical pipelined instruction execution stages known as microblenders, and can execute the same program regardless of the number of microblenders. The current value of the instruction pointer (IP) in a packet determines the next instruction to be executed on the data contained in the packet. Any processing unit can change the instruction that will be executed by a subsequent processing unit by modifying the IP (and/or condition codes) of a packet that it asserts to the subsequent processing unit. Other aspects of the invention include graphics processors (each including a pixel shader configured in accordance with the invention), methods and systems for generating packets of data for processing in accordance with the invention, and methods for pipelined processing of packets of data."
6982490,An interface device having a video BIOS component. The device includes a substrate for implementing a mother board connection and implementing a GPU (graphics processor unit) connection. A video BIOS component is mounted on the substrate for providing video BIOS functions for the computer system.
6982718,"A system, method and computer program product are provided for programmable processing of fragment data in a computer hardware graphics pipeline. Initially, fragment data is received in a hardware graphics pipeline. It is then determined whether the hardware graphics pipeline is operating in a programmable mode. If it is determined that the hardware graphics pipeline is operating in the programmable mode, programmable operations are performed on the fragment data in order to generate output. The programmable operations are performed in a manner/sequence specified in a graphics application program interface. If it is determined that the hardware graphics pipeline is not operating in the programmable mode, standard graphics application program interface (API) operations are performed on the fragment data in order to generate output."
6982722,"A programmable system for dithering video data. The system is operable in at least two user-selectable modes which can include a small kernel mode and a large kernel mode. In some embodiments, the system is operable in at least one mode in which it applies two or more kernels (each from a different kernel sequence) to each block of video words. Each kernel sequence repeats after a programmable number of the blocks (e.g., a programmable number of frames containing the blocks) have been dithered. The period of repetition is preferably programmable independently for each kernel sequence. The system preferably includes a frame counter for each kernel sequence. Each counter generates an interrupt when the number of frames of data dithered by kernels of the sequence has reached a predetermined value. In response to the interrupt, software can change the kernel sequence being applied. Typically, the system performs both truncation and dithering on words of video data. For example, some embodiments produce dithered 6-bit color components in response to 8-bit input color component words. Preferably, the inventive system is optionally operable in either a normal mode (in which dithering is applied to all pixels in accordance with the invention) or in an anti-flicker mode. Another aspect of the invention is a computer system in which the dithering system is implemented as a subsystem of a pipelined graphics processor or display device. Another aspect of the invention is a display device that includes an embodiment of the dithering system."
6983357,"A method and apparatus for accelerating an object-oriented programming language are provided at a hardware gate level. In a Java-compliant embodiment, a Java Application framework is implemented in hardware. The Java.AWT, Java.NET. and Java.IO application frameworks are supported in the preferred embodiment of the invention. Instances and methods of supported application framework classes that are executed by a Java program are offloaded to a hardware object management system. A software stub is provided as an interface between the hardware object management system and the central processing unit."
6985143,"A system and method of maintaining computer graphics data sets in a line tree data structure. A data set is defined by a reference range with endpoint references r0 and r1 and is associated with a segment of a sampling line that analytically represents a part of an object. A data set contains data at the endpoint references r0 and r1 including values for depth, color, transparency, and depth range. Targeted data sets are defined as data sets containing certain reference values and are retrieved using a data set retrieval procedure. After retrieval, a targeted data set is compared to a new data set by a data set update procedure to determine whether the targeted data set remains, the new data set replaces the targeted data set, or modified data sets are required to be created and inserted into the line tree data structure."
6985151,"Circuits, apparatus, and methods that enable a shader to read and write data from and to a memory location during a single pass through a graphics pipeline. Some embodiments of the present invention provide an increase in the number of buffers available to a shader. These buffers may be read/write (input/output) or read only (input) buffers. Another provides pixel store and pixel load commands that may be used as instructions in a shader program or program portion, and may appear at positions other than the end of the shader program or program portion. Other embodiments provide a data path between a shader and a graphics memory, typically through a frame buffer interface. This data path simplifies the timing of the above store (write) and load (read) commands. Various embodiments may incorporate one or more of these features."
6985152,"A computer system includes an integrated graphics subsystem and a graphics connector for attaching either an auxiliary graphics subsystem or a loopback card. A first bus connection communicates data from the computer system to the integrated graphics subsystem. With a loopback card in place, data travels from the integrated graphics subsystem back to the computer system via a second bus connection. When the auxiliary graphics subsystem is attached, the integrated graphics subsystem operates in a data forwarding mode. Data is communicated to the integrated graphics subsystem via the first bus connection. The integrated graphics subsystem then forwards data to the auxiliary graphics subsystem. A portion of the second bus connection communicates data from the auxiliary graphics subsystem back to the computer system. The auxiliary graphics subsystem communicates display information back to the integrated graphics subsystem, where it is used to control a display device."
6987517,"A programmable graphics processor including an execution pipeline and a texture unit is described. The execution pipeline processes graphics data as specified by a fragment program. The fragment program may include one or more opcodes. The texture unit includes one or more sub-units which execute the opcodes to perform specific operations such as an LOD computation, generation of sample locations used to read texture map data, and address computation based on the sample locations."
6989840,"A system, method and computer program product are provided for transparency rendering in a graphics pipeline. Initially, colored-transparency information is collected from a plurality of depth layers (i.e. colored-transparency layers, etc.) in a scene to be rendered. The collected colored-transparency information is then stored in memory. The colored-transparency information from the depth layers may then be blended in a predetermined order."
6992667,"A graphics hardware system and method are provided for graphics processing. Such system includes a transform module positioned on a single semiconductor platform for transforming graphics data. Coupled to the transform module is a lighting module which is positioned on the single semiconductor platform for lighting the graphics data. Also included is a rasterizer coupled to the lighting module and positioned on the single semiconductor platform for rendering the graphics data. As an option, the graphics hardware system may further be equipped with skinning, swizzling and masking capabilities."
6992669,"A graphics pipeline system and method are provided for graphics processing. Such system includes a transform module adapted for receiving graphics data. The transform module serves to transform the graphics data from a first space to a second space. Coupled to the transform module is a lighting module which is positioned on the single semiconductor platform for performing lighting operations on the graphics data received from the transform module. Also included is a rasterizer coupled to the lighting module and positioned on the single semiconductor platform for rendering the graphics data received from the lighting module. During use, an antialiasing feature is implemented on the single semiconductor platform to improve a quality of the graphics rendering."
6995767,"Trilinear optimization is a technique to reduce the number of texture samples used to determine a texture value associated with a graphics fragment. Bilinear interpolations replace some trilinear interpolations, thereby reducing the number of texture samples read and simplifying the filter computation. A programmable trilinear slope is used to control replacement of a trilinear computation with a bilinear computation, permitting a user to determine a balance between improved texture map performance and texture filtering quality."
6999088,A graphics memory includes a plurality of memory partitions. A memory controller organizes tile data into subpackets that are assigned to subpartitions to improve memory transfer efficiency. Subpackets of different tiles may be further assigned to subpartitions in an interleaved fashion to improve memory operations such as fast clear and compression.
7002577,A graphics pipeline system and associated method are provided with an integrated clipping operation. First included is a transform module positioned on a single semiconductor platform for transforming graphics data from a first space to a second space. Also provided is a lighting module positioned on the same single semiconductor platform as the transform module. The lighting module is adapted for performing lighting operations on the graphics data. A clipping operation is also performed utilizing the single semiconductor platform.
7002588,"A system, method and computer program product are provided for branching during graphics processing. Initially, a first operation is performed on data. In response to the first operation, a branching operation is performed to a second operation. The first operation and the second operation are associated with instructions selected from a predetermined instruction set."
7002797,"Embodiments of the present invention provide for a noise-reducing blower structure in which a fan-housing is disposed on an expansion card and juxtaposed to a heat sink. The heat sink is disposed on the expansion card and resides within a rigid frame above a processing unit chip. A fan that circulates air is disposed on the expansion card within the fan-housing. A duct is disposed on the expansion card, covering the heat sink and the fan-housing, and the duct is mechanically separated from the fan-housing for reducing vibration noises. By placement of the fan next to the heat sink, and not on top of it, the fan can be made larger to thereby rotate at slower speeds."
7005871,An integrated circuit includes an accelerated aging circuit block that has at least one circuit that ages at a faster rate than a functional circuit block. The accelerated aging circuit block is monitored during normal operation of the integrated circuit. Changes in the accelerated aging circuit block are used to generate data indicative of an aging trend for the functional circuit block.
7006101,"A system, method and computer program product are provided for branching during programmable processing utilizing a graphics application program interface in conjunction with a hardware graphics pipeline. Initially, a first instruction defined by the graphics application program interface is identified. A first operation is performed on graphics data based on the first instruction utilizing the hardware graphics pipeline. Any some point, the present technique may involve branching to an additional instruction defined by the graphics application program interface other than a subsequent sequential instruction. Next, another operation is performed on the graphics data based on the additional instruction utilizing the hardware graphics pipeline."
7009605,"A method and computer program product are provided for generating a shader program. Initially, a file associated with a graphics effect is a selected. Such file is then read and processed. A shader program is subsequently generated based on the processing of the file to apply the graphics effect to an object."
7009607,"A method, apparatus and article of manufacture are provided for a transform system for graphics processing as a computer system or on a single integrated circuit. Included is an input buffer adapted for being coupled to a vertex attribute buffer for receiving vertex data therefrom. A multiplication logic unit has a first input coupled to an output of the input buffer. Also provided is an arithmetic logic unit having a first input coupled to an output of the multiplication logic unit. Coupled to an output of the arithmetic logic unit is an input of a register unit. An inverse logic unit is provided including an input coupled to the output of the arithmetic logic unit or the register unit for performing an inverse or an inverse square root operation. Further included is a conversion module coupled between an output of the inverse logic unit and a second input of the multiplication logic unit. In use, the conversion module serves to convert scalar vertex data to vector vertex data. Memory is coupled to the multiplication logic unit and the arithmetic logic unit. The memory has stored therein a plurality of constants and variables for being used in conjunction with the input buffer, the multiplication logic unit, the arithmetic logic unit, the register unit, the inverse logic unit, and the conversion module for processing the vertex data. Finally, an output converter is coupled to the output of the arithmetic logic unit for being coupled to a lighting module to output the processed vertex data thereto."
7009608,"The present invention is related to rendering computer animated video and/or images generally, and to efficiently intersecting rays with an object scene while shading complex object representations. The present invention, generally, includes creating a plurality of representations for the object. After creating the plurality of representations, a plurality of primary positions are established on one of the representations. Shading positions on one or more other representations included in the plurality of representations are then established by reference to the primary positions. These shading positions correspond to the plurality of primary positions and each of these representations has a coarser resolution than the representation with the primary positions. Shading values for the shading positions are the computed and applied to the plurality of primary positions."
7009615,"A system, method and computer program product are provided for buffering data in a computer graphics pipeline. Initially, graphics floating point data is read from a buffer in a graphics pipeline. Next, the graphics floating point data is operated upon in the graphics pipeline. Further, the graphics floating point data is stored to the buffer in the graphics pipeline."
7010724,Circuitry for detecting operating system hang conditions is provided. The circuitry includes interrupt logic for receiving system interrupts targeted for a central processing unit. Further included is hang detection logic that is in communication with the interrupt logic. The hang detection logic is capable of determining whether the central processing unit has processed an interrupt within a period of time. Hang resolution logic is further provided for removing the central processing unit from a hang state when it is determined that the interrupt has not been processed within the period of time.
7015913,"A graphics processor and method for executing a graphics program as a plurality of threads where each sample to be processed by the program is assigned to a thread. Although threads share processing resources within the programmable graphics processor, the execution of each thread can proceed independent of any other threads. For example, instructions in a second thread are scheduled for execution while execution of instructions in a first thread are stalled waiting for source data. Consequently, a first received sample (assigned to the first thread) may be processed after a second received sample (assigned to the second thread). A benefit of independently executing each thread is improved performance because a stalled thread does not prevent the execution of other threads."
7015914,"Multiple output buffers are supported in a graphics processor. Each output buffer has a unique identifier and may include data represented in a variety of fixed and floating-point formats (8-bit, 16-bit, 32-bit, 64-bit and higher). A fragment program executed by the graphics processor can access (read or write any of the output buffers. Each of the output buffers may be read from and used to process graphics data by a fragment shader within the graphics processor. Likewise, each output buffer may be written to by the graphics processor, storing graphics data such as lighting parameters, indices, color, and depth."
7015915,A CPU selectively programs one or more graphics devices by writing a control command to the command buffer that designates a subset of graphics devices to execute subsequent commands. Graphics devices not designated by the control command will ignore the subsequent commands until re-enabled by the CPU. The non-designated graphics devices will continue to read from the command buffer to maintain synchronization. Subsequent control commands can designate different subsets of graphics devices to execute further subsequent commands. Graphics devices include graphics processing units and graphics coprocessors. A unique identifier is associated with each of the graphics devices. The control command designates a subset of graphics devices according to their respective unique identifiers. The control command includes a number of bits. Each bit is associated with one of the unique identifiers and designates the inclusion of one of the graphics devices in the first subset of graphics devices.
7015970,"A method and apparatus are provided for displaying progressive material on an interlaced display where the number of lines of the source frame is equal to or less than the number of lines in a display field, where such lines in the display field are derived from all of the lines of the source frame."
7023437,"A system and method are provided for accelerating graphics processing utilizing multiple-pass rendering. Initially, geometry operations are performed on graphics data, and the graphics data is stored in memory. During a first rendering pass, various operations take place. For example, the graphics data is read from the memory, and the graphics data is rasterized. Moreover, first z-culling operations are performed utilizing the graphics data. Such first z-culling operations maintain a first occlusion image. During a second rendering pass, the graphics data is read from memory. Still yet, the graphics data is rasterized and second z-culling operations are performed utilizing the graphics data and the first occlusion image. Moreover, visibility operations are performed utilizing the graphics data and a second occlusion image. Raster-processor operations are also performed utilizing the graphics data, during the second rendering pass."
7027062,"A graphics processing unit can queue a large number of texture requests to balance out the variability of texture requests without the need for a large texture request buffer. A dedicated texture request buffer queues the relatively small texture commands and parameters. Additionally, for each queued texture command, an associated set of texture arguments, which are typically much larger than the texture command, are stored in a general purpose register. The texture unit retrieves texture commands from the texture request buffer and then fetches the associated texture arguments from the appropriate general purpose register. The texture arguments may be stored in the general purpose register designated as the destination of the final texture value computed by the texture unit. Because the destination register must be allocated for the final texture value as texture commands are queued, storing the texture arguments in this register does not consume any additional registers."
7027063,"A method of storing a texel in a texel cache comprising reading a t coordinate of the texel, the t coordinate comprising a plurality of bits, reading a s coordinate of the texel, the s coordinate comprising a plurality of bits, forming an offset by concatenating bits of the t coordinate with bits of the s coordinate and forming an index by concatenating bits of the t coordinate with bits of the s coordinate and at least one bit of a level of detail is discussed."
7030879,"The present invention is related to rendering computer animated video and/or images generally, and to improving the calculation of diffusely reflected light. The present invention includes a system and method of computing diffusely reflected light at one or more positions on surfaces in an object scene from object scene data. The present invention typically includes the step of and/or instructions for selecting a non-regular order for processing a plurality of positions on a surface—the plurality of positions having been predetermined. The present invention also includes the step of and/or instruction for processing the plurality of positions in the non-regular order. This processing typically includes computing diffusely reflected light at a position in the plurality of positions by reference to diffusely reflected light incident on the position when deriving the diffusely reflected light at the position by reference to diffusely reflected light at other positions computed by reference to diffusely reflected light incident on the other positions is inaccurate. Alternatively, deriving the diffusely reflected light at the position by reference to the diffusely reflected light at the other positions computed by reference to diffusely reflected light incident on the other positions when deriving the diffusely reflected light at the position by reference to the diffusely reflected light at the other positions is accurate."
7034829,"A graphics pipeline system with an integrated masking operation is provided. Included is a transform module adapted for being coupled to a buffer to receive graphics data therefrom. Such transform module is positioned on a single semiconductor platform for transforming the graphics data from a first space to a second space. Also included is a lighting module coupled to the transform module and positioned on the same single semiconductor platform as the transform module. The lighting modules serves for performing lighting operations on the graphics data received from the transform module. In use, a masking operation is further performed on the single semiconductor platform."
7038678,"Antialiasing shadows using a programmable graphics processor. Shadows are antialiased using dependent texture mapping to displace shadow map coordinates. A jitter texture is applied to an object in screen space using non-perspective corrected jitter texture coordinates. The jitter texture coordinates are used to read texture coordinate displacements stored as the jitter texture. The texture coordinate displacements are combined with the shadow, map coordinates to generate displaced shadow map coordinates. The displaced shadow map coordinates are used to read depth values stored as the shadow map. The depth values read from the shadow map are compared with corresponding depth values of the object in light source coordinate space to determine whether each fragment within the object is either “in shadow” or “out of shadow”."
7038685,"A programmable graphics processor for multithreaded execution of program instructions including a thread control unit. The programmable graphics processor is programmed with program instructions for processing primitive, pixel and vertex data. The thread control unit has a thread storage resource including locations allocated to store thread state data associated with samples of two or more types. Sample types include primitive, pixel and vertex. A number of threads allocated to processing a sample type may be dynamically modified."
7038686,"A programmable graphics processor for multithreaded execution of program instructions including a thread control unit. The programmable graphics processor is programmed with program instructions for processing primitive, pixel and vertex data. The thread control unit has a thread storage resource including locations allocated to store thread state data associated with samples of two or more types. Sample types include primitive, pixel and vertex. A number of threads allocated to processing a sample type may be dynamically modified."
7038692,"A method for caching data defining vertices of a polygon to be displayed by an input/output display device including the steps of providing an index by a vertex for which data is to be cached, storing data defining attributes of a polygon at a vertex in a cache under the index provided, issuing a command signifying a polygon to be manipulated by indicating indices of the vertices of the polygon for which data is cached."
7039717,"An Internet client communicates with an Internet server such as an HTTP server or SMTP server through a TCP streaming socket on the Internet device with the Internet client. The TCP streaming sockets can be established through an Internet ready command line interface. The Internet ready command line interface includes “IR” commands that can establish, resume, release and terminate TCP sockets."
7042263,"Circuits, methods, and apparatus for reducing power on a graphics processor integrated circuit by generating two memory clock signals, reducing the frequency of one under certain conditions, and maintaining the frequency of the other. To reduce skew and jitter between these two memory clocks, and to ensure that they remain in phase, a synchronizer circuit is used by an exemplary embodiment of the present invention. The synchronizer circuit is also useful as a general application clock generator."
7050055,"A graphics pipeline system and associated method are provided for graphics processing. Such system includes a transform module adapted for receiving graphics data. The transform module serves to transform the graphics data from a first space to a second space. Coupled to the transform module is a lighting module which is positioned on the single semiconductor platform for lighting the graphics data. During use, the graphics pipeline system is capable of carrying out a fog and blending operation."
7050065,"An apparatus for graphics processing unit, which includes a memory for storing pixel data in a red, green and blue (RGB) color space and a display pipeline. The display pipeline includes an RGB color space to a luminance color, blue color difference and red color difference (YCbCr) color space converter module configured to convert the pixel data from the RGB color space to the YCbCr color space. The RGB to YCbCr color space converter module generates a luminance color component (Y) of the pixel data by adding ¼ of a red color (R) component of the pixel data to ½ of a green color (G) component of the pixel data and ¼ of a blue color (B) component of the pixel data. The luminance color component (Y) of the pixel data may be determined by left shifting the green color (G) component of the pixel data by one bit, adding the result to the red color (R) component of the pixel data and the blue color (B) component of the pixel data, and right shifting the sum by two bits."
7050068,"Jittered sub-pixel samples are used to reduce aliasing during rendering in a graphics pipeline. Sub-pixel samples are jittered using programmed sub-pixel offset values, permitting an application to select not only the number of sub-pixel samples within a pixel, but also the position of each sub-pixel sample within the pixel."
7051152,"A data storage system using compression to increase performance. The system has a hardware compression/decompression engine for performing data compression on a data block and performing data decompression of the data block. A controller is coupled to the hardware compression/decompression engine and is for storing compressed data of the data block in a primary region of a data storage device and is further for storing any overflow from the primary region in an overflow region of the data storage device. The overflow region is dedicated to the primary region. There may be a number of such primary regions and a number of such secondary regions, with the secondary regions mapped one-to-one to the primary regions."
7053893,"Prior to executing a program on a fragment, a conflict detection unit, within a fragment processor checks if there is a position conflict indicating a RAW (read after write) hazard may exist. A RAW hazard exists when there is a pending write to a destination location that source data will be read from during execution of the program. When the fragment enters a processing pipeline, each destination location that may be written during the processing of the fragment is entered in conflict detection unit. During processing, the conflict detection unit is updated when a pending write to a destination location is completed."
7053901,"Embodiments of the invention accelerate at least one special purpose processor, such as a GPU, or a driver managing a special purpose processor, by using at least one co-processor. Advantageously, embodiments of the invention are fault-tolerant in that the at least one GPU or other special purpose processor is able to execute all computations, although perhaps at a lower level of performance, if the at least one co-processor is rendered inoperable. The co-processor may also be used selectively, based on performance considerations."
7053903,"A system for processing graphics data. The system comprises a local memory for storing a first vertex array. The system further comprises a host memory for storing a second vertex array. A page table is configured to store page table entries related to the second vertex array, the page table entries including information indicating pages that have changed from the first vertex array to a second vertex array. A write watch module is coupled to the page table. The write watch module is configured to cause the first vertex array to be updated with changed pages."
7053904,"Apparatuses and methods for detecting position conflicts during fragment processing are described. Prior to executing a program on a fragment, a conflict detection unit, within a fragment processor checks if there is a position conflict indicating a RAW (read after write) hazard may exist. A RAW hazard exists when there is a pending write to a destination location that source data will be read from during execution of the program. When the fragment enters a processing pipeline, each destination location that may be written during the processing of the fragment is entered in conflict detection unit. During processing, the conflict detection unit is updated when a pending write to a destination location is completed."
7054987,"A bus interface unit is adapted to receive transaction requests for at least two different targets. The bus interface unit monitors a capacity of a resource associated with servicing transaction requests to the targets, such as a posted write buffer. If a transaction request would fill the resource beyond a current remaining capacity of the resource such that the execution of other pipelined transactions would become stalled, the bus interface generates a retry response so that the request is retried at a later time, permitting other transactions to proceed while the resource drains."
7058769,"A data storage system using compression to increase performance. The system has a hardware compression/decompression engine for performing data compression on a data block and performing data decompression of the data block. A controller is coupled to the hardware compression/decompression engine and is for storing compressed data of the data block in a primary region of a data storage device and is further for storing any overflow from the primary region in an overflow region of the data storage device. The overflow region is dedicated to the primary region. There may be a number of such primary regions and a number of such secondary regions, with the secondary regions mapped one-to-one to the primary regions."
7064763,A graphics pipeline system and method are provided for graphics processing. Such system includes a transform module positioned on a single semiconductor platform for transforming graphics data from object space to screen space. Coupled to the transform module is a lighting module which is positioned on the single semiconductor platform for lighting the graphics data. Also included is a rasterizer coupled to the lighting module and positioned on the single semiconductor platform for rendering the graphics data.
7065630,"Systems and methods for providing on-demand memory management. In response to a mapping request from a device driver or other program, a first portion of the memory is mapped to one or more virtual addresses in a first region of a virtual memory space so that it can be directly accessed by the CPU. In response to an unmapping request the first portion of the memory is unmapped. Mapping and unmapping requests may be made at any time."
7068272,"A system, method and article of manufacture are provided for early Z-value based culling prior to pixel rendering in a graphics pipeline. In initial stages of processing, Z-value culling is performed on at least one pixel. Thereafter, the pixel is conditionally rendered. Whether the pixel is rendered or not is conditioned on results of the Z-value culling. By culling, or removing, the pixels that do not meet certain criteria prior to rendering, much processing is avoided in the rendering portion of the graphics pipeline."
7068278,"A graphics processing unit, which includes a clock generator configured to generate a clock signal and a controller coupled to the clock generator. The controller is configured to receive the clock signal, compare the clock signal with a synchronization signal to generate a timing signal, and transmit the timing signal to a second graphics processing unit connected to the graphics processing unit."
7071947,A system adjusts floating-point-valued images prior to conversion to a display signal so that the dynamic range of the display device is effectively used. Images are adjusted using transfer functions to create an adjusted image within the dynamic range of the display device. The adjusted image also has a frequency distribution of pixel values to maximize the perception of visual detail. The system generates transfer functions from statistical attributes of one or more images. The transfer functions are applied to images on the fly as they are converted into a display signal. The statistical attributes of the image are computed on the fly as it is converted into a display signal. A first transfer function is applied to an image to produce an adjusted image in parallel with the generation of a second transfer function to be applied to a future image.
7075539,"A computing system has a graphics processor, a graphics memory, main memory, a bridge, and a central processing unit configured to process floating-point data of a first fixed size. An interconnect grid includes communication paths to link the graphics processor, the graphics memory, main memory, the bridge, and the central processing unit. A computing system component (e.g., the graphics processor or central processing unit) converts floating-point data to graphics floating-point data with a fixed size smaller than the fixed size of the floating-point data. The computing system passes the floating-point data and/or the graphics floating-point data over at least a portion of the interconnect grid. Alternately, the graphics processor may directly read and process previously compressed and stored graphics floating-point data."
7075541,"Systems and methods for balancing a load among multiple graphics processors that render different portions of a frame. A display area is partitioned into portions for each of two (or more) graphics processors. The graphics processors render their respective portions of a frame and return feedback data indicating completion of the rendering. Based on the feedback data, an imbalance can be detected between respective loads of two of the graphics processors. In the event that an imbalance exists, the display area is re-partitioned to increase a size of the portion assigned to the less heavily loaded processor and to decrease a size of the portion assigned to the more heavily loaded processor."
7077679,"This clip is used to secure a connection bridge onto the top edge of two graphics adaptor cards. It works by securing with a screw through the graphics adaptor card bracket that when tightened, applied downward pressure onto the bridge. The pressure is created by the bump above the screw boss; when the screw is tightened the bump acts as a pivot point and applied downward force on the other side of the pivot point to the bridge."
7079156,A rasterizer stage configured to implement multiple interpolators for graphics pipeline. The rasterizer stage includes a plurality of simultaneously operable low precision interpolators for computing a first set of pixel parameters for pixels of a geometric primitive and a plurality of simultaneously operable high precision interpolators for computing a second set of pixel parameters for pixels of the geometric primitive. The rasterizer stage also includes an output mechanism coupled to the interpolators for routing computed pixel parameters into a memory array. Parameters may be programmably assigned to the interpolators and the results thereof may be programmably assigned to portions of a pixel packet.
7080194,"A method and system for arbitrating among memory access commands from clients seeking access to a DRAM or other memory, and an arbiter for use in implementing such method or system. When arbitrating among competing commands that include at least one command of the same read/write type as the current command, the arbiter selects a command of the same read/write type as the current command. In a wait mode, when arbitrating among a set of the commands that includes no command of the same read/write type as the current command, the arbiter prevents each command in the set from reaching the memory. Preferably, after operating in the wait mode for a limited time, the arbiter enters another arbitration mode in which it can select a command of the opposite read/write type as the current command. Preferably, the arbiter is implemented to be operable in any of multiple operating modes. For example, it can have separately programmable wait times for “read to write” and “write to read” situations. Preferably, the arbiter monitors for occurrence of potential page fault conditions."
7081895,"Method and apparatus for graphics processing is described. More particularly, a graphics processing subsystem capable of multi-pass graphics data processing is described. The graphics processing subsystem includes a geometry processor and a fragment processor, where output from the fragment processor is input compatible with the geometry processor. Data produced in a pass through a graphics data-processing pipeline including the fragment processor and geometry processor may be used as an input to processing during a subsequent pass. Data read from a texture map may be used to define or modify data, including vertex data, being processed in the geometry processor or the fragment processor."
7081896,"Methods and apparatus for changing the timing of memory requests in a graphics system. Reading data from memory in a graphics system causes ground bounce and other electrical noise. The resulting ground bounce may be undesirably synchronized with a video retrace signal sent to a display, and may therefore cause visible artifacts. Embodiments of the present invention shift requests made by one or more clients by a duration or durations that vary with time, thereby changing the timing of the data reads from memory. The requests may be shifted by a different duration for each memory request, for each frame, or multiples of requests or frames. The durations may be random, pseudo-random, or determined by another algorithm, and they may advance or delay the requests. By making the ground bounce and other noise asynchronous with the video retrace signal, these artifacts are reduced or eliminated."
7081902,"A graphics processor performed gamma correction of the coverage values of pixels. In one embodiment, a gamma correction factor is written into a run-time loadable lookup table of the graphics processor. The gamma corrected coverage values may be used in an anti-aliasing process to form smoothed primitives."
7084780,"Aspects for remotely controlling audio/visual (A/V) devices with a personal computer (PC) are described. The aspects include providing connection hardware for connecting a plurality of A/V devices to a PC. A remote control device with selectable buttons is provided for transmitting data signals wirelessly to the connection hardware. The plurality of A/V devices are controlled according to the data signals from button selections on the remote control device. Through the present invention, a multi-function wireless remote is disclosed which allows for full command of a plurality of A/V devices in a PC, such as a DVD player, TV receiver, Digital Video Recorder (DVR), and electronic programming guide. In this manner, PC users are ensured of a simplified and intuitive interactive PC/video experience."
7085184,"A delayed bitline leakage compensation circuit for memory devices is disclosed. The delayed bitline leakage compensation circuit includes a bitline leakage model circuit for modeling discharge of a bitline by leakage current in a read operation. It further has a delayed charge signal generator for generating a delayed charge signal in response to the bitline leakage model circuit discharging to approximately a discharge threshold. The delayed charge signal generator is deactivated if the bitline is discharged by a selected memory cell. Moreover, the delayed bitline leakage compensation circuit includes a delayed charge circuit for charging the bitline in response to the delayed charge signal."
7091979,"A pixel load instruction for a programmable graphics processor. The pixel load instruction may be used during processing of graphics data to load graphics data from a writable output buffer into a local storage element. Using the pixel load instruction may ensure that the graphics data loaded is current, i.e., any pending writes to the location storing the graphics data are completed prior to loading the graphics data. Furthermore, the pixel load instruction may be enabled and disabled for one or more writable output buffers by setting or clearing bits in a pixel load enable register."
7091982,A graphics processor is disclosed having a programmable Arithmetic Logic Unit (ALU) stage for processing pixel packets. Scalar arithmetic operations are performed in the ALUs to implement a graphics function.
7091983,"An apparatus and method for using non-power of two texture maps with anisotropic filtering is described. An anisotropic perturbation is applied to a texture map coordinate to produce a perturbed texture coordinate. A wrapped texture map index for various wrap modes is computed using the perturbed texture coordinate and an LOD width. In addition to the anisotropic perturbation, the perturbed texture coordinate may also include a tap perturbation."
7091984,"A method for displaying a desktop display surface. The method includes creating a render target surface having substantially the same dimensions as a desktop display surface, casting the desktop display surface as a texture, and setting the render target surface as a scanout read location. The method further includes creating a two dimensional rectangular object, rendering the two dimensional rectangular object by mapping the desktop display surface texture to the two dimensional rectangular object, storing the rendered two dimensional rectangular object to the render target surface and scanning out the rendered two dimensional rectangular object from the render target surface."
7095386,"A graphics display system is disclosed. The display system comprises a plurality of heads. Each of the plurality of heads includes a VGA controller and each of the plurality of heads is adapted for a display. The graphics display system also includes a host coupled to the plurality of heads, wherein all the standard VGA settings for each of the plurality of the heads could be programmed by a single command by the host. Each of the heads are adapted for a display. A system and method for providing a broadcast mode VGA feature is disclosed. A method and system in accordance with the present invention includes one VGA controller per head. In so doing, in a broadcast mode a write transaction from the bus is broadcast or written to both heads. Also, in a broadcast mode, the VGA read data from the bus always comes from one of the heads. The output timing registers specific to a non-CRT output are not broadcast. To provide broadcast VGA to a CRT and/or a flat panel, software sets up the timing in extended registers and enables the display devices. The VGA application can then provide mode settings via the appropriate write VGA registers and the correct display will be on each head."
7095414,"A system and method are provided for a hardware implementation of a blending technique during graphics processing in a graphics pipeline. During processing in the pipeline, a plurality of matrices and a plurality of weight values are received. Also received is vertex data to be processed. A sum of a plurality of products may then be calculated by the multiplication of the vertex data, one of the matrices, and at least one of the weights."
7098922,"Multiple output buffers are supported in a graphics processor. Each output buffer has a unique identifier and may include data represented in a variety of fixed and floating-point formats (8-bit, 16-bit, 32-bit, 64-bit and higher). A fragment program executed by the graphics processor can access (read or write any of the output buffers. Each of the output buffers may be read from and used to process graphics data by an execution pipeline within the graphics processor. Likewise, each output buffer may be written to by the graphics processor, storing graphics data such as lighting parameters, indices, color, and depth."
7100013,"A method for managing host system power consumption is provided. The host system includes host memory and external memory. The method initiates with providing a processor in communication with a memory chip over a bus. The memory chip is external memory. Then, a usage measurement of the external memory is determined. If the usage measurement is below a threshold value, the method includes copying data from the memory chip to the host memory and terminating power to the memory chip. In one embodiment, the power is terminated to at least one bank of memory in the memory chip. In another embodiment, an amount of reduction of the external memory can be determined rather than a usage measurement. In yet another embodiment, an address map is reconfigured in order to maintain a contiguous configuration. A graphical user interface and a memory chip are provided also."
7102646,"A memory system and methods of operating the same that drastically increase the efficiency in memory use and allocation in graphics systems. In a graphics system using a tiled architecture, instead of pre-allocating a fixed amount of memory for each tile, the invention dynamically allocates varying amounts of memory per tile depending on the demand. In one embodiment all or a portion of the available memory is divided into smaller pages that are preferably equal in size. Memory allocation is done by page based on the amount of memory required for a given tile."
7103720,"Methods and systems for caching graphics data using dedicated level one caches and a shared level two cache are described. Furthermore, each method includes a protocol for maintaining coherency between the level one caches and between the level one caches and the level two cache. The level one caches may store different versions of the graphics data, permitting simultaneous processing of execution threads, each thread accessing a different version of the graphics data."
7106336,"A method of deferring evaluation of a transform, in accordance with one embodiment of the present invention, includes buffering a plurality of vertex data. The method also includes receiving a draw command, accessing a given vertex data corresponding to the draw command and an associated transform indicator bit. The given vertex data is transformed if the associated indicator bit is cleared. After performing the transform, the vertex data is overwritten with the transformed vertex data and the associated transform indicator bit is set."
7109996,"A system and method for rendering fonts into a memory is disclosed. The system and method comprises a data structure located within the memory. The data structure includes at least one font array. The method and system includes a graphics controller for accessing at least one font array in the memory and for rendering characters of at least one font array into the appropriate locations in the memory to be scanned onto a monitor. Accordingly, a system and method in accordance with the present invention provides for a plurality of font arrays to be provided within a memory of a computer system. The memory could be the frame buffer, system memory or any other memory within the computer system. The graphics controller includes a mechanism which allows for a font array to be accessed by the graphics controller. The graphics controller also includes a mechanism for allowing each font character to be rendered into the memory. In so doing, the number of transfers from the CPU is significantly reduced."
7109999,A method and system for implementing programmable texture lookups from texture coordinate sets. The method includes the step of generating a plurality of texture coordinates using a shader module. The shader module executes floating point calculations on received pixel data to generate the texture coordinates. A plurality of texture values are fetched using the texture coordinates. The fetching is performed by a texture unit coupled to receive the texture coordinates from the shader module. The fetching of the texture values is programmable with respect to the texture coordinates such that the number of texture coordinates are decoupled from the number of textures.
7117238,"A pipelined circuit configured to generate a Taylor's series approximation at least one function, preferably at least one of the reciprocal and the reciprocal square root, of an input value. The circuit is preloaded with or configured to generate a predetermined set of Taylor's series coefficients for each segment of the input value range. Other aspects of the invention are methods for determining preferred parameters for elements of such a circuit, a circuit designed in accordance with such a method, and a system (e.g., a pipelined graphics processor) for and method of pipelined graphics data processing using any embodiment of the circuit. The preferred parameters are determined by minimizing the circuit's size subject to constraints on input and output value format and output accuracy, assuming a specific function to be approximated and a specific degree for the approximation but allowing variation of parameters such as coefficient width and number of input value range segments."
7117421,"The present invention provides flexible and efficient memory configuration that is capable of economically addressing both resource consumption and ECC concerns. A memory system facilitates transparent ECC operations without dedicated ECC connections. A first dynamic random access memory structure stores data, wherein the data connections to the memory system are limited to the width of the first dynamic random access memory structure. A second dynamic random access memory structure dedicated to storing error correction code information, wherein the error correction code information is accessed via the data connections. In one exemplary implementation, the first memory structure and the second memory structure the data and ECC are included in the same memory bank. In an alternate implementation, the first memory structure and the second memory structure the data and ECC are included in the different memory banks and are accessed in parallel."
7119806,"A system, method and article of manufacture are provided for shadow mapping while rendering a primitive in a graphics pipeline. Initially, an offset operation is performed in order to generate a depth value while rendering a primitive. Further, a value of a slope associated with an edge of the primitive is identified. Thereafter, the depth value is conditionally clamped based on the value of the slope."
7120653,"A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. In one embodiment, file handling functions are now integrated into a storage processing unit (SPU) that can also be deployed on the same chipset, where the SPU serves as an overall file and disk management processor."
7120816,"A method for testing synchronization between a first graphics processing unit coupled to a second graphics processing unit. The method includes detecting whether an incoming synchronization signal has been received, determining whether the incoming synchronization signal is received from one of the first graphics processing unit, the second graphics processing unit and an external synchronization signal, and indicating on a control panel one of a first and second synchronization input/output ports on one of the first graphics processing unit and the second graphics processing unit as an input port and the other one of the first and second synchronization input/output ports as an output port, if the incoming synchronization signal is received from the one of the first graphics processing unit and the second graphics processing unit."
7120930,"Method and apparatus for enhanced security for communication over a network, and more particularly to control of security protocol negotiation to enable multiple clients to establish a virtual private network connection with a same remote address, is described. A mapping table accessible by a gateway computer is used to form associations between a local address for the client and a destination address for a peer and a Security Parameters Index associated with IPSec-protected traffic from the peer. When a packet is received at the gateway from a client it is checked to determine if it is an Internet Key Exchange (IKE) packet, whether an IKE session has already been recorded from this client in the mapping table for the destination address in the IKE packet, whether a Security Parameters Index has been observed in the clear from a remote computer associated with the destination address."
7123180,"A remote control device and method are described for controlling an input parameter to an electronic device. In one embodiment, the remote control device includes a housing sized to be held in the hand of a user during operation of the remote control device and a gyroscopic sensor that is integrated with the housing and configured to produce a signal in response to an angular motion about a single reference axis. The input parameter that the user wants to control is responsive to the signal that the gyroscopic sensor produces when the gyroscopic sensor is activated."
7126608,"A graphics processor or display device including a microcontroller that functions as a sequencer, a computer system including at least one such graphics processor or display device, and a microcontroller for use in such a graphics processor or display device. In preferred embodiments, the microcontroller functions as a sequencer for controlling the timing of power up and/or power down operations by one or both of a graphics processor and a display device. The microcontroller is implemented to exclude any capacity to handle interrupts and so can provide guaranteed timing, and is preferably implemented to be small, simple, and programmable, and to store a small number of programs. Each program consists of instructions belonging to a small instruction set, such as a set consisting of set and clear instructions (for overriding or overwriting specified register bits) and wait, release, and stop instructions. When executing a program, the microcontroller typically overrides (in an ordered sequence) state and control bits that would otherwise be asserted."
7126826,"The present invention represents a significant advancement in the field of thermal solutions for computer hardware. In one embodiment, a quick-connect system for cooling a heat-generating electronic device is provided. The electronic device is mounted to a first side of a circuit board. The system includes a first plate having an opening and configured to be coupled to the first side of the circuit board. The system further includes a second plate disposed within the opening and coupled to the first plate with a first suspension system, wherein the first suspension system is configured to enable the second plate to be disposed substantially flat against the electronic device when the first plate is coupled to the first side of the circuit board. The system further includes a cooling module thermally coupled to the second plate and configured to dissipate heat transferred from the electronic device to the second plate."
7129909,"A method and system using a compressed display mode list is disclosed. In particular, the compressed display mode list includes a plurality of data representing the display modes. The data is formatted according to a plurality of compression format rules. The compression format rules reduce and minimize the size of the compressed display mode list. A driver controls a graphical processing unit that renders an image for displaying on a display device according to a selected display mode from the compressed display mode list. Moreover, a computer-readable medium can store the compressed display mode list."
7133892,"A system, method and computer program product are provided for network-based information management. A first habitat is initiated. The first habitat has markers that are utilized for identifying information selected by a user. The information associated with the markers is retrieved and displayed on an information screen of the first habitat utilizing a network. Multiple users are allowed to view the information screen of the first habitat. A second habitat is also allowed to access the first habitat for retrieving information from the first habitat."
7136068,"A method and apparatus which includes a graphics accelerator, circuitry responsive to pixel texture coordinates to select texels and generate therefrom a texture value for any pixel the color of which is to be modified by a texture, and a cache for texels for use by the circuitry to generate texture value for any pixel."
7136070,"A system, method and computer program product are provided for programmable pixel processing in a computer graphics pipeline. In one embodiment of the present invention, a computed arbitrary quantity is applied as texture address."
7136071,An apparatus and method for using non-power of two texture maps is described. Normalized texture map coordinates such as s and t are converted from a floating point format to a fixed point format and wrapping operations are performed to produce unnormalized texture map coordinates such as u and v corresponding to non-power of two texture maps.
7136081,"This invention relates generally to the art of computer graphics, and more specifically to the field of line sampling object scene information for the purpose of reconstructing an image of the object scene. In particular, the inventions distributes a set of line samples across an image plane such that the distribution of the set of line samples is non-regular. Additionally, the invention projects objects from an object scene onto an image plane and computes a view of the objects along each line sample in the set of line samples. Finally, the invention combines the view along each line sample in the set of line samples to form a view of the object scene."
7136953,"A bus permits the number of active serial data lanes of a data link to be re-negotiated in response to changes in bus bandwidth requirements. In one embodiment, one of the bus interfaces triggers a re-negotiation of link width and places a constraint on link width during the re-negotiation."
7139003,"Apparatuses and methods for detecting position conflicts during fragment processing are described. Prior to executing a program on a fragment, a conflict detection unit, within a fragment processor checks if there is a position conflict indicating a RAW (read after write) hazard may exist. A RAW hazard exists when there is a pending write to a destination location that source data will be read from during execution of the program. When the fragment enters a processing pipeline, each destination location that may be written during the processing of the fragment is entered in conflict detection unit. During processing, the conflict detection unit is updated when a pending write to a destination location is completed."
7142192,"Embodiments of the present invention generally provide methods, systems, and articles of manufacture for locating a cursor displayed on one of a set of one or more monitors. According to some embodiments, in response to receiving specified user input, visual indication of the location of the cursor may be provided on one or more monitors not containing the cursor. Visual indication of the location of the cursor may also be provided on the monitoring containing the cursor. The specified user input may include any type of suitable user input, such as mouse movements, keystroke sequences (e.g., hot keys,) and/or audio input (e.g., voice commands). For some embodiments, parameters used for locating the cursor (e.g., the specified user input, sensitivity to mouse movements, etc.) may be specified by a user, for example, via a graphical user interface (GUI) screen."
7142206,"Method and apparatus for shaping a shared edge between two or more N-patches is described. More particularly, vertices and normals of a polygon, tristip, quadstrip and so on, are obtained. Shared vertices corresponding to the shared edge are identified. When normal vectors at a shared vertex are determined to differ, tangents of the normal vectors are computed. These tangents may be used to optionally shape the shared edge, along with control points."
7142214,"A graphics processor includes programmable arithmetic logic units (ALUs) for performing scalar arithmetic operations on pixel packets. For a selected scalar arithmetic operation, operands in pixel packets may be formatted in a S1.8 format to improve dynamic range. For at least one other scalar arithmetic operation, the pixel packets may be formatted in a different data format."
7142215,A graphics data-processing pipeline including a geometry processor and a fragment processor. The graphics data-processing pipeline being configured to render stencil data and to output the stencil data in a format compatible with input to the fragment processor. An output of the graphics data-processing pipeline is written to local memory and the output is subsequently read using the fragment processor without host processor intervening usage to format the stencil data or process the stencil data.
7143137,"Method and apparatus for Internet Protocol Security (IPSec) and Network Address Translation (NAT) integration is described. A client obtains a public address from a gateway for IPSec communication. A mapping table is used to form associations between a local address for the client and a destination address for a peer, an Internet Security Association and Key Management Protocol (ISAKMP) Initiator Cookie and a Security Parameters Index associated with communication between the client and the peer. Incoming and outgoing routing may be done at the gateway using the mapping table."
7143188,"Method and apparatus for enhanced security for communication over a network, and more particularly to Network Address Translation (NAT) integration Internet Protocol Security (IPSec), is described. A client computer makes a second address request in order to prompt an address server to provide a public address. This address, recorded in a mapping table accessible by a gateway computer. This public address is used as a source address for packets from a client using IPSec. When the gateway computer identifies a packet's source address as one of it's public addresses, NAT is suspended for this packet, and the packet is routed without NAT. Incoming traffic is routed using the mapping table."
7145565,"Lights can be conservatively bounded within a depth range. When image pixels are outside of a light's depth range, an associated volume fragment does not have to be rendered. Depth bounds registers can be used to store minimum and maximum depth values for a light. As graphics hardware processes volume fragments overlapping the image, the image's depth values are compared with the values in the depth bounds register. If the image's depth is outside of the depth range for the light, stencil buffer and illumination operations for this volume fragment are bypassed. This optimization can be performed on a per-pixel basis, or simultaneously on a group of adjacent pixels. The depth bounds are calculated from the light, or from the intersection of the volume with one or more other features. A rendering application uses API functions to set the depth bounds for each light and to activate depth bounds checking."
7151543,"Method and interface for sending vertex data output from a vertex processing unit to memory is described. Conventionally, the vertex data output is not output directly to memory via a dedicated write interface, but is instead passed through downstream computation units in a graphics processor and written to memory via the write interface normally used to write pixel data. When the downstream computation units are configured to pass the vertex data output through unmodified, processing of the vertex data output by the downstream computation units is deferred until a second pass through those units. When the vertex data output is output directly to memory, processing of the vertex data output by the downstream computation units can be initiated during a first pass through those units."
7151667,"One embodiment of a modular, scalable cooling system includes a core cooling module configured to be thermally coupled to a heat-generating electronic device and a supplemental cooling module configured to be thermally coupled to the core cooling module. A first interface attached to the core cooling module is configured to thermally couple the core cooling module to the supplemental cooling module. The core cooling module and the supplemental cooling module may be used alone or in combination to dissipate heat from the heat-generating electronic device."
7154507,"A system, method and computer program product are provided for texture shading in a hardware graphics processor. Initially, a plurality of texture coordinates is identified. Further, it is determined whether a hardware graphics processor is operating in a texture shader mode. If the hardware graphics processor is operating in the texture shader mode, the texture coordinates are mapped to colors utilizing a plurality of texture shader stages in the hardware graphics processor. If, however, the hardware graphics processor is not operating in the texture shader mode, the texture coordinates are mapped to colors utilizing a conventional graphics application program interface (API) in conjunction with the hardware graphics processor."
7154749,"One embodiment of a system for efficiently cooling a processor includes a mounting plate configured to be thermally coupled to the processor, a passive heat transport device thermally coupled to the mounting plate and a heat exchanger coupled to the passive heat transport device."
7159104,"Automatic recognition of the type of memory within a device package by using strap resistors within the device package. Such recognition enables a processor, such as a GPU, to automatically configure itself to work with the memory. A device package includes a strap contact and a bit input that are electrically connected. The device package beneficially contains a processor (such a GPU) that is operatively connected to the bit input, and a memory device that is operatively connected to the processor. By selectively inserting a strap resistor the voltage applied to the bit input changes state. That state can be read and used to set up the system."
7159112,"Encrypted graphics data is transmitted between systems or components of a system. The data is decrypted within a graphics processor or other recipient device that has been provided with an appropriate key. In one embodiment, encryption is performed by perturbing selected parameters of the graphics data so that the encrypted data can be used to generate a distorted image, and decryption is performed by reversing the perturbation."
7161812,"A surface mount grid array implemented on a PCB (printed circuit board) optimized for trace escape routing for the PCB. The surface mount grid array includes a plurality of connection blocks, with each connection block including an array of pins and an array of vias, wherein the pins and vias are configured to communicatively connect an integrated circuit device to a plurality of traces of the PCB. The connection blocks are disposed in a tiled arrangement, wherein the connection blocks implement a plurality of trace escape channels along connection block boundaries. The trace escape channels are configured for routing traces from inner pins of the surface mount grid array to a periphery of the surface mount grid array."
7162716,A central processing unit (CPU) including an operating system for executing code segments capable of performing graphics processing on the CPU. Associated therewith is a graphics application specific integrated circuit (ASIC) for performing graphics processing in accordance with a graphics processing standard. An extension to the software is included that identifies a first portion of the graphics processing to be performed on the graphics ASIC and a second portion of the graphics processing to be performed on the CPU. Such second portion of the graphics processing includes application-programmable vertex processing unavailable by the graphics ASIC. A compiler compiles the software to execute the first portion of the graphics processing on the graphics ASIC and the second portion of the graphics processing on the CPU in accordance with the extension.
7166934,A device package that receives a voltage from a power supply on a motherboard and that includes provisions for a voltage control element that controls the power supply voltage. The provisions for the voltage control element are such that the voltage from the power supply has a first voltage if the voltage control element is installed and a second voltage if the voltage control element is missing. Such a device is useful in (computer) systems having wiring boards with power supplies that produce output voltages that depend on adjust voltages on adjust inputs. The provisions of the device package can then set the adjust voltage such that the power supply has a first voltage if the voltage control element is installed and a second voltage if the voltage control element is missing.
7167183,"The current invention involves new systems and methods for reorganizing a texture sampling order that is used to read texels from a texel cache. When anisotropic filtering is used to process the texels read from the texel cache, the texels are read in an order based on a major axis alignment. Reorganizing texture sampling order to use the order based on the major axis alignment results in improved texel cache locality, thereby improving texel cache performance."
7170513,"A system and method are provided for conditional branching in a hardware graphics pipeline. Initially, a plurality of graphics commands is received. Condition data is then affected based on at least some of the graphics commands utilizing the hardware graphics pipeline. At least one of the graphics commands is then conditionally skipping based on the condition data in response to another graphics command utilizing the hardware graphics pipeline."
7170515,"A rendering pipeline system for a computer environment uses screen space tiling (SST) to eliminate the memory bandwidth bottleneck due to frame buffer access and performs screen space tiling efficiently, while avoiding the breaking up of primitives. The system also reduces the buffering size required by SST. High quality, full-scene anti-aliasing is easily achieved because only the on-chip multi-sample memory corresponding to a single tile of the screen is needed. The invention uses a double-z scheme that decouples the scan conversion/depth-buffer processing from the more general rasterization and shading processing through a scan/z engine. The scan/z engine externally appears as a fragment generator but internally resolves visibility and allows the rest of the rendering pipeline to perform setup for only visible primitives and shade only visible fragments. The resulting reduced raster/shading requirements can lead to reduced hardware costs because one can process all parameters with generic parameter computing units instead of with dedicated parameter computing units. The invention processes both opaque and transparent geometries."
7170757,"One embodiment of a field changeable graphics system for a computing device includes a graphics card and an interface assembly. The interface assembly is adapted to interface the graphics card with the motherboard of a computing device, without directly mounting the graphics card to the motherboard. One advantage of the disclosed graphics system is that it enables a computing device user to upgrade the existing device's graphics system. Thus, the user is not forced to purchase an entirely new computing device in order to take advantage of graphics innovations. This advantage is particularly significant for users of portable computing devices, such as laptop computers and PDAs."
7171051,"Method and apparatus for providing texture and/or alpha compression. In one embodiment, the present invention incorporates stored palettes, e.g., a luminance palette and a chrominance palette such that, compressed texture data pertaining to a fixed blocksize is decoded and applied to the stored palettes to extract the texel data. In a second embodiment, the present method uses a plane to estimate the alpha value at each of the texels, and a three-bit correction factor to adjust the estimate to produce a final alpha value."
7173635,"Methods, apparatus and systems for the display, on a remote node, of a three-dimensional (3D) image rendered on a host system in a first image format are described. In general, the 3D image is transformed into a second image format that is compressed (i.e., uses fewer data bits per pixel) relative to the first image format, (optionally) scaled to a screen size of remote node, and subsequently transferred to remote node for display. In instances, the transformation of the image from the first image format to the second image format and the optional scaling of the image to the screen size of remote node may be done in a graphics processing unit (GPU) on the host system. As an example, the first image format may be an RGB-based format, such as RGBA (32-bits per pixel) or standard RGB (24-bits per pixel) and the second image format may be a YUV-based format, such as YV12 (12-bits per pixel)."
7174432,"The present invention provides a system and method for implementation and use of a shared memory. The shared memory may be accessed both independently and asynchronously by one or more processes at corresponding nodes, allowing data to be streamed to multiple processes and nodes without regard to synchronization of the plurality of processes. The various nodes may be adaptive computing nodes, kernel or controller nodes, or one or more host processor nodes. The present invention maintains memory integrity, not allowing memory overruns, underruns, or deadlocks. The present invention also provides for “push back” after a memory read, for applications in which it is desirable to “unread” some elements previously read from the memory."
7174436,"In a multi-processor, multi-memory system, a technique designates portions of a local memory as being regions to be shadowed. A shadow control unit detects write operations to those regions designated for shadowing. The shadow control unit then executes a cloning of a write operation designated for a local memory region to be shadowed and provides the cloned data to a memory space in system memory which corresponds to the local memory region which is being shadowed."
7176878,"Embodiments of the present invention generally provide m Methods and apparatus for reducing power consumption of backlit displays are described. Power consumption is reduced by dimming backlighting by a first scale factor and boosting pixel values by a second scale factor to compensate for the dimming. The scale factors may be constant values. Alternately, one or both of the scale factors may be determined based on pixel values for one or more frames to be displayed and/or one or more frames that have been displayed. For example, scale factors may be calculated based on an average linear amplitude of one or more frames of pixel values or from a maximum pixel value of one or more frames of pixel values. A graphical processing system is described including an integrated circuit capable of transforming a pixel value from a gamma-compensated space to a linear space."
7178130,"A system whereby a data flow language written in relatively high-level description is compiled to a hardware definition. The hardware definition is then used to configure data flow in a target processing system at execution time, or run time. In a preferred embodiment, the target processing system includes a Reduced-Instruction Set Computer (RISC) processor in communication with a finite state machine (FSM), shared memory, on-board memory, and other resources. The FSM is primarily used for accelerating matrix operations and is considered the target machine to be configured according to the dataflow definition. The RISC processor serves as a co-processor to an external central processing unit (CPU) that is a host processor for executing application code. Other embodiments can use aspects of the invention in any other processing architecture. A dataflow language is used to define interconnections among hardware elements in the matrix datapath and controlled by FSM at run time and, thus, to determine hardware functionality at run time. The interconnectivity between the matrix datapath components, elements or resources, is capable of changing every clock cycle to optimize preferred calculations. The dataflow language is used to describe the optimized functions to an application programmer. The dataflow language is also compiled to a hardware definition that is used to create aspects of the desired functionality in silicon."
7180742,"An apparatus and method for cooling semiconductor devices. A cooling system for semiconductor devices is disclosed and includes a semiconductor substrate, horizontal channels and a cooling medium. Specifically, the semiconductor substrate is incorporated into a die. Also, one or more horizontal channels are formed in a backside of the semiconductor substrate of the die. The horizontal channels collect thermal energy that is generated by electrical components located on a front side of the semiconductor substrate. A cooling medium circulates within the one or more horizontal channels for transferring the thermal energy away from the die."
7184040,Early stencil rejection is used to improve throughput of a graphics processing pipeline. Early stencil rejection of some fragments may be performed prior to fragment shading using stencil test results based on a predicted stencil function. Early stencil rejection is performed when either the predicted stencil function matches the actual stencil function or the actual stencil function is a subset of the predicted stencil function. Early stencil rejection is performed without additional read accesses of a stencil buffer.
7185286,"A graphical user interface (GUI) for visual representation and manipulation of a transaction pattern. The GUI includes a workplace view for receiving user specification of content and/or a transaction for a transaction pattern, a pattern view for manipulating properties of the pattern, a device editor view for specifying pattern-related output on a client device, and a script view that allows a user to utilize scripting. A system, method and article of manufacture for recording a transaction pattern utilizing a graphical user interface are also provided. An interface is displayed. A user is allowed to specify interactions with content via the interface. The interactions are recorded. A pattern is generated based on the recorded interactions. The pattern, which includes a graphical representation of each interaction, is displayed on a GUI. Methods for recording an interaction with a database, recording a File Transfer Protocol (FTP) interaction, and generating a template for an electronic mail message are provided."
7187220,"Circuits, methods, and apparatus for slowing clock circuits on a graphics processor integrated circuit in order to reduce power dissipation. An exemplary embodiment of the present invention provides a graphics processor having two memory clocks, specifically, a switched memory clock and an unswitched memory clock. The switched memory clock frequency is reduced under specific conditions, while the unswitched memory clock frequency remains fixed. In a specific embodiment, the switched memory clock frequency is reduced when related graphics, display, scaler, and frame buffer circuits are not requesting data, or are such data requests can be delayed. Further refinements to the present invention provide circuits, methods, and apparatus for ensuring that the switched and unswitched memory clock signals remain in-phase and aligned with each other."
7188250,"A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though, in one embodiment, it is sharing the same chip."
7188263,An arrangement provides for further power reduction where a system includes two or more electrical components that can be placed into two or more power consumption states. The arrangement can take advantage of existing circuitry to selectively disable certain state transition detectors to thereby provide additional power reduction.
7190366,"A method and system for a general instruction capable raster stage that generates flexible pixel packets is disclosed. In one embodiment, the rasterizing of a geometric primitive comprising a plurality of vertices wherein each vertex comprises a respective color value, is performed by a rasterization module of a graphics pipeline. The rasterizing includes a plurality of programmable interpolators for computing pixel parameters for pixels of a geometric primitive. The rasterizing module further includes a memory for storing a first instruction associated with a first programmable interpolator for indicating a first parameter on which said first programmable interpolator is to operate and for indicating a first portion of a pixel packet in which to store its results. The rasterizing module additionally includes a memory for storing a second instruction associated with a second programmable interpolator for indicating a second parameter on which said second programmable interpolator is to operate and also for indicating a second portion of said pixel packet in which to store its results."
7191088,A method and system for memory temperature measurement. The method includes the step of monitoring a plurality of accesses to a memory component. A number of accesses occurring to the memory component over a time period is determined. A temperature of the memory component is determined based on the number of accesses occurring over the time period.
7191331,"Method and apparatus for integration of network address translation and source address security, including, but not limited to, determining whether a gateway computer is integrated for network address translation and source address security, is described. A client computer requests a first address from the gateway computer and then requests a second address from the gateway computer. The latter request is done with a different client identifier that is nearly equivalent, except for one bit, to the client identifier used for the prior address request. If the gateway computer is integrated for network address translation and source address security, in response to the latter request a public address will be provided from the gateway computer to the client computer."
7193627,"Trilinear optimization is a technique to reduce the number of texture samples used to determine a texture value associated with a graphics fragment. Bilinear interpolations replace some trilinear interpolations, thereby reducing the number of texture samples read and simplifying the filter computation. A programmable trilinear slope is used to control replacement of a trilinear computation with a bilinear computation, permitting a user to determine a balance between improved texture map performance and texture filtering quality."
7194598,"The present invention provides an adaptive computing engine (ACE) that includes processing nodes having different capabilities such as arithmetic nodes, bit-manipulation nodes, finite state machine nodes, input/output nodes and a programmable scalar node (PSN). In accordance with one embodiment of the present invention, a common architecture is adaptable to function in either a kernel node, or k-node, or as general purpose RISC node. The k-node acts as a system controller responsible for adapting other nodes to perform selected functions. As a RISC node, the PSN is configured to perform computationally intensive applications such as signal processing. The present invention further provides an interconnection scheme so that a plurality of ACE devices operates under the control of a single k-node."
7194605,"A method for compressing a set of instructions in an adaptive computing machine includes identifying frequently executed instructions, inserting an explicit caching instruction associating the identified instructions with an index value in the set of instructions before the identified instructions and replacing at least one instance of the frequently executed instructions subsequent to the explicit caching instruction with a compressed instruction referencing the index value. One or more instructions can be identified for compression, including groups of consecutive or non-consecutive instructions. The explicit caching instruction directs a node in an adaptive computing machine to store instructions in an instruction storage unit in association with an index value. Instructions stored in the storage unit are retrievable with reference to the index value. The compressed instruction may include one or more references to index values, and can include a sequence of index values indicating the sequence of execution of the associated instructions."
7196703,"Method and apparatus for generating a primitive extension defining a generalized primitive is described. The primitive extension defines the connectivity and vertices used to specify a collection of connected primitives, such as a strip-type or fan-type generalized primitive. A generalized primitive includes a number of vertices where some of the vertices are shared with neighboring primitives. The primitive extension includes an originating primitive, vertex data, and connectivity information. The primitive extension provides a general interface for describing a variety of connected primitives."
7197686,"A reconfigurable bit-manipulation node is disclosed. The node includes an execution unit configured to perform a number of bit-oriented functions and a control unit configured to control the execution unit to allow one of the bit-oriented functions to be performed. The execution unit includes a number of elements interconnected with one another to allow the bit-oriented functions to be performed. The elements include a programmable butterfly unit, a number of non-programmable butterfly units, a number of data path elements, a look-up table memory, and a reorder memory. The execution unit is capable of engaging in one of a number of operating modes to perform the bit-oriented functions. The operating modes include a programmable mode and a number of fixed operating modes including Viterbi decoding, turbo decoding and variable length encoding and decoding. The data path elements include a programmable shifter and a programmable combiner."
7199799,A graphics processor includes an arithmetic logic unit (ALU) stage for processing pixel packets. Pixels are assigned as either even pixels or odd pixels. The pixel packets of odd and even pixels are interleaved to account for ALU latency.
7205973,"Embodiments of the present invention generally provide methods, apparatus, systems, and articles of manufacture for gradually dimming backlit displays. The backlit displays may be gradually dimmed by reducing a level of the backlighting from an initial level to a final level in a plurality of steps over a dimming interval. The gradual dimming operations may be performed by any suitable combination of software and hardware components. For some embodiments, parameters used for the dimming, such as the dimming interval and final level of the backlighting, may be specified by a user."
7205997,"A method and system for converting an image data generated by a graphics subsystem into a video format. In one embodiment, the method includes generating the image data, storing the image data in a buffer, capturing the buffer to convert the image data to a texture, mapping the texture to at least one polygon to create a formatted image, and converting the formatted image to a stream of data in the video format."
7206556,"Modification of transmission control parameters is prevented during data transmission in a wireless transmitter. A lockout unit is used to prevent modification of the transmission control parameters during data transmission and allow modification of the transmission control parameters when data is not being transmitted. When the wireless transmitter is included in a computing system a software driver for the wireless transmitter does not need to include a software lockout mechanism. Furthermore, the wireless transmitter including the lockout unit may be tested as a standalone device, facilitating regulatory agency certification as a modular transmitter."
7206872,"A system and method are provided for inserting Interval Markers in a data stream comprising data blocks. Included is a Buffer having a predetermined number of registers for temporarily and storing data blocks read from a Target System, wherein the Buffer temporarily stores a portion of a data transmission requested from an Initiator System. A Block Counter indicates the number of data blocks in the data stream that have been read into the Buffer. A Marker Offset counter indicates where an Interval Marker are inserted relative to the data blocks in the data stream. A Data Transmitter transmits the data blocks temporarily stored within the Buffer whenever sufficient data is present in the Buffer and Interval Markers have been inserted if required, wherein the Data Transmitter updates the Block Counter and the Marker Offset counter after the contents of the Buffer have been transferred to the Data Transmitter. A Marker Insertion Module inserts Interval Markers at positions in the data stream determined by the value of the Marker offset counter, and the value of the Block Counter."
7206902,"A system, apparatus, and method are disclosed for predicting accesses to memory. In one embodiment, an exemplary apparatus comprises a processor configured to execute program instructions and process program data, a memory including the program instructions and the program data, and a memory processor. The memory processor can include a speculator configured to receive an address containing the program instructions or the program data. Such a speculator can comprise a sequential predictor for generating a configurable number of sequential addresses. The speculator can also include a nonsequential predictor configured to associate a subset of addresses to the address and to predict a group of addresses based on at least one address of the subset, wherein at least one address of the subset is unpatternable to the address."
7209133,"A display controller in a computer system controls the asynchronous output of graphics display data in a computer system having at least one fixed resolution flat panel display. Fixed panel displays may have problems displaying non-native resolutions particularly at lower resolutions. The controller of the present invention uses a time base converter, horizontal and vertical Discrete Time Oscillators (DTO), and polyphase interpolator, which may be Discrete Cosine Transform (DCT)-based to expand graphics display data asynchronously from native resolution to at least one resolution suitable for display on a fixed resolution panel. Graphics data may also be output asynchronously to a CRT. Time base converter receives frequency related input parameters and generates at least one asynchronous output at the desired output resolution."
7209140,"A system, method and article of manufacture are provided for programmable processing in a computer graphics pipeline. Initially, data is received from a source buffer. Thereafter, programmable operations are performed on the data in order to generate output. The operations are programmable in that a user may utilize instructions from a predetermined instruction set for generating the same. Such output is stored in a register. During operation, the output stored in the register is used in performing the programmable operations on the data."
7216050,"A system for testing a printed circuit board assembly (PCBA), in accordance with embodiments of the present invention, includes an interface diagnostic module coupled to a multi-dimensional search module. The multi-dimensional search module performs a simultaneous switching output pattern based stress test for each of a plurality of sets of timing parameters. The interface diagnostic module determines an error rate on an interface of the printed circuit board assembly for each of the stress tests. The multi-dimensional search module determines a best set of timing parameters based on the determined error rates."
7218291,"A fragment processor includes a fragment shader distributor, a fragment shader collector, and a plurality of fragment shader pipelines. Each fragment shader pipeline executes a fragment shader program on a segment of fragments. The plurality of fragment shader pipelines operate in parallel, executing the same or different fragment shader programs. The fragment shader distributor receives a stream of fragments from a rasterization unit and dispatches a portion of the stream of fragments to a selected fragment shader pipeline until the capacity of the selected fragment shader pipeline is reached. The fragment shader distributor then selects another fragment shader pipeline. The capacity of each of the fragment shader pipelines is limited by several different resources. As the fragment shader distributor dispatches fragments, it tracks the remaining available resources of the selected fragment shader pipeline. A fragment shader collector retrieves processed fragments from the plurality of fragment shader pipelines."
7221368,"Stippled lines are drawn by evaluating a distance function for a set of points within the area of a stippled line. The distance function gives a distance value proportional to the distance from a point to the end of the stippled line. Using the point's distance value, a pattern index value defines a correspondence between a point and at least one stipple pattern bit. The value of pattern bits are applied to the points on the stippled line, masking the points such that only a portion of the set of points are displayed or determining intensity values according to the position of the points within the stipple pattern. A distance function may be an edge equation associated with the line end or a segment of a polyline. The distance function can be evaluated for the set of points in any order, allowing portions of a stippled line to be drawn in parallel."
7221369,"Apparatus, system, and method for delivering data to multiple memory clients are described. In one embodiment, a graphics processing apparatus includes an output pipeline including a set of memory clients. The graphics processing apparatus also includes a memory controller connected to the output pipeline. The memory controller is configured to retrieve data requested by respective ones of the set of memory clients from a memory. The graphics processing apparatus further includes a buffering module connected between the memory controller and the output pipeline. The buffering module includes a unitary buffer and a buffer controller connected to the unitary buffer. The buffer controller is configured to coordinate storage of the data in the unitary buffer, and the buffer controller is configured to coordinate delivery of the data from the unitary buffer to respective ones of the set of memory clients."
7221371,Shortening a footprint is a technique to reduce the number of texture samples anisotropically filtered to determine a texture value associated with a graphics fragment. Reducing the number of texture samples anisotropically filtered reduces the number of texture samples read and simplifies the filter computation. Programmable knobs are used to shorten the footprint of a pixel in texture space thereby reducing the number of texture samples used during anisotropic filtering. These knobs permit a user to determine a balance between improved texture map performance and anisotropic texture filtering quality.
7221566,"A system is described for cooling a processor. In one embodiment, a heat sink assembly has a fan and air channels. In addition, a heat sink lid that is configured to cover only a region above the fan is coupled to the heat sink assembly."
7221851,"Aspects of performing search transitions in a DVD system are described. The aspects include calculating an instantaneous frame rate, adjusting a timestamp of a frame based on the calculated instantaneous, and displaying the frame according to the adjusted timestamp."
7224359,"A system, method and computer program product are provided for depth clamping in a hardware graphics pipeline. Initially, a depth value is identified. It is then determined as to whether a hardware graphics pipeline is operating in a depth clamping mode. If the hardware graphics pipeline is operating in the depth clamping mode, the depth value is clamped within a predetermined range utilizing the hardware graphics pipeline."
7225216,"Aspects for performing a multiply-accumulate operation on floating point numbers in a single clock cycle are described. These aspects include mantissa logic for combining a mantissa portion of floating point inputs and exponent logic coupled to the mantissa logic. The exponent logic adjusts the combination of an exponent portion of the floating point inputs by a predetermined value to produce a shift amount and allows pipeline stages in the mantissa logic, wherein an unnormalized floating point result is produced from the mantissa logic on each clock cycle."
7225279,"A data distributor in a computational unit of an integrated circuit is enclosed. The data distributor receives data from a network and distributes the data to a plurality of components within the computational unit. The data distributor includes an input mechanism for receiving the data from the network, and distributes the data to a selected component of the plurality of components, a control mechanism responsive to a control signal for distributing the data to the selected component using a data distribution selected between a look-up table-based memory write and a point-to-point distribution with acknowledgement. The plurality of components comprises a Peek/Poke Module, an Execution Unit, a DMA Engine, and a Hardware Task Manager Message Generator. The selected data distribution type may comprise using an output port number or a direct-memory address transfer or an interrupt to distribute the data."
7225323,"A multipurpose functional unit is configurable to support a number of operations including multiply-add and comparison testing operations, as well as other integer and/or floating-point arithmetic operations, Boolean operations, and format conversion operations."
7231138,Aspects of performing single frame backwards playback in a DVD system are described. The aspects include receiving a signal indicating selection of a single frame reverse function. Frame data for a preceding frame of an original playback is then reconstructed while utilizing memory sufficient to support the reconstruction. The reconstructed frame data of the preceding frame is then displayed.
7231585,Systems and methods are disclosed to detect and correct errors in a flash memory by detecting in hardware an error based on one of three selectable modes of error detection and correction; and correcting the error by executing error correction software corresponding to the selected mode of error detection and correction.
7233334,"Accordingly, embodiments of the present invention provide circuits, methods, and apparatus that improve utilization of storage buffers by overwriting data in them as soon as the data is no longer needed. An exemplary embodiment employs a counter to add each time a particular unit of data is needed by a circuit. The counter also subtracts each time the data is actually used by the circuit. When the counter reaches zero, upstream circuitry is checked to see if a command allowing the particular data to be overwritten has been issued. If it has, the command is not waited for, rather the data may be overwritten immediately. Embodiments of the present invention may also make use of one level of indirection to mask physical storage buffer locations from upstream circuitry. In this way, utilization can be improved."
7234161,"Method and apparatus for deflecting connection flooding attacks. Specifically, the stateful firewall allows all connection attempts to flow into the destination host, but monitors the connection attempts to ensure that only legitimate connections are allowed. If the firewall detects that a connection is half-open for longer than a certain timer threshold, it will instruct the destination host to tear down the half-open connection, thereby freeing up resources in the destination host for other connection attempts. The timer threshold can be dynamically adjusted if a connection flooding attack is detected."
7240179,"A system, apparatus, and method are disclosed for increasing the physical memory address space accessible to a processor, at least in part, by translating linear addresses associated with a memory hole into a subset of physical memory addresses that otherwise is inaccessible as system memory by a processor. In one embodiment, a memory controller reclaims memory holes in a system memory divided into ranges of linear addresses, where the system memory includes a number of arbitrarily-sized memory devices. The memory controller includes a memory configuration evaluator configured to determine a translated memory hole size for a memory hole, the memory hole including restricted linear addresses that translate into a subset of physical addresses. Also, memory configuration evaluator can be configured to form adjusted ranges to translate at least one linear address into a subset of physical addresses. As such, the system memory increases by at least the subset of physical addresses."
7240184,"A multipurpose functional unit is configurable to support a number of operations including multiply-add and comparison testing operations, as well as other integer and/or floating-point arithmetic operations, Boolean operations, and format conversion operations."
7243341,A method and apparatus for encoding/decoding between interchange format data and structured data utilizes a scripting language. The structure of the data can be controlled by the sequence of commands in the script and changes to the structure can be implemented by changing the script. A parser/interpreter is the only software necessary to implement the technique.
7245302,"Circuits, methods, and apparatus provide for the storage of texture descriptors in a graphics memory. Since the texture descriptors are stored in a graphics memory, they do not need to be stored in the graphics processor itself, thus reducing graphics processor circuitry and cost. This allows more textures to be associated with each graphics primitive, thereby improving image realism."
7248261,"The present invention provides for accelerating the generation of graphical images that include shadow effects by, for example, reducing the amount of data transmitted and/or stored necessary to render graphics based on stencil shadow volumes. In one embodiment, an exemplary apparatus is configured to render shadows using stencil shadow volumes. The apparatus includes a memory to store a degree of shadowing for each sample. A co-processor, which is coupled to the memory, is configured to generate an indicator that represents a common degree of shadowing associated with the subset of samples. In some cases, the apparatus includes a graphics processing unit (“GPU”), which is coupled to the co-processor, that is configured to render one or more shadows for a computer-generated image based on the indicator."
7248264,"One embodiment of an edge connector for a field changeable graphics system includes a right angle edge connector having a plurality of contact pins adapted to engage contacts on a graphics card. The edge connector is adapted to interface the graphics card with the motherboard of a computing device, without directly mounting the graphics card to the motherboard. One advantage of the disclosed edge connector is that it is compatible with a plurality of graphics cards and systems, thereby enabling a computing device user to upgrade the existing device's graphics system. Thus, the user is not forced to purchase an entirely new computing device in order to take advantage of graphics innovations. A further advantage of the disclosed edge connector is that it enables upgrades to low voltage differential signaling (LVDS) features, without the need for additional costly devices capable of operating at LVDS data rates."
7248597,"The present invention permits an I/O port to be used with a variety of different I/O devices, regardless of their device type implementation, such as tri-state I/O devices, pull-up I/O devices, or pull-down I/O devices. Thus, one set of pins may be used for various different I/O devices."
7249242,"Input pipeline registers are provided at inputs to functional units and data paths in a adaptive computing machine. Input pipeline registers are used to hold last-accessed values and to immediately place commonly needed constant values, such as a zero or one, onto inputs and data lines. This approach can reduce the time to obtain data values and conserve power by avoiding slower and more complex memory or storage accesses. Another embodiment of the invention allows data values to be obtained earlier during pipelined execution of instructions. For example, in a three stage fetch-decode-execute type of reduced instruction set computer (RISC), a data value can be ready from a prior instruction at the decode or execute stage of a subsequent instruction."
7249306,"A System and Method for generating Cyclic Redundancy Check (CRC) values in a system adapted simultaneously handling a plurality of blocks in parallel is described. Included is a memory or other storage device for storing data blocks, wherein the memory or storage device is adapted to output a plurality of data blocks in parallel. A data bus provides a data path wide enough to accommodate the parallel data blocks and is further coupled to a plurality of CRC cores coupled to the data bus, wherein CRC values are calculated for every combination of data blocks on the data bus. A multiplexer coupled to the CRC cores selects the output of one of the CRC cores based on the number of valid data blocks on the data bus. Once the correct CRC value has been calculated, it is appended to a data segment, comprised of a group of data blocks, for transmission to another device."
7250946,"Systems and methods for shaping a shared edge between two or more N-patches may be used to eliminate gaps when normal vectors along a shared edge are not equal. More particularly, vertices and normals of a polygon, tristip, quadstrip and so on, are obtained. Shared vertices corresponding to the shared edge are identified. When normal vectors at a shared vertex are determined to differ, tangents of the normal vectors are computed. These tangents may be used to optionally shape the shared edge, along with control points."
7250953,A graphics processor includes a graphics pipeline having a set of tap points. A configurable test point selector monitors a selected subset of tap points and counts statistics for at least one condition associated with each tap point of the subset of tap points.
7253599,"A bandgap reference circuit having a low sensitivity to temperature and supplied voltage installs a compensation circuit on a bandgap reference circuit to substitute a prior art that uses a resistor to match the circuit startup purpose and solve the problem of startup error caused by the manufacturing error. The bandgap reference circuit includes a first amplifier, a second amplifier, and a reference circuit having a plurality of transistors and a plurality of bipolar junction transistors, and the bandgap reference circuit is electrically connected to a same supplied power of which the reference circuit is electrically connected and also includes a plurality of transistors and a compensation circuit of the second amplifier, so as to output a stable startup voltage which has a low sensitivity to the change of temperature and the change of supplied voltage."
7256571,"A regulator set point circuit. The circuit includes a voltage regulator configured to produce an output voltage. An adjustable voltage source is coupled to the voltage regulator via a feedback circuit, and is configured to generate a voltage adjust signal to control the output voltage."
7256788,The present invention facilitates utilization of flexible and efficient power savings in graphics systems. A graphics power management method loads a first set of graphics commands from a CPU into a GPU at the beginning of a frame cycle. The CPU is put into a power saving mode after the loading is complete. The GPU processes the commands and forwards the results to a graphics buffer. The display begins the presentation of the data at the beginning of the following refresh cycle. The CPU leaves the power savings mode at end of the frame cycle to begin loading a second set of commands. The CPU recognizes the end of the frame cycle by counting a predetermined number of frame flip interrupt requests. After the CPU counts the predetermined number of frame flip interrupt requests the CPU begins to communicate additional graphics commands and then returns to the power savings mode.
7256792,An apparatus and method for using non-power of two texture maps is described. Normalized texture map coordinates such as s and t are converted from a floating point format to a fixed point format and wrapping operations are performed to produce unnormalized texture map coordinates such as u and v corresponding to non-power of two texture maps.
7256796,"A fragment program may configure a fragment shader to compute a destination position for a fragment, where the destination position is independent of a position computed for the fragment during rasterization of a primitive. The destination position may be computed based on fragment parameters such as color, depth, and transparency. A raster operation unit writes processed fragment data to the destination position. Furthermore, the fragment program may configure the fragment shader to compute a per-fragment stencil operation for use by the raster operation unit during stencil buffering."
7259606,"Circuits, methods, and apparatus for training a phase shift circuit to provide a phase shift for improved data recovery. A specific embodiment of the present invention provides a variable delay cell. A delay through the variable delay cell is changed while training patterns are received. The presence of errors in the received data pattern is tracked, and from the presence or absence of errors a preferred delay is selected and used for receiving data."
7260631,"An Internet small computer system interface (iSCSI) system, method and associated data structure are provided for receiving data in protocol data units. After a protocol data unit is received, a data list is identified that describes how the data contained in the protocol data unit is to be stored (i.e. placed, saved, etc.) in memory (i.e. application memory). Further stored is a state of the data list. To this end, the state of the data list is used in conjunction with the storage of data from a subsequent protocol data unit."
7260686,"A system, apparatus, and method are disclosed for storing predictions as well as examining and using one or more caches for anticipating accesses to a memory. In one embodiment, an exemplary apparatus is a prefetcher for managing predictive accesses with a memory. The prefetcher can include a speculator to generate a range of predictions, and multiple caches. For example, the prefetcher can include a first cache and a second cache to store predictions. An entry of the first cache is addressable by a first representation of an address from the range of predictions, whereas an entry of the second cache is addressable by a second representation of the address. The first and the second representations are compared in parallel against the stored predictions of either the first cache and the second cache, or both."
7262776,"Tile buffers in a graphics processing system are managed using “copy-on-write” semantics, in which tile data stored in a memory location is not transferred to another location until the tile data for one of the buffers is modified, thereby providing copy on flip behavior to support incremental updating of the data. Tile data for a new frame is written to one of the two memory spaces by reference to a first logical buffer that associates each tile with one of the memory spaces. Concurrently, tile data for a current frame is read from the two memory spaces by reference to a second logical buffer that also associates each tile with one of the memory spaces. In response to a frame flip signal, the tile associations of the second logical buffer are modified to match those of the first logical buffer. Subsequent tile data updates are written to the memory spaces by reference to the second logical buffer after modifying one of the first and second tile associations such that they no longer match."
7265759,"One embodiment of a field changeable rendering system includes an output device interfaced to a motherboard, a fixed rendering device mounted to the motherboard for generating information to be output on said output device, a connector for attaching a field-changeable rendering card to the motherboard, said field-changeable rendering card capable of housing a discrete rendering device for generating information to be output on said output device and detection circuitry for detecting that a field-changeable rendering card housing a discrete rendering device is coupled to said connector and causing information from said field-changeable rendering card housing a discrete rendering device to be output on said output device. One advantage of the disclosed edge connector is that it is compatible with a plurality of graphics cards and systems, thereby enabling a computing device user to upgrade the existing device's graphics system. Thus, the user is not forced to purchase an entirely new computing device in order to take advantage of graphics innovations. A further advantage of the disclosed edge connector is that it enables upgrades to low voltage differential signaling (LVDS) features, without the need for additional costly devices capable of operating at LVDS data rates."
7265764,"A compositor for providing a pixel value corresponding to a current pixel is implemented on a chip. A desktop pixel logic circuit supplies a desktop pixel value. A cursor logic circuit supplies a cursor pixel value. A hardware icon logic circuit provides an icon pixel value by accessing an icon memory located on the compositor chip. The hardware icon logic circuit supports selectable magnification and color modes. Priority logic selects one of the icon pixel value, the desktop pixel value, and the cursor pixel value as the final pixel value. Whether the hardware icon is displayed can be controlled based on a hardware condition."
7268785,"A system and method for interfacing graphics program modules written to execute on a plurality of functional units of a graphics processor using a shared memory. A central processing unit (CPU) receives a first graphics program module that outputs a first parameter referenced by a first graphics program module identifier, a second graphics program module that inputs the first parameter by referencing the first graphics program module identifier, and a first data structure that includes, in a pre-defined order, a list of first data structure identifiers. The CPU identifies a memory location in the shared memory, based on the pre-defined order of the first data structure identifiers, for one of the first data structure identifiers that is the same as the first graphics program module identifier. The CPU modifies the first and second graphics program modules to reference the first parameter by the identified memory location in the shared memory."
7268786,A graphics processor has elements of a graphics pipeline coupled by distributors. The distributors permit the process flow of pixel packets through the pipeline to be reconfigured in response to a command from a host.
7271810,"Systems and methods for determining the number of texture samples used to produce an anisotropically filtered texture mapped pixel may improve texture mapping performance or image quality. The number of texture samples may be increased or decreased based on texture state variables that may be specific to each texture map. Furthermore, the texture samples may be positioned along an axis of anisotropy to approximate an elliptical footprint, ensuring that the texture samples span the entire axis of anisotropy. A graphics driver may load the texture state variables and configure a system to modify the number of texture samples and/or position the texture samples used to produce the anisotropically filtered texture mapped pixel."
7272680,"An improved method for accessing data is disclosed, which is capable of increasing the efficiency of data access by reducing the time consumed by registering data in the system memory while transferring data between computer peripherals."
7274369,"Digital Image compositing using a programmable graphics processor is described. The programmable graphics processor supports high-precision data formats and can be programmed to complete a plurality of compositing operations in a single pass through a fragment processing pipeline within the programmable graphics processor. Source images for one or more compositing operations are stored in graphics memory, and a resulting composited image is output or stored in graphics memory. More-complex compositing operations, such as blur, warping, morphing, and the like, can be completed in multiple passes through the fragment processing pipeline. A composited image produced during a pass through the fragment processing pipeline is stored in graphics memory and is available as a source image for a subsequent pass."
7274373,"A system, method and computer program product are provided for programmable pixel processing in a computer graphics pipeline. In one embodiment of the present invention, arbitrary texture filtering is applied via a programmable shader."
7274568,"An apparatus and method for cooling semiconductor devices. A cooling system for semiconductor devices is disclosed and includes a semiconductor substrate, horizontal channels and a cooling medium. Specifically, the semiconductor substrate is incorporated into a die. Also, one or more horizontal channels are formed in a backside of the semiconductor substrate of the die. The horizontal channels collect thermal energy that is generated by electrical components located on a front side of the semiconductor substrate. A cooling medium circulates within the one or more horizontal channels for transferring the thermal energy away from the die."
7275121,"A system and method for managing access to a shared resource employs mutually exclusive flags. The flags enable arbitration between all applications requesting the use of the shared resource and ensure that each application has exclusive and continuous use of the shared resource. The preferred embodiment uses hardware to realize the flags and the flag arbitrating means. In one embodiment, the applications control and observe the flags through read/write registers. Alternative embodiments provide a unique read/write register for each application using the shared resource."
7275123,A method and apparatus for providing peer-to-peer data transfer through an interconnecting fabric. The method and apparatus enable a first device to read and/or write data to/from a local memory of a second device by communicating read and write requests across the interconnectivity fabric. Such data transfer can be performed even when the communication protocol of the interconnectivity fabric does not permit such transfers.
7275143,"A system, apparatus, and method are disclosed for controlling accesses into memory to minimize sequential accesses to the same bank of memory, at least in part, by characterizing a subset of an address in parallel with address translations associated with those accesses. In one embodiment, an exemplary memory controller can include an address translator configured to translate an address useable by a processor to a first memory address. Also, the memory controller includes a bit characterizer configured to characterize a subset of the address as having a value from a range of values, and a bank separator coupled to the address translator and the bit characterizer for receiving a first portion of the first memory address and the value, respectively. Accordingly, the bank separator is configured to differentiate the first portion from a second portion of a second memory address."
7277581,"The invention provide methods and code for better detecting 3:2 pulldown or other video formats. In one respect, embodiments of the invention improve the way in which fields of video data are compared. In another respect, embodiments of the invention provide pattern matching techniques and code for processing the field difference data."
7278008,"A virtual address translation table and an on-chip address cache are usable for translating virtual addresses to physical addresses. Address translation information is provided using a cluster that is associated with some range of virtual addresses and that can be used to translate any virtual address in its range to a physical address, where the sizes of the ranges mapped by different clusters may be different. Clusters are stored in an address translation table that is indexed by virtual address so that, starting from any valid virtual address, the appropriate cluster for translating that address can be retrieved from the translation table. Recently retrieved clusters are stored in an on-chip cache, and a cached cluster can be used to translate any virtual address in its range without accessing the address translation table again."
7279887,"Methods and systems for testing an integrated circuit during an assembly process are described. The integrated circuit is received from inventory. The integrated circuit is placed in a socket on a first circuit board for system-level testing. The system-level testing is performed prior to placement and permanent attachment of the integrated circuit onto a second circuit board. Provided the integrated circuit passes the system-level testing, the placement and permanent attachment of the integrated circuit to the second circuit board is the next step following the system-level testing in the assembly process."
7280112,An arithmetic logic unit (ALU) in a graphics processor is described. The ALU includes circuitry for performing an operation using a first set of pixel data. The first set of pixel data is resident in a pipeline register coupled to the circuitry. A temporary register is coupled to the circuitry. The temporary register can receive a result of the operation. The temporary register allows a result generated using one set of pixel data to be used with a subsequent set of pixel data in the same ALU. The result of the operation can thus be used in a second operation with a second set of pixel data that resides in the pipeline register after the first set of pixel data.
7281232,"A method and apparatus for checking topology layout routing is described. A method for checking topology layout routing includes accessing actual topology layout information of a circuit. Then, compliance topology information is established. Then, the method checks the actual topology layout information complies with the compliance topology information. Then, the method presents violations of the compliance topology information."
7286066,"Described are methods and systems for variable length decoding. A first execution unit executes a first single instruction that optionally reverses the order of bits in an encoded bitstream. A second execution unit executes a second single instruction that extracts a specified number of bits from the bitstream produced by the first execution unit. A third execution unit executes a third single instruction that identifies a number of consecutive zero bit values at the head of the bitstream produced by the first execution unit. The outputs of the first, second and third execution units are used in a process that decodes the encoded bitstream."
7286129,"A system, method and computer program product are provided for two-sided stencil testing during graphics processing. Initially, primitives are received to be processed in a graphics processing pipeline. In use, it is then determined whether the graphics processing pipeline is operating with same-sided stencil testing enabled. If same-sided stencil testing is not enabled, the primitives are passed without same-sided stencil testing and two-sided stencil testing. If, on other hand, same-sided stencil testing is enabled, it is determined whether the graphics processing pipeline is operating with two-sided stencil testing enabled. If the two-sided stencil testing is enabled and the same-sided stencil testing is enabled, two-sided stencil testing is performed on the primitives. If, on the other hand, the two-sided stencil testing is disabled and the same-sided stencil testing is enabled, same-sided stencil testing is performed on the primitives."
7286133,"A system, method and computer program product are provided for programmable processing of fragment data in a computer hardware graphics pipeline. Initially, fragment data is received in a hardware graphics pipeline. It is then determined whether the hardware graphics pipeline is operating in a programmable mode. If it is determined that the hardware graphics pipeline is operating in the programmable mode, programmable operations are performed on the fragment data in order to generate output. The programmable operations are performed in a manner/sequence specified in a graphics application program interface. If it is determined that the hardware graphics pipeline is not operating in the programmable mode, standard graphics application program interface (API) operations are performed on the fragment data in order to generate output."
7286134,"A tiled graphics memory permits z data and stencil data to be stored in different portions of a tile. The tile may be further divided into data sections, each of which may have a byte size corresponding to a memory access size."
7287145,"A system, apparatus, and method are disclosed for increasing the physical memory size accessible to a processor, at least in part, by reclaiming physical address space typically associated with addresses of a restricted linear address space (i.e., addresses that are otherwise unusable by the processor as system memory). In one embodiment, an exemplary memory controller redirects a linear address associated with a range of addresses to access a reclaimed memory hole. The memory controller includes an address translator configured to determine an amount of restricted addresses and to establish a baseline address identified as a first number being a first integer power of 2. The range of addresses can be located at another address identified as a second number being a second integer power of 2. As such, the address translator translates the linear address into a translated address associated with the reclaimed memory hole based on the baseline address."
7289125,"A bridge associated with a broadcast aperture facilitates the transfer of rendering commands and data between a processor and multiple graphics devices. The bridge receives data written by the processor to the broadcast aperture and forwards it to multiple graphics devices, eliminating the need for the processor to perform duplicative(?) write operations. During system initialization, a broadcast aperture is allocated to the bridge in address space based on an aperture size value set using a system configuration utility and stored in system configuration memory. A graphics driver activates the broadcast aperture by sending unicast aperture parameters associated with the multiple graphics devices to the bridge via a bridge driver. Upon activating the broadcast aperture, multiple graphics devices can be operated in parallel to improve rendering performance. Parallel rendering techniques include split-frame, alternate frame, and combined split- and alternate frame rendering."
7289126,"Methods, circuits, and apparatus for handling gamma-corrected texels stored in a graphics memory. On-the-fly gamma-to-linear and linear-to-gamma conversions are performed such that gamma-corrected texels are provided to circuits that are able to process them, while linear valued texels are supplied where needed. In various embodiments, these conversions are done by lookup tables, software instructions, or dedicated hardware. Gamma-corrected texels may be tracked by a shader program, pipeline states, or driver instructions, and may be identified by header or flag information, or by part of a texture descriptor."
7289539,"Methods and apparatus for synchronizing a stereo viewing device in a multiple end-view environment. Two or more video streams and a corresponding number of signals, each synchronous with one of the video streams, are provided. Each of the video streams may have a different refresh rate. One of the video streams is selected for stereo viewing, and a corresponding synchronizing signal is selected. The selected synchronizing signal is used to generate a control signal that synchronizes a stereo viewing device to the selected video stream."
7292239,"The VPC unit and setup unit of a graphics processing subsystem perform culling operations. The VPC unit performs culling operations on geometric primitives falling within a specific criteria, such as having a property within a numerical range limit of the VPC unit. This limitation reduces the complexity of the VPC unit. As increasing rendering complexity typically produces a large number of small primitives, the VPC unit can cull many primitives despite its culling limitations. The VPC unit also includes a cache for storing previously processed vertices in their transformed form, along with culling information previously computed for the vertices. To minimize memory bandwidth, the VPC unit retrieves vertex data used for culling operations first. After completing the culling operations, the VPC unit retrieves the attributes of a vertex only if the primitive has not been culled. The VPC unit applies a perspective correction factor to the vertex attributes."
7292242,"Clipping techniques introduce additional vertices into existing primitives without requiring creation of new primitives. For an input triangle with one vertex on the invisible side of a clipping surface, a quadrangle can be defined. The vertices of the quadrangle are the two internal vertices of the input triangle and two clipped vertices. For determining attribute values for pixel shading, three vertices of the quadrangle are selected, and a parameter value for an attribute equation is computed using the three selected vertices. For determining pixel coverage for the quadrangle, the three edges that do not correspond to the edge created by clipping are used."
7292254,"Apparatus, system, and method for clipping graphics primitives are described. In one embodiment, a graphics processing apparatus includes a mapping unit and a clipping engine that is connected to the mapping unit. The mapping unit is configured to map a graphics primitive onto a canonical representation. The clipping engine is configured to perform a set of clipping operations with respect to the canonical representation."
7296139,"A virtual address translation table and an on-chip address cache are usable for translating virtual addresses to physical addresses. Address translation information is provided using a cluster that is associated with some range of virtual addresses and that can be used to translate any virtual address in its range to a physical address, where the sizes of the ranges mapped by different clusters may be different. Clusters are stored in an address translation table that is indexed by virtual address so that, starting from any valid virtual address, the appropriate cluster for translating that address can be retrieved from the translation table. Recently retrieved clusters are stored in an on-chip cache, and a cached cluster can be used to translate any virtual address in its range without accessing the address translation table again."
7296213,"Systems and methods are disclosed to detect and correct errors in a flash memory using an error correction cache that provides error correction information by accessing data from a physical block number (PBN) of the flash memory; and if a data error occurred, applying error correction information stored in the cache corresponding to the accessed PBN to correct the data error."
7298375,"An arithmetic logic stage in a graphics pipeline is described. The arithmetic logic stage includes a plurality of series-coupled scalar arithmetic logic units, each unit for performing an arithmetic logic operation on a set of input operands and for producing a result based thereon."
7301542,"A graphics processing system performs filtering of oversampled data during a scanout operation. Sample values are read from an oversampled frame buffer and filtered during scanout; the filtered color values (one per pixel) are provided to a display device without an intervening step of storing the filtered data in a frame buffer. In one embodiment, the filtering circuit includes a memory interface configured to read data values corresponding to sample points from a frame buffer containing the oversampled data; and a filter configured to receive the data values provided by the memory interface, to compute a pixel value from the data values, and to transmit the pixel value for displaying by a display device, wherein the filter computes the pixel value during a scanout operation."
7302499,"An Internet client communicates with an Internet server such as an HTTP server or SMTP server through a TCP streaming socket on the Internet device with the Internet client. The TCP streaming sockets can be established through an Internet ready command line interface. The Internet ready command line interface includes “IR” commands that can establish, resume, release and terminate TCP sockets."
7302512,"A computer device, an input/output (“I/O”) communication subsystem, a chipset and a method are disclosed for implementing interrupt message packets to facilitate peer-to-peer communications between a device controller and a coprocessor. Advantageously, the various embodiments of the invention obviate a requirement for specialized circuitry on a motherboard to establish peer-to-peer communications. In one embodiment, an I/O communication subsystem includes a bus interface for coupling the I/O communication subsystem to a general-purpose bus. It also includes a device controller being configured to generate an interrupt as an interrupt message packet for a coprocessor, which, in turn, interrupts processing functions that otherwise are performed by the host processor. The device controller can reside either internal or external to the I/O communication subsystem."
7307628,"Graphics processing devices and methods are provided for culling small primitives that do not cover any pixels. A boundary (e.g., a diamond) is defined around a pixel center, with pixel coverage being determined for some types of primitives based on whether the boundary is crossed. The boundaries divide the raster into internal regions and external regions. Each region is assigned a unique canonical identifier. Each vertex of a primitive is assigned the canonical identifier corresponding to the region that contains that vertex. The canonical coordinates of the vertices are used to cull primitives that do not satisfy the boundary crossing coverage rules for any pixels."
7310722,"Instruction dispatch in a multithreaded microprocessor such as a graphics processor is not constrained by an order among the threads. Instructions are fetched into an instruction buffer that is configured to store an instruction from each of the threads. A dispatch circuit determines which instructions in the buffer are ready to execute and may issue any ready instruction for execution. An instruction from one thread may be issued prior to an instruction from another thread regardless of which instruction was fetched into the buffer first. Once an instruction from a particular thread has issued, the fetch circuit fills the available buffer location with the following instruction from that thread."
7313710,"A high quality and performance 3D graphics architecture suitable for portable handheld devices is provided. The 3D graphics architecture incorporates a module to classify polygons by size and other characteristics. In general, small and well-behaved triangles can be processed using “lower-precision” units with power efficient circuitry without any quality and performance sacrifice (e.g., realism, resolution, etc.). By classifying the primitives and selecting the more power-efficient processing unit to process the primitive, power consumption can be reduced without quality and performance sacrifice."
7315912,"Circuits, apparatus, and methods for avoiding deadlock conditions in a bus fabric. One exemplary embodiment provides an address decoder for determining whether a received posted request is a peer-to-peer request. If it is, the posted request is sent as a non-posted request. A limit on the number of pending non-posted requests is maintained and not exceed, such that deadlock is avoided. Another exemplary embodiment provides an arbiter that tracks a number of pending posted requests. When the number pending posted requests reaches a predetermined or programmable level, a Block Peer-to-Peer signal is sent to the arbiter's clients, again avoiding deadlock."
7315957,"Methods, circuits, and apparatus for changing a frequency of a clock signal provided to a graphics memory while reducing any resulting visual glitch or disturbance on a monitor. A specific embodiment provides multiple clock sources that may be multiplexed or selected to provide a memory clock signal to the graphics memory. The multiplexer switches from providing a first clock source signal as the memory clock signal to providing a second clock source signal as the memory clock signal. The first clock source changes its frequency of operation. After the first clock source settles or stabilizes, the multiplexer switches back to providing the first clock source signal as the memory clock signal."
7318139,"A system uses specialized software instructions for efficient management of freelists. In a preferred embodiment, special load and store instructions are provided. The load instruction is mapped to a register or memory location. When the load instruction is performed, hardware uses a bit-map free slot map to return an index of a free slot. Similarly, the store instruction is used to release, or free, a slot. The store instruction allows software to specify an index of a slot to be freed."
7324026,"Systems and methods for optimizing system performance in variable length decoding systems are described. Embodiments are described in which decode tables are analyzed and elements of the tables sorted by probability of occurrence. Storage of elements can be determined by probability of occurrence and embodiments of the present invention can optimize system efficiency by storing most likely entries into fast-memory and least likely entries in slowest memory. In certain embodiments, a single large table is provided that cannot fit into decoder fast-memory. In some embodiments, individual elements can be optimized for storage in fast-memory by selecting more frequently occurring entries or groups of entries into decoder memory."
7324105,"Method and apparatus for neighbor and edge indexing is described. A vertex is identified and assigned a reference. One-ring neighbor vertices of the vertex are identified. The reference is assigned to each of the one-ring neighbor vertices identified. An index to one of the one-ring neighbor vertices is assigned. The index is successively incremented to provide indices for each of the one-ring neighbor vertices remaining. Edge indexing follows as described above, with the vertex and its one-ring neighbors defining end points of edges. Additionally, offset indexing is described, and may be used for a consistent order of computation."
7324106,An apparatus and method for translating fixed function state into a shader program. Fixed function state is received and stored and when a new shader program is detected the fixed function state is translated into shader program instructions. Registers specified by the program instructions are allocated for processing in the shader program. The registers may be remapped for more efficient use of the register storage space.
7324111,"One embodiment of a connector for a stand-alone graphics module is adapted for coupling a computing device to the stand-alone graphics module, which is external to the computing device. The connector is adapted for receiving a PCI express signal from the computing device and for delivering the PCI express signal to the stand-alone graphics module. The connector is further adapted for receiving display output signals from the stand-alone graphics module and delivering the display output signals to the computing system, e.g., for use in accordance with one or more output display panels coupled to said computing device."
7324112,"A method for processing divergent samples in a programmable graphics processing unit is described. In one embodiment, the method includes the step of incrementing a subroutine depth of a first sample to designate that first call instructions are to be executed on the first sample. The method also includes the steps of pushing state data of a second sample upon which the first call instructions are not to be executed onto a global stack and executing the first call instructions on the first sample."
7324113,"A method of optimizing perspective correction computations to be executed in a programmable fragment shader, identifying a sequence of program instructions; determining whether the sequence of program instructions can be optimized based on the status of the bit; sourcing one or more interpolated texture map coordinates to thereby disable the perspective correction computation comprising division by (1/w); and enabling the optimized execution of one of a plurality of perspective computation functions by a sought operation in a shader unit without division of the interpolated texture maps coordinates by (1/w). The optimized function includes able mapping, projective mapping, normalization, or scaling invariant operations."
7324117,"An apparatus and method for using non-power of two texture maps is described. Texture map coordinates for a non-power of two dimension texture map such as u and v are computed without requiring a division operation. In addition to accessing non-power of two texture maps, the texture map coordinates may be used to access filtered versions of the non-power of two texture map, where the dimensions of each filtered version is arbitrary."
7324547,"A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though, in one embodiment, it is sharing the same chip."
7327442,"Methods and systems for automatically determining the height of an object observed by a camera are described. One such method involves determining the distance from the top of the object to the camera, determining the distance from the bottom of the object to the camera, measuring the angle of incidence, from the camera's perspective, between the top and bottom of the object, and computing the height of the object from the two distances and the angle of incidence. The method may be computer controlled."
7328358,"A high quality and performance 3D graphics architecture suitable for portable handheld devices is provided. The 3D graphics architecture incorporates a module to classify polygons by size and other characteristics. In general, small and well-behaved triangles can be processed using “lower-precision” units with power efficient circuitry without any quality and performance sacrifice (e.g., realism, resolution, etc.). By classifying the primitives and selecting the more power-efficient processing unit to process the primitive, power consumption can be reduced without quality and performance sacrifice."
7328439,A first process executing in a computer system creates thread-level message hooks within a second process executing in the computer system. A copy of a global notification hook of the first process is created in the second process. The copy detects a triggering message passed to or from a thread of the second process and determines when and whether to activate a thread-level message hook within the second process; the thread-level message hook is configured to monitor subsequent messages passed to or from the thread of the second process and may take various actions in response to any such messages.
7330183,"A method for constructing mapping coordinates for a high-resolution graphics model includes the steps of expanding a projection cage to substantially encompass both a low-resolution graphics model and the high-resolution graphics model, and defining a volume that extends from a polygon of the projection cage through a corresponding polygon of the low-resolution graphics model. The method also includes the steps of determining points within an area on a surface of the high-resolution graphics model defined by an intersection of the volume and the high-resolution model, and, for each point where the corresponding polygon is the closest polygon of the low-resolution graphics model to the point, projecting the point to the corresponding polygon to define a projection point on the corresponding polygon."
7330866,"A system for frequency-domain scaling for DCT computation. Scale factors are applied to coefficients during the final steps of composition of 2-point DCTs. The number of multiplications and required precision are reduced. Fixed values for various scale factors can be computed and stored prior to executing the DCT so that performance can be improved. The fixed values are derived by knowing the length of the time-domain sequence. Some fixed values can be derived independently of the length of the time-domain sequence. The approach of the invention can also reduce the number of multiplications to compute the transform, and allow smaller bit-width sizes by reducing the number of required high-precision calculations."
7330916,"A system for providing a command stream that includes a controller chip is disclosed. The controller chip includes an engine operative to manage a memory. The engine includes an interface. A storage element is coupled to the engine and the storage element is accessible by a central processing unit (CPU) through the engine. The engine receives commands from the CPU via the interface, manages the storage element via the interface and writes the commands into the memory. The engine incorporates the storage element as part of the memory."
7330962,A list scheduler in a compiler can select from a plurality of alternative instruction sequences for one or more computation performed within an application. A scheduler can initially identify and track one or more computations for which multiple alternative instruction sequences exist. An available instruction list can be populated with the alternative instruction sequences. The list scheduler can access the available instruction list during scheduling of the application. The list scheduler can perform a cost analysis while scheduling the instructions by performing a look ahead. The list scheduler may select alternate instruction sequences for similar computations occurring in different portions of the application based on the cost benefit analysis.
7331013,"In accordance with an embodiment of the present invention, a Viterbi decoder is described that operates on convolutional error correcting codes. The decoder allows for a pipelined architecture and a unique partitioning of survivor memory to maintain data integrity. Throughput rate is improved and stalling minimized by accessing memory words using a look-ahead function to fill the pipeline."
7333119,A graphics system has a mode of operation in which real samples and virtual samples are generated for anti-aliasing pixels. Each virtual sample identifies a set of real samples associated with a common primitive that covers a virtual sample location within a pixel. The virtual samples provide additional coverage information that may be used to adjust the weights of real samples.
7334050,"A system, method and computer program product are provided for initiating a tailored voice application according to an embodiment. First, a voice application is installed at a server. A request to instantiate the voice application is received from a user. User-specific configuration parameters are also received. An instance of the voice application is instantiated in a modified form based on the user-specific configuration parameters. A system, method and computer program product provide a voice-based interface according to one embodiment. A voice application is provided for verbally outputting content to a user. An instance of the voice application is instantiated. Content is selected for output. The content is output verbally using the voice application. The instance of the voice application pauses the output and resumes the output. A method for providing a voice habitat is also provided according to one embodiment. An interface to a habitat is provided. A user is allowed to aggregate content in the habitat utilizing the interface. A designation of content for audible output is received from the user. Some or all of the designated content is output. The user is also allowed to aggregate applications in the habitat utilizing the interface. Spoken commands are received from the user and are interpreted using a voice application. Commands are issued to one or more of the applications in the habitat via the voice application."
7334108,"A virtual address translation table and an on-chip address cache are usable for translating virtual addresses to physical addresses. Address translation information is provided using a cluster that is associated with some range of virtual addresses and that can be used to translate any virtual address in its range to a physical address, where the sizes of the ranges mapped by different clusters may be different. Clusters are stored in an address translation table that is indexed by virtual address so that, starting from any valid virtual address, the appropriate cluster for translating that address can be retrieved from the translation table. Recently retrieved clusters are stored in an on-chip cache, and a cached cluster can be used to translate any virtual address in its range without accessing the address translation table again."
7336277,"Per-pixel luminosity adjustment uses a luminosity mask applied as a texture. In one embodiment, a luminosity texture is defined. Pixel data of an underlying image is converted to an image texture. The image texture is blended onto a target surface. The luminosity texture is also blended onto the target surface, thereby generating luminosity compensated pixel data for the image."
7339590,"A graphics processing subsystem includes a vertex processing unit that allows vertex shader programs to arbitrarily access data stored in vertex texture maps. The vertex processing unit includes a vertex texture fetch unit and vertex processing engines. The vertex processing engines operate in parallel to execute vertex shader programs that specify operations to be performed on vertices. In response to a vertex texture load instruction, a vertex processing engine dispatches a vertex texture request to the vertex texture fetch unit. The vertex texture fetch unit retrieves the corresponding vertex texture map data. While the vertex texture fetch unit is processing a vertex texture request, the requesting vertex processing engine is adapted to evaluate whether instructions that follow the vertex texture load instruction are dependent on the vertex texture map data, and if the instructions are not dependent on the vertex texture map data, to execute the additional instructions."
7339592,An apparatus and method for simulating a multiported memory using lower port count memories as banks. A portion of memory is allocated for storing data associated with a thread. The portion of memory allocated to a thread may be stored in a single bank or in multiple banks. A collector unit coupled to each bank gathers source operands needed to process a program instruction as the source operands output from one or more banks. The collector unit outputs the source operands to an execution unit when all of the source operands needed to process the program instruction have been gathered.
7339593,"Anisotropic optimization is a technique to reduce the number of texture samples anisotropically filtered to determine a texture value associated with a graphics fragment. Reducing the number of texture samples anisotropically filtered reduces the number of texture samples read from memory and speeds up the filter computation. A programmable bias is used to control the number of texture samples used during anisotropic filtering, permitting a user to determine a balance between improved texture map performance and anisotropic texture filtering quality."
7339594,"Systems and methods for determining the number of texture samples used to produce an anisotropically filtered texture mapped pixel may improve texture mapping performance or image quality. The number of texture samples may be increased or decreased based on texture state variables that may be specific to each texture map. Furthermore, the texture samples may be positioned along an axis of anisotropy to approximate an elliptical footprint, ensuring that the texture samples span the entire axis of anisotropy. A graphics driver may load the texture state variables and configure a system to modify the number of texture samples and/or position the texture samples used to produce the anisotropically filtered texture mapped pixel."
7339789,"One embodiment of a modular, scalable cooling system includes a core cooling module configured to be thermally coupled to a heat-generating electronic device and a supplemental cooling module configured to be thermally coupled to the core cooling module. A first interface attached to the core cooling module is configured to thermally couple the core cooling module to the supplemental cooling module. The core cooling module and the supplemental cooling module may be used alone or in combination to dissipate heat from the heat-generating electronic device."
7340547,"A driver program for a multiprocessor subsystem includes an interrupt servicing routine (ISR) and a deferred procedure call (DPC). The ISR, invoked in response to an interrupt, determines whether any of the co-processors in the multiprocessor subsystem generated an interrupt. If one of the co-processors generated an interrupt, the ISR schedules the DPC for execution and disables sending of further interrupts from all of the co-processors. The DPC services pending interrupts from any of co-processors, then re-enables sending of interrupts from the co-processors."
7340562,"A distributed data cache includes a number of cache memory units or register files each having a number of cache lines. Data buses are connected with the cache memory units. Each data bus is connected with a different cache line from each cache memory unit. A number of data address generators are connected with a memory unit and the data buses. The data address generators retrieve data values from the memory unit and communicate the data values to the data buses without latency. The data address generators are adapted to simultaneously communicate each of the data values to a different data bus without latency. The cache memory units are adapted to simultaneously load data values from the data buses, with each data value loaded into a different cache line without latency."
7340577,"A method and system for efficiently executing reads after writes in a memory. The system includes a memory controller and a memory core interfacing with the memory controller. The memory operates with a read data latency and a similar write data latency, and the memory immediately processes a read in a read-after-write situation. The system further includes a control circuit for controlling the memory and detecting an address collision between the read and a previously issued write and, in response thereto, stalling the memory by delaying issuance of the read to the memory until after the previously issued write completes."
7340734,"Method and apparatus to make code more difficult to reverse engineer is described. Inert instructions are inserted between instructions within a program. The inert instructions may perform logic operations with the net effect of not changing an argument. Furthermore, the inserted inert instructions may be repositioned within the program to further obfuscate the desired function of the program, making the code more difficult to reverse engineer."
7342590,"Methods, circuits, and apparatus for reducing memory bandwidth used by a graphics processor. Uncompressed tiles are read from a display buffer portion of a graphics memory and received by an encoder. The uncompressed tiles are compressed and written back to the graphics memory. When a tile is needed again before it has been modified, the compressed version is read from memory, uncompressed, and displayed. To reduce the number of unnecessary writes of compressed tiles to memory, a tile is only written to memory if it has remained static for some number of refresh cycles. Also, to prevent a large number of compressed tiles being written to the display buffer in one refresh cycle, the encoder can be throttled after a number of tiles have been written. Validity information can be stored for use by a CRTC. If a tile is updated, the validity information is updated such that invalid compressed data is not read from memory and displayed."
7343625,"A system, method and computer program product for extracting data from an applet are provided. Data from a data page is downloaded to a browser. The data includes an applet written in Java. Additional spy code is added. The spy code is used for interacting with the applet on the browser. Data is extracted from the applet using the spy code. Also, other types of interactions with the applet can be performed using the spy code. A method for extracting data from a browser object is also provided."
7346894,"Methods and systems for specifying settings used by a file are described. A file is accessed using a software application. Associated with the file are global settings defined by the application. The application automatically imposes the global settings on all files associated with the application. However, a file-specific setting is defined for the file and saved. The file-specific setting replaces a corresponding global setting defined by the application for the file. The global settings for other files associated with the application are not affected by the file-specific setting. The file-specific setting is used instead of the corresponding global setting upon subsequent accessing of the file."
7348836,"An integrated circuit core power supply event monitor is disclosed. The integrated circuit core power supply event monitor includes a plurality of sub-circuit power supply event monitors. Each sub-circuit power supply event monitor includes a first input for receiving a first voltage, a second input for receiving a second voltage, a comparator for comparing the first voltage to the second voltage in order to detect an occurrence of a voltage deviation of the first voltage from a predetermined magnitude and an output for outputting an indicator of the occurrence of a voltage deviation of the first voltage from a predetermined magnitude if a voltage deviation of the first voltage from a predetermined magnitude occurs. A register for receiving the indicator of the occurrence of the voltage deviation of the first voltage from a predetermined magnitude and for registering the indicator of the occurrence of the voltage deviation from a predetermined magnitude."
7353243,"A reconfigurable filter node including an input data memory adapted to store a plurality of input data values, a filter coefficient memory adapted to store a plurality of filter coefficient values, and a plurality of computational units adapted to simultaneously compute filter data values. Filter data values are the outputs of a filter in response to input data values or a second plurality of filter coefficients to be used in subsequent filter data value computations. First and second input data registers load successive input data values input data memory or from adjacent computational units. Each computational unit comprises a pre-adder adapted to output either the sum two input data values stored in the computational unit or alternately to output a single input data value, and a multiply-and-accumulate unit adapted to multiply the output of the pre-adder by a filter coefficient and accumulate the result."
7353369,"One embodiment of a computing system configured to manage divergent threads in a thread group includes a stack configured to store at least one token and a multithreaded processing unit. The multithreaded processing unit is configured to perform the steps of fetching a program instruction, determining that the program instruction is not a branch instruction, determining whether the program instruction includes a pop-synchronization bit, and updating an active program counter, where the fashion in which the active program counter is updated relates to whether the program instruction includes a pop-synchronization bit."
7353480,"An apparatus to design a via pad of a via is described. In one embodiment, the apparatus includes a vertex determination module configured to determine a vertex of the via pad based on a position of a trace that is connected to the via. The apparatus also includes a contour definition module configured to define an extended contour of the via pad based on the vertex. The extended contour is defined such that an electrical length design characteristic of the trace is substantially unchanged by the extended contour."
7353516,"The present invention concerns data flow control in adaptive integrated circuitry which utilizes a data flow model for data processing. The present invention controls task initiation and execution based upon data consumption measured in data buffer units. In the various embodiments, when a first task of a plurality of tasks is initiated, buffer parameter is determined and a buffer count is initialized for the first task. For each iteration of the first task using a data buffer unit of input data, the buffer count is correspondingly adjusted, such as incremented or decremented. When the buffer count meets the buffer parameter requirements, the state of the first task is changed, which may including stopping the first task, and a next action is determined, such as initiating a second task. The various apparatus embodiments include a hardware task manager, a node sequencer, a programmable node, and use of a monitoring task within an adaptive execution unit."
7355602,"Methods and apparatuses for effectively clearing stencil buffers at high speed using surrogate stencil buffer clearing. A hardware register tracks the number of surrogate clears of the stencil buffer since the last actual clear. Bits are reserved in each stencil register for storing the surrogate clear number that cleared other stencil registers the last time the stencil register held an assigned value. A comparison between the contents of the hardware register and the reserved bits in each stencil register determines if each stencil register should be assigned a cleared value. If the numbers do not match the stencil register is assigned a predetermined surrogate clear value. In some applications the number of reserved bits is fixed, while in other applications the number of reserved bits can be set, either by a designer or by software."
7355603,"Floating-point texture filtering units leverage existing fixed-point filter circuits. Groups of floating-point texture values are converted to products of a fixed-point mantissa and a scaling factor that is the same for each texture value in the group. The fixed-point mantissas are filtered using a fixed-point filter circuit, and the filtered mantissa is combined with the scaling factor to determine a floating-point filtered value. Multiple floating-point filter results may be combined in a floating-point accumulator circuit. The same fixed-point filter circuit may also be used to filter fixed-point texture data by providing fixed-point input path that bypasses the format conversion and a fixed-point accumulator."
7356621,"Transferring data between a requesting program and a hardware device. An program requests a pre-allocation of non-pageable memory. The program requests a transfer via a direct memory access (DMA) from the hardware device into the non-pageable memory. The requesting program is notified when the DMA is complete. The requesting program reads the data from the non-pageable memory. A determination may be made whether a range of addresses specified in the DMA request is within the pre-allocated range of non-pageable memory. If the range of addresses is within the pre-allocated non-pageable memory, the data transfer involves fewer transfers between system memory and the CPU than if the range of addresses is outside the pre-allocated non-pageable memory."
7358970,"A method and apparatus for generating depth values in a programmable graphics system. Depth values are calculated under control of a pixel program using a variety of sources as inputs to programmable computation units (PCUs) in the programmable graphics system. The PCUs are used to compute traditional interpolated depth values and modified depth values. The PCUs are also used to compute arbitrary depth values which, unlike traditional interpolated depth values and modified depth values, are not dependent on the coordinates of the geometry primitive with which the arbitrary depth values are associated. Several sources are available as inputs to the PCUs. Clipping with optional clamping is performed using either interpolated depth values or calculated depth values, where calculated depth values are arbitrary depth values or modified depth values. Final depth values, used for depth testing, are selected from interpolated depth values and arbitrary depth values after clipping is performed."
7359197,One embodiment of a system for efficiently cooling a processor includes an active hybrid heat transport module adapted to be integrated with a fansink. The hybrid heat transport module comprises both a fluid channel and an air channel adapted for transporting heat. The hybrid heat transport module and the fansink may be used alone or in combination to dissipate heat from the processor.
7359205,"Embodiments of the present invention recite an electronic device comprising a chassis, a backplane, at least one heat generating component coupled with the backplane, and a fan. In embodiments of the present invention, the chassis comprises at least one air inlet disposed on a side of the chassis and at least one exhaust outlet disposed on the bottom surface of the chassis. The heat generating component is suspended from said backplane when coupled therewith and is disposed above the at least one exhaust outlet. The fan draws cooling air through the at least one air inlet and expels the cooling air through the at least one exhaust outlet."
7359380,"Method and apparatus for routing and bridging are described. An address from a packet is obtained and used to find an index in a table. If the address is found in the table, the index stored in association with the address obtained. The index is stored in a data structure associated with the packet."
7359983,"Method and apparatus for reassembling a packet from fragments. The fragments of the packet are obtained by a device, such as a firewalling device. The fragments are sorted according to the packet and order of the fragments. The fragments are stored in association with the packet and in order. Once all the fragments to reconstitute the packet have been collected, the fragments are assembled in order to reconstitute the packet."
7360216,"A method of selecting tasks for execution on a processing node is provided. A plurality of indications of execution times corresponding to a first plurality of tasks is received. Also, a plurality of indications of maximum allowable latencies corresponding to the first plurality of tasks is received. At least a subset of the first plurality of tasks is selected for execution on the processing node based on the plurality of indications of execution times and the plurality of indications of maximum allowable latencies."
7362332,"The present invention is related to rendering computer animated video and/or images generally, and to simulating motion blur efficiently in computer graphics. The present invention includes selecting a plurality of sample locations from which to sample an object scene. If a given sample location overlaps a moving object, existing sample data computed or initialized for the sample location is replicated. This data is then separately updated by sampling the moving object at a plurality of times during the object scene. The replicated data is updated further by subsequently sampling moving and non-moving objects at some or all of the plurality of times. After all of the objects that overlap the sample location have been processed, the replicated data, which may be updated, is combined."
7362772,"A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though, in one embodiment, it is sharing the same chip."
7363572,A method and apparatus for editing outbound frames and generating acknowledgements for a TCP connection is described. Acknowledgements are automatically generated and included in outbound frames during data transmissions with minimal processor intervention.
7363610,"Systems and methods for designing and generating integrated circuits using a high-level language are described. The high-level language is used to generate performance models, functional models, synthesizable register transfer level code defining the integrated circuit, and verification environments. The high-level language may be used to generate templates for custom computation logical units for specific user-determined functionality. The high-level language and compiler permit optimizations for power savings and custom circuit layout, resulting in integrated circuits with improved performance per watt of power consumption."
7366745,"Methods and apparatuses are presented for determining coefficients for a polynomial-based approximation of a function, by iteratively estimating a first coefficient, reducing the first coefficient to a lower precision to obtain a first limited-precision coefficient, analytically calculating a second coefficient by taking into account the first limited-precision coefficient, reducing the second coefficient to a lower precision to obtain a second limited-precision coefficient, iteratively estimating a third coefficient by taking into account at least one of the first limited-precision coefficient and the second limited-precision coefficient, and reducing the third coefficient to a lower precision to obtain a third limited-precision coefficient. In one embodiment of the invention, the polynomial-based approximation relates to a minimax approximation of the function approximated, and at least one of the steps for iteratively estimating the first coefficient and iteratively estimating the third coefficient involves use of a Remez exchange algorithm."
7366842,"A circular buffer having an active cache window can be configured to temporarily allocate one or more locations in the active cache as permanent memory locations to eliminate the possibility of overwriting the contents of the permanent memory locations. The cache window can be a subset of the entire circular buffer. If contents within the cache window are identified as persistent data, the locations corresponding to the persistent data can be identified as permanent memory locations. The position of the cache within the circular buffer can be frozen based on the permanent memory locations. A write mask can be used to maintain the contents of the permanent memory locations, while the remainder of the cache is configured as a temporary circular buffer. Operation of the cache returns to the entire circular buffer once the contents of the permanent memory locations no longer need to be maintained."
7366878,"A processor buffers asynchronous threads. Current instructions requiring operations provided by a plurality of execution units are divided into phases, each phase having at least one math operation and at least one texture cache access operation. Instructions within each phase are qualified and prioritized, with texture cache access operations in a subsequent phase not qualified until all of the texture cache access operations in a current phase have completed. The instructions may be qualified based on the status of the execution unit needed to execute one or more of the instructions. The instructions may also be qualified based on an age of each instruction, a divergence potential, locality, thread diversity, and resource requirements. Qualified instructions may be prioritized based on execution units needed to execute current instructions and the execution units in use. One or more of the prioritized instructions is issued per cycle to the plurality of execution units."
7366929,"Methods and apparatus for selecting one of a plurality of N-bit digital values stored in a table, via a parallel interface having a bus width less than N is provided. The plurality of N-bit digital values stored in the table may be loaded via a serial interface."
7369003,"There are many inventions described and illustrated herein. In one aspect, the present inventions relate to oscillator systems which employ a plurality of microelectromechanical resonating structures, and methods to control and/or operate same. The oscillator systems are configured to provide and/or generate one or more output signals having a predetermined frequency over temperature, for example, (1) an output signal having a substantially stable frequency over a given/predetermined range of operating temperatures, (2) an output signal having a frequency that is dependent on the operating temperature from which the operating temperature may be determined (for example, an estimated operating temperature based on a empirical data and/or a mathematical relationship), and/or (3) an output signal that is relatively stable over a range of temperatures (for example, a predetermined operating temperature range) and is “shaped” to have a desired turn-over frequency."
7369126,"The present invention provides for accelerating the generation of graphical images that include shadow effects by, for example, reducing the amount of data transmitted and/or stored necessary to render graphics based on stencil shadow volumes. In one embodiment, an exemplary apparatus is configured to render shadows using stencil shadow volumes. The apparatus includes a memory to store a degree of shadowing for each sample. A co-processor, which is coupled to the memory, is configured to generate an indicator that represents a common degree of shadowing associated with the subset of samples. In some cases, the apparatus includes a graphics processing unit (“GPU”), which is coupled to the co-processor, that is configured to render one or more shadows for a computer-generated image based on the indicator."
7369132,A graphics processing apparatus includes an output pipeline including a set of memory clients. The graphics processing apparatus also includes a memory controller connected to the output pipeline. The memory controller is configured to retrieve data requested by respective ones of the memory clients from a memory. The graphics processing apparatus further includes a buffering module connected between the memory controller and the output pipeline. The buffering module includes a buffer including a buffering space shared by the memory clients. The buffering module also includes a buffer controller connected to the buffer. The buffer controller is configured to: (1) dynamically assign portions of the buffering space to respective ones of the memory clients; (2) coordinate storage of the data in the assigned portions; and (3) coordinate delivery of the data from the assigned portions to respective ones of the memory clients.
7369133,"A memory system having a number of partitions each operative to independently service memory requests from a plurality of memory clients while maintaining the appearance to the memory client of a single partition memory subsystem. The memory request specifies a location in the memory system and a transfer size. A partition receives input from an arbiter circuit which, in turn, receives input from a number of client queues for the partition. The arbiter circuit selects a client queue based on a priority policy such as round robin or least recently used or a static or dynamic policy. A router receives a memory request, determines the one or more partitions needed to service the request and stores the request in the client queues for the servicing partitions. In one embodiment, an additional arbiter circuit selects memory requests from one of a subset of the memory clients and forwards the requests to a routing circuit, thereby providing a way for the subset of memory clients to share the client queues and routing circuit. Alternatively, a memory client can make requests directed to a particular partition in which case no routing circuit is required. For a read request that requires more than one partition to service, the memory system must collect the read data from read queues for the various partitions and deliver the collected data back to the proper client. Read queues can provide data in non-fifo order to satisfy an memory client that can receive data out-of-order."
7369135,"A virtual memory system that maintains a list of pages that are required to be resident in a frame buffer to guarantee the eventual forward progress of a graphics application context running on a graphics system composed of multiple clients. Pages that are required to be in the frame buffer memory are never swapped out of that memory. The required page list can be dynamically sized or fixed sized. A tag file is used to prevent page swapping of a page from the frame buffer that is required to make forward progress. A forward progress indicator signifies that a page faulting client has made forward progress on behalf of a context. The presence of a forward progress indicator is used to clear the tag file, thus enabling page swapping of the previously tagged pages from the frame buffer memory."
7369136,"A system and method for computing anisotropic texture mapping parameters by using approximation techniques reduces the complexity of the calculations needed to perform high quality anisotropic texture filtering. Anisotropic texture mapping parameters that are approximated may be computed using dedicated processing units within a graphics processor, thereby improving anisotropic texture mapping performance. Specifically, the major axis and minor axis of anisotropy are determined and their respective lengths are calculated using approximations. Other anisotropic texture mapping parameters, such as a level of detail for selecting a particular level are computed based on the calculated lengths of the major and minor axes."
7369140,"A system, apparatus, and method are disclosed for modifying positions of sample positions for selectably oversampling pixels to anti-alias non-geometric portions of computer-generated images, such as texture, at least in part, by translating (e.g., shifting) shading sample positions relative to a frame of reference in which there is no relative motion between the geometries and the coverage sample positions. In one embodiment, an exemplary method determines whether a coverage sample position is covered by a geometric primitive. The method includes translating a shading sample position from an original shading sample position to the coverage sample position. This generally occurs if the geometry covers the coverage sample position to form a covered coverage sample position. Further, the method samples a shading value at the covered coverage sample positions for the pixel portion to anti-alias, for example, texture to reduce level of detail (“LOD”) artifacts."
7369679,"A visible digital watermark is applied to output images from a computer program. Various attributes of the watermark are modified from image to image, making the watermark difficult to remove. For example, a watermark indicating “not for commercial use” can be applied to all output images from the program. Such watermarking permits full functioning demonstration versions of the computer program to be freely distributed to users while commercial use is inhibited. This is accomplished by a minimal level of intrusiveness to file sharing capabilities between a commercial version of the software and a non-commercial version of the software."
7370132,"A bus permits the number of active serial data lanes of a data link to be re-negotiated in response to changes in bus bandwidth requirements. In one embodiment, clock buffers not required to drive active data lanes are placed in an inactive state to reduce clock power dissipation."
7370153,"Method and apparatus for implementing controlled pre-fetching of data. An extended data structure can be used to specifying where and when data is to be pre-fetched, and how much pre-fetching is to be performed, if any. The extended data structure has a pre-fetch flag that signals a host controller if pre-fetching is to be done. If the pre-fetch flag is set, pre-fetching is performed, otherwise pre-fetching is not performed. The host controller parses the extended data structure and formulates a data request that is sent to the disk drive. Pre-fetched data can be stored in a buffer memory for future use."
7370170,"Methods and apparatuses that enable memory devices to inform graphical processing systems about the results of WRITE de-skew training. A WRITE-TRAINING mode is added to a memory device. When the WRITE-TRAINING mode is asserted the memory data mask (DM) pin is converted to an output port. Incoming WRITE data is strobed-into the memory device and the resulting data pattern is compared to a desired pattern. If the incoming WRITE data and strobed-in data match, that result is sent to the graphical processing system by setting the DM pin HIGH. If the incoming WRITE data and the strobed-in data do not match, that result is sent to the graphical processing system by setting the DM pin LOW. Beneficially, the incoming data and the desired pattern are derived from pseudo random bit sequence (PRBS) sources."
7370186,"A multi-task boot strap system and method for expediting boot up initialization processes are presented. In one embodiment, a multi-task boot strap method includes accessing interrupt vector table information stored in a non-volatile memory. For example, an interrupt vector table and corresponding interrupt service routine information associated with a system management (SM) bus controller operation are accessed from a read only memory (ROM). A program interrupt controller (PIC) is initialized to interpret the interrupt information from the non-volatile memory. This permits the operation of the system management bus controller to be performed in a multi-tasking environment (e.g., operating the SM bus controller in an interrupt mode). A processor can be configured to retrieve the boot up information (e.g., serial presence detect data) and process interrupts with interrupt service routine information retrieved from non-volatile memory. The processor can performing other multi-task operations while waiting for an interrupt during boot up operations."
7372378,"Methods and systems that leverage the advantages of Huffman coding to increase processing efficiency of a data-stream while simultaneously minimizing storage requirements are provided. Decoding efficiency and table storage requirements can be balanced to produce systems that can be adapted for use in high-end network infrastructure applications and for low-resourced portable consumer devices. The systems and methods are operative in decoding data streams using multi-symbol codes and sign information, including AAC and MP3 data streams. A hierarchical structure of tables is described as having primary tables, secondary tables, tertiary tables and so on. Optimization balances processing requirements, table storage requirements and the described systems and methods may be implemented on a variety of processing platforms."
7372379,"This application provides a flexible and efficient way to handle escape symbols during decoding of N-tuple variable length codes (VLCs). The user can request that the decoder resolve a sequence of symbols. The Huffman lookup tables can contain a field to notify the decoder if a given N-tuple VLC includes an escape symbol. For non-escape symbols, as identified by the escape indicator bit in the Huffman lookup table entry, the decoder can finish resolving the N symbols of the N-tuple without requiring a symbol-by-symbol comparison of each symbol to detect escape conditions. For escape symbols, as identified by the escape indicator bit in the Huffman lookup table entry, the decoder can either look back to the user for help, or use pre-defined logic to resolve the escape symbols. Aspects of certain embodiments enable parallelism between Huffman symbol decoding and escape condition detection without losing future expandability."
7372465,"A system and method processes graphics data for remote display. A graphics processing system including a plurality of graphics processing devices is coupled to a host system that includes a host graphics processor and a display device that is remote relative to the graphics processing system. Graphics processing performance may be scaled by distributing processing between the plurality of graphics processing devices and the host graphics processor such that each of the plurality of graphics processing devices and the host graphics processor produces a portion of an image. The portions are combined to produce the image, which is output by the host graphics processor to the display device."
7372467,"Systems and methods for modifying the number of texture samples used to produce an anisotropically filtered texture mapped pixel may improve texture mapping performance. When the number of texture samples is reduced, fewer texels are read and fewer filtering computations are needed to produce a texture value for an anisotropic footprint. The number of texture samples is reduced based on the mip map level weight. The number of texture samples may also be modified using specific parameters for the coarse and/or fine mip map levels. The spacing between the texture samples along the major axis of anisotropy may be modified to improve image quality or texture cache performance."
7372468,"Systems and methods for modifying the number of texture samples used to produce an anisotropically filtered texture mapped pixel may improve texture mapping performance. When the number of texture samples is reduced, fewer texels are read and fewer filtering computations are needed to produce a texture value for an anisotropic footprint. The number of texture samples is reduced based on the mip map level weight. The number of texture samples may also be modified using specific parameters for the coarse and/or fine mip map levels. The spacing between the texture samples along the major axis of anisotropy may be modified to improve image quality or texture cache performance."
7372471,A graphics system has a mode of operation in which primitive coverage information is generated for real sample locations and virtual sample locations for use in anti-aliasing pixels. An individual pixel has a single real sample with color information and at least one virtual sample. In one implementation each virtual sample within a pixel is a pointer that identifies whether the virtual sample belongs to the single real sample within the pixel or to a proximate neighboring pixel. The virtual sample information permits a blending weight to be determined for blending color values of a partially covered pixel with color values of neighboring pixels.
7375727,"Z-buffer rendering of three-dimensional scenes is made more efficient through a method for occlusion culling by which occluded geometry is removed prior to rasterization. The method uses hierarchical z-buffering to reduce the quantity of image and depth information that needs to be accessed. A separate culling stage in the graphics pipeline culls occluded geometry and passes visible geometry on to a rendering stage. The culling stage maintains its own z-pyramid in which z-values are stored at low precision (e.g., in 8 bits). The efficiency of hierarchical z-buffering is improved through hierarchical evaluation of line and plane equations."
7376803,"Circuits, methods, and apparatus for reordering memory access requests in a manner that reduces the number of page misses and thus increases effective memory bandwidth. An exemplary embodiment of the present invention uses an exposed FIFO structure. This FIFO is an n-stage bubble compressing FIFO that preserves the order of requests but allows bypassing to avoid page misses and their resulting delays. A specific embodiment exploits DRAM page locality by maintaining a set of history registers that track the last bank and row usage. Embodiments of the present invention may limit the number of times a request may be bypassed by incrementing an associated bypass counter each time the request is bypassed. Further, to avoid continuous page misses that may occur if requests alternate between two rows, a hold-off counter may be implemented."
7379475,"A communication processor of a class, such as an Internet tuner, provides such desirable features (FIG. 2) as LAN support, an SPI interface (128), a dedicated port (56), and ADPCM (22) for audio applications. The invention provides a low-cost, low-power, easily manufactured, small form-factor network access module which has a low memory demand and provides a highly efficient protocol decode. The invention comprises a hardware-integrated system that both decodes multiple network protocols in a streaming manner concurrently and processes packet data in one pass, thereby reducing system memory and form factor requirements, while also eliminating software CPU overhead."
7382366,"Overclocking parameters in a graphics system are automatically set. In one embodiment, in response to a user request, overclocking parameters for different sets of overclocking parameters are tested using a graphical stress test to select optimum overclocking parameters."
7382368,"A z buffer stores compressed z data represented in a planar format for one or more tiles. The compressed format includes a set of tile specific coefficients defining a plane equation for each z tested primitive intersecting the tile. The z buffer stores a maximum number of sets of tile specific coefficients for each tile, and when the maximum number of sets is exceeded for a particular tile, an uncompressed format is used to store the z data for the particular tile."
7382377,"Method and apparatus for processing one or more fragment data. In one embodiment, the method includes processing one or more fragment data to generate one or more texture map addresses for one or more texels, determining relevance information that correspond to the texture map addresses, and translating the relevance information into a rendering constraint data structure."
7382616,"The present invention represents a significant advancement in the field of cooling systems for computer hardware. In one embodiment, a system for cooling a heat-generating electronic device is provided. The system is mountable to a first side of a circuit board. The system includes a first set of fins, a fan operable to force air through the first set of fins, and a first heat pipe to conduct heat from the heat-generating electronic device to the first set of fins. One advantage of the disclosed cooling system is that it more equally distributes heat across the fins and more equally distributes airflow across surfaces of the fins. Thus, the design increases the effective area of the fin surfaces used in for transferring heat from the heat-generating electronic device to the air, resulting in a more efficient cooling system."
7383352,"A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though, in one embodiment, it is sharing the same chip."
7383412,"On-demand memory synchronization is provided for peripheral subsystems, including graphics systems, that include multiple co-processors operating in parallel. A region of master memory (memory associated with one of the peripheral co-processors) is copied, on demand, to a corresponding region of a different memory associated with another of the peripheral co-processors using a direct memory access operation that does not involve a CPU."
7385604,"A fragment program may configure a fragment processor to compute several output positions and associated data for a fragment, effectively scattering the fragment. Each output position may be independent of a position computed for the fragment during rasterization of a primitive. Each output position may be computed based on a point light source position to compute a shadow map corresponding to the point light source. A raster operation unit writes processed fragment data to each output position. Furthermore, the fragment program may configure the fragment processor to compute per-output position parameters for the fragment such as stencil and alpha values."
7385607,"A scalable shader architecture is disclosed. In accord with that architecture, a shader includes multiple shader pipelines, each of which can perform processing operations on rasterized pixel data. Shader pipelines can be functionally removed as required, thus preventing a defective shader pipeline from causing a chip rejection. The shader includes a shader distributor that processes rasterized pixel data and then selectively distributes the processed rasterized pixel data to the various shader pipelines, beneficially in a manner that balances workloads. A shader collector formats the outputs of the various shader pipelines into proper order to form shaded pixel data. A shader instruction processor (scheduler) programs the individual shader pipelines to perform their intended tasks. Each shader pipeline has a shader gatekeeper that interacts with the shader distributor and with the shader instruction processor such that pixel data that passes through the shader pipelines is controlled and processed as required."
7385609,A graphics pipeline has at least one stage that determines operations to be performed on graphics data based at least in part on data processing attributes associated with the graphics data. One application is to permit one or more operations in a stage to be bypassed. Another application is a multi-function stage in which the data operations that are performed depend at least in part on the data type.
7385611,"Systems and methods that decompress block compressed texture data may decompress the texture data while simplifying computations to reduce die area while maintaining the required accuracy. Reducing the die area permits more texture data to be decompressed in the same die area compared with a more accurate decompression, thereby increasing texture decompression throughput. Computations are simplified by combining denominators for linear interpolation with format conversion to decompress texture data components compressed using conventional block compression formats."
7386697,"In a virtual memory system, address translation information is provided using a cluster that is associated with some range of virtual addresses and that can be used to translate any virtual address in its range to a physical address, where the sizes of the ranges mapped by different clusters may be different. Clusters are stored in an address translation table that is indexed by virtual address so that, starting from any valid virtual address, the appropriate cluster for translating that address can be retrieved from the translation table. The clusters are dynamically created from a fragmented pool of physical addresses as new virtual address mappings are requested by consumers of the virtual memory space."
7388581,"A graphics processing unit implements conditional rendering by putting itself in a state in which it does not execute any rendering commands. Once the graphics processing unit is placed in this state, all subsequent rendering commands are ignored until another rendering command explicitly removes the graphics processing unit from this state. Conditional rendering commands enable the graphics processing unit to place itself in and out of this state based upon the value of a flag in memory. Conditional rendering commands can include conditions that must be satisfied by the flag value in order to change the state of the graphics processing unit. The value of the flag can be set by the graphics processing unit itself, a second graphics processing unit, a graphics coprocessor, or the central processing unit. This enables a wide variety of conditional rendering methods to be implemented."
7389006,"A configurable graphics pipeline has more than one possible process flow of pixel packets through elements of the graphics pipeline. In one embodiment, a data packet triggers an element of the graphics pipeline to discover an identifier."
7389095,"A system, method and system are disclosed for using a variable frequency clock generator to synchronize an average data rate over intervals of time in a variable clock domain to make it equal to a fixed data rate in a fixed clock domain while reducing electromagnetic interference, among other things. In various embodiments, setting the data rates equal to each other minimizes storage used to transition data signals between clock domains. In one embodiment, a variable frequency clock generator includes a phase modulator configured to form a variable frequency clock. Also, the variable clock generator is configured to maintain an average frequency over specific periods of time for the range of discrete frequencies. The phase-offset controller sets an average clock having substantially no offset between a fixed data rate in the fixed clock domain and an average data rate in the variable clock domain."
7395358,"For attached disk drive operations such a file copy and move, as well as more elaborate processes such as searching, virus-scanning and volume merge, a novel intelligent storage engine concept is disclosed. In one embodiment, a storage engine (40), utilizing local processor intelligence, and accessed through a suitable driver (60) and API (App. B), carries out disk access operations without burdening the host CPU (22) and without imposing data traffic on the local CPU bus (34), except for returning results data in an appropriate case."
7397776,"A method for autonomously and dynamically optimizing transmission power of an endpoint in a wireless network includes the step of monitoring a received signal strength, a received signal quality and a transmission error rate of a signal transmitted between an access point in the wireless network and the endpoint at a given transmission power and transmission speed. The method also includes the steps of reducing the transmission power when the received signal strength, the received signal quality and the transmission error rate are at respectively acceptable operating levels and then monitoring the transmission error rate of the signal transmitted at the reduced transmission power level. The method further includes the step of adjusting one of the transmission power or the transmission speed based on whether the transmission error rate of the signal transmitted at the reduced transmission power is still at its respective acceptable operating level."
7397797,"A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though, in one embodiment, it is sharing the same chip."
7400325,"The VPC unit and setup unit of a graphics processing subsystem perform culling operations. The VPC unit performs culling operations on geometric primitives falling within a specific criteria, such as having a property within of a numerical range limit. This limit reduces the complexity of the VPC unit. As increasing rendering complexity typically produces a large number of small primitives, the VPC unit culls many primitives despite its limitations. The VPC unit also includes a cache for storing previously processed vertices in their transformed form, along with previously computed culling information. This increases the VPC unit throughput by reducing the number of memory accesses and culling operations to be performed. The setup unit performs culling operations on any general primitive that cannot be culled by the VPC unit. By performing a first series of culling operations in the VPC unit, the processing burden on the setup unit is decreased."
7400326,"Systems and methods for delivering two data streams via two buses allow one of the buses to be used for delivering selected elements of the data stream that is primarily being delivered by the other bus. At an input rerouting circuit, the selected elements are rerouted from the second data stream into the first data stream; a token inserted in the second data stream identifies a position of the rerouted element. The modified streams are transmitted by the two buses. A receiving circuit reinserts the rerouted data element into the second data stream at the sequential position identified by the placeholder token."
7400327,"A memory system having a number of partitions each operative to independently service memory requests from a plurality of memory clients while maintaining the appearance to the memory client of a single partition memory subsystem. The memory request specifies a location in the memory system and a transfer size. A partition receives input from an arbiter circuit which, in turn, receives input from a number of client queues for the partition. The arbiter circuit selects a client queue based on a priority policy such as round robin or least recently used or a static or dynamic policy. A router receives a memory request, determines the one or more partitions needed to service the request and stores the request in the client queues for the servicing partitions. In one embodiment, an additional arbiter circuit selects memory requests from one of a subset of the memory clients and forwards the requests to a routing circuit, thereby providing a way for the subset of memory clients to share the client queues and routing circuit. Alternatively, a memory client can make requests directed to a particular partition in which case no routing circuit is required. For a read request that requires more than one partition to service, the memory system must collect the read data from read queues for the various partitions and deliver the collected data back to the proper client. Read queues can provide data in non-fifo order to satisfy an memory client that can receive data out-of-order."
7403208,"Jittered sub-pixel samples are used to reduce aliasing during rendering in a graphics pipeline. Sub-pixel samples are jittered using programmed sub-pixel offset values, permitting an application to select not only the number of sub-pixel samples within a pixel, but also the position of each sub-pixel sample within the pixel."
7404002,"Method and system for broadcasting live data over a network are described. In one embodiment, live data is accessed. Next, a first client is authenticated. The live data is then broadcast to a first client, wherein the first client is capable of buffering and re-transmitting the live data. Next, a second client is authenticated. A list of clients receiving the live data is then sent to the second client. The second client then selects the first client from the list, contacts the first client, and then receives the live data from the first client."
7404056,"State information in a processor is managed using a lookup table that has multiple memory circuits, each with multiple entries. Items of state information belonging to a current state version are stored in a first group of entries in the memory circuits. To create an updated state version, a virtual copy of each of the items of state information is created in a second group of entries in the memory circuits, and the virtual copy of the item being updated is replaced with a real copy of the item from the first group of entries. The item in the first group of entries is then updated."
7404059,"State information in a processor is managed using a lookup table that has multiple memory circuits, each with multiple entries. Items of state information belonging to a first state version are stored in a first group of the entries, with each entry in the first group being in a different one of the memory circuits. To create an updated state version, the items of state information are copied in parallel from the first group of entries to a second group of entries, with each entry in the second group is in a different one of the memory circuits. The copy in the second group of the item being updated is then replaced with the updated value."
7406546,"One embodiment of a long-distance synchronous bus includes a sending unit and a receiving unit. The sending unit and receiving unit are configured to use credit-based handshaking signals to regulate data flow between themselves. The receiving unit includes a skid buffer for storing data packets received from the sending unit. The sending unit transmits one data packet to the receiving unit for each credit in possession and consumes one credit for each such transmitted data packet. The receiving unit transmits one credit to the sending unit for each data packet that is read out of the skid buffer. In another embodiment, transmitted data may be broadcast to multiple receiving units by routing the data from the sending unit to the multiple receiving units and maintaining separate credit-based handshaking signals for each receiving unit."
7408553,"Systems and methods for identifying pixels that are inside a two-dimensional path may be used to fill the path. The path is segmented and a point in space is identified that is used to generate a triangle fan, where each triangle in the fan is formed by one of the segments of the path and the point. Locations in a winding buffer are updated for each pixel that is within a triangle of the triangle fan. The resulting winding buffer indicates the pixels that are inside the two-dimensional path. The winding buffer may be used to fill the path."
7412488,"A method of setting up a delegated connection for processing by an offload unit is described. The method comprises establishing a TCP connection and determining whether or not to delegate the TCP connection for processing by the offload unit, producing a delegated connection, and setting up the delegated connection by creating a delegated connection table entry. When frames are received on the delegated connection by the offload unit, the offload unit determines if user buffers are available. When user buffers are available, the offload unit uploads payload data to the user buffers. When user buffers are not available, the offload unit uploads a portion of the payload data to a buffer allocated in Operating System memory space."
7412554,A bus interface controller manages a set of serial data lanes. The bus interface controller supports operating a subset of the serial data lanes as a private bus.
7414550,"The architecture for a combined universal sample rate converter and a sample clock synchronizer is presented. The universal sample rate converter can be applied, for example, to audio samples created or mixed using any of the standard audio frequencies in the set H={8, 11.025, 22.05, 44.1, 48, 96, and 192} kHz and played back using any other frequency from the set H. The synchronizer can be used where audio data are streamed or otherwise broadcast from, for example, the Internet, along with a system timestamp, and where this timestamp needs to be matched to the local audio clock for proper play-back. The same synchronizer can also be used for audio/video or video only synchronization."
7415575,"A cache shared by multiple clients implements a client specific policy for replacing entries in the event of a cache miss. A request from any client can hit any entry in the cache. For purposes of replacing entries, at least of the clients is restricted, and when a cache miss results from a request by the restricted client, the entry to be replaced is selected from a fixed subset of the cache entries. When a cache misses results from a request by any client other than the restricted client, any cache entry, including a restricted entry, can be selected to be replaced."
7417637,An apparatus and method for fairly arbitrating between clients with varying workloads. The clients are configured in a pipeline for processing graphics data. An arbitration unit selects requests from each of the clients to access a shared resource. Each client provides a signal to the arbitration unit for each clock cycle. The signal indicates whether the client is waiting for a response from the arbitration unit and whether the client is not blocked from outputting processed data to a downstream client. The signals from each client are integrated over several clock cycles to determine a servicing priority for each client. Arbitrating based on the servicing priorities improves performance of the pipeline by ensuring that each client is allocated access to the shared resource based on the aggregate processing load distribution.
7418537,"Circuits, apparatus, and methods for avoiding deadlock conditions in a bus fabric. One exemplary embodiment provides an address decoder for determining whether a received posted request is a peer-to-peer request. If it is, the posted request is sent as a non-posted request. A limit on the number of pending non-posted requests is maintained and not exceed, such that deadlock is avoided. Another exemplary embodiment provides an arbiter that tracks a number of pending posted requests. When the number pending posted requests reaches a predetermined or programmable level, a Block Peer-to-Peer signal is sent to the arbiter's clients, again avoiding deadlock."
7418576,"A graphics processor buffers vertex thread and pixel threads. The different types of threads issue instructions corresponding to different sets of operations. A plurality of different types of execution units are provided, each type of execution unit servicing a different class of operations, such as an executing unit supporting texture operations, an execution unit supporting blending operations, and an execution unit supporting mathematical operations. Current instructions of the threads are buffered and prioritized in a common instruction buffer. A set of high priority instructions is issued per cycle to the plurality of different types of execution units."
7418606,"A high quality and performance 3D graphics architecture suitable for portable handheld devices is provided. The 3D graphics architecture incorporates a module to classify polygons by size and other characteristics. In general, small and well-behaved triangles can be processed using “lower-precision” units with power efficient circuitry without any quality and performance sacrifice (e.g., realism, resolution, etc.). By classifying the primitives and selecting the more power-efficient processing unit to process the primitive, power consumption can be reduced without quality and performance sacrifice."
7420557,"Vertices defining a graphics primitive may be processed in homogeneous space and projected into normalized device coordinate space by dividing each coordinate of a vertex by w. When the w coordinate for a vertex is equal to zero, the projected coordinates are set equal to the homogeneous coordinate values. During a viewport transform operation, only the viewport scale is applied rather than applying the viewport scale and viewport bias to produce the vertex in device coordinate space (screen space). Furthermore, when an edge slope is computed for a vertex with a w coordinate equal to zero, the slope is set equal to the vertex in device coordinate space rather than the difference of the two vertices defining the edge. Therefore, a vertex at infinity is correctly positioned avoiding the introduction of visual artifacts."
7420565,"A computer system includes an integrated graphics subsystem and a graphics connector for attaching either an auxiliary graphics subsystem or a loopback card. A first bus connection communicates data from the computer system to the integrated graphics subsystem. With a loopback card in place, data travels from the integrated graphics subsystem back to the computer system via a second bus connection. When the auxiliary graphics subsystem is attached, the integrated graphics subsystem operates in a data forwarding mode. Data is communicated to the integrated graphics subsystem via the first bus connection. The integrated graphics subsystem then forwards data to the auxiliary graphics subsystem. A portion of the second bus connection communicates data from the auxiliary graphics subsystem back to the computer system. The auxiliary graphics subsystem communicates display information back to the integrated graphics subsystem, where it is used to control a display device."
7420568,"A tiled graphics memory permits graphics data to be stored in different tile formats. One application is selecting a tile format optimized for the data generated for particular graphical surfaces in different rendering modes. Consequently, the tile format can be selected to optimize memory access efficiency and/or packing efficiency. In one embodiment a first tile format stores pixel data in a format storing two different types of pixel data whereas a second tile format stores one type of pixel data. In one implementation, a z-only tile format is provided to store only z data but no stencil data. At least one other tile format is provided to store both z data and stencil data. In one implementation, z data and stencil data are stored in different portions of a tile to facilitate separate memory accesses of z and stencil data."
7420572,"An apparatus, system, and method for clipping graphics primitives are described. In one embodiment, a graphics processing apparatus includes a clipping unit that is configured to issue an initial set of outputs based on execution of a set of clipping operations. The graphics processing apparatus also includes a control unit that is connected to the clipping unit. The control unit is configured to preserve an initial execution state of the clipping unit in response to an initial command for context switching, and the initial execution state is preserved based on a number of the initial set of outputs."
7420931,"A method and apparatus for filtering a packet on a connection within a computing system. In one embodiment, the method includes: receiving the packet; delegating the packet to an offload unit for filtering the packet; and determining, by the offload unit, whether the connection is a delegated connection."
7421303,A Linear Complementarity Problem (LCP) solver is characterized by multiple execution units operating in parallel to implement a competent computational method adapted to resolve physics-based LCPs in real-time.
7421604,"Methods and apparatus for controlling a voltage supplied to a device based on an anticipated change in load current demanded by the device are provided. In response to detecting the anticipated change in load current, a load control signal may be generated that causes the voltage regulator to adjust the output voltage supplied to the device."
7423882,"Apparatus and methods for mounting of a cooling device coupled to a circuit board include use of a clip that is rotated to mate with and engage the cooling device. Rotation of the clip occurs during installation of the cooling device and slides slots in the clip into interconnection with respective protrusions of the cooling device extending through the circuit board to where the clip is disposed. In an assembled configuration, the clip biases the cooling device to a processing unit coupled to the circuit board on an opposite side from the clip."
7425956,"One embodiment of the present invention sets forth a method for implementing occlusion testing prior to processing a primitive command. The method includes the steps of determining that an occlusion test should be performed on an enclosed primitive, saving the primitive command on a deferred list, and disabling a rendering functionality in hardware. The method also includes the step of performing an occlusion query on the enclosed primitive where a pixel count is generated that indicates how many pixels within a bounding volume defined around the enclosed primitive are visible. One advantage of this method is that it provides occlusion testing functionality for graphics applications that do not use the occlusion testing functionality provided by graphics APIs. Implementing occlusion testing functionality in this fashion reduces rendering time, thereby increasing rendering performance."
7425966,"A pixel center position that is not covered by a primitive covering a portion of the pixel is displaced to lie within a fragment formed by the intersection of the primitive and the pixel. X,y coordinates of a pixel center are adjusted to displace the pixel center position to lie within the fragment, affecting actual texture map coordinates or barycentric weights. Alternatively, a centroid sub-pixel sample position is determined based on coverage data for the pixel and a multisample mode. The centroid sub-pixel sample position is used to compute pixel or sub-pixel parameters for the fragment."
7426594,"Apparatus, system, and method for arbitrating between memory requests are described. In one embodiment, a processing apparatus includes a memory request generator configured to generate memory requests specifying data for respective presentation elements. The memory request generator is configured to assign priorities to the memory requests based on a presentation order of the presentation elements. The processing apparatus also includes a memory request arbiter connected to the memory request generator. The memory request arbiter is configured to issue the memory requests based on the priorities assigned to the memory requests."
7426597,"A bus permits the number of active serial data lanes of a data link to be re-negotiated in response to changes in bus bandwidth requirements. In one embodiment, one of the bus interfaces triggers a re-negotiation of link width and places a constraint on link width during the re-negotiation."
7426724,"A system optimizes two or more stream processing programs based upon the data exchanged between the stream processing programs. The system alternately processes each stream processing program to identify and remove dead program code, thereby improving execution performance. Dead program code is identified by propagating constants received as inputs from other stream processing programs and by analyzing a first stream processing program and determining the outputs of a second stream processing program that are unused by the first stream processing program. The system may perform multiple iterations of this optimization is previous iterations introduce additional constants used as inputs to a stream processing program. Following optimization of the stream processing programs, the optimized stream processing programs are compiled to a format adapted to be executed by a stream processing system."
7428566,"A multipurpose functional unit is configurable to support a number of operations including multiply-add and format conversion operations, as well as other integer and/or floating-point arithmetic operations, Boolean operations, and logical test operations."
7429528,"An integrated circuit and method of fabricating the same are provided. Included are an active circuit, and a metal layer disposed, at least partially, above the active circuit. Further provided is a bond pad disposed, at least partially, above the metal layer. To prevent damage incurred during a bonding process, the aforementioned metal layer is meshed."
7432981,"Apparatus, system, and method for processing digital audio/video signals are described. In one embodiment, a decoder is configured to process an input signal having an analog television format. The decoder includes a signal detector, and the signal detector is configured to determine whether the input signal incorporates a digital television signal. The decoder also includes a signal extractor connected to the signal detector, and the signal extractor is configured to extract the digital television signal from the input signal based on determining that the input signal incorporates the digital television signal."
7433398,"The invention provides a DMT or OFDM equalization system that deals with each tone not only separately, but also globally, which provides better overall performance. In the inventive system, only M+T variables are required to be determined, where M is the number of tones and T represents the number of SIRF taps. The invention defines a matrix R, in which optimal coefficients are found as the eigenvector corresponding to the smallest eigenvalue of the matrix R. The dynamic range of all variables is limited in a system in accordance with the present invention, which provides ease of hardware implementation. Furthermore, the inventive system retains the advantages of per-tone equalization by providing a smoother signal-to-noise ratio (SNR) distribution function versus synchronization delay. In addition, no effort is wasted on the equalization of unused tones, because it is unnecessary to determine the coefficients for unused tones."
7433909,"A computational unit, or node, in a adaptable computing system is described. A preferred embodiment of the node allows the node to be adapted for use for any of ten types of functionality by using a combination of execution units with a configurable interconnection scheme. Functionality types include the following: Asymmetric Finite Impulse Response (FIR) Filter, Symmetric FIR Filter, Complex Multiply/FIR Filter, Sum-of-absolute-differences, Bi-linear Interpolation, Biquad Infinite Impulse Response (IIR) Filter, Radix-2 Fast Fourier Transform (FFT)/Inverse Fast Fourier Transform (IFFT), Radix-2 Discrete Cosign Transform (DCT)/Inverse Discrete Cosign Transform (IDCT), Golay Correlator, Local Oscillator/Mixer."
7433981,"An architecture is described, wherein an operation unit, such as an arithmetic unit, is used for performing a variety of repetitive tasks. The present invention includes embodiments and related methods for power and computationally efficiency in performing repetitive tasks. The system includes an operation unit and a configuration control unit that is in communication with a processor. The processor sends the configuration information to the configuration unit and the configuration unit provides configuration information to the operation unit. The method includes configuring the operation unit using the configuration unit based on the configuration information, retrieving data from a designated location upon which the operation unit operates, and producing a result that is formatted and send to a destination."
7434032,"A scoreboard memory for a processing unit has separate memory regions allocated to each of the multiple threads to be processed. For each thread, the scoreboard memory stores register identifiers of registers that have pending writes. When an instruction is added to an instruction buffer, the register identifiers of the registers specified in the instruction are compared with the register identifiers stored in the scoreboard memory for that instruction's thread, and a multi-bit value representing the comparison result is generated. The multi-bit value is stored with the instruction in the instruction buffer and may be updated as instructions belonging to the same thread complete their execution. Before the instruction is issued for execution, this multi-bit value is checked. If this multi-bit value indicates that none of the registers specified in the instruction have pending writes, the instruction is allowed to issue for execution."
7437548,"Method and apparatus for network level protocol negotiation for Internet Protocol Security (IPSec) and Internet Protocol Payload Compression (IPComp) are described. More particularly, IPSec and IPComp capabilities are instantiated in a network processor unit of a network interface in at least two communicating computers. By determining each computer has the capacity to due IPSec and IPComp at the transport level, such is negotiated and executed at the transport level independently of an operating system and a central processing unit usage. Additionally, encryption and/or compression are done at the network level operating system and central processing unit offloading."
7439883,"A bitstream generator is described, for placing variable length coding (VLC) data into a fixed width data stream. The bitstream generator includes an input for receiving VLC data; the VLC data may be separated into a value component, and a length component. The bitstream generator also includes an output buffer, a memory module, for storing the VLC data before sending. The bitstream generator also incorporates a backup buffer, which is used to store any overflow data which does not fit in the output buffer. A comparator is used, to determine how much of the VLC data will fit in the output buffer. Any portion of the VLC data which does not fit in the output buffer is stored in the backup buffer."
7439979,"A shader having a cache memory for storing program instructions is described. The cache memory beneficially stores both current programming instructions for a fragment program being run and “look-ahead” programming instructions. The cache memory supports a scheduler that forms program commands that control programmable processing stations. The cache memory can store multiple programming instructions for a plurality of shaders. If the cache memory does not include the desired programming instructions, a miss is asserted and a scheduler (instruction processor) recovers the programming instructions to be run. Beneficially, the scheduler recovers additional programming instructions to support the look-ahead programming. The cache memory stores program instructions by cachelines, where each cacheline comprises a plurality of programming instructions. The cache memory can also store program identifiers."
7439988,"Apparatus, system, and method for clipping graphics primitives are described. In one embodiment, a clipping module includes a mapping unit and a clipping engine that is connected to the mapping unit. The mapping unit is configured to map a graphics primitive onto a canonical representation that is defined with respect to a clipping plane. The clipping engine is configured to clip the graphics primitive with respect to the clipping plane based on the canonical representation."
7441087,"A system, apparatus, and method are disclosed for managing predictive accesses to memory. In one embodiment, an exemplary apparatus is configured as a prediction inventory that stores predictions in a number of queues. Each queue is configured to maintain predictions until a subset of the predictions is either issued to access a memory or filtered out as redundant. In another embodiment, an exemplary prefetcher predicts accesses to a memory. The prefetcher comprises a speculator for generating a number of predictions and a prediction inventory, which includes queues each configured to maintain a group of items. The group of items typically includes a triggering address that corresponds to the group. Each item of the group is of one type of prediction. Also, the prefetcher includes an inventory filter configured to compare the number of predictions against one of the queues having the either the same or different prediction type as the number of predictions."
7441137,"Methods and apparatus for controlling a voltage supplied to a device based on an anticipated change in load current demanded by the device are provided. In response to detecting the anticipated change in load current, a load control signal may be generated that causes the voltage regulator to adjust the output voltage supplied to the device."
7443389,"Circuits, methods, and apparatus that reduce the peak or maximum EMI generated by video signals provided to a CRT or digital display monitor. One exemplary embodiment provides for spreading the spectrum of the video signal in order to spread or diffuse its peak spectral component. This may be done by spreading the spectrum of a pixel clock that is used to clock or time pixel information provided to the monitor. One embodiment spreads the spectrum of the pixel clock by varying the frequency of its operation. The pixel clock is generated by a phase-locked loop having a number of dividers. These dividers divide the frequency of one or more of the signals around the phase-locked loop. The divide ratio is varied as a function of time, resulting in a variation of an output signal frequency as a function of time."
7444491,"Embodiments of the present invention recite a method and system for allocating memory resources. In one embodiment, a control component coupled with a memory device determines that a data buffer adjacent to a boundary of a first FIFO queue does not contain current data. The control component also determines that a second data buffer of a second FIFO queue adjacent to the boundary does not contain current data. The control component then automatically shifts the boundary to include the second data buffer in the first FIFO queue."
7444551,"Method and apparatus for channel monitoring, channel throughput restoration and system testing in relation to channel monitoring and channel throughput restoration is described. A failure status of a channel is identified. The channel and at least one engine associated with the failure status is disabled. A client application assigned such a channel is notified that the channel has been disabled. The at least one engine and the channel associated with the failure status is restored. Additionally, the client application is allowed to destroy and reconstruct command status and state of the channel. Additionally, error information for the failure status is stored. Other aspects include: error injection which may be used for testing ability to detect an error and recover; and a graphical user interface for rendering mode selection for increasing channel throughput."
7446773,An integrated circuit includes at least two different types of processors. The integrated circuit includes an integrated host and associated scheduler. At least one operation is supported by two or more different types of processors. The scheduler schedules operations on the different types of processors.
7446780,"Multisampling techniques provide temporal as well as spatial antialiasing. Coverage for a primitive is be determined at multiple sample locations for a pixel. In one embodiment, coverage is determined using boundary equations representing a boundary surface of the primitive in a three-dimensional space-time. A shading value for the primitive is computed for the pixel and stored for each coverage sample location of the pixel that is covered by the primitive. The sample locations are distributed in both space and time, and multiple sample locations share a single shading computation. The multisampling techniques are extendable to other dimensions that correspond to other image attributes."
7447490,"An apparatus for calibrating gain of an radio frequency receiver (“Rx”) is disclosed to provide, among other things, a structure for performing in-situ gain calibration of an RF integrated circuit over time and/or over temperature without removing the RF integrated circuit from its operational configuration, especially when the gain of the RF integrated circuit is susceptible to variations in process, such as inherent with the CMOS process. In one embodiment, an exemplary apparatus includes a thermal noise generator configured to generate thermal noise as a calibrating signal into an input of an Rx path of an RF integrated circuit. The apparatus also includes a calibrator configured to first measure an output signal from an output of the Rx path, and then adjust a gain of the Rx path based on the thermal noise. In one embodiment, the thermal noise generator further includes a termination resistance and/or impedance."
7447873,"In a multithreaded processing core, groups of threads are executed using single instruction, multiple data (SIMD) parallelism by a set of parallel processing engines. Input data defining objects to be processed received as a stream of input data blocks, and the input data blocks are loaded into a local register file in the core such that all of the data for one of the input objects is accessible to one of the processing engines. The input data can be loaded directly into the local register file, or the data can be accumulated in a buffer and loaded after accumulation, for instance during a launch operation for a SIMD group. Shared input data can also be loaded into a shared memory in the processing core."
7450027,"A method and system for implementing a serial enclosure management interface is disclosed. In one embodiment, the LED indicators for a storage device in an external enclosure are managed. First, a set of bit patterns for driving the LED indicators is repeatedly placed on a serial bus that is connected to an external enclosure for transmission by varying the states of the serial bus. This process continues until a change to this set of bit patterns is detected. In one embodiment, the change is captured in a memory mapped register, which is typically accessible by a storage device controller. The detected change prompts accesses to a virtualized register, which generally resides in system memory, to generate a different set of bit patterns to place on the serial bus."
7450120,"A processor generates Z-cull information for tiles and groups of tiles. In one embodiment the processor includes an on-chip cache to coalesce Z information for tiles to identify occluded tiles. In a coprocessor embodiment, the processor provides Z-culling information to a graphics processor."
7450123,"A system, method and computer program product are provided for performing depth peeling. In use, a first rendering pass is executed for collecting information relating to a first depth layer. Further, at least one additional rendering pass is executed for collecting additional information relating to at least one additional depth layer. Depth peeling is carried out during the execution of the rendering passes by rendering an object, creating a texture based on the rendered object, and rendering the object again utilizing the texture."
7450129,"A distributed rendering system with compression of streams of rendering commands. The controlling device 110 fits streams of rendering commands to the rendering devices 120 within the frame duration by distributing compressed streams. Streams are compressed by caching relatively duplicative sequences of rendering commands. To provide additional efficiency, textures that are mapped to 3D objects can be stored at the rendering devices 120 such that they do not need to be sent from a controlling device 110 everytime the rendering device 120 needs them. Also, long chains of individual vertex calls can be converted on the fly into vertex arrays."
7450136,"A pixel processing unit reduces the number of pixels exterior to a primitive that must be rendered solely for the purpose of generating texture derivative information required to shade pixels within the primitive. In one embodiment, the alignment of group footprints is selected to reduce pixels exterior to primitives which must be calculated to generate texture derivatives. In another embodiment pairs of primitives from the same graphical surface sharing a common boundary are coalesced and shaded concurrently."
7451259,A method and apparatus for providing peer-to-peer data transfer through an interconnecting fabric. The method and apparatus enable a first device to read and/or write data to/from a local memory of a second device by communicating read and write requests across the interconnectivity fabric. Such data transfer can be performed even when the communication protocol of the interconnectivity fabric does not permit such transfers.
7453158,"An integrated circuit and method of fabricating the same are provided. Included are an active circuit, and a metal layer disposed, at least partially, above the active circuit. Further provided is a bond pad disposed, at least partially, above the metal layer. To prevent damage incurred during a bonding process, the aforementioned metal layer is meshed."
7454320,"A system and method are provided for computing partial differential equations in a hardware graphics pipeline. Initially, input is received in a hardware graphics pipeline. Next, the input is processed to generate a solution to a partial differential equation utilizing the hardware graphics pipeline."
7454566,"One embodiment of the present invention includes the steps of determining the optimal RAID level to implement for a given disk drive array, and to the extent applicable, making unallocated disk space available to the user in the form of unprotected disk space. The method efficiently allocates appropriate RAID volumes for the given disk drive array, and, by making the unallocated disk space available to users, allows disk drives of unequal sizes to be effectively used in the disk drive array. Another embodiment of the present invention reconfigures an existing RAID array such that the storage space available on various disk drives in the disk drive array may be used in the most efficient manner. The alternative embodiment is especially useful if an existing RAID array is upgraded by adding a disk drive to, or modified by replacing one or more disk drives in, the existing disk drive array."
7456833,"Circuits, methods, and apparatus for graphically displaying performance metrics of processors such as graphics processing units in multiple processor systems. Embodiments of the present invention may provide metric information regarding operations in alternate-frame rendering, split-frame rendering, or other modes of operation. One embodiment of the present invention provides data in split-frame rendering mode including load balancing, graphics processing unit utilization, frame rate, and other types of system information in a graphical manner. Another exemplary embodiment of the present invention provides graphical information regarding graphics processing unit utilization, frame rate, and other system information while operating in the alternate-frame rendering mode."
7456835,"A graphics processing unit can queue a large number of texture requests to balance out the variability of texture requests without the need for a large texture request buffer. A dedicated texture request buffer queues the relatively small texture commands and parameters. Additionally, for each queued texture command, an associated set of texture arguments, which are typically much larger than the texture command, are stored in a general purpose register. The texture unit retrieves texture commands from the texture request buffer and then fetches the associated texture arguments from the appropriate general purpose register. The texture arguments may be stored in the general purpose register designated as the destination of the final texture value computed by the texture unit. Because the destination register must be allocated for the final texture value as texture commands are queued, storing the texture arguments in this register does not consume any additional registers."
7456838,"A system, method and computer program product are provided for programmable vertex processing. Initially, a vertex program is identified including branch labels and instruction sequences with branch commands. The vertex program is then converted to a binary format capable of being executed by a hardware graphics pipeline. The vertex program may then be executed in the binary format utilizing the hardware graphics pipeline for transforming vertices. As an option, the vertex program is initially written in a textual format capable of being read by a human prior to being converted."
7456846,"A system, apparatus, and method are disclosed for modifying positions of sample positions for selectably oversampling pixels to anti-alias non-geometric portions of computer-generated images, such as texture, at least in part, by shifting shading sample positions relative to a frame of reference. There is generally no relative motion between the geometries and the coverage sample positions. In one embodiment, an apparatus, such as a graphics pipeline and/or a general purpose graphics processing unit, anti-aliases geometries of a computer-generated object. The apparatus includes at least a texture unit and a pipeline front end unit to determine geometry coverage and a subpixel shifter to shift shading sample positions relative to the frame of reference. The apparatus can receive subpixel shifting masks to select subsets of shading sample positions. Each of the shading sample positions is shifted to a coverage sample position to reduce level of detail (“LOD”) artifacts."
7457937,"Embodiments of the present invention recite a method and system for accessing data. In one embodiment of the present invention, a plurality of instances of data are stored in a memory device which comprises a plurality of memory modules disposed as an array of parallel columns. In response to receiving an indication that said plurality of instances of data is being accessed as a row of data, a first address translation table is accessed which describes the same row address in each of said plurality of memory modules wherein an instance of data is stored. Then, in response to receiving an indication that said plurality of instances of data is being accessed as a column of data, a second address translation table is accessed which describes a successive row address in each successive memory module wherein an instance of data is stored."
7460175,"An output pipeline for a video processing device provides supersampling of the output data the digital domain to eliminate or reduce unwanted frequency components in an analog output signal. An encoder converts a pixel stream to digital sample values for a target analog signal at a base sampling rate. The base data stream is supersampled, and the supersampled data is provided to a digital to analog converter The supersampling rate can be selected so as to provide substantial attenuation of a higher frequency echo in the analog output signal."
7461211,"A system, apparatus, and method are disclosed for storing and prioritizing predictions to anticipate nonsequential accesses to a memory. In one embodiment, an exemplary apparatus is configured as a prefetcher for predicting accesses to a memory. The prefetcher includes a prediction generator configured to generate a prediction that is unpatternable to an address. Also, the prefetcher also can include a target cache coupled to the prediction generator to maintain the prediction in a manner that determines a priority for the prediction. In another embodiment, the prefetcher can also include a priority adjuster. The priority adjuster sets a priority for a prediction relative to other predictions. In some cases, the placement of the prediction is indicative of the priority relative to priorities for the other predictions. In yet another embodiment, the prediction generator uses the priority to determine that the prediction is to be generated before other predictions."
7463065,An apparatus includes a single-rail input connected to a low-voltage domain and a voltage-transition circuit connected to the single-rail input. The voltage-transition circuit is configured to convert a voltage of the low-voltage domain received via the single-rail input to a voltage of the high-voltage domain.
7463259,"A graphics processing subsystem is programmed with shader programs that make calls to an abstract interface. One or more subshaders implementing the functions of the abstract interface can also be defined. The binding of interfaces to functions is resolved by a language runtime module that compiles the subshaders. As shader programs are compiled, the runtime module determines whether each method call is associated with an interface function. For each interface method call, the runtime module determines the appropriate implementation of the interface to be bound to the method call. Once the appropriate implementation is identified, the interface binding is created using string substitution or indirect addressing instructions. At the time of compilation, which may be during the execution of the rendering application, the desired combinations of subshaders are specified and compiled into a combined shader program, which can then be executed by the graphics processing subsystem."
7463260,"Information associated with representation of textual information can be captured, stored and manipulated in a convenient and efficient automated manner that conserves resources. A handheld text image processing device can include a camera, a graphics processing component, a text processing component and a memory. The camera captures digital picture information associated with text on an object. The graphics processing component performs graphics processing on the digital picture information that facilitate text recognition (e.g., transforms, rotations, etc.). The text processing component recognizes representations of the text in the digital picture information and converts the digital picture information associated with the text into a text file format. The memory stores the information in a text file format. The text file format can represent the textual information utilizing less bits than a file format in which the text information is captured. The text information can also be communicated in a text file format."
7464183,A firewall identifies unsolicited messages having an address resolution for a network protocol address different than cached address resolution information. The accuracy of the unsolicited messages is checked by requesting network elements to report address resolution information for the network protocol address.
7466316,"An integrated circuit includes at least two different types of processors, such as a graphics processor and a video processor. At least one operation is commonly by supported by two different types of processors. For each commonly supported operation that is scheduled, a decision is made to determine which type of processor will be selected to implement the operation."
7466318,"Systems and methods for avoiding unnecessary uncovered texture fetches may improve texture mapping performance. A shader program compiler performs data-flow analysis to determine if texture fetches may be required for pixels that are not covered by a graphics primitive fragment. A graphics driver then determines which texture maps do not require texels for uncovered neighbor pixels, dependent on texture filter mode information, thereby avoiding unnecessary uncovered texture fetches."
7466322,"Vertices defining a graphics primitive are converted into homogeneous space and clipped against a single clipping plane, the w=0 plane, to produce a clipped graphics primitive having vertices including w coordinates that are greater than or equal to zero. Rasterizing a graphics primitive having a vertex with a w coordinates that is greater than or equal to zero is less complex than rasterizing a graphics primitive having a vertex with a w coordinate that is less than zero. Clipping against the w=0 plane is less complex than conventional clipping since conventional clipping may require that the graphics primitive be clipped against each of the six faces of the viewing frustum to produce a clipped graphics primitive."
7467289,Software can freeze portions of a pipeline operation in a processor by asserting a predetermined freeze register in the processor. The processor halts operations relating to portions of a common pipeline processing in response to an asserted freeze register. Processor resources that operate downstream from the common pipeline continue to process any scheduled instructions. The processor is prevented from initiating any context switching in which a processor resource is allocated to a different channel. The processor stops supplying any additional data to downstream resources and ensures that the interface to downstream resources is clear of previously sent data. The processor prevents state machines from making additional requests. The processor asserts an acknowledgement indication in response to the freeze assertion when the processing has reached a stable state. Software is allowed to manipulate states and registers within the processor. Clearing the freeze register allows processing to resume.
7467308,"A PCI-Express bus is incorporated in a method for transmitting a power-saving command between a computer system and its plurality of peripheral devices of the present invention. More particularly, a specific power management command is introduced into the signal transmission protocol of a system command, which is transmitted between the plural system chips. Therefore, the peripheral devices coupled with the system chips can enter a certain power mode simultaneously. The present invention is used to solve the problem of the peripheral devices cannot enter the certain power mode since the system chip has no power management unit disposed under the PCI-Express structure."
7467313,"A method for transmitting a power-saving command between a computer system and system chips thereof is described. A power-saving command associated with a first system chip is introduced to the computer system since a BIOS is modified therefore. The CPU of the computer system determines the power mode of the first system chip according to a register therein. As the first system chip enters the power-saving mode, the second system chip is informed entering the power-saving mode as well. Therefore, the peripheral devices coupled to the system chips can enter the power-saving mode smoothly so as to solve that the devices cannot enter the mode simultaneously since there is no power management unit (PMU) installed in the first system chip."
7468726,"A graphics processor performs culling of invisible primitives in a vertex processing unit that includes a geometry shader or other processing engine that performs per-primitive operations. Primitives can be culled after clip space coordinates for the vertices have been computed and in some instances before at least one other vertex attribute has been computed. To the extent that this early culling reduces the number of vertices for which the full set of attributes is computed or reduces the number of primitives or vertices delivered to downstream units, throughput of the processor is increased."
7469309,"Methods and apparatus for peer-to-peer data transfers in a computing environment provide configurable control over the number of outstanding read requests by one peer device to another. A requesting peer device includes a control register that stores a high-watermark value associated with requests to a target peer device. Each time a read request to the target peer device is generated, the number of such requests already outstanding is compared to the high-water mark. The request is blocked if the number of outstanding requests exceeds the high-water mark and remains blocked until such time as the number of outstanding requests no longer exceeds the high-water mark. Different high-water marks can be associated with different combinations of requesting and target devices."
7469311,A bus interface permits an upstream bandwidth and a downstream bandwidth to be separately selected. In one implementation a link control module forms a bidirectional link with another bus interface by separately configuring link widths of an upstream unidirectional sub-link and a downstream unidirectional sub-link.
7469349,"A computer system and a method of signal transmission via a PCI-Express bus is provided for transmitting a power-saving signal among a plurality of peripheral devices. For the peripheral devices coupled with the system chips can enter a power-saving mode successfully, a signal snooping and blocking manners are introduced into the system chips. The present invention is to improve on a problem that the system chips cannot enter the power-saving mode simultaneously since the system chips don't set any power-management unit therein."
7469355,"Methods, apparatuses, and systems are presented for dynamically overclocking a processor comprising operating the processor at a clock rate to run an executable program by using the processor to carry out a plurality of instructions associated with the executable program, while the processor is running the executable program, repeatedly monitoring at least one activity measure associated with a specific operation of the processor, wherein the at least one activity measure is generated from within the processor, evaluating the at least one activity measure to determine whether a predefined condition representing processor activity level is met, and, if the predefined condition is met, dynamically adjusting the clock rate of the processor to modify execution speed at which the processor carries out instructions."
7469366,"Health of a high-speed interface link, such as a PCI Express link, is measured. In one embodiment, counter data representing data sent and errors occurring in a high-speed interface link is read. Health statistics based on the counter data are computed. The health statistics may be displayed as a graphical representation. Various statistics representing bus utilization, error rates, efficiency and/or other measures of link health may be computed and displayed."
7474312,"In one embodiment of the present invention, a GPU contains an authentication module at the front end, and a memory security engine and graphic memory interface at the backend. In one embodiment of the present invention, the memory security engine provides a privilege table. The programmable privilege table maps memory address ranges, and user IDs to privileges for accessing the memory address ranges. In one embodiment of the present invention, the memory security engine receives a memory access command along with an associated authenticated user ID. In one embodiment of the present invention, the memory security engine checks the authenticated user ID and address range against the privilege table. In one embodiment of the present invention, if the table indicates that the user has authorization for the particular read or write transaction to the graphic memory, the instruction is executed by the graphic memory interface. If the accessed address is not in the table, no special privileges are needed to access that address. If the table indicates that the user does not have authorization for the particular read or write transaction, the memory security engine provides a memory redirect."
7474313,"A graphics system coalesces Z data and color data for a raster operations stage. The Z data and color data are stored in a memory aligned tile format. In one embodiment, rendering modes in which the tile does not have a data capacity corresponding to Z data or color data for a whole number of pixels have data for at least one pixel split across entries to improve packing efficiency. Rendering modes having a number of bits for Z data or color data that does not equal a power of two such as 24 bits, 48 bits, and 96 bits, may be implemented with a high packing efficiency in tile formats having a data capacity corresponding to a power of 2 bits."
7475001,"A PPU enhanced system stores software packages implementing, at least in part, a physics subroutine. The package being implemented as a plurality of modules, at least one module being stored and executed on a host system and another module being stored and executed on the PPU."
7475197,A method for efficiently managing memory resources in a computer system having a graphics processing unit that runs several processes simultaneously on the same computer system includes using threads to communicate that additional memory is needed to avoid termination or less than optimal performance of a process. If the request indicates that termination will occur then other processes will reduce their memory usage to a minimum to avoid termination but if the request indicates that the process will not run optimally then the other processes will reduce their memory usage to 1/N where N is the count of the total number of running processes. The apparatus includes a computer system using a graphics processing unit and processes with threads that can communicate directly with other threads and with a shared memory which is part of the operating system memory.
7477091,"Circuits, methods, and apparatus for using redundant circuitry on integrated circuits in order to increase manufacturing yields. One exemplary embodiment of the present invention provides a circuit configuration wherein functional circuit blocks in a group of circuit blocks are selected by multiplexers. Multiplexers at the input and output of the group of circuit blocks steer input and output signals to and from functional circuit blocks, avoiding circuit blocks found to be defective or nonfunctional. Multiple groups of these circuit blocks may be arranged in series and in parallel. Alternate multiplexer configurations may be used in order to provide a higher level of redundancy. Other embodiments use all functional circuit blocks and sort integrated circuits based on the level of functionality or performance. Other embodiments provide methods of testing integrated circuits having one or more of these circuit configurations."
7477205,"A computer system including a processor, a display, and a graphics unit coupled between the processor and the display, in which the processor is configured to perform multi-display operations which generate multiple frames of display data for simultaneous display, and a graphics unit for use in such a system. Typically, the graphics unit includes graphics memory that includes at least two frame buffers, and the processor operates as if it were independently asserting multiple streams of display data to multiple frame buffers for driving multiple displays independently. Another aspect of the invention is a system that displays data from a frame buffer on a screen. The frame buffer holds data indicative of a virtual desktop that is larger than can be displayed on the screen or available portion thereof, the system can display on the screen any of a number of different subsets of the frame buffer data, each subset indicative of a different portal of the desktop, and the system includes a processor including texture processing circuitry operable to filter a subset of the frame buffer data that is indicative of a portal to be displayed."
7477255,"A method for synchronizing divergent samples in a programmable graphics processing unit is described. In one embodiment, the method includes the steps of determining that a divergence has occurred and detecting that a first sample of a group of samples has encountered a first synch token. The method also includes the steps of determining whether each of the other samples of the group has encountered a synch token and determining whether the synch token encountered by each of the other samples of the group is the first synch token."
7477256,"A system and method for providing a dedicated digital interface between multiple graphics devices. The dedicated interface provides a point-to-point connection between each of the multiple graphics devices for the transfer of digital pixel data and synchronization signals. Graphics processing, including combining of portions of a displayable image, is distributed between the multiple graphics devices. One of the multiple graphics devices, a master graphics device converts the combined portions of the displayable image as needed for a specific display device."
7477257,"A memory hub permits a graphics processor to access random access memories, such as dynamic random access memories (DRAMs). In one implementation, the memory hub permits an increase in effective memory bandwidth by aggregating the memory of two or more memories. In another implementation, the memory hub permits a graphics processor to offload memory access interfacing operations to the memory hub."
7477260,"A system of processing data in a graphics processing unit having a core configured to process data in hexadecimal form and other graphics modules configured to process data in quads includes a transpose buffer with a crossbar to reorganize incoming data, several memory banks to store the reorganized data over a period of several clock cycles, and a second crossbar for reorganizing the stored data after it is read from the bank of memories in one clock cycle. The method for converting between data in hexadecimal form and data in quads includes providing data in hexadecimal form, reorganizing the data provided in hexadecimal form, storing the reorganized data in several memories, and reading several of the memory locations, which contain all of the elements of the quad, in one clock cycle."
7477266,"Digital Image compositing using a programmable graphics processor is described. The programmable graphics processor supports high-precision data formats and can be programmed to complete a plurality of compositing operations in a single pass through a fragment processing pipeline within the programmable graphics processor. Source images for one or more compositing operations are stored in graphics memory, and a resulting composited image is output or stored in graphics memory. More-complex compositing operations, such as blur, warping, morphing, and the like, can be completed in multiple passes through the fragment processing pipeline. A composited image produced during a pass through the fragment processing pipeline is stored in graphics memory and is available as a source image for a subsequent pass."
7478189,"Circuits, apparatus, and methods for avoiding deadlock conditions in a bus fabric. One exemplary embodiment provides an address decoder for determining whether a received posted request is a peer-to-peer request. If it is, the posted request is sent as a non-posted request. A limit on the number of pending non-posted requests is maintained and not exceed, such that deadlock is avoided. Another exemplary embodiment provides an arbiter that tracks a number of pending posted requests. When the number pending posted requests reaches a predetermined or programmable level, a Block Peer-to-Peer signal is sent to the arbiter's clients, again avoiding deadlock."
7478289,"A system and method for increasing the yield of integrated circuits containing memory partitions the memory into regions and then independently tests each region to determine which, if any, of the memory regions contain one or more memory failures. The test results are stored for later retrieval. Prior to using the memory, software retrieves the test results and uses only the memory sections that contain no memory failures. A consequence of this approach is that integrated circuits containing memory that would have been discarded for containing memory failures now may be used. This approach also does not significantly impact die area."
7479753,Embodiments of the present invention provide a low noise and high efficiency fan speed controller. The fan speed controller generates a pulse width modulation signal. The pulse width modulation signal is utilized to switch mode convert a supply voltage into a linear voltage. The voltage level of the linear voltage is a function of the pulse width modulation signal. The linear voltage is utilized to control the operating speed of a direct current fan.
7479965,"Circuits, methods, and apparatus that reduce the amount of data transferred between a graphics processor integrated circuit and graphics memory. Various embodiments of the present invention further improve the efficiency of blenders that are included on a graphics processor. One embodiment provides for the storage of a reduced number of subsamples of a pixel when the storage of a larger number of subsamples would be redundant. The number of subsamples that are blended with source data are compressed, thereby reducing the task load on the blenders increasing their efficiency. These methods can be disabled to avoid errors that may arise in certain applications."
7480739,"Circuits, methods, and apparatus that increase utilization of available USB bandwidth, limit the amount of data accessed from memory, and provide for parallel requests for data from memory. An exemplary embodiment of the present invention caches a pointer for each transfer descriptor in a periodic and async schedule. Several transfer descriptors are also cached. Caching pointers reduces the time needed to organize the needed transfer descriptors to be transmitted. Caching several transfer descriptors eliminates the need to access the main memory each time they are needed. Also, if more transfer descriptors are needed beyond those in cache, memory requests for multiple transfer descriptors may be done in parallel since their pointers are available in cache."
7480749,"Methods and apparatus for using a predetermined portion of main memory as extended disk buffer memory that is used as disk buffer memory for a disk drive. A controller causes data, such as prefetched data, to flow between disk electronics and the extended disk buffer memory. Data is stored in the extended disk buffer memory along with the logical block address associated with that data and with validation information. Valid data recalled from the extended disk buffer memory can be used directly by the processor without going to the disk drive. In some embodiments the extended disk buffer memory can provide all of the disk buffer memory, while in other embodiments the extended disk buffer memory is augmented by disk drive buffer memory."
7483029,"In one embodiment, the present invention is implemented as a GPU configured for traversing pixels of an area. The GPU includes a set-up unit for generating polygon descriptions and a rasterizer unit coupled to the set-up unit for rasterizing the polygon descriptions. The rasterizer unit is configured to traverse a plurality of pixels of an image using a first boustrophedonic pattern along a predominant axis, and during the traversal using the first boustrophedonic pattern, traverse a plurality of pixels of the image using a second boustrophedonic pattern, wherein the second boustrophedonic pattern is nested within the first boustrophedonic pattern."
7483031,"A method for synchronizing two of more graphics processing units. The method includes the steps of determining whether the phase of a first timing signal of a first graphics processing unit and the phase of a second timing signal of a second graphics processing unit are synchronized, and adjusting the frequency of the first timing signal to the frequency of the second timing signal if the first timing signal and the second timing signal are not synchronized."
7483032,"Circuits, methods, and apparatus that allow the elimination of a frame buffer connected directly to a graphics processing unit. The graphics processing unit includes an on-chip memory. Following system power-up or reset, the GPU initially renders comparatively low-resolution images to the on-chip memory for display. Afterward, the GPU renders images, which are typically higher resolution, and stores them in a system memory, apart from the graphics processing unit. The on-chip memory, which is no longer needed for image storage, instead stores address information, referred to as page tables, identifying the location of data stored by the GPU in the separate system memory."
7483039,"A programmable system for dithering video data. The system is operable in at least two user-selectable modes which can include a small kernel mode and a large kernel mode. In some embodiments, the system is operable in at least one mode in which it applies two or more kernels (each from a different kernel sequence) to each block of video words. Each kernel sequence repeats after a programmable number of the blocks (e.g., a programmable number of frames containing the blocks) have been dithered. The period of repetition is preferably programmable independently for each kernel sequence. The system preferably includes a frame counter for each kernel sequence. Each counter generates an interrupt when the number of frames of data dithered by kernels of the sequence has reached a predetermined value. In response to the interrupt, software can change the kernel sequence being applied. Typically, the system performs both truncation and dithering on words of video data. For example, some embodiments produce dithered 6-bit color components in response to 8-bit input color component words. Preferably, the inventive system is optionally operable in either a normal mode (in which dithering is applied to all pixels in accordance with the invention) or in an anti-flicker mode. Another aspect of the invention is a computer system in which the dithering system is implemented as a subsystem of a pipelined graphics processor or display device. Another aspect of the invention is a display device that includes an embodiment of the dithering system."
7483375,"An Internet network protocol stack, along with special logic, is embedded with a modem, thereby enabling a modem to become Internet-ready. As a result, the modem offloads much of the network protocol processing from the main CPU and improves the overall performance of the communication system."
7483823,"Systems and methods for designing and generating integrated circuits using a high-level language are described. The high-level language is used to generate performance models, functional models, synthesizable register transfer level code defining the integrated circuit, and verification environments. The high-level language may be used to generate templates for custom computation logical units for specific user-determined functionality. The high-level language and compiler permit optimizations for power savings and custom circuit layout, resulting in integrated circuits with improved performance per watt of power consumption."
7484076,"Methods, apparatuses, and systems are presented for performing instructions using multiple execution units in a graphics processing unit involving issuing an instruction for P executions of the instruction wherein each execution uses different data, P being a positive integer, the instruction being issued based on a first clock having a first clock rate, operating Q execution units to achieve the P executions of the instruction, Q being a positive integer less than P and greater than one, each of the execution units being operated based on a second clock having a second clock rate higher than the first clock rate of the first clock, and wherein the second clock rate of the second clock is equal to the first clock rate of the first clock multiplied by the ratio P/Q."
7486290,"A graphical shader and a method of distributing graphical data to shader pipelines in a graphical shader are disclosed. In accordance with the method, a shader pipeline input delay is set. Further, a group of the graphical data is distributed to a shader pipeline of the graphical shader to be processed. The method includes waiting for the shader pipeline input delay to elapse. After the shader pipeline input delay has elapsed, another group of the graphical data is distributed to another shader pipeline of the graphical shader to be processed. In another embodiment, a graphical shader includes a plurality of shader pipelines for processing graphical data. Further, the graphical shader includes a shader distributor for distributing a group of the graphical data to one of the shader pipelines and for distributing another group of the graphical data to another one of the shader pipelines after a shader pipeline input delay has elapsed."
7486519,"A system for cooling a heat-generating electronic device in a computer system includes a printed circuit board having one or more ventilation holes and coupled to a first side of the heat-generating electronic device, and a fan assembly having a top side and a bottom side and coupled to a second side of the heat-generating electronic device. The fan assembly is disposed relative to the printed circuit board to allow air to flow into the top side of the fan assembly and into the bottom side of the fan assembly through the one or more ventilation holes. One advantage of this design is that it enables a greater volume of air to flow through the fan assembly relative to prior art designs, thereby resulting in more efficient cooling of the heat-generating electronic device."
7487371,"A data path controller, a computer device, an apparatus and a method are disclosed for integrating power management functions into a data path controller to manage power consumed by processors and peripheral devices. By embedding power management within the data path controller, the data path controller can advantageously modify its criteria in-situ so that it can adapt its power management actions in response to changes in processors and peripheral devices. In addition, the data path controller includes a power-managing interface that provides power-monitoring ports for monitoring and/or quantifying power consumption of various components. In one embodiment, the data path controller includes a power-monitoring interface for selectably monitoring power of a component. It also includes a controller for adjusting operational characteristics of the component for modifying the power consumed by the component to comply with a performance profile, which generally specifies permissible power consumption levels for the component."
7487516,"A first graphics application produces surface data using a first graphics applications programming interface. A second graphics application uses a second graphics applications programming interface that is incompatible with the first graphics applications programming interface to process the surface data for display. A device driver requests driver level information from the second graphics application and stores the surface data in a portion of memory specified by the driver level information. Although the first graphics application is incompatible with the second graphics application, surface data produced by the first graphics application may be processed for display by the second graphics application."
7489315,"Systems and methods for converting graphics data represented in a hexadecimal form into a quad form may be used to reorganize the graphics data for performing raster operations. Prior to performing raster operations the graphics data received for each component is assembled to interleave the components for each pixel as needed to perform the raster operations. The assembly process varies depending on the number of bits per component, the number of components to be processed, and the memory format of the render target used to store the processed graphics data."
7489318,"An exemplary method detects an update to data representing a portion of a render target, according to one embodiment of the invention. Also, this method forms a copy of the portion configured to be overwritten with data for a subsequent update when that portion of the render target is selected to receive subsequent updates. Lastly, the data representing the portion can be designated as texture."
7490208,"Architecture for compact multi-ported register file is disclosed. In an embodiment, a register file comprises a single-port random access memory (RAM). The single-port RAM comprises a single port for read operations and for write operations. Either a single read or a single write operation is performed for a given clock via the single port. Moreover, the single-port RAM serially performs N read operations and M write operations associated with a data group using a clock phase of (N+M) clock phases generated from a clock. In another embodiment, a semiconductor device includes the architecture for compact multi-ported register file. The semiconductor device comprises a plurality of register files. Each register file comprises a RAM comprising a port for read operations and for write operations. Moreover, each RAM serially performs N read operations and M write operations associated with one of a plurality of data groups using a corresponding clock phase of (N+M) clock phases generated from a clock. Further, the semiconductor device comprises an input staging unit for staging write data of one or more of the write operations. Continuing, the semiconductor device comprises an output staging unit for staging read data of one or more of the read operations. The semiconductor device can be a graphics processing unit (GPU)."
7492131,"A circuit for use in powering a load having dynamic power needs. A variable strength controller is provided that has a feedback terminal, at least one p-terminal, and at least one n-terminal. The p− and n-terminals are each suitable for driving a respective semiconductor device to partially control the power to the load as the said feedback terminal receives a feedback signal representative of actual demand for the power by the load. A total of at least three p− and n-terminals are provided, and their selective employment thus collectively fully controls the power to the load."
7492204,"One embodiment of the present invention sets forth a set of three building block circuits for designing a flexible timing generator for an integrated circuit. The first and second building blocks include delay elements that may be customized and fine-tuned prior to fabrication. The third building block may be tuned prior to fabrication as well as after fabrication. The three building blocks may be incorporated into a modular architecture, enabling designers to easily generate well-characterized, flexible, generic timer circuits."
7492368,A multiprocessor system executes parallel threads. A controller receives memory requests from the parallel threads and coalesces the memory requests to improve memory transfer efficiency.
7493244,"Computer simulation of the dynamics of rigid bodies interacting through collisions, stacks and joints is performed using a constraint-based system in which constraints are defined in terms of the positions of the bodies. Displacements caused by reaction forces necessary to ensure that the bodies comply with the position constraints can be calculated and can be done iteratively by updating equations defining the reaction forces and the displacements such that the computation time and memory resources required to perform the calculations is linearly dependent upon the number of bodies and the number of contacts and joints between the bodies. Computational requirements and memory requirements are reduced further by performing the calculations using vector operations."
7495343,"An integrated circuit and method of fabricating the same are provided. Included are an active circuit, and a metal layer disposed, at least partially, above the active circuit. Further provided is a bond pad disposed, at least partially, above the metal layer. To prevent damage incurred during a bonding process, the aforementioned metal layer may define a frame with an outer periphery and an inner periphery."
7495985,"Memory component temperature information is used to implement a method for ODT (on die termination) thermal load management. A respective temperature of a plurality of memory components are accessed, and based on this temperature, an ODT cycle is directed to a first of the memory components to avoid imposing a thermal load from the ODT cycle on a second of the memory components."
7496788,"Systems and methods for monitoring the accuracy of unit status reporting within an application specific integrated circuit device may be used reduce power consumption. Accurate status reporting of an idle state is needed to safely disable a clock signal for a unit in order to reduce the power needed by that unit. A watchdog monitor may be used during functional simulation and synthesized for formal verification, emulation, and functional device testing and debugging. The watchdog monitor may also be configured based on specific characteristics of the unit that it is monitoring."
7499690,"A system, method and system are disclosed for using a variable frequency clock generator to synchronize an average data rate over intervals of time in a variable clock domain to make it equal to a fixed data rate in a fixed clock domain while reducing electromagnetic interference, among other things. In various embodiments, setting the data rates equal to each other minimizes storage used to transition data signals between clock domains. In one embodiment, a variable frequency clock generator includes a phase modulator configured to form a variable frequency clock. Also, the variable clock generator is configured to maintain an average frequency over specific periods of time for the range of discrete frequencies. The phase-offset controller sets an average clock having substantially no offset between a fixed data rate in the fixed clock domain and an average data rate in the variable clock domain."
7500041,A graphics processing unit is operable as an individual graphics processing unit. However the graphics processing unit has a mode of operation in which a private bus is formed with a second graphics processing unit.
7502010,"A display for a computer system, such as an LCD, is configured to consume less power when compared to conventional designs. The display includes a screen and at least one backlight configured to illuminate the screen. An input to the at least one backlight is adjustable to produce a desired level of brightness. The input may be computed based on a generated source image and a defined constraint. An input to the display is computed based on the input to the at least one backlight and the source image. The input to the display modifies the level of brightness provided by the at least one backlight to produce a viewable image."
7502035,"A graphics processing apparatus coalesces groups of primitives for concurrent processing in a pixel shader. In one implementation, the shader concurrently processes coalesced groups for multisampling. In another implementation, the shader concurrently processes coalesced groups to calculate derivative information."
7502354,A system and methods for wireless computing devices to become mesh member nodes within a self-configuring mesh network includes mechanisms for neighbor discovery and sharing of a common topology database including mesh topology and mesh network information. Each mesh node may use the topology database to determine optimized routing paths within the mesh network. Mesh member nodes are configured to detect and communicate topology changes and measured mesh network attributes to other members of the self-configuring wireless network.
7502915,"The present invention provides an adaptive computing engine (ACE) that includes processing nodes having different capabilities such as arithmetic nodes, bit-manipulation nodes, finite state machine nodes, input/output nodes and a programmable scalar node (PSN). In accordance with one embodiment of the present invention, a common architecture is adaptable to function in either a kernel node, or k-node, or as general purpose RISC node. The k-node acts as a system controller responsible for adapting other nodes to perform selected functions. As a RISC node, the PSN is configured to perform computationally intensive applications such as signal processing."
7502925,"An alternate checksum option for transmitting TCP frame data is used that does not require computing a TCP checksum. Instead, an integrity check value is computed and placed in the ESP authentication portion near the end of the frame. Transmission of a portion of the TCP frame data may begin before all of the TCP frame data is received by a TCP checksum offload device because the integrity check value is inserted at the end of the frame. Furthermore, the integrity check value is computed using a static key or a dynamic key may be computed to cover a greater portion of the frame compared with ESP authentication specified by the IPsec standard."
7504872,"One embodiment of the present invention sets forth a set of three building block circuits for designing a flexible timing generator for an integrated circuit. The first and second building blocks include delay elements that may be customized and fine-tuned prior to fabrication. The third building block may be tuned prior to fabrication as well as after fabrication. The three building blocks may be incorporated into a modular architecture, enabling designers to easily generate well-characterized, flexible, generic timer circuits."
7506134,"The present invention enables efficient matrix multiplication operations on parallel processing devices. One embodiment is a method for mapping CTAs to result matrix tiles for matrix multiplication operations. Another embodiment is a second method for mapping CTAs to result tiles. Yet other embodiments are methods for mapping the individual threads of a CTA to the elements of a tile for result tile computations, source tile copy operations, and source tile copy and transpose operations. The present invention advantageously enables result matrix elements to be computed on a tile-by-tile basis using multiple CTAs executing concurrently on different streaming multiprocessors, enables source tiles to be copied to local memory to reduce the number accesses from the global memory when computing a result tile, and enables coalesced read operations from the global memory as well as write operations to the local memory without bank conflicts."
7506237,"A reconfigurable bit-manipulation node is disclosed that includes an execution unit configured to perform a number of bit-oriented functions and a control unit configured to control the execution unit to allow one of the bit-oriented functions to be performed. The execution unit is comprised of interconnected elements that include a programmable butterfly unit, a number of non-programmable butterfly units, a number of data path elements, a look-up table memory, and a reorder memory. The execution unit is capable of engaging in one of a number of operating modes to perform the bit-oriented functions. The operating modes include a programmable mode and a number of fixed operating modes including Viterbi decoding, turbo decoding and variable length encoding and decoding. The data path elements include a programmable shifter and a programmable combiner."
7508390,A method for rendering a shadow in a 3 D scene includes generating a penumbra map using a z-buffer and generating an occluder map using the z-buffer. The penumbra map and the occluder map are projected into a 3 D scene to render at least one shadow having a penumbra region and an umbra region.
7508394,"Method and apparatus for graphics processing is described. More particularly, a graphics processing subsystem capable of multi-pass graphics data processing is described. The graphics processing subsystem includes a geometry processor and a fragment processor, where output from the fragment processor is input compatible with the geometry processor. Data produced in a pass through a graphics data-processing pipeline including the fragment processor and geometry processor may be used as an input to processing during a subsequent pass. Data read from a texture map may be used to define or modify data, including vertex data, being processed in the geometry processor or the fragment processor."
7508397,"Methods, apparatuses, and systems are presented for modifying data in memory associated with an image, involving processing data operations in a pipelined process affecting data in memory corresponding to the image. The data operations include a first data operation involving a first read operation followed by a first write operation, and a second data operation involving a second read operation followed by a second write operation. After starting the first read operation, a determination is made whether data associated with the first data operation overlaps with data associated with the second data operation. If a data overlap occurs, the second read operation is started after the first write operation is completed, and if no data overlap occurs, the second read operation is started before the first write operation is completed."
7508398,A system and method for providing antialiased memory access includes receiving a request to access a memory address. The memory address is examined to determine if the memory address is within a virtual frame buffer. If the memory address is within a virtual frame buffer then the memory address is transformed into one or more physical addresses within a frame buffer that is utilized for antialiasing. The frame buffer may be a single memory space containing subpixel information corresponding to pixels of the virtual frame buffer. Subpixels located at the physical addresses within the frame buffer are then accessed. The disclosed invention provides for direct access by a software application.
7508448,"Video filtering using a programmable graphics processor is described. The programmable graphics processor may be programmed to complete a plurality of video filtering operations in a single pass through a fragment-processing pipeline within the programmable graphics processor. Video filtering functions such as deinterlacing, chroma up-sampling, scaling, and deblocking may be performed by the fragment-processing pipeline. The fragment-processing pipeline may be programmed to perform motion adaptive deinterlacing, wherein a spatially variant filter determines, on a pixel basis, whether a “bob”, a “blend”, or a “weave” operation should be used to process an interlaced image."
7510423,"A communication connector, in accordance with one embodiment of the invention, includes an insulative housing having a cylindrical opening, a light source, and a first and second electrical interconnect. The insulative housing includes a body portion and a head portion. The cylindrical opening extends through the head portion and partially into the body portion of the insulative housing. The light source is disposed in the insulative housing proximate the head portion. The first electrical interconnect includes a terminal portion for fixedly connecting the communication connector to a device and a contact portion comprising a resilient conductive element disposed in the cylindrical opening for engaging a mating communication connector. The second electrical interconnect couples an indicator signal to the light source."
7511714,"Video conversion using a 3D graphics pipeline of a graphical processing unit (GPU) is disclosed. A plurality of video data formatted in a first video format is accessed from a memory unit. Moreover, the plurality of video data is converted from the first video format to a second video format using a 3D graphics pipeline of the GPU. The plurality of video data formatted in the second video format is sent to the memory unit. The 3D graphics pipeline applies a filtering technique. In an embodiment, the filtering technique is an interpolation technique."
7511717,"Hybrid sampling of pixels of an image involves generating shading values at multiple shading sample locations and generating depth values at multiple depth sample locations, with the number of depth sample locations exceeding the number of shading sample locations. Each shading sample location is associated with one or more of the depth sample locations. Generation and filtering of hybrid sampled pixel data can be done within a graphics processing system, transparent to an application that provides image data."
7512736,"One embodiment of the present invention includes the steps of determining the optimal RAID level to implement for a given disk drive array, and to the extent applicable, making unallocated disk space available to the user in the form of unprotected disk space. The method efficiently allocates appropriate RAID volumes for the given disk drive array, and, by making the unallocated disk space available to users, allows disk drives of unequal sizes to be effectively used in the disk drive array. Another embodiment of the present invention reconfigures an existing RAID array such that the storage space available on various disk drives in the disk drive array may be used in the most efficient manner. The alternative embodiment is especially useful if an existing RAID array is upgraded by adding a disk drive to, or modified by replacing one or more disk drives in, the existing disk drive array."
7512773,"A halt sequencing protocol permits a context switch to occur in a processing pipeline even before all units of the processing pipeline are idle. The context switch method based on the halt sequencing protocol includes the steps of issuing a halt request signal to the units of a processing pipeline, monitoring the status of each of the units, and freezing the states of all of the units when they are either idle or halted. Then, the states of the units, which pertain to the thread that has been halted, are dumped into memory, and the units are restored with states corresponding to a different thread that is to be executed after the context switch."
7515208,"Apparatus, system, and method for detecting AC-coupled electrical loads of a set of digital-to-analog converters are described. In one embodiment, a processing apparatus includes a digital-to-analog converter. The processing apparatus also includes a pulse generation module connected to the digital-to-analog converter, and the pulse generation module is configured to direct the digital-to-analog converter to transmit a pulse of electrical energy. The processing apparatus further includes a load detection module connected to the digital-to-analog converter, and the load detection module is configured to determine a connection status of the digital-to-analog converter based on a degree to which the pulse of electrical energy is reflected during a transient response time period."
7516301,"Heterogeneous processors can cooperate for distributed processing tasks in a multiprocessor computing system. Each processor is operable in a “compatible” mode, in which all processors within a family accept the same baseline command set and produce identical results upon executing any command in the baseline command set. The processors also have a “native” mode of operation in which the command set and/or results may differ in at least some respects from the baseline command set and results. Heterogeneous processors with a compatible mode defined by reference to the same baseline can be used cooperatively for distributed processing by configuring each processor to operate in the compatible mode."
7516412,"Method and apparatus for content based dynamic rendering of user interfaces. The present invention provides a system that receives an unformatted stream of content, and then considers the physical dimensions of its controlled screen area and dynamically lays out the content to fit in this screen area."
7519507,"A system, method, and computer program product are provided for quantitatively gauging video processing. In use, at least one quantitative aspect and at least one qualitative aspect of video processing of a processor are identified. To this end, the video processing of the processor may be gauged based on the quantitative and qualitative aspects."
7519781,"Circuits, methods, and apparatus for efficiently storing page characteristics. Page characteristics for memory pages are stored post address translation using addresses for physical locations in memory, for example, in a bit vector. The characteristics may include access or dirty bits, as well as other types of information. These bit vectors can also be stored and accumulated to generate histogram data. Two bit vectors may be included, while a first bit vector is written to, another is used. After data has been written to the first, the bit vectors are flipped, and data is written to the second while the first is used."
7519892,"Embodiments for binary encoding and/or decoding data are disclosed. In or more embodiments, N data bits may be encoded using one of a plurality of codes derived from at least N+1 bits wherein each of the plurality of codes comprises approximately equal numbers of bits at a first logical level and a second logical level."
7519893,"Embodiments for binary encoding and/or decoding of data for transmission and/or reception over a data interconnect are disclosed. For an embodiment, a code may comprise a base portion, a subset of the base portion, a complement bit associated with the base portion, and a complement bit associated with the subset of the base portion."
7522167,"Coherence of displayed images is provided for a graphics processing systems having multiple processors operating to render different portions of a current image in parallel. As each processor completes rendering of its portion of the current image, it generates a local ready event, then pauses its rendering operations. A synchronizing agent detects the local ready event and generates a global ready event after all of the graphics processors have generated local ready events. The global ready signal is transmitted to each graphics processor, which responds by resuming its rendering activity."
7522169,"A graphics processing unit has a set of parallel processing units. A primitive pipeline delivers tiles of a primitive to selected processing units of the set of processing units. An attribute pipeline distributes attributes to the selected processing units when the end of the primitive is reached, while withholding attributes from the remaining processing units of the set of processing units."
7522171,"A system of processing data in a graphics processing unit having a core configured to process data in hexadecimal form and other graphics modules configured to process data in quads includes a transpose buffer with a crossbar to reorganize incoming data, several memory banks to store the reorganized data over a period of several clock cycles, and a second crossbar for reorganizing the stored data after it is read from the bank of memories in one clock cycle. The method for converting between data in hexadecimal form and data in quads includes providing data in hexadecimal form, reorganizing the data provided in hexadecimal form, storing the reorganized data in several memories, and reading several of the memory locations, which contain all of the elements of the quad, in one clock cycle."
7522173,Systems and methods for processing linear colorspace data may be reused to process nonlinear colorspace data at a comparable performance level while maintaining the precision of the nonlinear colorspace data. Nonlinear colorspace data is converted to a compact floating point format in a linear colorspace used by conventional graphics processors. The compact floating point format includes an 8 bit explicit mantissa (without an implied leading one) and a 3 bit exponent to maintain the precision of the nonlinear colorspace data. The 8 bit mantissa may be processed by conventional texture filtering units designed to process 8 bit (fixed or floating point) color values. The 3 bit exponent may by processed by conventional texture filtering units designed to process floating point color values.
7522540,A system and methods for wireless computing devices to become mesh member nodes within a self-configuring mesh network includes mechanisms for neighbor discovery and sharing of a common topology database including mesh topology and mesh network information. Each mesh node may use the topology database to determine optimized routing paths within the mesh network. Mesh member nodes are configured to detect and communicate topology changes and measured mesh network attributes to other members of the self-configuring wireless network.
7523209,"Method and interface for configuring a link is described. A transceiver has configuration registers. The configuration registers are read to determine capability of the transceiver. An application is selected, and the configuration registers of the transceiver are configured responsive to the application selected. A protocol having initialization, transmit and receive portions is described to facilitate configuration operations, such as reads and writes of configuration registers, for such a link."
7523264,An array of streaming multiprocessors shares data via a shared memory. A flushing mechanism is used to guarantee that data required for dependent computations is available in the shared memory.
7523467,"One embodiment of the invention is an architecture for improving the performance of a computer system containing a plurality of hardware input/output devices. The architecture implements an operating system configured to perform all related input/output operations within the operating system kernel. Thus, the operating system enables a first device driver that produces data to pass data directly to a second device driver that consumes data, without a context switch. One advantage of this approach is that computer system performance may be substantially increased due to a reduction in context switching."
7523468,"One embodiment of the present invention is a computer system having an operating system that includes a first device driver and a second device driver, and a hardware layer that includes a first input/output device controlled by the first device driver and a second input/output device controlled by the second device driver. In response to a request, the first input/output device is configured to transmit data directly to the second input/output device, without the data first being transmitted to the first device driver or to the second device driver. One advantage of the disclosed architecture is that all related input/output operations are performed in the hardware layer such that data can be transmitted directly between input/output devices without context switching or use of software data buffers. Such an approach may substantially increase overall performance due to reductions in context switching and software overhead."
7525547,"Methods, apparatuses, and systems are presented for operating a plurality of graphics devices involving using the graphics devices to processes a sequence of images, wherein at least one first graphics device processes a first image, and at least one second graphics device processes a second image, communicating a first command associated with the first image to the at least one first graphics device and the at least one second graphics device, wherein the first command is to be executed by the at least one first graphics device and the at least one second graphics device, and communicating a second command associated with the first image to the at least one first graphics device and the at least one second graphics device, wherein the second command is to be executed by the at least one first graphics device but not by the at least one second graphics device."
7525548,"One embodiment of a video processor includes a first media processing device coupled to a first memory and a second media processing device coupled to a second memory. The second media processing device is coupled to the first media processing device via a scalable bus. A software driver configures the media processing devices to provide video processing functionality. The scalable bus carries video data processed by the second media processing device to the first media processing device where the data is combined with video data processed by the first media processing device to produce a processed video frame. The first media processing device transmits the combined video data to a display device. Each media processing device is configured to process separate portions of the video data, thereby enabling the video processor to process video data more quickly than a single-GPU video processor."
7525549,"Method, apparatuses, and systems are presented for processing a sequence of images for display using a display device involving operating a plurality of graphics devices, including at least one first graphics device that processes certain ones of the sequence of images, including a first image, and at least one second graphics device that processes certain other ones of the sequence of images, including a second image, delaying processing of the second image by the at least one second graphics device, by a specified duration, relative to processing of the first image by the at least one first graphics device, to stagger pixel data output for the first image and pixel data output for the second image, and selectively providing output from the at least one first graphics device and the at least one second graphics device to the display device."
7525551,"Ripmapping and footprint assembly are used to anisotropically filter texture maps. A subset of the set of ripmaps associated with a base texture is created and stored. The subset includes ripmaps selected to maximize anisotropic texture sampling performance and to minimize the texture memory requirements. For pixel footprints not aligned with the anisotropy of ripmaps or requiring a ripmap outside of the subset, footprint assembly is used to perform anisotropic filtering by taking multiple isotropic probes from a mipmap. For texture samples aligned within a tolerance range of the anisotropy of a ripmap, footprint assembly constructs an anisotropic texture sample from one or more samples of a ripmap. Ripmap statistics are collected during texture mapping to dynamically determine an optimal subset of ripmaps, and additional ripmaps can be added to the subset on demand if warranted. A graphics driver can analyze ripmap statistics to determine the subset of ripmaps."
7526456,"A method of operating a Linear Complementarity Problem (LCP) solver is disclosed, where the LCP solver is characterized by multiple execution units operating in parallel to implement a competent computational method adapted to resolve physics-based LCPs in real-time."
7526593,"Multiple data transfer requests can be merged and transmitted as a single packet on a packetized bus such as a PCI Express (PCI-E) bus. In one embodiment, requests are combined if they are directed to contiguous address ranges in the same target device. An opportunistic merging procedure is advantageously used that merges a first request with a later request if the first request and the later request are mergeable and are received within a holdoff period that is dynamically determined based on a level of bus activity; otherwise, requests can be transmitted without merging."
7526604,"Method and apparatus for improving system performance using controlled speculative write prefetching in systems that use command queuing. Speculative write prefetching can be forced on or off, or a determination can be made regarding the benefit versus detriment of speculative write prefetching. The state of the queue switch can be used to determine if speculative write prefetching is to be performed. The state of the queue switch can be set by a queue counter that tracks over time whether speculative write prefetching is or is not beneficial. The content of the queue counter can be controlled by incrementing its value if speculative write prefetching helped and decrementing that value if speculative write prefetching did not help."
7526619,One embodiment of the present invention sets forth a technique for emulating a floppy disk drive using network storage services. An application executing on a diskless computing device generates INT 13 access requests to gain access to a floppy disk image residing on a storage server. The INT 13 access requests are directed to a translation function that maps cylinder head sector (CHS) addresses and commands native to floppy disk media to linear block addresses (LBA) and commands used to access data within SCSI devices. An iSCSI initiator residing within the diskless computing device directs the LBA requests to an iSCSI target residing within the storage server to access a LUN residing on the storage server that contains a floppy disk image. The application is then able to conduct access requests to the floppy disk image as though a physical floppy disk drive were present on the diskless computing device.
7526634,"Systems and methods for synchronizing processing work performed by threads, cooperative thread arrays (CTAs), or “sets” of CTAs. A central processing unit can load launch commands for a first set of CTAs and a second set of CTAs in a pushbuffer, and specify a dependency of the second set upon completion of execution of the first set. A parallel or graphics processor (GPU) can autonomously execute the first set of CTAs and delay execution of the second set of CTAs until the first set of CTAs is complete. In some embodiments the GPU may determine that a third set of CTAs is not dependent upon the first set, and may launch the third set of CTAs while the second set of CTAs is delayed. In this manner, the GPU may execute launch commands out of order with respect to the order of the launch commands in the pushbuffer."
7526666,"Two or more circuits (e.g. processing cores of a graphics processor) operate synchronously at a fast clock frequency. A core interface to each of the processing cores is designed to communicate in synchronous fashion with one or more other core interfaces at a slow clock frequency. The fast clock is distributed to each processing core in a manner that provides minimized skew and jitter, e.g. with a balanced tree network. The slow clock is locally derived from the fast clock in each core interface. One of the core interfaces is selected to provide a synchronism signal, and the synchronism signal is distributed among the multiple core interfaces to synchronize the locally derived slow clocks."
7528836,A CPU selectively programs one or more graphics devices by writing a control command to the command buffer that designates a subset of graphics devices to execute subsequent commands. Graphics devices not designated by the control command will ignore the subsequent commands until re-enabled by the CPU. The non-designated graphics devices will continue to read from the command buffer to maintain synchronization. Subsequent control commands can designate different subsets of graphics devices to execute further subsequent commands. Graphics devices include graphics processing units and graphics coprocessors. A unique identifier is associated with each of the graphics devices. The control command designates a subset of graphics devices according to their respective unique identifiers. The control command includes a number of bits. Each bit is associated with one of the unique identifiers and designates the inclusion of one of the graphics devices in the first subset of graphics devices.
7528839,"A graphics processing subsystem defines a bounding area as the portion of the display buffer and other memory buffers occupied by one or more rendered objects. When clearing the memory buffers, only the portions of the buffers corresponding to the bounding area need to be cleared. A graphics pipeline includes a bounding area memory to store bounding area values. The bounding area values are modified during rendering so that each rendered primitive falls within the bounding area values. The graphics processing subsystem clears a portion of the memory buffer in response to a clear command specifying a bounding area. The clear command may include a set of bounding area values defining the bounding area, or alternatively a reference to the bounding area memory. For applications that draw objects in isolation, the bounding area will be smaller than the window, resulting in a decreased time requirement for clearing the memory buffer."
7528843,"Systems and methods for dynamically canceling texture fetches may improve texture mapping performance. A shader program compiler inserts condition code writes and condition code comparison operations for shader program instructions that contribute to a texture read instruction and do not need to be executed if certain conditions are met. During execution of the shader program, the inserted condition codes are used to compute a dynamic writemask that indicates if the texture data resulting from the texture read is unnecessary. The dynamic writemask is used to cancel unnecessary texture fetches during execution of the shader program."
7532218,"Embodiments of methods and apparatus for memory training concurrent with data transfers are disclosed. For an example embodiment, data may be transferred from a first memory device to a first partition of a memory controller, and a training operation may be performed for a second partition of the memory controller coupled to a second memory device while the first partition of the memory controller is transferring data from the first memory device."
7532480,"Embodiments of methods, apparatuses, devices, and/or systems for power delivery for electronic assemblies are disclosed."
7533236,Systems and methods for dynamically allocating memory for thread processing may reduce memory requirements while maintaining thread processing parallelism. A memory pool is allocated to store data for processing multiple threads that does not need to be large enough to dedicate a fixed size portion of the memory pool to each thread that may be processed in parallel. Fixed size portions of the memory pool are dynamically allocated and deallocated to each processing thread. Different fixed size portions may be used for different types of threads to allow greater thread parallelism compared with a system that requires allocating a single fixed portion of the memory pool to each thread. The memory pool may be shared between all of the thread types or divided to provide separate memory pools dedicated to each particular thread type.
7533237,Systems and methods for dynamically allocating memory for thread processing may reduce memory requirements while maintaining thread processing parallelism. A memory pool is allocated to store data for processing multiple threads that does not need to be large enough to dedicate a fixed size portion of the memory pool to each thread that may be processed in parallel. Fixed size portions of the memory pool are dynamically allocated and deallocated to each processing thread. Different fixed size portions may be used for different types of threads to allow greater thread parallelism compared with a system that requires allocating a single fixed portion of the memory pool to each thread. The memory pool may be shared between all of the thread types or divided to provide separate memory pools dedicated to each particular thread type.
7534145,"Embodiments of methods and apparatus for plating a PCI Express edge connector are described. In one embodiment, a printed circuit board having connectors is employed for electroplating one or more of the connectors formed thereon. The printed circuit board comprises a substrate having one or more layers, and a plurality of connectors formed on one or more of the layers, wherein at least one connector includes at least one short pin and at least one extra pin. The at least one extra pin extends beyond an outer shape of the printed circuit board after fabrication. The printed circuit board also includes connection circuitry formed on one or more of the layers, wherein the connection circuitry is configured to electrically connect the short pin with the extra pin at least during electroplating of said short pin."
7535433,"A system and method for modifying the configuration of one or more graphics adapters and one or more displays without rebooting the system allows a user to quickly transition between different graphics adapter/display configurations. A single display driver interfaces between the operating system and the one or more graphics devices. The display driver reconfigures the one or more graphics devices to change the adapter/display configuration without shutting down or rebooting the system. Unlike a conventional system reboot performed by the operating system, the display driver checks that there are no memory leaks or error conditions during the reconfiguration."
7535913,"The invention is embodied in a gigabit Ethernet adapter. A system according to the invention provides a compact hardware solution to handling high network communication speeds. In addition, the invention adapts to multiple communication protocols via a modular construction and design."
7535959,"A video encoder includes a programmable rate controller. In one embodiment, the programmable rate controller includes a variable bit rate controller, a constant bit rate controller, and an arbitration logic for selecting one of the two outputs. An embodiment of a variable bit rate controller tracks long-term changes to average bit rate. An embodiment of a constant bit rate controller classifies macroblock types, determines a statistical indicator of complexity for each macroblock type, and generates a target bit rate based on estimated complexity."
7538773,"A method of determining pixel parameters, wherein the pixel parameters were clamped to a valid range. The method includes a step of accessing a geometric primitive comprising a plurality of vertices wherein each vertex has associated therewith a plurality of parameters including a pair of texture coordinates. During rasterization of said geometric primitive performed in a rasterization module of graphics pipeline, a respective pair of texture coordinates for each pixel of said geometric primitive are computed using interpolation. Each computed texture coordinate includes an integer portion and a fractional portion. Only the fractional portions of said texture coordinates are propagated to a downstream data fetch module of said graphics pipeline."
7539218,A method is described for synchronously processing and rendering digitized media data streams where each data stream is made up of a sequence of samples. The described method includes processing each data stream in a single task. The method includes the generating the timing signals for different data streams from a single operating system timer and further processing the media in the data stream synchronously in one task using this timing signal.
7541835,"Techniques and circuits for ensuring undefined control signals are not inadvertently driven onto a bus due to core logic and I/O logic supply voltages reaching final voltage levels at different times are provided. According to some embodiments, an internal voltage supply sense circuit may monitor a level of a voltage supply that powers core logic that generates control signals to be driven on I/O pads. The sense circuit may generate one or more control signals used to keep I/O pads in a high impedance state."
7542042,"A new method of operating a fragment shader to produce complex video content comprised of a video image or images, such as from a DVD player, that overlays a fragment shader-processed background. Pixels are fragment shader-processed during one loop or set of loops through a texture processing stations to produce a fragment shader-processed background. Then, at least some of those pixels are merged with the video or images to produce complex video content. The resulting complex image is then made available for further processing."
7542043,"Methods and apparatus for subdividing a shader program into regions or “phases” of instructions identifiable by phase identifiers (IDs) inserted into the shader program are provided. The phase IDs may be used to constrain execution of the shader program to prohibit texture fetches in later phases from being executed before a texture fetch in a current phase has completed. Other operations (e.g., math operations) within the current phase, however, may be allowed to execute while waiting for the current phase texture fetch to complete."
7542046,"An apparatus, system, and method for clipping graphics primitives are described. In one embodiment, a graphics processing apparatus includes a clipping unit, a read-only memory that is connected to the clipping unit, a read-write memory that is connected to the clipping unit, and an addressing unit that is connected to the read-only memory and the read-write memory. The read-only memory is configured to store a clipping program, and the read-write memory is configured to store a patch program. The addressing unit is configured to selectively address one of the read-only memory and the read-write memory based on a set of input conditions."
7542292,One embodiment of a system for efficiently cooling a processor includes an active hybrid heat transport module adapted to be integrated with a fansink. The hybrid heat transport module comprises both a fluid channel and an air channel adapted for transporting heat. The hybrid heat transport module and the fansink may be used alone or in combination to dissipate heat from the processor.
7542749,"A system, method and system are disclosed for using a variable frequency clock generator to synchronize an average data rate over intervals of time in a variable clock domain to make it equal to a fixed data rate in a fixed clock domain while reducing electromagnetic interference, among other things. In various embodiments, setting the data rates equal to each other minimizes storage used to transition data signals between clock domains. In one embodiment, a variable frequency clock generator includes a phase modulator configured to form a variable frequency clock. Also, the variable clock generator is configured to maintain an average frequency over specific periods of time for the range of discrete frequencies. The phase-offset controller sets an average clock having substantially no offset between a fixed data rate in the fixed clock domain and an average data rate in the variable clock domain."
7543110,"A RAID disk array controller implements a write mask to support partial-stripe updates from a host system without expensive RAM to RAM copying and repeated disk accesses to assemble the updated stripe. New data from the host is transferred into a single buffer and a local processor tracks—by setting bits in the write mask—which segments of the target stripe are updated. The disk array is accessed to transfer the target stripe into the same buffer, but the buffer memory write enable is inhibited—responsive to the write mask—during transfer of the segments that were updated by the host. The complete, updated stripe is thus formed in a single buffer for parity calculations and write to the disk array."
7543136,"One embodiment of a computing system configured to manage divergent threads in a thread group includes a stack configured to store at least one token and a multithreaded processing unit. The multithreaded processing unit is configured to perform the steps of fetching a program instruction, determining that the program instruction is a branch instruction, determining that the program instruction is not a return or break instruction, determining whether the program instruction includes a set-synchronization bit, and updating an active program counter, where the manner in which the active program counter is updated depends on a branch instruction type."
7545380,"Method, apparatuses, and systems are presented for processing an ordered sequence of images for display using a display device, involving operating a plurality of graphics devices, including at least one first graphics device that processes certain ones of the ordered sequence of images, including a first image, and at least one second graphics device that processes certain other ones of the ordered sequence of images, including a second image, the first image preceding the second image in the ordered sequence, delaying at least one operation of the at least one second graphics device to allow processing by the at least one first graphics device to advance relative to processing by the at least one second graphics device, in order to maintain sequentially correct output of the ordered sequence of images, and selectively providing output from the graphics devices to the display device."
7545382,"A graphics system utilizes page table entries to provide information on the storage format used to store graphics data. The page table entries, in turn, may be used for address translation. Exemplary kinds of storage format information include compression mode, a packing mode for storing Z data in tiles or color data in tiles, and a mode for allocating tile data among partitions in a partitioned memory."
7545741,"One embodiment of the present invention is a method for identifying a faulty NIC in a team of NICs using a minimum number of packets transmitted in a round-robin scheme. Relative to prior art schemes, the disclosed method advantageously reduces the number of keep-alive packets necessary to monitor the NICs within a team and, to the extent there is a failure, enables the faulty NIC to be identified."
7545984,"Methods, apparatuses, and systems are presented for measuring difference between graphics images relating to performing an arithmetic operation involving a first graphics image comprising a plurality of first pixels and a second graphics image comprising a plurality of second pixels to produce a difference image comprising a plurality of difference pixels, generating measures of proximity from a plurality of ranges of observation within the difference image, wherein the measures of proximity represent spatial proximity of difference pixels to other difference pixels within the difference image, and applying non-uniform weighting to the difference pixels to produce a weighted difference image, wherein the non-uniform weighting depends on the measures of proximity generated from the plurality of ranges of observation."
7546307,"A system for a block storage client to work with data blocks in a virtual filesystem (VFS) where the actual data for the data blocks is stored in a real filesystem (RFS). A virtual block mapping table caches references to the actual data in files and directory structures of the RFS. A read mapper then accesses the files and directory structures based on the cached references in the virtual block mapping table, and constructs the data blocks from the files or synthesizes them from the directory structures. And a VFS interface receive read requests from the client, directs the read mapper to prepare the data blocks, and provides the data blocks to the client."
7546483,Systems and methods for using a graphics processor to perform RAID parity functions may improve disk access performance. A method is provided for configuring a graphics processor to perform XOR parity computations when data is written to the RAID array. Another method is provided for configuring the graphics processor to perform the XOR parity computations to restore data when a disk is damaged. Using the graphics processor as a coprocessor to offload parity computations from a central processing unit may improve disk access performance and overall system performance.
7548178,"A sigma delta analog-to-digital converter (ADC) to convert an analog converter input signal to a digital converter output signal. Multiple integrator stages, including at least a first and a final one, each receive an analog input signal and an analog feedback signal and output an integrated signal. The integrator stages are serially ordered to receive the converter input signal and then preceding of the integrated signals. A quantizer receives the integrated signal of the final or multiple integrator stages and provides the converter output signal. A feedback system also receives the converter output signal and provides the respective analog feedback signals to at least one of the integrator stages. The feedback system particularly includes resisters arrayed so that at least one is in the paths of all of the analog feedback signals and others are only in the paths of each individual analog feedback signal."
7548238,"Methods and systems are described that unite various shading applications under a single language, enable the simple re-use and re-purposing of shaders, facilitate the design and construction of shaders without need for computer programming, and enable the graphical debugging of shaders."
7548481,"An aspect of the invention relates to a method of dynamically adjusting power consumption of a random access memory (RAM) coupled to a processor. Frequency of a memory clock signal coupled to the RAM is reduced. At least one supply voltage coupled to the RAM is reduced. At least one latency parameter of the RAM is configured in response to the reduced frequency and the reduced at least one supply voltage. The RAM may then be re-initialized. In this manner, voltage supplied to the RAM is reduced, thereby reducing power consumption in the RAM."
7548740,"A system, method and system are disclosed for using a variable frequency clock generator to synchronize an average data rate over intervals of time in a variable clock domain to make it equal to a fixed data rate in a fixed clock domain while reducing electromagnetic interference, among other things. In various embodiments, setting the data rates equal to each other minimizes storage used to transition data signals between clock domains. In one embodiment, a variable frequency clock generator includes a phase modulator configured to form a variable frequency clock. Also, the variable clock generator is configured to maintain an average frequency over specific periods of time for the range of discrete frequencies. The phase-offset controller sets an average clock having substantially no offset between a fixed data rate in the fixed clock domain and an average data rate in the variable clock domain."
7549596,"An image bearing surface. In accordance with a first embodiment of the present invention, an image bearing surface comprises a surface for interacting with a writing element of an electronic interactive device to embody a user created image thereon. The image bearing surface includes a first demarked region for accepting a plurality of user created images, each of the images representing a user response to a question, and a second demarked region for accepting a plurality of user created images identifying characteristics of the first demarked region to the electronic interactive device. The first and second demarked regions comprise a permanently printed encoded pattern of location information on the surface for providing location information to the electronic interactive device. The image bearing surface may be used to facilitate the use of supplementary educational testing materials."
7551442,"One embodiment of a system for cooling a heat-generating device includes a base adapted to be coupled to the heat-generating device, a housing coupled to the base, a liquid channel formed between the base and the housing, where a heat transfer liquid may be circulated through the liquid channel to remove heat generated by the heat-generated device, and a heat pipe disposed within the liquid channel, where the heat pipe increases the heat transfer surface area to which the heat transfer liquid is exposed. Among other things, the heat pipe advantageously increases the heat transfer surface area to which the heat transfer liquid is exposed and efficiently spreads the heat generated by the heat-generating device over that heat transfer surface area. The result is enhanced heat transfer through the liquid channel relative to prior art cooling systems."
7554538,"Embodiments of methods, apparatuses, devices, and/or systems for video processing, such as for hidden surface removal or reduction, are described."
7554546,"Stippled lines are drawn by evaluating a distance function for a set of points within the area of a stippled line. The distance function gives a distance value proportional to the distance from a point to the end of the stippled line. Using the point's distance value, a pattern index value defines a correspondence between a point and at least one stipple pattern bit. The value of pattern bits are applied to the points on the stippled line, masking the points such that only a portion of the set of points are displayed or determining intensity values according to the position of the points within the stipple pattern. A distance function may be an edge equation associated with the line end or a segment of a polyline. The distance function can be evaluated for the set of points in any order, allowing portions of a stippled line to be drawn in parallel."
7558348,"A radio frequency antenna system and high-speed digital data link are disclosed to, among other things, reduce electromagnetic interference (“EMI”) at relatively high data rates while reducing the manufacturing complexities associated with conventional data links. In one embodiment, a radio frequency (“RF”) antenna system includes an antenna and an RF radio coupled to the antenna for receiving wireless RF signals. In particular, the RF radio is configured to digitize RF signals at a fixed data rate to form digitized data signals and to apply the digitized data signals at a variable data rate to a high-speed digital link. The variable data rate distributes the signal energy of the digitized data signals over one or more bands of frequencies, thereby beneficially altering an EMI spectral profile describing emissions that develop as the digitized data signals are transported through a channel."
7558400,"A method for optimizing the number of bilinear samples includes the steps of computing a desired bilerp count for a pixel footprint in a mipmap, where a fractional distance represents the distance between the desired bilerp count and a first available bilerp count relative to the distance between a second available bilerp count and the first available bilerp count, determining a modified bilerp count based on the desired bilerp count, and computing a modified fractional distance based on the modified bilerp count, where the modified fractional distance is zero if the fractional distance is between zero and a first-non-zero value, but is between zero and one if the fractional distance is within a transition band. Texture values for the bilerps in the first available count and one or more additional bilerps are average to generate a pixel texture value, where the modified fractional distance determines the weights applied."
7558873,"Method for Internet Protocol Payload Compression (IPComp) and Large Send is described. More particularly, a Large Send initiated by a computer is used to trigger an IPComp negotiation. After agreement on IPComp, data blocks for such a Large Send are compressed in accordance with an agreed upon compression algorithm prior to being divided up into smaller blocks, such as being divided by a maximum transmission unit, for sending. To further improve performance, a intelligent network interface with Large Send and IPComp capabilities is used for offloading Large Send and IPComp functions."
7561163,"Multiple graphics processors in a graphics processing system are interconnected in a unidirectional or bidirectional ring topology, allowing pixels to transferred from any one graphics processor to any other graphics processor. The system can automatically identify one or more “master” graphics processors to which one or more monitors are connected and configures the links of the ring such that one or more other graphics processors can deliver pixels to the master graphics processor, facilitating distributed rendering operations. The system can also automatically detect the connections or lack thereof between the graphics processors."
7561932,"A user can assign different audio data streams to different output channels of a single audio card using substantially conventional APIs, device drivers, and Audio Codec Interfaces (ACIs). An Application Processing Unit (APU) sequences audio data streams in accordance with a user's output channel assignment."
7562174,"A motherboard includes two bus connectors. Each connector has contact positions for a set of serial data lanes. A private bus is formed in the motherboard to couple a subset of the serial data lanes of the two connectors. In one implementation, each connector is a Peripheral Component Interface Express (PCIe) connector with a private bus coupling a subset of the serial data lanes of the two PCIe connectors."
7562205,"A virtual address translation table and an on-chip address cache are usable for translating virtual addresses to physical addresses. Address translation information is provided using a cluster that is associated with some range of virtual addresses and that can be used to translate any virtual address in its range to a physical address, where the sizes of the ranges mapped by different clusters may be different. Clusters are stored in an address translation table that is indexed by virtual address so that, starting from any valid virtual address, the appropriate cluster for translating that address can be retrieved from the translation table. Recently retrieved clusters are stored in an on-chip cache, and a cached cluster can be used to translate any virtual address in its range without accessing the address translation table again."
7564456,"A graphics pipeline rasterizes primitives and generates a stream of groups of pixels, such as a stream of pixel quads. A tile coalesce unit received the stream of groups of pixels and generates pixel tiles for use by downstream pixel processing units. The pixel tiles facilitate hazard checks and transaction coherency."
7565279,Embodiments of a callback procedure mechanism and method are disclosed in relation to a system running a physics simulation in parallel with a main application. A main application registers callback procedures in memory shared with the physics simulation in response to data generated by the physics simulation. The callback procedures are executed by the physics simulation with data generated by the physics simulation.
7565490,"Circuits, methods, and apparatus that provide an L2 cache that services requests out of order. This L2 cache processes requests that are hits without waiting for data corresponding to requests that are misses to be returned from a graphics memory. A first auxiliary memory, referred to as a side pool, is used for holding subsequent requests for data at a specific address while a previous request for data at that address is serviced by a frame buffer interface and graphics memory. This L2 cache may also use a second auxiliary memory, referred to as a take pool, to store requests or pointers to data that is ready to be retrieved from an L2 cache."
7567104,"Circuits, methods, and apparatus for training a phase shift circuit to provide a phase shift for improved data recovery. A specific embodiment of the present invention provides a variable delay cell. A delay through the variable delay cell is changed while training patterns are received. The presence of errors in the received data pattern is tracked, and from the presence or absence of errors a preferred delay is selected and used for receiving data."
7568056,One embodiment of the present invention provides a universal storage bus adaptor that can interface a host computer's bus to any of multiple types of storage devices. The universal serial bus adaptor provides transport layer functionality in such a way that a separate transport layer does not have to be provided for each type of storage device. Another embodiment of the present invention includes a file management system (or storage stack) that has a read/write chimney configured to enable a READ/WRITE operation to bypass the exception processing and management functionalities of the file management system. Bypassing these functionalities increases the processing efficiency of READ/WRITE operations.
7568086,"A method for compressing a set of instructions in an adaptive computing machine includes identifying frequently executed instructions, inserting an explicit caching instruction associating the identified instructions with an index value in the set of instructions before the identified instructions and replacing at least one instance of the frequently executed instructions subsequent to the explicit caching instruction with a compressed instruction referencing the index value. One or more instructions can be identified for compression, including groups of consecutive or non-consecutive instructions. The explicit caching instruction directs a node in an adaptive computing machine to store instructions in an instruction storage unit in association with an index value. Instructions stored in the storage unit are retrievable with reference to the index value. The compressed instruction may include one or more references to index values, and can include a sequence of index values indicating the sequence of execution of the associated instructions."
7570088,Embodiments for providing a plurality of bias voltages to input/output circuitry are disclosed.
7570266,"Multiple output buffers are supported in a graphics processor. Each output buffer has a unique identifier and may include data represented in a variety of fixed and floating-point formats (8-bit, 16-bit, 32-bit, 64-bit and higher). A fragment program executed by the graphics processor can access (read or write any of the output buffers. Each of the output buffers may be read from and used to process graphics data by a fragment shader within the graphics processor. Likewise, each output buffer may be written to by the graphics processor, storing graphics data such as lighting parameters, indices, color, and depth."
7570273,"Method and apparatus for a graphics pipeline is described. More particularly, a transform engine is configured to rotate, and/or rotate and translate, one or more polygons in response to screen orientation. Thus, when texture, obtained from a pre-rotated image is applied to a rotated polygon used to render such an image, a rotated version of such an image is generated in response to screen orientation. Alternatively, a user may select a rotation to re-orient an image to a screen view position."
7571281,"In one embodiment, an apparatus includes an input port to receive a request to determine whether data units are stored in the cache, as well as an output port to generate look-ups for the pool of tags. The apparatus also includes a look-up filter coupled to the input and output ports, and operates to filter out superfluous look-ups for the data units, thereby forming filtered look-ups. Advantageously, the look-up filter can filter out superfluous look-ups to at least reduce the quantity of look-up operations associated with the request, thereby reducing stalling associated with multiple look-up operations. In a specific embodiment, the look-up filter can include a data unit grouping detector and a look-up suppressor."
7571296,"Circuits, methods, and apparatus that adaptively control 1T and 2T timing for a memory controller interface. An embodiment of the present invention provides a first memory interface as well as an additional memory interface, each having a number of address and control lines. The address and control lines of the redundant memory interface may be individually enabled and disabled. If a line in the additional interface is enabled, it and its corresponding line in the first interface drive a reduced load and may operate at the higher 1T data rate. If a line in the additional interface is disabled, then its corresponding line in the first interface drives a higher load and may operate at the slower 2T data rate. In either case, the operating speed of the interface may also be considered in determining whether each line operates with 1T or 2T timing."
7571373,"Method and apparatus for sending data from a disk drive as that data is being read. Error correction and checking is performed after the data is sent, followed by a calculation and transmission of communication cyclic redundancy check information. If error correction and checking identifies a problem, corrected replacement data is determined and sent. Data off-sets can be sent to inform the host system where the corrected data is to be applied."
7573485,A graphics system has a mode of operation in which real samples and virtual samples are generated for anti-aliasing pixels. Each virtual sample identifies a set of real samples associated with a common primitive that covers a virtual sample location within a pixel. The virtual samples provide additional coverage information that may be used to adjust the weights of real samples.
7573490,"Method and apparatus for a graphics pipeline is described. More particularly, a transform engine is configured to rotate, and/or rotate and translate, one or more polygons in response to screen orientation. Thus, when texture, obtained from a pre-rotated image is applied to a rotated polygon used to render such an image, a rotated version of such an image is generated in response to screen orientation. Alternatively, a user may select a rotation to re-orient an image to a screen view position."
7573528,"A method and apparatus are provided for displaying progressive material on an interlaced display where the number of lines of the source frame is equal to or less than the number of lines in a display field, where such lines in the display field are derived from all of the lines of the source frame."
7574274,"Embodiments of the present invention provide an audio system having wholly independent audio processing modules. The audio system includes a plurality of audio processing modules, a clock manager, a sample rate converter and a buffer. The audio processing modules are communicatively coupled to the clock manager and the buffer. The sample rate converter is communicatively coupled to the clock manager and the buffer. The buffer provides for storing audio data generated and consumed by the audio processing modules. The clock manager provides for determining the clock source of each audio processing module. The clock manager also provides for configuring the audio processing modules and the sample rate converter as a function the clock source of each audio processing module. The sample rate converter provides for synchronizing a flow rate of audio data generated by a first audio processing module and a flow rate of audio data consumed by a second audio processing module, when the clock source of the first and second audio processing modules are different."
7574647,"Embodiments for binary encoding and/or decoding data are disclosed. In one or more embodiments, N data bits may be encoded using one of a plurality of codes derived from at least N+1 bits wherein said one of the plurality of codes is selected to most closely maintain a programmable non-equal ratio of bits at a first logical level to bits at a second logical level."
7574711,"A system, method and computer program product provide functionality via a non-natively coded application on a client device. Initially, user input is received on a device. A pattern is replayed on the device. Navigation of the pattern is managed. Data is retrieved based on the user input utilizing at least one connector, as specified in the pattern. Finally, the retrieved data is output. A system, method and computer program product are also provided for creating an application for a client device. The functionality of the desired application on a device is provided by selecting functional computer code that processes data. The functional computer code does not include coding to the native API's of the device. One or more connectors are selected and programmed to interface with programs on the device for retrieving data for processing. One or more output nodes are generated for outputting the processed data from the device. The functional computer code, connectors, and output nodes are stored in a device-resident pattern for installation on the device. The retrieved data is processed by the functional computer code upon replaying of the pattern for providing the functionality."
7576745,A system and method for providing a dedicated interface between two or more graphics adapters installed on a motherboard. Surplus signals within an interface conforming to an interface specification are used to create the dedicated interface. The dedicated interface may connect the two or more graphics adapters using connectors via an interface device. Alternatively the dedicated interface may directly connect the two or more graphics adapters using dedicated connectors or a portion of the connectors coupled through conductive traces integrated onto the motherboard.
7576751,"A pixel center position that is not covered by a primitive covering a portion of the pixel is displaced to lie within a fragment formed by the intersection of the primitive and the pixel. X,y coordinates of a pixel center are adjusted to displace the pixel center position to lie within the fragment, affecting actual texture map coordinates or barycentric weights. Alternatively, a centroid sub-pixel sample position is determined based on coverage data for the pixel and a multisample mode. The centroid sub-pixel sample position is used to compute pixel or sub-pixel parameters for the fragment."
7577199,"A digital video recorder is described. In one embodiment, the digital video recorder includes an event detector configured to define a target region included in a set of video frames. The event detector is configured to detect movement of an object represented in the target region based on a motion vector associated with the object. The digital video recorder also includes an event recorder coupled to the event detector. The event recorder is configured to coordinate storage of at least a portion of the set of video frames in response to the detected movement. The digital video recorder further includes an event notifier coupled to the event detector. The event notifier is configured to generate an event notification in response to the detected movement."
7577762,A system and method schedules command streams for processing by a variety of consumers. A single command stream is parsed and commands included in the command stream are output to one of the variety of consumers at a time. A pre-emptive scheduling mechanism is used so that a first consumer may yield to a second consumer when the first consumer has received a sufficient amount of commands. The pre-emptive scheduling enables several of the consumers to process commands concurrently. The pre-emptive scheduling mechanism may be implemented by a device driver inserting yield commands into the command stream or by a unit parsing the command stream.
7577799,"The present invention provides a system and method for implementation and use of a shared memory. The shared memory may be accessed both independently and asynchronously by one or more processes at corresponding nodes, allowing data to be streamed to multiple processes and nodes without regard to synchronization of the plurality of processes. The various nodes may be adaptive computing nodes, kernel or controller nodes, or one or more host processor nodes. The present invention maintains memory integrity, not allowing memory overruns, underruns, or deadlocks. The present invention also provides for “push back” after a memory read, for applications in which it is desirable to “unread” some elements previously read from the memory."
7580046,"A transform engine is configured to rotate, and/or rotate and translate, one or more polygons in response to screen orientation. Thus, when texture, obtained from a pre-rotated image is applied to a rotated polygon used to render such an image, a rotated version of such an image is generated in response to screen orientation. Alternatively, a user may select a rotation to re-orient an image to a screen view position."
7580821,"A method is disclosed for executing a physics simulation in a system comprising a computational platform, a main application stored in the computational platform, a secondary application stored in the computational platform, and a smoothed particle hydrodynamics (SPH) application programming interface (API) implemented in the computational platform. The method defines a SPH call in the SPH API, and by operation of the main application, invokes a software routine using the SPH call. Additionally, by operation of the secondary application, a state of the physics simulation is updated in response to the software routine."
7581182,"Media center icons are used to navigate a media center. The media center icons may include media device icons, a remote control icon, and media player icons. The media center icons may be used during a setup process, to select between media devices, and to navigate between media devices and media content."
7583126,An apparatus and method are provided for preventing a current leakage or direct current when a low voltage domain is powered down. Included is a voltage transition circuit connected between a low voltage domain and a high voltage domain. Such voltage transition circuit includes a circuit component for preventing a current leakage when the low voltage domain is powered down.
7583277,"A transform engine is configured to rotate, and/or rotate and translate, one or more polygons in response to screen orientation. Thus, when texture, obtained from a pre-rotated image is applied to a rotated polygon used to render such an image, a rotated version of such an image is generated in response to screen orientation. Alternatively, a user may select a rotation to re-orient an image to a screen view position."
7584321,"Circuits, methods, and apparatus for multiplexing addresses and data at a memory interface such that multiple data widths are provided without the need to change a motherboard or other printed circuit board design. A specific embodiment of the present invention achieves this using a single integrated circuit design where the datapath width is selected using a bonding option, fuse, data input, or other selection mechanism. The specific embodiment supports both 64 and 128-bit datapaths, though other numbers of datapaths, and other datapath widths are supported by other embodiments."
7584342,"Parallel data processing systems and methods use cooperative thread arrays (CTAs), i.e., groups of multiple threads that concurrently execute the same program on an input data set to produce an output data set. Each thread in a CTA has a unique identifier (thread ID) that can be assigned at thread launch time and that controls various aspects of the thread's processing behavior, such as the portion of the input data set to be processed by each thread, the portion of the output data set to be produced by each thread, and/or sharing of intermediate results among threads. Where groups of threads are executed in SIMD parallelism, thread IDs for threads in the same SIMD group are generated and assigned in parallel, allowing different SIMD groups to be launched in rapid succession."
7584475,"A software program includes at least two performance levels. Each performance level has an associated processor utilization. Each performance level corresponds to optimization criteria, such as a quality of data processing performed by the software program. The performance level is selected to maintain processor utilization by the software program within constraints, such as a desired range of processor utilization and a minimum idle thread allocation."
7586489,"Disclosed is a method of generating a three-dimensional (3D) surface defined by a boundary of a 3D point cloud. The method comprises generating density and depth maps from the 3D point cloud, constructing a 2D mesh from the depth and density maps, transforming the 2D mesh into a 3D mesh, and rendering 3D polygons defined by the 3D mesh."
7586492,"In a graphics processor, a rendering object and a post-processing object share access to a host processor with a programmable execution core. The rendering object generates fragment data for an image from geometry data. The post-processing object operates to generate a frame of pixel data from the fragment data and to store the pixel data in a frame buffer. In parallel with operations of the host processor, a scanout engine reads pixel data for a previously generated frame and supplies the pixel data to a display device. The scanout engine periodically triggers the host processor to operate the post-processing object to generate the next frame. Timing between the scanout engine and the post-processing object can be controlled such that the next frame to be displayed is ready in a frame buffer when the scanout engine finishes reading a current frame."
7586493,"A system, method, and computer program product are provided for offloading application tasks in a multi-processor environment. In use, an application is executed utilizing a first processor. Such application performs a plurality of tasks. A driver is provided for determining at least a subset of the tasks. To this end, the subset of tasks may be executed utilizing a second processor."
7586496,Shortening a footprint is a technique to reduce the number of texture samples anisotropically filtered to determine a texture value associated with a graphics fragment. Reducing the number of texture samples anisotropically filtered reduces the number of texture samples read and simplifies the filter computation. Programmable knobs are used to shorten the footprint of a pixel in texture space thereby reducing the number of texture samples used during anisotropic filtering. These knobs permit a user to determine a balance between improved texture map performance and anisotropic texture filtering quality.
7587032,"An apparatus, method and computer program product are provided for deferring the answering of a phone call. Initially, a phone call is received from a caller. As a function of an input from a receiver of the phone call, the phone call is placed on hold and a message is played back to the caller. After the phone call is placed on hold, communication is allowed between the caller and the receiver."
7587053,"Embodiments of the present invention provide an audio-based position tracking system. The position tracking systems comprises one or more speakers, an array of microphones and a computing device. The speaker is located at a fixed position and transmits an audio signal. The microphone array is mounted upon a moving object and receives the audio signal. The computing device determines a position of the moving object as a function of the delay of the audio signal received by each microphone in the array."
7587470,"An Internet client communicates with an Internet server such as an HTTP server or SMTP server through a TCP streaming socket on the Internet device with the Internet client. The TCP streaming sockets can be established through an Internet ready command line interface. The Internet ready command line interface includes “IR” commands that can establish, resume, release and terminate TCP sockets."
7589741,"Circuits, methods, and apparatus provide for the storage of texture descriptors in a graphics memory. Since the texture descriptors are stored in a graphics memory, they do not need to be stored in the graphics processor itself, thus reducing graphics processor circuitry and cost. This allows more textures to be associated with each graphics primitive, thereby improving image realism."
7590815,"A method for managing host system power consumption is provided. The host system includes host memory and external memory. The method initiates with providing a processor in communication with a memory chip over a bus. The memory chip is external memory. Then, a usage measurement of the external memory is determined. If the usage measurement is below a threshold value, the method includes copying data from the memory chip to the host memory and terminating power to the memory chip. In one embodiment, the power is terminated to at least one bank of memory in the memory chip. In another embodiment, an amount of reduction of the external memory can be determined rather than a usage measurement. In yet another embodiment, an address map is reconfigured in order to maintain a contiguous configuration. A graphical user interface and a memory chip are provided also."
7593018,"A system and method for providing explicit weights for texture filtering permits filter weights to vary for each pixel within a primitive. A different filter kernel may be used for each pixel. The weights may be computed or read from a texture map. Because the weights are explicit, the fractional portions of the texture map coordinates that are typically used to determine a bilinearly filtered texel are not used."
7593021,"An apparatus and method for converting color data from one color space to another color space. A driver determines that a set of shader program instructions perform a color conversion function and the set of shader program instructions are replaced with either a single shader program instruction or a flag is set within an existing shader program instruction to specify that output color data is represented in a nonlinear color format. The output color data is converted to the nonlinear color format prior to being stored in a frame buffer. Nonlinear color data read from the frame buffer is converted to a linear color format prior to shading, blending, or raster operations."
7593025,"A transform engine is configured to rotate, and/or rotate and translate, one or more polygons in response to screen orientation. Thus, when texture, obtained from a pre-rotated image is applied to a rotated polygon used to render such an image, a rotated version of such an image is generated in response to screen orientation. Alternatively, a user may select a rotation to re-orient an image to a screen view position."
7593543,"Video watermarks are added to video content to trace distribution. The video watermarks are in the form of watermarking pixels. Watermarking modules in individual computers add additional sets of watermarks to whatever initial set of watermarks are present in video content. As a result, the accumulated watermarks in distributed video content provide information on the distribution of video content."
7593971,"A configurable lookup table having a fixed number of entries is used to manage multiple versions of state information. Based on information provided by a program executing on the processor, a number of items of state information to be included in each state version is determined. Based on that determination, a maximum number of state versions to be concurrently maintained in the lookup table is determined. A management scheme to be used to store and update state information in the lookup table is selected; a different scheme can be selected at any time if the number of items per state version changes."
7594095,"In a multithreaded processing core, groups of threads are launched in parallel for single-instruction, multiple-data (SIMD) execution by a set of parallel processing engines. Thread-specific input data for threads in a new SIMD group can be loaded directly into the local register files used by the parallel processing engines, or the data can be accumulated in a buffer until a launch condition is satisfied. When the launch condition is satisfied, the entire group is launched. Various launch conditions can be defined, including but not limited to full population of the SIMD group, a change in data processing conditions, or a timeout."
7594229,"A system including a method employed by a dedicated processor for allocating resources to other processors with a multi-processor computing environment. The dedicated processor is dedicated only to providing resource allocation to the other processors. Specifically, a script file is provided to the dedicated processor, the script containing information related to the resources required by the other processors. The script file is parsed by the dedicated processor to determine the resources required by the second processor. Thereafter, the dedicated processor dynamically allocates the resources and synchronizes resource allocation at the time needed by the other processors."
7595806,"A method for implementing LOD (level of detail) filtering in a cube mapping application. The method includes accessing a first sample and a second sample for a cube map. A cube map path is computed between the first sample and the second sample. A distance is computed between the first sample and the second sample, wherein the distance is measured using the cube map path. LOD filtering is then implemented by using the distance between the first sample and the second sample."
7596647,"An arbiter decides to grant access from multiple clients to a shared resource (e.g. memory) using efficiency and/or urgency terms. Urgency for a client may be determined based on an “in-band” request identifier transmitted from the client to the resource along with the request, and an “out-of-band” request identifier that is buffered by the client. A difference between the out-of-band request identifier and the in-band request identifier indicates the location of the request in the client buffer. A small difference indicates that the request is near the end of the buffer (high urgency), and a large difference indicates that the request is far back in the buffer (low urgency). Efficiency terms include metrics on resource overhead, such as time needed to switch between reading/writing data from/to memory via a shared memory bus, or bank management overhead such as time for switching between DRAM banks."
7598948,"A system for adjusting display data orientation. The system includes graphics circuitry to send and receive control signals over a set of control lines. The exchange of control signals is governed by a communication protocol. The graphics circuitry is configured to request orientation information via the set of control lines upon detecting a modulation of the set of control lines that is undefined by or illegal under the communication protocol. Based on the orientation information received in response to the request, the graphics circuitry adjusts the orientation of display data transmitted by the graphics circuitry."
7598958,"A multi-chip graphics system includes a master chip and a slave chip coupled by an interlink. The slave chip performs a graphics processing operation in parallel with the master chip, improving the performance of the master chip. In one embodiment, an individual graphics processing unit (GPU) chip includes a normal operational mode, a master mode, and a slave mode to permit an individual GPU chip to be used as individual processor or to be packaged as part of a master/slave pair."
7598967,"A transform engine is configured to rotate, and/or rotate and translate, one or more polygons in response to screen orientation. Thus, when texture data obtained from a pre-rotated image is applied to a rotated polygon from an image, a rotated version of the image is generated in response to screen orientation. Alternatively, a user may select a rotation to re-orient the image to a screen view position. Batch processing of data changes is utilized to render a plurality of changes together."
7599975,"Systems and methods compress and decompress 16 bit data. The 16 bit data may be signed or unsigned and represented in a fixed point or floating point format. A fixed block size of data is compressed into a fixed length format. Data compressed using a medium quality compression scheme may be efficiently decompressed in hardware. Data may be efficiently compressed and decompressed in hardware using a high quality compression scheme. The high quality compression scheme has a lower compression ratio compared with the medium quality compression scheme, but is near lossless in terms of quality."
7600058,"A bypass method for disk I/O (input output) in a computer system. The method includes transferring a command to a disk controller, wherein the command causes a start up of a disk drive coupled to the disk controller. Disk transaction information is then prepared by packaging a plurality of data structures comprising the disk transaction. The disk transaction information is transferred to the disk controller. The disk controller processes the disk transaction information to control the disk drive and implement a disk I/O."
7600155,A system has a graphics processing unit with a processor to monitor selected criteria and circuitry to initiate the storage of execution state information when the selected criteria reaches a specified state. A memory stores execution state information. A central processing unit executes a debugging program to analyze the execution state information.
7602395,"Multiple graphics devices are operable in parallel to render stereo images using efficient programming techniques. The same command stream is delivered to each graphics device, and device masks are used to control the execution of commands by different graphics devices. A viewing transform command corresponding to a left-eye transform is executed by one device while a viewing transform command corresponding to a right-eye transform is executed another device. Other rendering commands are executed by both devices to render the same image from somewhat different viewpoints."
7603246,"Embodiments for positioning transitions in one or more data signals in relation to a data strobe signal are disclosed. For an example embodiment, a receiving device may return a test value to a transmitting device. Timing for one or more data signals may be adjusted in relation to a clock signal according, at least in part, to the test value returned from a receiving device."
7603503,"An arbiter decides to grant access from multiple clients to a shared resource (e.g. memory) using efficiency and/or urgency terms. Urgency for a client may be determined based on an “in-band” request identifier transmitted from the client to the resource along with the request, and an “out-of-band” request identifier that is buffered by the client. A difference between the out-of-band request identifier and the in-band request identifier indicates the location of the request in the client buffer. A small difference indicates that the request is near the end of the buffer (high urgency), and a large difference indicates that the request is far back in the buffer (low urgency). Efficiency terms include metrics on resource overhead, such as time needed to switch between reading/writing data from/to memory via a shared memory bus, or bank management overhead such as time for switching between DRAM banks."
7603574,A system is coupled to a network by a network interface. In a power savings mode the speed setting of the network interface is reduced to accommodate increased system latency.
7605725,"Systems and methods for optimizing system performance in variable length decoding systems are described. Embodiments are described in which decode tables are analyzed and elements of the tables sorted by probability of occurrence. Storage of elements can be determined by probability of occurrence and embodiments of the present invention can optimize system efficiency by storing most likely entries into fast-memory and least likely entries in slowest memory. In certain embodiments, a single large table is provided that cannot fit into decoder fast-memory. In some embodiments, individual elements can be optimized for storage in fast-memory by selecting more frequently occurring entries or groups of entries into decoder memory."
7605820,"Discontinuities along texture mapped seams of three-dimensional models may be reduced by creating and sampling texture data outside of chart boundaries. When a texel center is not within a chart boundary (a group of connected triangles in texture space) a phantom face is generated that includes the texel center. Phantom texture coordinates are created for each texel center that is covered by the phantom face. The phantom texture coordinates are used to read a texture sample from another chart in texture space that is adjacent to the chart boundary in model space, producing a smooth transition across the seam."
7605822,"A method and system for performing texture mapping across adjacent texture maps. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of determining whether a texel crosses a boundary of a first texture map, examining a first texture state identifier associated with the first texture map, and requesting for a second texture state identifier associated with a second texture map that is adjacent to the first texture map to enable traversal to the second texture map to access the texel if the first texture state identifier includes a mode indicative of wrapping to an adjacent texture map and texture adjacency information that points to a second texture map."
7606175,A system and methods for wireless computing devices to become mesh member nodes within a self-configuring mesh network includes mechanisms for neighbor discovery and sharing of a common topology database including mesh topology and mesh network information. Each mesh node may use the topology database to determine optimized routing paths within the mesh network. Mesh member nodes are configured to detect and communicate topology changes and measured mesh network attributes to other members of the self-configuring wireless network.
7606546,"A system, method and system are disclosed for using a variable frequency clock generator to synchronize an average data rate over intervals of time in a variable clock domain to make it equal to a fixed data rate in a fixed clock domain while reducing electromagnetic interference, among other things. In various embodiments, setting the data rates equal to each other minimizes storage used to transition data signals between clock domains. In one embodiment, a variable frequency clock generator includes a phase modulator configured to form a variable frequency clock. Also, the variable clock generator is configured to maintain an average frequency over specific periods of time for the range of discrete frequencies. The phase-offset controller sets an average clock having substantially no offset between a fixed data rate in the fixed clock domain and an average data rate in the variable clock domain."
7609272,"Circuits, methods, and apparatus that provide for partial texture load instructions. Instead of one instruction that may take several shader passes to complete, several instructions are issued, where each instruction is an instruction to retrieve a part or portion of a texture. While each instruction is performed, the other shader circuits can perform other instructions, thus increasing the utilization of the shader circuits when large textures are read from memory. Since several shader passes may be required to read a texture, if a particular instruction needs the texture, one exemplary embodiment reorders instructions such that other instructions are performed before the particular instruction that needs the texture."
7609273,"A pixel load instruction for a programmable graphics processor. The pixel load instruction may be used during processing of graphics data to load graphics data from a writable output buffer into a local storage element. Using the pixel load instruction may ensure that the graphics data loaded is current, i.e., any pending writes to the location storing the graphics data are completed prior to loading the graphics data. Furthermore, the pixel load instruction may be enabled and disabled for one or more writable output buffers by setting or clearing bits in a pixel load enable register."
7609281,"A transform engine is configured to rotate, and/or rotate and translate, one or more polygons in response to screen orientation. Thus, when texture data obtained from a pre-rotated image is applied to a rotated polygon from an image, a rotated version of the image is generated in response to screen orientation. Alternatively, a user may select a rotation to re-orient the image to a screen view position. The rotated image may also be shifted to maintain conformance with edge rules."
7609696,A method and apparatus for storing and accessing connection information is described. A delegated connection table stores an entry for each connection delegated by a TCP stack for processing by an offload unit. A portion of the delegated connection table storing receive buffer information is accessed by the TCP stack without disrupting receive or transmit traffic. The offload unit offloads some TCP processing from a host processor and processes data received on connections not stored in the delegated connection table while accepting incoming data.
7610483,"One embodiment of the present invention sets forth a technique for concisely identifying the hardware configuration of a computer system through a single signature value. This signature value is computed by passing specific hardware configuration information through a hashing function. The hardware configuration information may include, among other things, selected elements of the SMBIOS system description as well as PCI topology and PCI bus type information."
7613064,Embodiments of power management modes for memory devices are disclosed.
7613109,"A method and apparatus for processing data received and transmitted on a TCP connection is described. An offload unit processes received data for which a special case does not exist, to produce payload data, which is uploaded directly to application memory. The offload unit partially processes received data for which a special case does exist and uploads the partially processed received data to a buffer stored in system memory. The partially processed received data is then further processed by a TCP stack to produce payload data, which is copied to application memory."
7616202,"Methods and systems for processing fragment groups are described. Fragment groups that include z-only pixels are accessed. A z-only pixel has associated therewith two or more z-values instead of a single z-value. Fragment groups that are not covered by a geometric primitive are discarded, while fragment groups that are covered by a geometric primitive are forwarded to a shader pipeline."
7616204,"Disclosed is a method of simulating a dynamic object comprising a plurality of vertices. The method comprises defining a current position and a current velocity for a vertex “v” among the plurality of vertices, generating an estimated next position for vertex “v” based on the current position and current velocity, updating the estimated next position based on a plurality of constraints, and after updating the estimated next position, computing a next position and a next velocity for vertex “v” based on the current position and estimated next position."
7616206,"One embodiment of the invention sets forth a technique for efficiently combining two graphics processing units (“GPUs”) to enable an improved price-performance tradeoff and better scalability relative to prior art multi-GPU designs. Each GPU's memory interface is split into a first part coupling the GPU to its respective frame buffer and a second part coupling the GPU directly to the other GPU, creating an inter-GPU private bus. The private bus enables higher bandwidth communications between the GPUs compared to conventional communications through a PCI Express™ bus. Performance and scalability are further improved through render target interleaving; render-to-texture data duplication; data compression; using variable-length packets in GPU-to-GPU transmissions; using the non-data pins of the frame buffer interfaces to transmit data signals; duplicating vertex data, geometry data and push buffer commands across both GPUs; and performing all geometry processing on each GPU."
7616207,"Multichip graphics processing subsystems include at least three distinct graphics devices (e.g., expansion cards) coupled to a high-speed bus (e.g., a PCI Express bus) and operable in a distributed rendering mode. One of the graphics devices provides pixel data to a display device, and at least one of the other graphics devices transfers the pixel data it generates to another of the devices via the bus to be displayed. Where the high-speed bus provides data transfer lanes, allocation of lanes among the graphics devices can be optimized."
7616209,"Prescient cache management methods and systems are disclosed. In one embodiment, within a pre-raster engine operations stage in a graphics rendering pipeline, tile entries are stored in a buffer. Each of these tile entries is related a transaction request that enters the pre-raster engine operations stage and has a screen coordinates field and a conflict field. If this buffer includes a first tile entry, which is related to a first transaction request associated with a first tile, and a second tile entry, which is related to a second transaction request that enters the pre-raster engine operations stage after the first transaction request and is also associated with the first tile, the conflict field of the first tile entry is updated with a conflict type that reflects a number of tile entries between the first tile entry and the second tile entry."
7616218,"Apparatus, system, and method for clipping graphics primitives are described. In one embodiment, a clipping module includes a clipping engine and a clipping controller connected to the clipping engine. The clipping controller is configured to determine which edges of an input graphics primitive intersect a first clipping plane. The clipping controller is configured to direct the clipping engine to clip, with respect to the first clipping plane, a first pair of edges of the input graphics primitive in response to determining that the first pair of edges intersect the first clipping plane."
7616445,"One embodiment of the present invention sets forth an electronic assembly, which comprises a printed circuit board having at least one opening, an electronic component mounted on a first side of the printed circuit board, and a thermal dissipation structure including at least one heat sink having a first surface and a second surface. The first surface includes a first region coupled with a surface of the electronic component, and one or more second region provided with at least a heat dissipating member that is exposed through the opening on a second side of the printed circuit board."
7617100,"An improved audio compression scheme is provided. The scheme uses an excitation pattern to more efficiently provide audio signal compression. Under the scheme, an input signal is transformed to the frequency domain. Next, the excitation pattern corresponding to the transformed input signal is calculated. Bit allocation processing is then performed based on the excitation pattern. Frequencies are then coded based on the results of the bit allocation processing. Finally, bitstream packing is performed to generate the output coded audio bit stream. In one exemplary implementation, the audio compression scheme is implemented in an encoder."
7617267,"One embodiment of a configurable multi-tap filter includes a parallel-to-serial formatter configured to transform a pixel stream into a first component pixel stream and a second component pixel stream, a configurable memory that includes a first channel and a second channel, wherein pixels from the first component pixel stream are stored in the first channel and pixels from the second component pixel stream are stored in the second channel, and a multi-tap filter configured to process a component of a pixel from the first channel and a like component of a pixel from the second channel. In various embodiments, the configurable multi-tap filter may be implemented as a two-tap, three-tap or five-tap filter and may be used to process either RGB or YUV pixels streams. One advantage of the disclosed configurable multi-tap filter is that it uses memory more efficiently than prior art filters."
7617348,A bus interface controller manages a set of serial data lanes. The bus interface controller supports operating a subset of the serial data lanes as a private bus.
7617368,"A memory interface coupling a plurality of clients to a memory having memory banks provides independent arbitration of activate decisions and read/write decisions. In one implementation, precharge decisions are also independently arbitrated."
7617384,One embodiment of a computing system configured to manage divergent threads in a SIMD thread group includes a stack configured to store state information for processing control instructions. A parallel processing unit is configured to perform the steps of determining if one or more threads diverge during execution of a conditional control instruction. Threads that exit a program are identified as idle by a disable mask. Other threads that are disabled may be enabled once the divergent threads reach an instruction that enables the disabled threads. Use of the disable mask allows for the use of conditional return and break instructions in a multithreaded SIMD architecture.
7617396,"A system and apparatus for inserting a watermark into a compiled computer program selectively replaces specified optimizations by non-optimized code to encode bit values of the watermark. The watermark is read by decoding the executable code and assigning the decoded bit values, determined by the presence or absence of optimized code, to bit positions in a signature."
7619401,"A bandgap reference circuit having a low sensitivity to temperature and supplied voltage installs a compensation circuit on a bandgap reference circuit to substitute a prior art that uses a resistor to match the circuit startup purpose and solve the problem of startup error caused by the manufacturing error. The bandgap reference circuit includes a first amplifier, a second amplifier, and a reference circuit having a plurality of transistors and a plurality of bipolar junction transistors, and the bandgap reference circuit is electrically connected to a same supplied power of which the reference circuit is electrically connected and also includes a plurality of transistors and a compensation circuit of the second amplifier, so as to output a stable startup voltage which has a low sensitivity to the change of temperature and the change of supplied voltage."
7619444,"Techniques and circuits for ensuring one or more circuit components are not subjected to voltage levels above their rated voltage tolerance due to core logic and I/O logic supply voltages reaching final voltage levels at different times are provided. According to some embodiments, an internal voltage supply sense circuit may monitor a level of a voltage supply that powers core logic that generates control signals used to program a voltage regulator. In response to determining the core logic voltage supply is below a predetermined level, the sense circuit may generate one or more regulated voltage signals to override regulated voltage signals generated by the voltage regulator."
7619625,"A culling data selection system and method are presented in accordance with embodiments of the present invention. In one embodiment, an occlusion prediction graphics processing method is utilized to predict which pixels are eventually occluded before intermediate processing stages are performed on the pixels. Culling information utilized to predict which pixel are occluded is selected and compressed in accordance with embodiments of the present invention. In one embodiment, cull data for a pixel culling area is retrieved and an end of pipe depth occlusion data associated with a prediction area within the pixel culling area is received. A selection metric for analyzing adjustments to cull data is established and a cull data adjustment decision is made based upon the selection metric. In one exemplary implementation the possible occlusion volumes associated with “old” culling data, “new” culling data (e.g., based upon an occlusion value received from a stage later in a graphics processing pipeline) and “merged” culling data are determined. The culling data associated with the greatest volume is selected for culling operations."
7619629,"A methods and system for utilizing memory interface bandwidth to connect multiple graphics processing units are disclosed. According to one embodiment of the present invention, a first graphics processing unit is configured to allocate a portion of an initial memory interface supported by both the first graphics processing unit and a first video memory for a private connection. This private connection enables this first graphics processing unit to directly communicate with a second graphics processing unit and also access resources of the second graphics processing unit."
7619631,"A technique for performing an anti-aliasing operation by multiple graphics processing units includes utilizing a first graphics processing unit to generate a first subset of filtered data resulting from performing anti-aliasing processing and similarly utilize a second graphics processing unit to generate a second subset of filtered data. The first graphics processing unit then pulls a first portion of the second subset of filtered data from a first memory block of a temporary buffer and blends such pulled data with a first portion of the first subset of filtered data. Overlapping in time with the pulling and blending operation of the first graphics processing unit, the second graphics processing unit pulls a second portion of the first subset of filtered data from a second memory block of the temporary buffer and blends such pulled data with a second portion of the second set of filtered data."
7619635,"Systems and methods for positioning bilinear texture samples to produce an anisotropically filtered texture mapped pixel may improve texture mapping performance and image quality. The bilinear texture samples are positioned along a major axis of anisotropy to approximate an elliptical footprint, ensuring that the bilinear texture samples span the entire axis of anisotropy without extending beyond the major axis of anisotropy. An additional bilinear texture sample or a pair of additional bilinear texture samples is positioned in the center of the axis of anisotropy dependent on the anisotropic ratio. The additional bilinear texture samples are weighed less than the other bilinear texture samples and all of the bilinear textures samples lie within the anisotropic footprint."
7619639,"The invention pertains to an adaptive scaling technique. A look-up table of optimized filter coefficients is used to configure a multi-tap filter when scaling a video image. The look-up table reflects the scaling between standardized video source (input) resolutions and video display (output) resolutions. When an actual scaling factor does not correspond to an optimized operating point, a device driver determines which two scaling factors reflected in the look-up table are closest to the actual scaling factor. A set of interpolated filter coefficients for the multi-tap filter is then generated from the optimized filter coefficients associated with the two closest scaling factors. One advantage of the disclosed technique is that scaling operations are performed using filter coefficients interpolated from filter coefficients optimized for two similar scaling operations. Thus, the technique provides more precise filtering relative to prior art designs, resulting in higher-quality scaled video images."
7619687,"Video filtering using a programmable graphics processor is described. The programmable graphics processor may be programmed to complete a plurality of video filtering operations in a single pass through a fragment-processing pipeline within the programmable graphics processor. Video filtering functions such as deinterlacing, chroma up-sampling, scaling, and deblocking may be performed by the fragment-processing pipeline. The fragment-processing pipeline may be programmed to perform motion adaptive deinterlacing, wherein a spatially variant filter determines, on a pixel basis, whether a “bob”, a “blend”, or a “weave” operation should be used to process an interlaced image."
7619889,A system and method are provided for controlling a transfer of heat between circuit board components. Included is a circuit board with components mounted thereon. Also provided is a controllable heat transfer medium for controlling a transfer of heat between the components.
7620070,"Method and apparatus for packet processing by re-insertion into network interface circuitry. A method for handling a burst of packets sent to network interface circuitry includes checking for a connection table entry for received packets, and responsive to non-existence of the connection table entry for the received packets, sending the packets to network interface software for processing. The network interface software processing includes: building the connection table entry; processing the packets; and sending the packets as processed to the network interface circuitry. Additionally, a method for re-inserting a packet responsive to an active audit mode is described."
7620210,"Anisotropic optimization is a technique to reduce the number of texture samples anisotropically filtered to determine a texture value associated with a graphics fragment. Reducing the number of texture samples anisotropically filtered reduces the number of texture samples read from memory and speeds up the filter computation. A programmable bias is used to control the number of texture samples used during anisotropic filtering, permitting a user to determine a balance between improved texture map performance and anisotropic texture filtering quality."
7620530,"A PPU-enhanced computer system is provided including a Physics Processing Unit (PPU), a Graphics Processing Unit (GPU), a Central Processing Unit (CPU) and a main memory, wherein the system creates an animation from application data stored in the main memory by data communication between the GPU, PPU, CPU and main memory. The system may include a memory controller and a chip set connecting the bus structure to the CPU and GPU through an I/O interface and connecting the PPU though a bus structure. The PPU may be a separate processing core logically grouped with the CPU and GPU processing cores. In this preferred embodiment, the CPU, GPU and PPU receive data from a common L2 cache and/or a main system memory."
7620678,Aspects for reducing the time-to-market concerns for embedded system design are described. The aspects include providing an infrastructure to support a plurality of heterogeneous processing nodes as a reconfigurable network. Further included is utilizing the infrastructure to customize at least one of the heterogeneous processing nodes according to individualized design needs to achieve a desired embedded system signal processing engine.
7620738,"A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though, in one embodiment, it is sharing the same chip."
7620747,Systems and methods for performing native command queuing according to the protocol specified by Serial ATA II for transferring data between a disk and system memory are described. Native command queuing context for queued commands is maintained by a host controller device driver and is provided to the host controller as needed to process the queued commands. The host controller is simplified since it only stores the context of the one command being processed. The host controller generates a backoff interrupt when a command cannot be queued. The host controller generates a DMA transfer context request interrupt to request programming of the registers that store the context for the one command being processed.
7620793,Systems and methods for addressing memory using non-power-of-two virtual memory page sizes improve graphics memory bandwidth by distributing graphics data for efficient access during rendering. Various partition strides may be selected for each virtual memory page to modify the number of sequential addresses mapped to each physical memory partition and change the interleaving granularity. The addressing scheme allows for modification of a bank interleave pattern for each virtual memory page to reduce bank conflicts and improve memory bandwidth utilization. The addressing scheme also allows for modification of a partition interleave pattern for each virtual memory page to distribute accesses amongst multiple partitions and improve memory bandwidth utilization.
7620798,A synchronization mechanism is used to synchronize events across multiple execution pipelines that process transaction streams. A common set of state configuration is included in each transaction stream to control processing of data that is distributed between the different transaction streams. Portions of the state configuration correspond to portions of the data. Execution of the transaction streams is synchronized to ensure that each portion of the data is processed using the state configuration that corresponds to that portion of the data. The synchronization mechanism may be used for multiple synchronizations and when the synchronization signals are pipelined to meet chip-level timing requirements.
7620804,"A central processing unit (CPU) architecture with enhanced branch execution, being substantially a pipelined CPU with multiple pipelines, each pipeline having a plurality of stages, by which all instructions relating directly to a branch instruction of a code executed by the pipelined CPU are being fetched respectively by each corresponding pipeline for enabling the code to be executed without stall so that the number of cycles required to execute the code can be reduced effectively. Moreover, the multiple pipelines can save more cycles when the number of stages in one pipeline is large."
7621769,"One embodiment of an edge connector for a field changeable graphics system includes a right angle edge connector having a plurality of contact pins adapted to engage contacts on a graphics card. The edge connector is adapted to interface the graphics card with the motherboard of a computing device, without directly mounting the graphics card to the motherboard. One advantage of the disclosed edge connector is that it is compatible with a plurality of graphics cards and systems, thereby enabling a computing device user to upgrade the existing device's graphics system. Thus, the user is not forced to purchase an entirely new computing device in order to take advantage of graphics innovations. A further advantage of the disclosed edge connector is that it enables upgrades to low voltage differential signaling (LVDS) features, without the need for additional costly devices capable of operating at LVDS data rates."
7622947,"A method and apparatus for utilizing redundant circuitry on integrated circuits (ICs) that may increase manufacturing yields, while maintaining a predetermined set of interfaces for connection with external circuitry without drastically increasing die area and circuit complexity are provided. In this manner, even though an IC may have defects which would otherwise render it inoperable, embodiments of the present invention allow the defects to be circumscribed or avoided while still maintaining a predetermined set of interfaces, thus providing for an operational circuit. Various embodiments further provide a method for sorting or separating devices based on their level of functionality or performance, which in turn depends on their number of defects and the desired number of interfaces."
7623126,"A display controller in a computer system controls the asynchronous output of graphics display data in a computer system having at least one fixed resolution flat panel display. Fixed panel displays may have problems displaying non-native resolutions particularly at lower resolutions. The controller of the present invention uses a time base converter, horizontal and vertical Discrete Time Oscillators (DTO), and polyphase interpolator, which may be Discrete Cosine Transform (DCT)-based to expand graphics display data asynchronously from native resolution to at least one resolution suitable for display on a fixed resolution panel. Graphics data may also be output asynchronously to a CRT. Time base converter receives frequency related input parameters and generates at least one asynchronous output at the desired output resolution."
7623131,"Multiple graphics processors in a graphics processing system are interconnected in a unidirectional or bidirectional ring topology, allowing pixels to transferred from any one graphics processor to any other graphics processor. The system can automatically identify one or more “master” graphics processors to which a monitor is connected and configures the links of the ring such that one or more other graphics processors can deliver pixels to the master graphics processor, facilitating distributed rendering operations. The system can also automatically detect the connections or lack thereof between the graphics processors."
7623132,"A method and apparatus of operating a shader having multiple texture or shader processing stations. That method includes feeding the output of a texture or shader processing station directly into the input of another texture or shader processing station. Further, only a subset of the processing stations has access to a shader register file."
7623133,"A computer system including a processor, a display, and a graphics unit coupled between the processor and the display, in which the processor is configured to perform multi-display operations which generate multiple frames of display data for simultaneous display, and a graphics unit for use in such a system. Typically, the graphics unit includes graphics memory that includes at least two frame buffers, and the processor operates as if it were independently asserting multiple streams of display data to multiple frame buffers for driving multiple displays independently. Another aspect of the invention is a system that displays data from a frame buffer on a screen. The frame buffer holds data indicative of a virtual desktop that is larger than can be displayed on the screen or available portion thereof, the system can display on the screen any of a number of different subsets of the frame buffer data, each subset indicative of a different portal of the desktop, and the system includes a processor including texture processing circuitry operable to filter a subset of the frame buffer data that is indicative of a portal to be displayed."
7623134,"One embodiment of the present invention sets forth a technique for processing address page requests in a GPU system that is implementing a virtual memory model. A hardware-based page fault manager included in the GPU system intercepts page faults otherwise processed by a software-based page fault manager executing on a host CPU. The hardware-based page fault manager in the GPU includes a DMA engine capable of reading and writing pages between system memory and frame buffer memory without involving the CPU or operating system. A net improvement in system performance is achieved by processing a significant portion of page faults within the GPU, reducing the overall load on the host CPU."
7623135,"Method and apparatus for display image adjustment is described. More particularly, handles associated with polygon vertices of a polygon rendered image are provided as a graphical user interface (GUI). These handles may be selected and moved by a user with a cursor pointing device to adjust a displayed image for keystoning, among other types of distortion. This GUI allows a user to adjust a projected image for position of a projector with respect to imaging surface, as well as for imaging surface contour, where such contour may be at least substantially planar, cylindrical, or spherical and where such contour may comprise multiple imaging surfaces. This advantageously may be done without special optics or special equipment. An original image is used as texture for rendering polygons, where the image is applied to the rendered polygons."
7623136,A texture unit of a graphics processing unit provides the ability to switch among different filter modes depending upon shader program instructions that are received by the texture unit. One filter mode has the capability to extract filter weights that have been specified in a received shader program instruction rather than calculating the weights within the texture unit itself.
7624107,"One embodiment of the present invention sets forth a technique for efficiently performing a radix sort operation on a graphics processing unit (GPU). The radix sort operation is conducted on an input list of data using one or more passes of a series of three processing phases. In each processing phase, thread groups are each associated with one segment of input data. In the first phase, occurrences of each radix symbol are counted and stored in a list of counters. In the second phase, the list of counters is processed by a parallel prefix sum operation to generate a list of offsets. In the third phase, the list of offsets is used to perform re-ordering on the list of data, according to the current radix symbol. To maintain sort stability, the one or more passes proceed from least significant data to most significant data in the sort key."
7624198,"A system and method are provided for communicating data in a network utilizing a transport offload engine. Included is a data list object that describes how data communicated in a network is to be stored (i.e. placed, etc.) in memory (i.e. application memory). Stored in association (i.e. located, kept together, etc.) with the data list object is a sequence object. Such sequence object identifies a sequence space associated with the data to be stored using the data list object. To this end, the sequence object is used by a transport offload engine to determine whether or not incoming data is to be stored using the data list object."
7624204,"A reconfigurable input/output controller (IOC) allows an adaptive computing engine (ACE) to communicate with external devices. The external devices can comprise a separate system on chip (SOC) or can be other devices or resources such as audio/visual output devices, memory, network or other communications, etc. The IOC allows different modes of transfer and performs necessary translation of input and output commands. In one embodiment, the IOC adheres to standard messaging and communication protocol used by other nodes in the ACE. This approach allows a uniform approach to the ACE design and provides advantages in scalability and adaptability of the ACE system. One feature of the invention provides a physical link adapter for accommodating different external communication types such as, RS231, optical, Firewire, universal synchronous bus (USB), etc. The physical link adapter uses a reconfigurable finite state machine, selectable couplings and a bus switch to allow connection of different communication types' signals to a common ACE component such as to an IOC."
7624221,"Optimization logic that optimizes a stream of requests being transmitted onto a link by a link interface unit can be enabled or disabled based on a performance metric that represents a measure of the degree to which a response to a request is likely to be slowed due to congestion, propagation delays, or other bottlenecks in the system. For example, the performance metric can be based on a measured level of link activity due to requests from the transmitting device and/or a prediction as to behavior (e.g., access time) of the target device that receives the stream of requests. The control logic advantageously does not require extra signals to be carried on the bus."
7624224,"A system, method, and computer program product are provided for directly executing code in block-based memory, which resides in communication with a processor and a controller. Utilizing the controller, a request is received from the processor for a subset of a block of data in the block-based memory, and at least a portion of the block is retrieved from the block-based memory. After the retrieval, at least a portion of the block is stored in a cache. The subset of the block is then transmitted to the processor, utilizing the controller. To this end, code in the block-based memory is directly executed."
7624255,A system and method controls the scheduling of program instructions included in a shader program for execution by a processing pipeline. One or more fence instructions may be inserted into the shader program. Each fence instruction specifies a constraint that is applied to control the scheduling of another program instruction in the shader program. Controlling the scheduling of program instructions for execution by the processing pipeline may result in a more efficient use of computing resources and improved performance.
7625239,"One embodiment of the present invention sets forth a cable assembly for separating video signals within a high-density connector to individual video connectors. The cable assembly includes a high-density connector, a cable to transmit multiple video signals, and a printed circuit board (PCB) assembly configured to separate the video signals into individual video signals. The individual video signals are routed under controlled impedance conditions provided by the PCB to individual video connectors attached to the PCB."
7626420,"An apparatus, system, and method are described for synchronously resetting logic circuits. A synchronous reset signal is coupled to at least one asynchronous reset input for synchronously resetting sequential logic. In one embodiment, reset logic generates a signal coupled to the at least one asynchronous reset input of the sequential logic to synchronously reset the sequential logic."
7626587,"A computer system including a processor, a display, and a graphics unit coupled between the processor and the display, in which the processor is configured to perform multi-display operations which generate multiple frames of display data for simultaneous display, and a graphics unit for use in such a system. Typically, the graphics unit includes graphics memory that includes at least two frame buffers, and the processor operates as if it were independently asserting multiple streams of display data to multiple frame buffers for driving multiple displays independently. Another aspect of the invention is a system that displays data from a frame buffer on a screen. The frame buffer holds data indicative of a virtual desktop that is larger than can be displayed on the screen or available portion thereof, the system can display on the screen any of a number of different subsets of the frame buffer data, each subset indicative of a different portal of the desktop, and the system includes a processor including texture processing circuitry operable to filter a subset of the frame buffer data that is indicative of a portal to be displayed."
7626588,"Prescient cache management methods and systems are disclosed. In one embodiment, a local cache that operates within a raster engine operations stage of a graphics rendering pipeline is managed by following a number of caching decisions related to a number of cached tiles. Each of these cached tiles has a certain priority to remain in the local cache, with the priority corresponding to a conflict type received from a buffer operating within a pre-raster engine operations stage of the graphics rendering pipeline."
7626815,"The present invention represents a significant advancement in the field of cooling systems for computer hardware. One embodiment of a system for cooling a heat-generating device includes a housing sized to fit within a drive bay of a computing device, a heat exchanger disposed within the housing and configured to transfer heat from liquid to air, a fan disposed within the housing and configured to force air through the heat exchanger, and a pump disposed within the housing and configured to circulate a liquid through a cold plate sub-assembly and back to the heat exchanger. The cold plate sub-assembly is configured to be thermally coupled to the heat-generating device. The disclosed system may be advantageously disposed in any computing device whose chassis has a standard-sized drive bay, thereby enabling the system to be easily implemented across a wide variety of computing devices."
7626821,Embodiments of this invention relate generally to systems used to cool computer hardware and more particularly to an adaptor for a graphics module. In one embodiment a graphics card assembly is provided. The graphics card assembly includes a printed circuit board (PCB); a graphics processing unit (GPU) attached to the PCB; and an adaptor having first and second surfaces and made from a thermally conductive material. The adaptor is disposed on the PCB so that the first surface is in thermal communication with the GPU and the second surface providing a standard interface for thermal communication with a cooling system.
7626854,"One embodiment of the present invention sets forth a twelve transistor static random access memory storage cell that provides two write ports and three read ports. The write word line operates at twice the clock frequency. The write bit lines are differential to provide high-performance writes. Each read word line operates at the clock frequency. Single-ended read bit lines are used to provide read performance comparable to write performance. The resulting storage cell only requires four horizontal word lines and five vertical bit lines, enabling very dense, yet high-performance designs."
7626871,"One embodiment of the present invention sets forth a high-speed single-ended memory read circuit that overcomes performance limitations of conventional single ended memory read circuits. A bit line keeper control mechanism for the high-speed single-ended memory read circuit is disclosed that automatically configures the bit line keeper for high-speed operation or low-speed operation, based on the frequency of a system clock. In high-speed operation, the bit line keeper is disabled, thereby eliminating short-circuit currents related to the bit line keeper and increasing the read performance of the single-ended memory read circuit. In low-speed operation, the bit line keeper is periodically disabled by a timer circuit to enable efficient read or write operations. Subsequent to the read or write operation, the bit line keeper is enabled to preserve state on the bit lines. By selectively enabling the bit line keeper, high-speed performance is improved while preserving correct function at low speeds."
7626878,"One embodiment of the present invention sets forth an active bit line charge keeper circuit for improving the reliability of a static random access memory (SRAM) circuit. The active bit line charge keeper circuit includes two sub-circuits, each disposed between bit line pairs within the SRAM circuit. The first sub-circuit mitigates residual state associated with over-developed read state on the bit lines. The second sub-circuit mitigates the effects of residual state associated with reading one value on a given pair of bit lines and subsequently writing a different value. By mitigating the effects of residual state within an SRAM circuit, higher reliability at a given performance level may be achieved."
7627723,"Methods, apparatuses, and systems are presented for updating data in memory while executing multiple threads of instructions, involving receiving a single instruction from one of a plurality of concurrently executing threads of instructions, in response to the single instruction received, reading data from a specific memory location, performing an operation involving the data read from the memory location to generate a result, and storing the result to the specific memory location, without requiring separate load and store instructions, and in response to the single instruction received, precluding another one of the plurality of threads of instructions from altering data at the specific memory location while reading of the data from the specific memory location, performing the operation involving the data, and storing the result to the specific memory location."
7627744,"An integrated circuit comprises an external memory, a plurality of parallel connected Vector Processing Engines (VPEs), and an External Memory Unit (EMU) providing a data transfer path between the VPEs and the external memory. Each VPE contains a plurality of data processing units and a message queuing system adapted to transfer messages between the data processing units and other components of the integrated circuit."
7627787,"Method and apparatus for channel monitoring, channel throughput restoration and system testing in relation to channel monitoring and channel throughput restoration is described. A failure status of a channel is identified. The channel and at least one engine associated with the failure status is disabled. A client application assigned such a channel is notified that the channel has been disabled. The at least one engine and the channel associated with the failure status is restored. Additionally, the client application is allowed to destroy and reconstruct command status and state of the channel. Additionally, error information for the failure status is stored. Other aspects include: error injection which may be used for testing ability to detect an error and recover; and a graphical user interface for rendering mode selection for increasing channel throughput."
7629978,"Circuits, methods, and apparatus that provide multiple graphics processor systems where specific graphics processors can be instructed to not perform certain rendering operations while continuing to receive state updates, where the state updates are included in the rendering commands for these rendering operations. One embodiment provides commands instructing a graphics processor to start or stop rendering geometries. These commands can be directed to one or more specific processors by use of a set-subsystem device mask."
7629982,"Circuits, methods, and apparatus that reduce the amount of data transferred between a graphics processor integrated circuit and graphics memory. Various embodiments of the present invention further improve the efficiency of blenders that are included on a graphics processor. One embodiment provides for the storage of a reduced number of subsamples of a pixel when the storage of a larger number of subsamples would be redundant. The number of subsamples that are blended with source data are compressed, thereby reducing the task load on the blenders increasing their efficiency. These methods can be disabled to avoid errors that may arise in certain applications."
7629987,"A transform engine within a graphics pipeline is configured to rotate, or rotate and translate, one or more polygons in response to a screen orientation. The transform engine obtains a texture from a pre-rotated polygon and applies the texture to the rotated polygon. An image that reflects the rotated or rotated and translated polygon is then rendered in response to the screen orientation."
7630369,One embodiment of the present invention sets forth a technique for establishing high user priority for Ethernet frames related to demand-paging operations over iSCSI. The iSCSI initiator is configured to identify demand-page operations using techniques specific to the operating system and to set the 802.1q tag control information (TCI) user priority bit field to reflect high priority for demand-page related Ethernet frames. The demand-page related Ethernet frames are then delivered to the iSCSI target with a higher priority through the intervening Ethernet network than other traffic. Overall performance of demand paging operations is improved relative to prior art systems through an average reduction in network latency.
7630389,"Systems and methods for generating synthesizable code representing first-in first-out (FIFO) memories may be used to produce FIFO memories for multi-threaded processing. A single FIFO memory is shared between the threads to conserve die area, however each thread may be executed independently, as if each thread has a dedicated FIFO memory. A synthesizable code generator produces synthesizable code for a sender interface, storage, receiver interface, and other features that are specified by a programmer. The other features may reduce power consumption or improve timing. The code generator is used to efficiently produce different variations of FIFO memories."
7631122,"One embodiment of the invention sets forth a method for performing a queue allocation operation that includes receiving a memory address associated with a queue allocation aperture, where the memory address is read by a client to request memory space in a memory queue for a payload, computing a payload size based on the memory address, determining an insertion pointer for the payload based on a first position of a horizon pointer, where the insertion pointer indicates a location within the memory queue for the client to insert the payload, adjusting the horizon pointer to a second position based on the payload size, and returning the insertion pointer to the client. Such an approach enables multiple clients to advantageously request and obtain space within a shared memory queue in a single atomic operation, thereby allowing clients to share a memory queue more efficiently relative to prior art approaches."
7631145,"Methods, apparatuses, and systems are presented for caching. A cache memory area may be used for storing data from memory locations in an original memory area. The cache memory area may be used in conjunction with a repeatedly updated record of storage associated with the cache memory area. The repeatedly updated record of storage can thus provide a history of data storage associated with the cache memory area. The cache memory area may be loaded with entries previously stored in the cache memory area, by utilizing the repeatedly updated record of storage. In this manner, the record may be used to “warm up” the cache memory area, loading it with data entries that were previously cached and may be likely to be accessed again if repetition of memory accesses exists in the span of history captured by the repeatedly updated record of storage."
7631152,"A memory flush is processed in accordance with a state machine that keeps track of the flush states of a memory target. A memory target is not flushed if it has not been written to, or if a memory flush has already been completed for that memory target. A memory target is flushed if the memory partition is in a flush needed state or a flush pending state. Each memory target has an associated state machine, but only one state machine is maintained per memory target."
7633277,"One embodiment of the present invention sets forth a system and a method for testing the worst-case transients in the output voltage produced by a switching-mode power supply (SMPS). The system includes an SMPS and a dynamic load generator (DLG). The SMPS converts the input voltage into the output voltage by using a top field-effect transistor (FET) and a bottom FET. The worst case transients occur when the load being provided to the SMPS is turned on or off at the same time the top FET is turned off. The DLG is configured to monitor the edge of the gate voltage of the top FET and to turn the load provided to the SMPS on or off when the edge of the gate voltage of the top FET is falling. Consequently, the disclosed system is able to test the worst-case transients in the output voltage produced by the SMPS in a manner that is more reliable than prior art approaches."
7633461,"The graphics display system comprises a plurality of heads. Each of the heads includes a VGA controller and each of the heads is adapted for a display. The display system also includes a host coupled to the heads, wherein all the standard VGA settings for each of the heads could be programmed by a single command by the host. A method and system in accordance with the invention includes one VGA controller per head. In a broadcast mode a write transaction from the bus is broadcast to both heads. The output timing registers specific to a non-CRT output are not broadcast. To provide broadcast VGA to a CRT and/or a flat panel, software sets up the timing in extended registers and enables the display devices. The VGA application can provide mode settings via the appropriate write VGA registers and the correct display will be on each head."
7633505,"A multi-chip graphics system includes a master chip and a slave chip coupled by an interlink. The slave chip performs pixel processing in parallel with the master chip, improving the performance of the master chip. In one embodiment, an individual graphics processing unit (GPU) chip includes a normal operational mode, a master mode, and a slave mode to permit an individual GPU chip to be used as individual processor or to be utilized as part of a master/slave pair."
7634621,"Circuits, methods, and apparatus that provide the die area and power savings of a single-ported memory with the performance advantages of a multiported memory. One example provides register allocation methods for storing data in a multiple-bank register file. In a thin register allocation method, data for a process is stored in a single bank. In this way, different processes use different banks to avoid conflicts. In a fat register allocation method, processes store data in each bank. In this way, if one process uses a large number of registers, those registers are spread among the banks, avoiding a situation where one bank is filled and other processes are forced to share a reduced number of banks. In a hybrid register allocation method, processes store data in more than one bank, but fewer than all the banks. Each of these methods may be combined in varying ways."
7634637,"In a processor, a SIMD group (a group of threads for which instructions are issued in parallel using single instruction, multiple data instruction issue techniques) is logically divided into two or more “SIMD subsets,” each containing one or more of the threads in the SIMD group. Each SIMD subset is associated with a different instance of a variable state parameter. The processor determines which of the instructions to be executed for the SIMD group rely on the state variable and serializes execution of such instructions so that the instruction is executed separately for each SIMD subset. Instructions that do not rely on the state variable are advantageously not serialized."
7634668,"A method for adapting power consumption of a processor based upon an application demand is provided. The method initiates with determining an application demand based upon a current processing operation. Then, a time interval associated with the application demand is determined. Next, unnecessary power consuming functions for the application demand are determined. Then, a clock frequency for the unnecessary power consuming functions is reduced for the time interval. In one embodiment, the power is terminated to the unnecessary power consuming functions. In another embodiment, the clock frequency of the processor is adjusted for at least a portion of the time interval. A program interface for adapting power consumption of a computer system, processor instructions for adapting power consumption of a computer system and a processor are included."
7640284,"Parallelism in a processor is exploited to permute a data set based on bit reversal of indices associated with data points in the data set. Permuted data can be stored in a memory having entries arranged in banks, where entries in different banks can be accessed in parallel. A destination location in the memory for a particular data point from the data set is determined based on the bit-reversed index associated with that data point. The bit-reversed index can be further modified so that at least some of the destination locations determined by different parallel processes are in different banks, allowing multiple points of the bit-reversed data set to be written in parallel."
7640285,"Multipurpose arithmetic functional units can perform planar attribute interpolation and unary function approximation operations. In one embodiment, planar interpolation operations for coordinates (x, y) are executed by computing A*x+B*y+C, and unary function approximation operations for operand x are executed by computing F2(xb)*xh2+F1(xb)*xh+F0(xb), where xh=x−xb. Shared multiplier and adder circuits are advantageously used to implement the product and sum operations for both classes of operations."
7640421,"A method and apparatus for automatically generating a list of circuit elements, such as registers, to be context switched designed to avoid the omission of elements that must be context switched are provided. The method generally involves creating a list of potential elements for context switching, assuming these elements will be context switched by default, and then excluding all elements that must not be context switched."
7643301,"A system, method, and computer program product are provided for circulating external air about a chipset. Included is a circuit board with a chipset mounted thereon that communicates with a central processing unit and controls interaction with memory. Further provided is an airflow subsystem coupled to the circuit board for circulating external air about the chipset."
7643330,"One embodiment of the present invention sets forth a synchronous two-port static random access memory (SRAM) design with the area efficiency of a one-port SRAM. By restricting both access ports to an edge-triggered, synchronous clocking regime, the internal timing of the SRAM can be optimized to allow high-performance double-pumped access to the SRAM storage cells. By double-pumping the SRAM storage cells, one read access and one write access are possible per clock cycle, allowing the SRAM to present two external ports, each capable of performing one transaction per clock cycle."
7643443,A method for autonomously and dynamically optimizing transmission power of an endpoint in a wireless network includes the step of monitoring the signal quality associated with data transfers between an access point in the wireless network and the endpoint at a first transmission power and a first transmission speed. The method also includes the steps of determining whether the signal quality is acceptable and adjusting one of the first transmission power or the first transmission speed based on whether the signal quality is acceptable.
7644205,"One embodiment of the present invention sets forth a technique for mapping a small computer system interface (SCSI) architecture model-3 (SAM-3) task priority to an IEEE Standard 802.1q tag control information (TCI) field. Four bits that define a SAM-3 task priority are mapped to the three user priority bits within a standard 802.1q TCI field. By enabling the SAM-3 task priority of a given SCSI command to determine the user priority within a related IEEE 802.1q Ethernet frame, the Ethernet network is enabled to substantially honor the requested task priority for the SCSI command."
7644279,"Aspects for consumer product distribution in the embedded system market are described. The aspects include forming a secure network for distributing product digitation files capable of configuring operations of an adaptive computing engine (ACE), and providing an agent server within the secure network for controlling licenses of the product digitation files, wherein a separation of responsibility and control of the distributing and licensing exists."
7646389,Methods and systems for texture mapping in a computer-implemented graphics pipeline are described. A sample group is identified as including a divergent pixel. A determination is made whether an operand of an instruction executing on the divergent pixel satisfies a condition. A scheme for determining a level of detail for the texture mapping is selected depending on whether or not the condition is satisfied.
7646790,"A communication processor of a class, such as an Internet tuner, provides such desirable features (FIG. 2) as LAN support, an SPI interface (128), a dedicated port (56), and ADPCM (22) for audio applications. The invention provides a low-cost, low-power, easily manufactured, small form-actor network access module which has a low memory demand and provides a highly efficient protocol decode. The invention comprises a hardware-integrated system that both decodes multiple network protocols in a streaming manner concurrently and processes packet data in one pass, thereby reducing system memory and form factor requirements, while also eliminating software CPU overhead."
7647203,"A system, method, and computer program product are provided for gauging video processing. In use, results are identified with respect to a first analysis for testing a performance of video processing of a processor, a second analysis for testing a functionality of the video processing of the processor, and a third analysis for testing a quality of the video processing of the processor. To this end, the video processing of the processor may be gauged based on the results."
7647467,"On the fly tuning of parameters used in an interface between a memory (e.g. high speed memory such as DRAM) and a processor requesting access to the memory. In an operational mode, a memory controller couples the processor to the memory. The memory controller can also inhibit the operational mode to initiate a training mode. In the training mode, the memory controller tunes one or more parameters (voltage references, timing skews, etc.) used in an upcoming operational mode. The access to the memory may be from an isochronous process running on a graphics processor. The memory controller determines whether the isochronous process may be inhibited before entering the training mode. If memory buffers for the isochronous process are such that the training mode will not impact the isochronous process, then the memory controller can enter the training mode to tune the interface parameters without negatively impacting the process."
7647561,"A system, method and computer program product are provided for generating an application. An interaction with a first application is recorded for capturing a functionality of the first application. An interaction with a second application is also recorded for capturing a functionality of the second application. A pattern is generated based on the recorded interactions. An application is generated based on the pattern. The interactions recorded in the pattern are repeated upon replay of the pattern for providing the functionalities of the first and second applications. A method for executing the pattern-based application is provided. Upon receiving a request for data, a pattern for retrieving the requested data is selected. The pattern is replayed. The recorded interaction is conducted as specified in the pattern for obtaining the requested data. The requested data is received."
7649269,"An integrated circuit and method of fabricating the same are provided. Included are an active circuit, and a metal layer disposed, at least partially, above the active circuit. Further provided is a bond pad disposed, at least partially, above the metal layer. To prevent damage incurred during a bonding process, the aforementioned metal layer may define a frame with an outer periphery and an inner periphery."
7649444,"Embodiments of the present invention recite a method and system for providing positional audio cues for an vehicle warning system. In one embodiment, a sensor disposed in a vehicle detects a warning event and generates a corresponding signal. In response to receiving the signal, a controller uses a positional audio algorithm to generate an audible warning via an audio system associated with the vehicle. The audible warning uniquely identifies the warning event and provides a location cue indicating the location of the warning event. In embodiments of the present invention, a sensor coupled with the controller may detect the proximity of and external object with reference to the vehicle and generate a corresponding signal. In embodiments of the present invention, the audible warnings may comprise steering cues indicating a desired direction, or a wrong direction, to a destination in response to input from a vehicle navigation system."
7649536,"A system, method, and computer program product are provided for utilizing natural motions of a user to display intuitively correlated reactions. In use, an application-independent command is received from an input device utilizing at least one natural motion of a user with an associated degree. In response to the application-independent command, a reaction is displayed on a display in a manner that is intuitively correlated with the at least one natural motion. Further, a degree of the reaction is a function of the degree of the at least one natural motion."
7649538,"Circuits, methods, and apparatus that provide texture caches and related circuits that store and retrieve texels in a fast and efficient manner. One such texture circuit provides an increased number of bilerps for each pixel in a group of pixels, particularly when trilinear or aniso filtering is needed. For trilinear filtering, texels in a first and second level of detail are retrieved for a number of pixels during a clock cycle. When aniso filtering is performed, multiple bilerps can be retrieved for each of a number of pixels during one clock cycle."
7649762,Embodiments for an area efficient high performance memory cell comprising a transistor connected to one of a bit line and a bit line bar are disclosed.
7650266,A method of simulating a deformable object comprises modeling deformable elasticity for the object by defining an actual shape and a goal shape and pulling points in the goal shape towards corresponding points in the goal shape.
7650645,"Circuits, methods, and apparatus that provide for trusted transactions between a device and system memory. In one exemplary embodiment of the present invention, a host processor asserts and de-asserts trust over a virtual wire. The device accesses certain data if the host processor provides a trusted instruction for it to do so. Once the device attempts to access this certain data, or perform a certain type of data access, a memory controller allows the access on the condition that the host processor previously made the trusted instruction. The device then accepts data if trust is asserted during the data transfer."
7653265,"This document discusses, among other things, systems and methods that track overall time for processing operations such that the processing time can be shared among the resources in an efficient manner. Processing time can be shifted to image processing where the time will provide the most benefit to image quality. Moreover, access time from one process is banked to be used by a subsequent process or on a subsequent group of pixels.This document also discusses, among other things, systems and methods that provide additional processing power on an as needed basis. In an example, a processing stage and its controller are outside the normal pixel processing flow path. When it is determined that additional processing is required, the processing stage and its controller are activated to perform the additional processing.This document further discusses, among other things, systems and methods that provide parallel processing in a processing stage such that the data can flow internal to the controller linked to the processing stage and data can flow globally."
7653825,"A method for adapting power consumption of a processor based upon an application demand is provided. The method initiates with determining an application demand based upon a current processing operation. Then, a time interval associated with the application demand is determined. Next, unnecessary power consuming functions for the application demand are determined. Then, a clock frequency for the unnecessary power consuming functions is reduced for the time interval. In one embodiment, the power is terminated to the unnecessary power consuming functions. In another embodiment, the clock frequency of the processor is adjusted for at least a portion of the time interval. A program interface for adapting power consumption of a computer system, processor instructions for adapting power consumption of a computer system and a processor are included."
7656954,Embodiments for single-ended tri-level encoding and/or decoding of data are disclosed.
7657775,"Methods, circuits, and apparatus for changing a frequency of a clock signal provided to a graphics memory while reducing any resulting visual glitch or disturbance on a monitor. A specific embodiment provides multiple clock sources that may be multiplexed or selected to provide a memory clock signal to the graphics memory. The multiplexer switches from providing a first clock source signal as the memory clock signal to providing a second clock source signal as the memory clock signal. The first clock source changes its frequency of operation. After the first clock source settles or stabilizes, the multiplexer switches back to providing the first clock source signal as the memory clock signal."
7659893,"At least two different processing sections in a graphics processors compute Z coordinates for a sample location from a compressed Z representation. The processors are designed to ensure that Z coordinates computed in any unit in the processor are identical. In one embodiment, the respective arithmetic circuits included in each processing section that computes Z coordinates are “bit-identical,” meaning that, for any input planar Z representation and coordinates, the output Z coordinates produced by the circuits are identical to each other."
7659897,"A system, method, and computer program product are provided for determining a performance associated with a graphics processor. In use, at least one aspect of a usage of a graphics processor is identified. Further, a performance of a video output of the graphics processor is determined, based on the identified aspect."
7659909,An arithmetic logic unit (ALU) in a graphics processor is described. The ALU includes circuitry for performing an operation using a first set of pixel data. The first set of pixel data is resident in a pipeline register coupled to the circuitry. A temporary register is coupled to the circuitry. The temporary register can receive a result of the operation. The temporary register allows a result generated using one set of pixel data to be used with a subsequent set of pixel data in the same ALU. The result of the operation can thus be used in a second operation with a second set of pixel data that resides in the pipeline register after the first set of pixel data.
7663621,"Circuits, methods, and apparatus that perform cylindrical wrapping in software without the need for a dedicated hardware circuit. One example performs cylindrical wrapping in software running on shader hardware. In one specific example, the shader hardware is a unified shader that alternately processes geometry, vertex, and fragment information. This unified shader is formed using a number of single-instruction, multiple-data units. Another example provides a method of performing a cylindrical wrap that ensures that a correct texture portion is used for a triangle that is divided by a “seam” of the wrap. To achieve this, primitive vertices are sorted such that results are vertex order invariant. One vertex is selected as a reference. For the other vertices, a difference is found for each coordinate and a corresponding coordinate of the reference vertex. If the coordinates are near, no change is made. If the coordinates are distant, the coordinate is adjusted."
7663633,A multiple GPU (graphics processor unit) graphics system is disclosed. The multiple GPU graphics system includes a plurality of GPUs configured to execute graphics instructions from a computer system. A GPU output multiplexer and a controller unit are coupled to the GPUs. The controller unit is configured to control the GPUs and the output multiplexer such that the GPUs cooperatively execute the graphics instructions from the computer system.
7663663,"A burn-in control method and video processor for executing the same. The video processor intelligently recognizes aspects of a video image that are likely to cause burn-in, and responsive to such recognition, modifies the video image to prevent uneven aging of the pixels. According to one aspect of the disclosure, modifications are spatially made to an entire video frame, one or more selected regions of a video frame, or one or more individual pixels of a video frame. According to another aspect of the disclosure, modifications are temporally made to all frames in a video stream, selected frames in a video stream, or a single frame in a video stream."
7664905,"In some applications, such as video motion compression processing for example, a request pattern or “stream” of requests for accesses to memory (e.g., DRAM) may have, over a large number of requests, a relatively small number of requests to the same page. Due to the small number of requests to the same page, conventionally sorting to aggregate page hits may not be very effective. Reordering the stream can be used to “bury” or “hide” much of the necessary precharge/activate time, which can have a highly positive impact on overall throughput. For example, separating accesses to different rows of the same bank by at least a predetermined number of clocks can effectively hide the overhead involved in precharging/activating the rows."
7664907,"Techniques and systems for dynamic binning, in which a stream of requests to access a memory is sorted into a reordered stream that enables efficient access of the memory. A page stream sorter can group requests to access a memory in a manner that results in some “locality” in the stream of requests issued from the page stream sorter to memory, such that as few pages as possible in the same bank are accessed and/or a number of page switches needed is minimized."
7671797,"A system, method, and computer program product are provided. In use, a plurality of coordinates is identified. Further, at least one aspect of an antenna is adjusted based on the coordinates. In addition, the coordinates include source coordinates that indicate a location of a source of a signal received by the antenna. Additionally, the at least one aspect of the antenna is adjusted includes an orientation of the antenna, where the orientation is further determined based on a strength of the signal received by the antenna."
7672179,"A system, method, and computer program product are provided for driving a memory circuit. In one embodiment, the memory circuit is driven utilizing a first resistance value in a first mode of operation. Further, in a second mode of operation, the memory circuit is driven utilizing a second resistance value. In another embodiment, a device is provided for driving a memory circuit without active termination utilizing a resistor."
7676596,"Method and system for broadcasting live data over a network are described. In one embodiment, live data is accessed. Next, a first client is authenticated. The live data is then broadcast to a first client, wherein the first client is capable of buffering and re-transmitting the live data. Next, a second client is authenticated. A list of clients receiving the live data is then sent to the second client. The second client then selects the first client from the list, contacts the first client, and then receives the live data from the first client."
7676657,"Instruction dispatch in a multithreaded microprocessor such as a graphics processor is not constrained by an order among the threads. Instructions for each thread are fetched, and a dispatch circuit determines which instructions in the buffer are ready to execute. The dispatch circuit may issue any ready instruction for execution, and an instruction from one thread may be issued prior to an instruction from another thread regardless of which instruction was fetched first. If multiple functional units are available, multiple instructions can be dispatched in parallel."
7680969,"A method and system for disk I/O (input output) command splitting in a computer system. The method includes tracking a head position of a disk drive. Upon receiving a request for data from the disk drive, a first split access is executed to read a first portion of the data and a second split access is executed to read a second portion of the data. The second split access is executed after a rotation of the disk drive. The first split access and the second split access are used to fulfill the request for data."
7680988,"A shared memory is usable by concurrent threads in a multithreaded processor, with any addressable storage location in the shared memory being readable and writeable by any of the threads. Processing engines that execute the threads are coupled to the shared memory via an interconnect that transfers data in only one direction (e.g., from the shared memory to the processing engines); the same interconnect supports both read and write operations. The interconnect advantageously supports multiple parallel read or write operations."
7680992,A memory interface permits a read-modify-write process to be implemented as an interruptible process. A pending read-modify-write is capable of being temporarily interrupted to service a higher priority memory request.
7681077,A graphics processing unit has a reduced memory space shadow memory as a source of state information for performing validation of commands. The reduced memory space shadow memory is smaller in size than a full version of state variables associated with an abstract state machine representation of a class of commands received from a software driver.
7681187,A method and apparatus for optimizing register allocation during scheduling and execution of program code in a hardware environment. The program code can be compiled to optimize execution given predetermined hardware constraints. The hardware constraints can include the number of register read and write operations that can be performed in a given processor pass. The optimizer can initially schedule the program using virtual registers and a goal of minimizing the amount of active registers at any time. The optimizer reschedules the program to assign the virtual registers to actual physical registers in a manner that minimizes the number of processor passes used to execute the program.
7683648,"An integrated circuit socket apparatus and method of use are provided. Included is a body capable of receiving an integrated circuit including a plurality integrated circuit contacts. Further provided is a bottom adapter assembly removably coupled to the body. The bottom adapter assembly includes a top portion, a bottom portion, and a plurality of pins removably situated between the top portion and the bottom portion of the bottom adapter assembly, for providing electrical communication between the integrated circuit contacts and a plurality of circuit board contacts. Still yet, a coupler is provided which is capable of coupling the top portion and the bottom portion of the bottom adapter assembly when the bottom adapter assembly is removed from the body."
7683905,"Apparatuses and methods for detecting position conflicts during fragment processing are described. Prior to executing a program on a fragment, a conflict detection unit, within a fragment processor checks if there is a position conflict indicating a RAW (read after write) hazard may exist. A RAW hazard exists when there is a pending write to a destination location that source data will be read from during execution of the program. When the fragment enters a processing pipeline, each destination location that may be written during the processing of the fragment is entered in conflict detection unit. During processing, the conflict detection unit is updated when a pending write to a destination location is completed."
7684440,"The present invention provides a method and an apparatus to facilitate the use of larger-than-Ethernet-standard frames having different sizes in a network, such as an extended local area network, where the network can include at least one network element that cannot transfer data as larger-than-Ethernet-standard frames. In one embodiment, a method for formatting data for transportation over a network comprises identifying a network element capable of using data formatted as a non-standard frame, such as a jumbo frame. Then, the method provides for determining a non-standard frame size that is useable by the network element. More generally, the technique is applicable to any LAN infrastructure comprised of devices supporting a variety of frame sizes, so that any device may discover the largest frame size that is supported to any other device within the same network."
7684641,Systems and methods for identifying pixels that are inside a two-dimensional path may be used to fill the path. The path is segmented and a slope direction is determined for each pixel that is covered by the segmented path. The slope directions are stored in a derivative mask that may be integrated for each scanline to produce a fill mask. The resulting fill mask indicates the pixels that are inside the two-dimensional path. The fill mask may be used to fill the path.
7685370,"A data processing system can establish or maintain data coherency by issuing a data flush operation. An agent can initialize a first flush operation by writing to a flush register. The agent can determine that the flush operation is complete by reading a status indicator from a status register. Additional agents can independently issue flush operations during the pendency of the first flush operation. A second flush instruction and any additional flush instructions that issue during the pendency of the first flush operation set a flush pending indicator in a status register. Once the first flush operation completes, the host performs all pending flush operations in a single second flush operation. The status indicator does not indicate a completed flush operation for the first flush operation until all flush operations are complete. Multiple co-pending flush operations are collapsed into at most two flush operations."
7685371,"A data processing system can establish or maintain data coherency by issuing a data flush operation. The data processing system can be configured as a host executing one or more independent processes using one or more lower level devices. The lower level devices can be viewed as peer devices. Any of the host or the plurality of peer devices can be configured to initiate the flush operation. A device can determine whether the initiator of a flush operation is the host or a peer device. The device can perform a flush limited to local memory, or a subset of all available memory, if a peer device initiates the flush operation."
7685619,"A system, method, and user interface for displaying electronic program guide (EPG) and personal video recorder (PVR) information as navigable three-dimensional images is described. In one embodiment, a three dimensional image is formed in which EPG data is presented on one surface of a three dimensional image and PVR data is presented on at least one other surface of the three-dimensional image."
7688325,"One embodiment of the invention sets forth a technique for compressing and storing display data and optionally compressing and storing cursor data in a memory that is local to a graphics processing unit to reduce the power consumed by a mobile computing device when refreshing the screen. Compressing the display data and optionally the cursor data also reduces the relative cost of the invention by reducing the size of the local memory relative to the size that would be necessary if the display data were stored locally in uncompressed form. Thus, the invention may improve mobile computing device battery life, while keeping additional costs low."
7689541,"One embodiment of the present invention sets forth a technique for efficiently performing a radix sort operation on a graphics processing unit (GPU). The radix sort operation is conducted on an input list of data using one or more passes of a series of three processing phases. In each processing phase, thread groups are each associated with one segment of input data. In the first phase, occurrences of each radix symbol are counted and stored in a list of counters. In the second phase, the list of counters is processed by a parallel prefix sum operation to generate a list of offsets. In the third phase, the list of offsets is used to perform re-ordering on the list of data, according to the current radix symbol. To maintain sort stability, the one or more passes proceed from least significant data to most significant data in the sort key."
7692654,"In a graphics pipeline of a graphics processor, a method for determining pixel location subsequent to rasterization. The method includes receiving a graphics primitive for rasterization in a raster stage of a graphics processor and rasterizing the graphics primitive to generate a plurality of tiles related to the graphics primitive. The method further includes performing a parameter evaluation on each of the plurality of tiles to eliminate noncontributing pixels and to generate a plurality of pixels related to the graphics primitive. A starting location is generated for a first of the plurality of pixels. For each subsequent pixel of the plurality of pixels, a vector to a starting location for each subsequent pixel is generated. Shader processing is performed on the plurality of pixels in a shader stage of the graphics processor by using the start location for the first pixel and the vector for each subsequent pixel."
7692659,"One embodiment of the present invention sets forth a technique for improving graphics rendering efficiency by processing pixels in a compressed format whenever possible within a multi-sampling graphics pipeline. Each geometric primitive is rasterized into fragments, corresponding to screen space pixels covered at least partially by the geometric primitive. Fragment coverage represents the pixel area covered by the geometric primitive and determines the weighted contribution of a fragment color to the corresponding screen space pixel. Samples associated with a given fragment are called sibling samples and have the same color value. The property of sibling samples having the same color value is exploited to compress and process multiple samples, thereby reducing the size of the associated logic and the amount of data written to and read from the frame buffer."
7693044,"The invention sets forth an approach for aggregating a plurality of NICs in a computing device into a single logical NIC as seen by that computing device's operating system. The combination of the single logical NIC and a network resource manager provides a reliable and persistent interface to the operating system and to the network hardware, thereby improving the reliability and ease-of-configuration of the computing device. The invention also may improve communications security by supporting the 802.1X and the 802.1Q networking standards."
7693326,"An image processing method and system using a low-complexity scheme is provided. According to one aspect of the method, input components from a RGB model are used directly to calculate the down-sampled components of a YCbCr model. In an exemplary instance where average down-sampling and a down-sampling rate of “4:2:0” are used, the following equations are used to derive the down-sampled components of the YCbCr model:where Ri, Gi and Bi are three input components of the color conversion for the pixel i and “SP” represents a specified sample precision under the RGB model. The foregoing method reduces computational complexity and cost thereby allowing an image color conversion process to be performed in a more efficient manner."
7693345,"A method for concealing errors in compressed images in the JPEG 2000 format diosclosed. JPEG2000 (ISO/IEC 15444) is the new standard for image compression catering to different needs of various applications. This standard is much more advanced than JPEG and is rich in features. An Error concealment method in JPEG 2000 is provided which mainly deals with estimating the lost regions in a Wavelet Transformed image and works in Wavelet Transform Domain. This results in optimum error concealment and therefore, The method is applied before taking Inverse DWT."
7694062,"Systems and apparatus for capacitively coupling signals with an integrated circuit (IC) are described. Capacitive elements disposed within a transmitting IC effectively function as AC coupling capacitors for a PCIe, DisplayPort™ or other interconnect linking the transmitting IC with a receiver disposed remote there from. Integrating the coupling capacitors allows for a smaller and more economical design for the circuits that utilize the interconnect."
7697007,"A controlling process may enable or disable the launching of a predicated process that has already been queued for launching, e.g. via a pushbuffer. The controlling process generates a report so that launching of the predicated process is enabled or disabled based on the report. The predicate may be global in application to enable or disable all subsequent launch commands. Alternatively, the predicate may be specific to one or more predicated processes. In an embodiment with a central processing unit (CPU) coupled to a graphics processing unit (GPU), the CPU may generate the controlling process that enables or disables the launch of the predicated process. Alternatively or additionally, the GPU may generate the controlling process that enables or disables the launch of the predicated process."
7697008,"A system, method and article of manufacture are provided for programmable processing in a computer graphics pipeline. Initially, data is received from a source buffer. Thereafter, programmable operations are performed on the data in order to generate output. The operations are programmable in that a user may utilize instructions from a predetermined instruction set for generating the same. Such output is stored in a register. During operation, the output stored in the register is used in performing the programmable operations on the data."
7697009,"Circuits, methods, and apparatus provide for the storage of texture descriptors in a graphics memory. Since the texture descriptors are stored in a graphics memory, they do not need to be stored in the graphics processor itself, thus reducing graphics processor circuitry and cost. This allows more textures to be associated with each graphics primitive, thereby improving image realism."
7698413,A method for accessing and maintaining socket control information for high speed network connections. A multi-port control block (CB) cache contains socket control information in CB entries for sockets assigned to the transport offload engine (TOE) by a host computer. Each port provides a TOE client direct access to the CB cache. Time critical logic are each provided dedicated ports to enable higher bandwidth accesses to the CB cache for these time critical clients. All other non-time critical TOE clients are given arbitrated access via a separate dedicated port. An optional external memory is given direct access to the CB cache via a dedicated port and can store more CB entries for additional sockets.
7698489,"Embodiments of the present disclosure provide techniques for dynamically turning off bus signals driven into a graphics processing unit (GPU) when the GPU is in a low power state. The GPU may be located on a graphics card mounted to a motherboard by a bus, such as a PCI-Express bus."
7698490,"A system for a universal serial bus (USB) device to perform power configuration to operate with a USB host. A connection to the USB host is enabled. Then a high-power configuration is reported to the USB host and successful enumeration by the USB host is monitored for. If such enumeration is not forthcoming within a preset time, the connection to the USB host is disabled and re-enabled, and a low-power configuration is then reported to the USB host. Optionally, the system can further ramp up power usage until a preset high-power configuration is reached, or until there is voltage sag on the VBUS and then either ramp power usage back down or measure the sag and set to a calculated power usage."
7701459,A graphics system has parallel processing units that do not share vertex information. The graphics system constructs independent batches of work for the parallel processing units in which each batch of work has a list of vertices for a set of primitives.
7705845,"Apparatus, system, and method for clipping graphics primitives are described. In one embodiment, a graphics processing apparatus includes a clipping engine and an output unit connected to the clipping engine. The clipping engine is configured to clip an input graphics primitive with respect to a set of clipping planes to derive spatial attributes of new vertices. The output unit is configured to identify a subset of the new vertices that defines an output graphics primitive, and the output unit is configured to derive non-spatial attributes of the subset of the new vertices to produce the output graphics primitive."
7705846,"Circuits, methods, and apparatus provide for the storage of texture descriptors in a graphics memory. Since the texture descriptors are stored in a graphics memory, they do not need to be stored in the graphics processor itself, thus reducing graphics processor circuitry and cost. This allows more textures to be associated with each graphics primitive, thereby improving image realism."
7705850,"In a computer system employing PCI Express (PCIe) links, the PCIe bandwidth is increased by configuring an endpoint device with at least two PCIe interfaces, and coupling the first of these interfaces with a PCIe interface of a system controller and the second of these PCIe interfaces with an expansion PCIe interface of an I/O controller. Therefore, the endpoint device's performance becomes more efficient. For example, if the endpoint device is a graphics processing unit, then the endpoint device can execute more frames per second. When a read request is split up and issued as multiple read requests over the at least two PCIe interfaces, the multiple read completion packets that are received in response thereto are ordered in accordance with the timing of the multiple read requests."
7705915,"Video filtering using a programmable graphics processor is described. The programmable graphics processor may be programmed to complete a plurality of video filtering operations in a single pass through a fragment-processing pipeline within the programmable graphics processor. Video filtering functions such as deinterlacing, chroma up-sampling, scaling, and deblocking may be performed by the fragment-processing pipeline. The fragment-processing pipeline may be programmed to perform motion adaptive deinterlacing, wherein a spatially variant filter determines, on a pixel basis, whether a “bob”, a “blend”, or a “weave” operation should be used to process an interlaced image."
7710424,"A method and system for accessing texture data is disclosed. The method includes the step of storing a low resolution version of a block of texture data in a low latency memory and storing a high resolution version of the block of texture data in high latency memory. Upon a request for the high resolution version of the block of texture data, the high resolution version is fetched from the high latency memory to the low latency memory. The low resolution version is subsequently accessed from the low latency memory until the high resolution version is fetched into the low latency memory."
7710427,"Embodiments of the present invention include an arithmetic logic unit for use in a graphics pipeline. The arithmetic logic unit comprising a plurality of scalar arithmetic logic subunits wherein each subunit performs a resultant arithmetic logic operation in the form of [a*b “op” c*d] on a set of input operands a, b, c and d. The arithmetic logic unit also for produces a result based thereon wherein “op” represents a programmable operation and wherein further the resultant arithmetic logic operation is software programmable to implement a plurality of different graphics functions."
7710741,"One embodiment of a reconfigurable graphics processing system includes a first MXM edge connector and a second MXM edge connector affixed to an interposer board and a first MXM board and a second MXM board coupled to the interposer board via the first and second MXM edge connectors, respectively. Each MXM board includes a GPU and other elements necessary to process graphics data. The system couples to the motherboard of a computing device through an interface connector on the interposer board. One advantage of such a system is that it may be configured to deliver more performance than a standard desktop graphics board, while occupying substantially the same volume, through the use of multiple, small form factor MXM boards."
7710858,A FFT module for a baseband processor of a receiver includes an input for receiving a timing window correction signal. In response to the timing window correction signal the FFT module adjusts a timing window for processing groups of samples within an input queue of the FFT module.
7711990,A system includes a graphics processing unit with a processor responsive to a debug instruction that initiates the storage of execution state information. A memory stores the execution state information. A central processing unit executes a debugging program to analyze the execution state information.
7714877,"An apparatus, system, and method for determining clipping distances are described. In one embodiment, a graphics processing apparatus includes a clipping unit and an instruction memory connected to the clipping unit. The instruction memory includes a clipping program to direct the clipping unit to perform clipping operations. The clipping program includes a clipping distance instruction to determine a clipping distance with respect to any of a set of clipping planes."
7716506,A system has a plurality of different clients. Each client generates a report signal indicative of a current latency tolerance associated with a performance state. A controller dynamically determines a power down level having a minimum power consumption capable of supporting the system latency of the configuration state of the clients.
7719545,"A system, method and computer program product are provided for programmable vertex processing. Initially, a vertex program is identified including branch labels and instruction sequences with branch commands. The vertex program is then converted to a binary format capable of being executed by a hardware graphics pipeline. The vertex program may then be executed in the binary format utilizing the hardware graphics pipeline for transforming vertices. As an option, the vertex program is initially written in a textual format capable of being read by a human prior to being converted."
7720311,"A new technique for image sample-rate conversion can be efficiently implemented with respect to memory, bandwidth and computational requirements. According to one aspect, the technique takes advantage of certain inherent similarities and symmetries within the image data to limit switching of filters during processing and to otherwise process the data in an efficient order. According to another aspect, the technique can be implemented within a decoding pipeline such as a JPEG/MPEG decoding pipeline in such a way that multiple transfers of image data in and out of the external memory can be avoided. According to a still further aspect, where poly-phase filters are used, computationally-efficient filters are chosen for use with the image conversion process. The technique is amenable to both hardware and software based implementations."
7721118,"A system and method for optimizing power usage and performance during data processing. A multi-processor graphics processing system includes a low power graphics processor and a high performance graphics processor. When a low power condition exists only the low power graphics processor is used to process graphics data and the high performance graphics processor is turned off. When turned off, the high performance graphics processor does not consume either static or dynamic power. When the low power condition does not exist, the high performance graphics processor is turned on and the low power graphics processor and the high performance graphics processor are used to process the graphics data."
7724211,"A system, method, and computer program product are provided for controlling stereo glasses shutters. In use, a right eye shutter of stereo glasses is controlled to switch between a closed orientation and an open orientation. Further, a left eye shutter of the stereo glasses is controlled to switch between the closed orientation and the open orientation. To this end, the right eye shutter and the left eye shutter of the stereo glasses may be controlled such that the right eye shutter and the left eye shutter simultaneously remain in the closed orientation for a predetermined amount of time."
7724253,"A system, and method are provided for dithering depth values. The depth values include a plurality of first depth values associated with a first object and a plurality of second depth values associated with a second object. Additionally, the first depth values and the second depth values are stored in a depth map in a predetermined configuration. In addition, the predetermined configuration takes on a checkerboard pattern."
7724254,"A multi-threaded graphics processor is configured to generate a tessellated iso-surface from a volumetric description using slices of values that are stored in render targets. The volumetric description can be a complex mathematic equation, a sum of metaballs, a pre-computed scalar field represented as a 3D volume texture, or a rendered volume. Slices are aligned along an axis and spaced before being intersected with the volume to determine iso-surface intersections for the x, y, and z axes. The intersections are stored in render targets and are processed by a shader program to produce a tessellated iso-surface."
7724263,"A system and method for a data write unit in a 3-D graphics pipeline including generic cache memories. Specifically, in one embodiment a data write unit includes a first memory, a plurality of cache memories and a data write circuit. The first memory receives a pixel packet associated with a pixel. The pixel packet includes data related to surface characteristics of the pixel. The plurality of cache memories is coupled to the first memory for storing pixel information associated with a plurality of surface characteristics of a plurality of pixels. Each of the plurality of cache memories is programmably associated with a designated surface characteristic. The data write circuit is coupled to the first a memory and the plurality of cache memories. The data write circuit is operable under program control to obtain designated portions of the pixel packet for storage into the plurality of cache memories."
7725518,"One embodiment of the present invention sets forth a technique for computing a parallel prefix sum using one or more cooperative thread arrays (CTA) within a graphics processing unit. The prefix sum input list is partitioned and distributed to each CTA. Within each CTA, the input list is further partitioned for processing by individual threads in a way that avoids access conflicts to memory. Each list partition within the CTA is assigned to one of a plurality of concurrent threads, which executes a prefix sum operation the partition. The final values of the prefix sum operations form a list that is then subjected to a second prefix sum operation. Each element of the second prefix sum operation is added to each element of the subsequent partition, completing the prefix sum operation within the CTA. This technique may be extended to prefix sum operations that span two or more CTAs."
7725688,"States that are used in configuring a processing pipeline are passed down through a separate pipeline in parallel with the data transmitted down through the processing pipeline. With this separate pipeline, the states for configuring any one stage of the processing pipeline are continuously available in the corresponding stage of the state pipeline, and new states for configuring the processing pipeline can be transmitted down the state pipeline without flushing the processing pipeline. The processing pipeline and the separate pipeline for the states can be divided into multiple sections so that the width of the separate pipeline for the states can be reduced."
7728841,"In a multiple render target mode, a pixel shader computes color values for pixels and stores the computed color values in a register file. The register file acts as a buffer for the computed color values. Conventionally writing pixels in the order they are received (pixel-major order) can result in large strides across memory in the frame buffer. At least a minimum amount of work should be done within a DRAM page, for example, to cover the overhead required in opening the DRAM page. Therefore, color values are written from the register file to two or more targets in a frame buffer in a target-major order within a segment. Writing in a target-major order (sequential with respect to targets but non-sequential with respect to quads received and processed) yields coherent writes to frame buffer memory and improves memory efficiency."
7729507,"Embodiments of the present invention include a system for stabilizing a rear view image. The system comprises a camera for capturing a rear view image, wherein the rear view image comprises elements located outside of a passenger vehicle and located behind the passenger vehicle. The system further comprises a motion detector for determining a relative movement between two or more objects e.g., the driver's head and an object within the vehicle. The system further includes an electronic image stabilizer for adjusting the rear view image according to the relative movement and a display device for displaying a stabilized rear view image."
7733419,"Video filtering using a programmable graphics processor is described. The programmable graphics processor may be programmed to complete a plurality of video filtering operations in a single pass through a fragment-processing pipeline within the programmable graphics processor. Video filtering functions such as deinterlacing, chroma up-sampling, scaling, and deblocking may be performed by the fragment-processing pipeline. The fragment-processing pipeline may be programmed to perform motion adaptive deinterlacing, wherein a spatially variant filter determines, on a pixel basis, whether a “bob”, a “blend”, or a “weave” operation should be used to process an interlaced image."
7734868,"A RAID class driver model enables users to easily combine two or more disks into a bootable RAID system without specialized disk controllers and allows the creation of RAID systems using disks of different types, controllers, and interfaces. A RAID class driver is initialized in response to the identification of a RAID controller. Disk controllers return RAID-specific device identifications, rather than a standard disk device identifications, for each disk to be included in the RAID system. The RAID class driver binds a RAID-specific functional interface to each disk having a RAID-specific device identification and combines the disks into a disk object representing the entire RAID system. The disk object provides the operating system with a standard disk device identification. The operating system loads a standard disk driver to interface with the disk object, thereby enabling transparent access to the RAID system."
7737988,Systems and methods used for font filtering may also be used to perform texture blits. Texture data is read in blocks that are coarsely aligned. Font engines may be used to align the texture data as specified by a copy (blit) instruction to provide a finely aligned region of the texture data within a font filter footprint. The finely aligned region is then bilinearly filtered using a “nearest” mode to provide the bit aligned region of the texture map specified by the copy instruction.
7738740,"An image processing system and method, in which an image processing operation is performed on a pixel or pixels by selecting and applying one of a plurality of implementations of the image processing operation. The plurality of implementations is varied from time to time, such that one or more of the implementations is replaced with a different implementation or implementations."
7739473,Systems and methods for dynamically allocating memory for thread processing may reduce memory requirements while maintaining thread processing parallelism. A memory pool is allocated to store data for processing multiple threads that does not need to be large enough to dedicate a fixed size portion of the memory pool to each thread that may be processed in parallel. Fixed size portions of the memory pool are dynamically allocated and deallocated to each processing thread. Different fixed size portions may be used for different types of threads to allow greater thread parallelism compared with a system that requires allocating a single fixed portion of the memory pool to each thread. The memory pool may be shared between all of the thread types or divided to provide separate memory pools dedicated to each particular thread type.
7739479,A method of providing physics data within a game program or simulation using a hardware-based physics processing unit having unique architecture designed to efficiently calculate physics related data.
7739531,"An apparatus and method for dynamically controlling the maximum frequency of operation of the IC is provided. The invention optimizes power consumption in a device by measuring a current maximum frequency of operation and adjusting IC operating voltage to provide a desired maximum operating frequency. The invention provides an apparatus and method for controlling multiple voltages in an IC to independently adjust maximum operating frequencies for a plurality of separate portions of the IC. The invention may equally be applied to a group of ICs. The invention further provides a method for calibrating an IC. Thus, the apparatus facilitates the operation of an IC at a minimum voltage for a selected maximum frequency, thereby minimizing power consumption overall a wide range of operating frequencies."
7739556,A method and system for overriding state information programmed into a processor using an application programming interface (API) avoids introducing error conditions in the processor. An override monitor unit within the processor stores the programmed state for any setting that is overridden so that the programmed state can be restored when the error condition no longer exists. The override monitor unit overrides the programmed state by forcing the setting to a legal value that does not cause an error condition. The processor is able to continue operating without notifying a device driver that an error condition has occurred since the error condition is avoided.
7742646,"Systems and methods for representing high dynamic range data in compressed formats with a fixed size block allow high dynamic range data to be stored in less memory. The compressed formats use 8 bits per pixel. A first compressed format includes two endpoint values and an index for each pixel in the block. A second compressed format includes four endpoint values, a partition index that specifies a mask for each pair of the four endpoint values, and an index for each pixel in the block. The two formats may be used for various blocks within a single compressed image and mode bits are included to distinguish between the two formats. Furthermore, each endpoint value may be encoded using an endpoint compression mode that is also specified by the mode bits. Compressed high dynamic range values represented in either format may be efficiently decompressed in hardware."
7746347,"Methods and systems for processing a geometry shader program developed in a high-level shading language are disclosed. Specifically, in one embodiment, after having received the geometry shader program configured to be executed by a first processing unit in a programmable execution environment, the high-level shading language instructions of the geometry shader program is converted into low-level programming language instructions. The low-level programming language instructions are then linked with the low-level programming language instructions of a domain-specific shader program, which is configured to be executed by a second processing unit also residing in the programmable execution environment. The linked instructions of the geometry shader program are directed to the first processing unit, and the linked instructions of the domain-specific shader program are directed to the second processing unit."
7746349,"To display a row of characters in the VGA alphanumeric mode, the ASCII and attribute bits for all such characters are retrieved from the main memory and stored in a local cache memory. The font and unused bits that are also retrieved from the memory during the retrieval of ASCII and attribute bits are discarded. The stored ASCII and attribute bits for each such character is then used to compute the address of the associated font bits in the main memory. Next, for each character, the font bits are retrieved from the main memory using a burst read operation and using the computed address for that font. The font bits associated with all the characters in the row are stored in the local cache memory and are subsequently scanned out to be used in the display of the characters."
7746350,"One embodiment of the invention sets forth a computing system for performing cryptographic computations. The computing system comprises a central processing unit, a graphics processing unit, and a driver. The central processing requests a cryptographic computation. In response, the driver downloads microcode to perform the cryptographic computation to the graphics processing unit and the graphics processing unit executes microcode. This offloads cryptographic computations from the CPU. As a result, cryptographic computations are performed faster and more efficiently on the GPU, freeing resources on the CPU for other tasks."
7746352,"A virtually-addressed local texture memory stores selected regions (a sparse representation) of a texture for use by a graphics processor. The graphics processor requests a texel of the texture by referencing a virtual address of the texel. A memory interface references an address map to determine whether the requested texel is in one of the regions of the texture that is resident in the local texture memory. If so, the texel is retrieved from the local memory and used in the rendering operation; if not, an alternative texel that is resident in the local memory is retrieved and used in the rendering operation. Non-resident regions that include requested texels are retrieved from a primary texture data store at regular intervals (e.g., once per frame) and stored in local texture memory for use in a subsequent rendering operation."
7747095,Methods and systems for compressing an image are described. A plurality of transformed and quantized values associated with a block of image data is accessed. The block corresponds to a position within the image. A count of the number of bits encoded during run-length encoding of the block is made. Run-length encoding of the block is concluded should the count reach a limit.
7747796,"Systems and methods for performing data transfer rate throttling o improve the effective data transfer rate for SATA storage devices. The data transfer rate is diluted by inserting ALIGN primitives when data is sent. The receiving device simply discards the ALIGN primitives. Therefore, the receive data FIFO does not fill as quickly and fewer flow control sequences are needed for flow control to prevent the receive data FIFO from overflowing. An advantage of using the ALIGN primitives instead of conventional flow control is that the round-trip handshake latency is not incurred to disable and later enable data transfers."
7747818,"One embodiment of the present invention sets forth a technique for reducing the latency associated with media protection notification for serial interface mass storage devices, such as serial AT attachment (SATA) hard disk drives. A new link layer primitive, referred to as hold-emergency (HOLDE), incorporates the flow-control behavior of the existing HOLD command, with the additional new action of notifying the hard disk drive to take emergency steps to prepare for impact. The HOLDE link layer primitive operates in conjunction with the existing hold-acknowledge (HOLDA) primitive and is semantically similar to the existing HOLD primitive. The HOLDE mechanism is preferably implemented directly in hardware in the SATA link layer state machines within the host and the hard disk drive."
7747842,"An output buffer in a multi-threaded processor is managed to store a variable amount of output data. Parallel threads produce a variable amount of output data. A controller is configured to determine how much output buffer space is needed per thread and how many threads can execute in parallel, given the available space in the output buffer. The controller also determines where each thread writes to in the output buffer."
7747915,"A system and method for increasing the yield of integrated circuits containing memory partitions the memory into regions and then independently tests each region to determine which, if any, of the memory regions contain one or more memory failures. The test results are stored for later retrieval. Prior to using the memory, software retrieves the test results and uses only the memory sections that contain no memory failures. A consequence of this approach is that integrated circuits containing memory that would have been discarded for containing memory failures now may be used. This approach also does not significantly impact die area."
7750915,"Methods, apparatuses, and systems are presented for performing multiple concurrent accesses in a shared memory resource comprising storing a first group of data elements in data entries across multiple banks in the shared memory resource, a first data element of the first group being stored in a data entry in a first bank; skipping at least one data entry in at least one bank after storing a last data element of the first group, to introduce an offset; following the offset, storing a second group of data elements in data entries across multiple banks in the shared memory resource, a first data element of the second group being stored in a data entry in a second bank different from the first bank; and concurrently accessing the first data element of the first group from the first bank and the first data element of the second group from the second bank."
7750956,"Described is a device (e.g., a cell phone incorporating a digital camera) that incorporates a graphics processing unit (GPU) to process image data in order to increase the quality of a rendered image. The processing power provided by a GPU means that, for example, an unacceptable pixel value (e.g., a pixel value associated with a malfunctioning or dead detector element) can be identified and replaced with a new value that is determined by averaging other pixel values. Also, for example, the device can be calibrated against benchmark data to generate correction factors for each detector element. The correction factors can be applied to the image data on a per-pixel basis. If the device is also adapted to record and/or play digital audio files, the audio performance of the device can be calibrated to determine correction factors for a range of audio frequencies."
7751142,"In a class of embodiments, a method and apparatus for detecting freefall of a disk device (thereby predicting that the disk device will likely suffer imminent physical impact) and typically also preventing damage that a disk drive of the device would otherwise suffer if and when a predicted impact occurs. In some embodiments, a disk device includes a freefall detection processor and a CPU. The freefall detection processor is configured to monitor acceleration data to determine whether the disk device is in freefall and to perform at least one other operation (e.g., decoding of MP3-encoded audio data to generate decoded audio data) while the CPU performs at least one other task. Other embodiments pertain to a portable device including a digital audio processing subsystem and an accelerometer. The digital audio processing subsystem is configured to monitor acceleration data to identify any rhythm associated with motion of the portable device and to modify the playback of audio data in response to any such identified rhythm."
7752351,"One embodiment of the present invention sets forth a technique for reducing the latency associated with media protection notification for serial interface mass storage devices, such as serial AT attachment (SATA) hard disk drives. A new link layer primitive, referred to as hold-emergency (HOLDE), incorporates the flow-control behavior of the existing HOLD command, with the additional new action of notifying the hard disk drive to take emergency steps to prepare for impact. The HOLDE link layer primitive operates in conjunction with the existing hold-acknowledge (HOLDA) primitive and is semantically similar to the existing HOLD primitive. The HOLDE mechanism is preferably implemented directly in hardware in the SATA link layer state machines within the host and the hard disk drive."
7755402,"Embodiments for positioning rising and/or filling edges of data strobe signals are disclosed. One example embodiment may comprise receiving a data signal, positioning an edge of a first delayed data strobe signal associated with the data signal by a first programmable amount, and positioning an edge of a second delayed data strobe signal associated with the data signal by a second programmable amount, wherein the second delayed data strobe signal is shifted approximately one bit-time in relation to the first delayed data strobe signal."
7755624,"A processor generates Z-cull information for tiles and groups of tiles. In one embodiment the processor includes an on-chip cache to coalesce Z information for tiles to identify occluded tiles. In a coprocessor embodiment, the processor provides Z-culling information to a graphics processor."
7755631,"Disclosed are an apparatus, a method, a programmable graphics processing unit (“GPU”), a computer device, and a computer medium to facilitate, among other things, the generation of parallel data streams to effect parallel processing in at least a portion of a graphics pipeline of a GPU. In one embodiment, an input of the apparatus receives graphics elements in a data stream of graphics elements. The graphics pipeline can use the graphics elements to form computer-generated images. The apparatus also can include a transposer configured to produce parallel attribute streams. Each of the parallel attribute streams includes a type of attribute common to the graphics elements. In one embodiment, the transposer can be configured to convert at least a portion of the graphics pipeline from a single data stream to multiple data streams (e.g., executable by multiple threads of execution) while reducing the memory size requirements to implement such a conversion."
7755634,"A system, method and computer program product are provided for branching during graphics processing. Initially, a first operation is performed on data. In response to the first operation, a branching operation is performed to a second operation. The first operation and the second operation are associated with instructions selected from a predetermined instruction set."
7755636,"A system, method and article of manufacture are provided for programmable processing in a computer graphics pipeline. Initially, data is received from a source buffer. Thereafter, programmable operations are performed on the data in order to generate output. The operations are programmable in that a user may utilize instructions from a predetermined instruction set for generating the same. Such output is stored in a register. During operation, the output stored in the register is used in performing the programmable operations on the data."
7756012,"A hash table in the network device driver maintains data on the traffic characteristics for each network interface (“NIC”) within a computing device. If one of the NICs in the computing device becomes unreliable, the cost function in the hash engine allows the software driver to initiate network traffic redistribution among the remaining reliable NICs in the computing device. Using this hash engine, the software driver is able to intelligently redirect each of the network connections on an unreliable NIC to a reliable NIC within the computing device, in a way that optimizes the distribution of network traffic across the remaining reliable NICs. Alternatively, if a connection is moved from an old NIC to a new NIC, the software driver can detect the moved connection and offload the moved connection to a hardware offload engine on the new NIC. With this approach, issues such as network interface overloading and computing device performance degradation may be more easily avoided when failing over network connections, thereby improving overall system performance relative to prior art techniques."
7756123,"A peripheral component interface express (PCIe) controller include a crossbar to reorder data lanes into an order compatible with PCIe negotiation rules. A full crossbar permits an arbitrary swizzling of data lanes, permitting greater flexibility in motherboard lane routing."
7756148,"Systems and methods for generating synthesizable code representing first-in first-out (FIFO) memories may be used to produce FIFO memories for multi-threaded processing. A single FIFO memory is shared between the threads to conserve die area, however each thread may be executed independently, as if each thread has a dedicated FIFO memory. A synthesizable code generator produces synthesizable code for a sender interface, storage, receiver interface, and other features that are specified by a programmer. The other features may reduce power consumption or improve timing. The code generator is used to efficiently produce different variations of FIFO memories."
7757073,"System configuration data is transferred from a master integrated circuit to a shadow integrated circuit in a computer system before the system is initialized. The configuration data is initially stored in configuration registers in the master integrated circuit. The configuration data may include values that are programmed via hardware (e.g., strapped pin values) or software (e.g., default or overridden values). A CPU accesses the configuration data in the configuration registers through a host module of the shadow integrated circuit. A copy of the configuration data is transferred to shadow registers in the shadow integrated circuit. After system initialization, the CPU may execute software to read configuration values directly from the configuration registers on the master integrated circuit. The CPU may also execute a write operation on the configuration data in both the configuration registers and the shadow registers such that the configuration settings are consistent across the system."
7760209,"Video conversion using a 3D graphics pipeline of a graphical processing unit (GPU) is disclosed. A plurality of video data formatted in a first video format is accessed from a memory unit. Moreover, the plurality of video data is converted from the first video format to a second video format using a 3D graphics pipeline of the GPU. The plurality of video data formatted in the second video format is sent to the memory unit. The 3D graphics pipeline applies a filtering technique. In an embodiment, the filtering technique is an interpolation technique."
7760619,"A hash table in the network device driver maintains data on the traffic characteristics for each network interface (“NIC”) within a computing device. If one of the NICs in the computing device becomes unreliable, the cost function in the hash engine allows the software driver to initiate network traffic redistribution among the remaining reliable NICs in the computing device. Using this hash engine, the software driver is able to intelligently redirect each of the network connections on an unreliable NIC to a reliable NIC within the computing device, in a way that optimizes the distribution of network traffic across the remaining reliable NICs. Alternatively, if a connection is moved from an old NIC to a new NIC, the software driver can detect the moved connection and offload the moved connection to a hardware offload engine on the new NIC. With this approach, issues such as network interface overloading and computing device performance degradation may be more easily avoided when failing over network connections, thereby improving overall system performance relative to prior art techniques."
7760936,Data that includes an encoded version of sets of color component values for a block of texels is accessed. The encoded version includes a first set of color component values selected from a pre-encoded version of the sets and a second set of color component values selected from the pre-encoded version of the sets. The first set and the second set correspond to endpoints of a range of colors. The encoded version further includes index values associated with the texels. The first set and the second set and an index value associated with a texel are used to decode a third set of color component values that describes a color for the texel. The index value indicates how to determine the third set using the first set and the second set.
7760968,"This document discusses, among other things, systems and methods that track overall time for processing operations such that the processing time can be shared among the resources in an efficient manner. Processing time can be shifted to image processing where the time will provide the most benefit to image quality. Moreover, access time from one process is banked to be used by a subsequent process or on a subsequent group of pixels.This document also discusses, among other things, systems and methods that provide additional processing power on an as needed basis. In an example, a processing stage and its controller are outside the normal pixel processing flow path. When it is determined that additional processing is required, the processing stage and its controller are activated to perform the additional processing.This document further discusses, among other things, systems and methods that provide parallel processing in a processing stage such that the data can flow internal to the controller linked to the processing stage and data can flow globally."
7761191,Disclosed are embodiments that may facilitate management of operation of an integrated circuit (IC) including adjustment of the IC. The adjustment may be based at least in part on a proximity of a temperature of the IC relative to a predetermined temperature.
7761697,"One embodiment of a computing system configured to manage divergent threads in a thread group includes a stack configured to store at least one token and a multithreaded processing unit. The multithreaded processing unit is configured to perform the steps of fetching a program instruction, determining that the program instruction is an indirect branch instruction, and processing the indirect branch instruction as a sequence of two-way branches to execute an indirect branch instruction with multiple branch addresses. Indirect branch instructions may be used to allow greater flexibility since the branch address or multiple branch addresses do not need to be determined at compile time."
7765500,"A method of more efficiently, easily and cost-effectively analyzing the performance of a device model is disclosed. Embodiments enable automated generation of theoretical performance analysis for a device model based upon a workload associated with rendering graphical data and a configuration of the device model. The workload may be independent of design configuration, thereby enabling determination of the workload without simulating the device model. Additionally, the design configuration may be updated or changed without re-determining the workload. Accordingly, the graphical data may comprise a general or random test which is relatively large in size and covers a relatively large operational scope of the design. Additionally, the workload may comprise graphical information determined based upon the graphical data. Further, the theoretical performance analysis may indicate a graphics pipeline unit of the device model causing a bottleneck in a graphics pipeline of the device model."
7768320,"One embodiment of the present invention sets forth a sense amplifier flop design that is tolerant of process variation. Specific staging of signal transitions through the sense amplifier flop circuit eliminate operational phases involving short-circuit currents between n-channel field-effect transistors (N-FETs) and p-channel field effect transistors (P-FETs) in a complementary-symmetry metal-oxide semiconductor process. By eliminating short-circuit currents between N-FETs and P-FETs within the sense amplifier flop, a large variation in conductivity ratio between N-FETs and P-FETs may be tolerated by the sense amplifier flop. This tolerance to conductivity ratio translates to a tolerance for process variation by the sense amplifier flop circuit."
7768515,A graphics processing unit has a reduced memory space shadow memory as a source of state information for performing validation of commands. The reduced memory space shadow memory is smaller in size than a full version of state variables associated with an abstract state machine representation of a class of commands received from a software driver. The reduced memory space shadow memory is used by validation logic to detect exceptions indicative of an illegal command or sequence of commands.
7768517,"A system for processing video data includes a host processor, a first media processing device coupled to a first buffer, the first media processing device configured to perform a first processing task on a frame of video data, and a second media processing device coupled to a second buffer, the second media processing device configured to perform a second processing task on the processed frame of video data. The architecture allows the two devices to have asymmetric video processing capabilities. Thus, the first device may advantageously perform a first task, such as decoding, while the second device performs a second task, such as post processing, according to the respective capabilities of each device, thereby increasing processing efficiency relative to prior art systems. Further, one driver may be used for both devices, enabling applications to take advantage of the system's accelerated processing capabilities without requiring code changes."
7768519,"A high-performance crossbar for a pipeline is disclosed. In particular, one embodiment of the crossbar receives multimedia data at a first throughput from a source operating in a first pipeline stage. The received data are stored in at least one input buffer corresponding to the source in the crossbar. The crossbar also causes the multimedia data from the input buffer to be routed to at least one output buffer at a second throughput. The output buffer corresponds to a destination operating in a second pipeline stage. Then the crossbar causes the multimedia data from the output buffer to be routed to the destination at the first throughput."
7768863,A device package that receives a voltage from a power supply on a motherboard and that includes provisions for a voltage control element that controls the power supply voltage. The provisions for the voltage control element are such that the voltage from the power supply has a first voltage if the voltage control element is installed and a second voltage if the voltage control element is missing. Such a device is useful in (computer) systems having wiring boards with power supplies that produce output voltages that depend on adjust voltages on adjust inputs. The provisions of the device package can then set the adjust voltage such that the power supply has a first voltage if the voltage control element is installed and a second voltage if the voltage control element is missing.
7769979,"A technique for caching page access parameters, in accordance with one embodiment of the present invention, includes translating a given virtual address to a particular physical address using an address translation data structure. One or more page access parameters related to the particular physical address is stored in a separate page access data structure. The technique may further include accessing the page access data structure to manage access to memory as a function of the page access data."
7770076,"The present disclosure pertains to multiple-platter disk drive digital data storage with integrated redundancy operations for improved reliability. Within a single disk drive assembly (300), one or more individual storage platters (304) can be used to store redundant data, enabling recovery of user data in the event that another platter (302) is defective, fails or is otherwise unavailable. “On-the-fly” redundancy operations (FIGS. 6A,6B) can be made transparent to the user or host, and impose no significant speed penalty. A data path switch (26) can reconfigure mappings between logical ports and platter interfaces (210) as needed."
7772696,"An integrated circuit package, according to one embodiment, includes a package substrate, an interface stratum and an integrated circuit die. Both the IC die and interface stratum are disposed on the package substrate. The integrated circuit die includes a microelectronic circuit having a plurality of inputs and outputs. A first set of the inputs and outputs are electrically coupled to a plurality of package-to-circuit connection regions on the package substrate. A second set of input and outputs are electrically coupled through the package substrate to package-to-circuit connection regions on the interface stratum."
7772885,"One embodiment of the present invention sets forth a technique for shifting the voltage level of signals from the high voltage domain to a low voltage domain, where VDD_IO is the supply voltage of the high voltage domain and VDD_Logic is the supply voltage of the low voltage domain. A level shifting circuit using a combination of I/O and logic transistors avoids exceeding a maximum tolerable voltage across the gate and source of any of the transistors. The level shifting circuit operates includes a reference voltage circuit that is independent of VDD_IO, so the same level shifting circuit may be used for various VDD_IO voltages. Additionally, the voltage level shifting circuit is not sensitive to scaling of VDD_Logic and operates properly when VDD_Logic is reduced due to shrinking silicon process technology and/or is reduced for a low power application."
7772891,"Apparatuses and methods are provided for a self-timed dynamic sense amplifier flop circuit, wherein a pulse generating circuit may be adapted to generate at least a first logic signal based, at least in part, on a first evaluation node signal, and a discharge path circuit comprising at least a first transistor within a first stack of transistors may be operatively responsive to the first timing signal."
7773090,"A kernel-mode graphics driver (e.g., a D3D driver running under Microsoft Windows) exploits the parallelism available in a dual-core computer system. When an application thread invokes the kernel-mode graphics driver, the driver creates a second (“auxiliary”) thread and binds the application thread to a first one of the processing cores. The auxiliary thread, which generates instructions to the graphics hardware, is bound to a second processing core. The application thread transmits each graphics-driver command to the auxiliary thread, which executes the command. The application thread and auxiliary thread can execute synchronously or asynchronously."
7773092,"The current invention involves new systems and methods for increasing texture filtering performance based on pixel coverage. When half of the pixels in a 2×2 pixel quad are not covered, texel coordinates for the uncovered pixels are not output. Therefore, the texels for the uncovered pixels are not read or processed, allowing the texel filtering processing throughput to be used to produce filtered results for covered pixels. This optimization is particularly useful when anisotropic filtering is used since the number of texels needed to produce a filtered result for a pixel increases as the anisotropic ratio increases. Elimination of unnecessary texel processing for uncovered pixels may improve texture filtering performance."
7774181,A system and method of providing physics data generated by a physics simulation and consumed by main application are provided. The main application may incorporate different scene versions or varying physics-based complexity while running on systems having different hardware and software resources.
7777750,"One embodiment of the invention sets forth a method for storing graphics data in a texture array in a local memory coupled to a graphics processing unit. The method includes the steps of specifying the texture array as a target in the local memory, and loading a first block of texture maps into the texture array, wherein each texture map in the first block has a first resolution and corresponds to a different slice of the texture array. One advantage of the disclosed method is that a complete block of texture images may be loaded into a texture array using a single API call. Thus, compared to prior art systems, where a texture array must be loaded one image for one slice of the array at a time, the disclosed method increases the efficiency of using arrays of texture maps for graphics processing operations."
7778800,"A method of calculating utilization and bottleneck performance parameters of a processing unit within a graphical processing unit (GPU). The utilization is a measure of a percentage that the processing unit is utilized over a draw call execution time. The bottleneck is the sum of the time period that the processing unit is active, the time period that the processing unit is full and does not accept data from an upstream processing unit, minus the time period that the processing unit is paused because the downstream processing unit is busy and cannot accept data, all over the execution time of the draw call. Performance parameters may be determined by sampling the processing unit and incrementing a counter when a condition is true. The method is repeated for the same draw call, for each processing unit of the GPU, and for a plurality of draw calls comprising a frame."
7779191,"A system and method for transitions a computing system between operating modes that have different power consumption characteristics. When a system management unit (SMU) determines that the computing system is in a low activity state, the SMU transitions the central processing unit (CPU) into a low power operating mode after the CPU stores critical operating state of the CPU in a memory. The SMU then intercepts and processes interrupts intended for the CPU, modifying a copy of the critical operating state. This effectively extends the time during which the CPU stays in lower power mode. When the SMU determines that the computing system exits a low activity state, the copy of the critical operating state is stored in the memory and the SMU transitions the CPU into a high power operating mode using the modified critical operating state."
7782334,"Systems and methods for performing data array resizing using a graphics processor resize a source data array of any dimensions to produce a destination data array of other dimensions. A pixel shader program may be used to configure the graphics processor to sample and filter the source data array to produce the destination data array. One or more destination data arrays may be mip maps of the source data array. A box filter or other type of filter may be used to produce each destination data array. Each pixel in the destination data array is produced in isolation, i.e., independently, thereby permitting the use of parallel processing to produce each pixel in the destination data array."
7782622,Disclosed is an attachment apparatus. The attachment apparatus may facilitate attachment of various components to a printed circuit board (PCB) including a thermal management component.
7787048,"One embodiment of a motion-adaptive video de-interlacing system includes a motion estimator and a pixel interpolator. The motion estimator determines the magnitude of motion associated with each pixel within a de-interlaced video frame. In some instances, as determined by the motion values, the pixel interpolator produces final pixel values by blending between pixel values produced through different de-interlacing methods optimized for different levels of pixel motion. The present invention advantageously produces de-interlaced video frames having relatively better picture quality than those produced using prior art techniques, especially for small pixel motions."
7788439,A bus interface permits an upstream bandwidth and a downstream bandwidth to be separately selected. In one implementation a link control module forms a bidirectional link with another bus interface by separately configuring link widths of an upstream unidirectional sub-link and a downstream unidirectional sub-link.
7788468,"A “cooperative thread array,” or “CTA,” is a group of multiple threads that concurrently execute the same program on an input data set to produce an output data set. Each thread in a CTA has a unique thread identifier assigned at thread launch time that controls various aspects of the thread's processing behavior such as the portion of the input data set to be processed by each thread, the portion of an output data set to be produced by each thread, and/or sharing of intermediate results among threads. Different threads of the CTA are advantageously synchronized at appropriate points during CTA execution using a barrier synchronization technique in which barrier instructions in the CTA program are detected and used to suspend execution of some threads until a specified number of other threads also reaches the barrier point."
7791193,"An integrated circuit and method of fabricating the same are provided. Included are an active circuit, and a metal layer disposed, at least partially, above the active circuit. Further provided is a bond pad disposed, at least partially, above the metal layer. To prevent damage incurred during a bonding process, the aforementioned metal layer is meshed."
7791611,"A data buffer incorporated in the read return path between a processing pipeline and a frame buffer enables data reads from the buffer to be in a different order from data writes to the buffer. With this buffer, the frame buffer no longer is required to process read requests in any particular order and can be configured for improved processing speeds. The buffer includes a RAM to which data from the frame buffer is written according to a first order and from which data is read according to a second order. The buffer may be configured with multiple RAMs if the speed of data arriving from the frame buffer is greater than the write speed of the RAM."
7791614,"Method and apparatus for display image adjustment is described. More particularly, handles associated with polygon vertices of a polygon rendered image are provided as a graphical user interface (GUI). These handles may be selected and moved by a user with a cursor pointing device to adjust a displayed image for keystoning, among other types of distortion. This GUI allows a user to adjust a projected image for position of a projector with respect to imaging surface, as well as for imaging surface contour, where such contour may be at least substantially planar, cylindrical, or spherical and where such contour may comprise multiple imaging surfaces. This advantageously may be done without special optics or special equipment. An original image is used as texture for rendering polygons, where the image is applied to the rendered polygons."
7791617,"A method for rendering adjacent polygons. The method includes determining when a first polygon and a second polygon have an abutting edge. If an abutting edge exists, a majority status is assigned to a pixel on the abutting edge. A first color of the first polygon or a second color of the second polygon is then allocated to the pixel in accordance with the majority status."
7792018,"A hash engine in a network device driver maintains data on the utilization and error rate for each network interface card (“NIC”) within a local computing device. From this data, the hash engine intelligently selects transmit NICs and receive NICs based on various networking parameters provided from a software driver program. Transmit packets sent from the operating system in a local computing device to a remote computing device are intercepted, modified and redirected to transmit NICs selected by the hash engine for transmission to remote computing devices. Similarly, address resolution protocol (“ARP”) response packets sent by the operating system in response to ARP request packets are intercepted, modified and redirected to receive NICs selected by the hash engine for transmission. By selecting receive NICs and transmit NICs in this fashion, the hash engine is able to intelligently load balance transmit and receive traffic in the local computing device, thereby improving overall network performance relative to prior art techniques."
7792891,"Systems and methods are disclosed to perform fast discrete cosine transform (DCT) by computing the DCT in five stages using three coefficients, and scaling the outputs using a plurality of scaling coefficients."
7792895,"The present invention enables efficient matrix multiplication operations on parallel processing devices. One embodiment is a method for mapping CTAs to result matrix tiles for matrix multiplication operations. Another embodiment is a second method for mapping CTAs to result tiles. Yet other embodiments are methods for mapping the individual threads of a CTA to the elements of a tile for result tile computations, source tile copy operations, and source tile copy and transpose operations. The present invention advantageously enables result matrix elements to be computed on a tile-by-tile basis using multiple CTAs executing concurrently on different streaming multiprocessors, enables source tiles to be copied to local memory to reduce the number accesses from the global memory when computing a result tile, and enables coalesced read operations from the global memory as well as write operations to the local memory without bank conflicts."
7793024,"A method for command transmission between systems is introduced. The command transmission between the systems, such as a north bridge chip, a south bridge chip and a central processing unit (CPU), employs the signals transmission specified by a PCI Express bus originally for the communication between system chips or peripheral devices. The signals transmission includes an interrupt or a system management instruction specified by the PCI Express bus, which further defines the specific addresses of a memory packet and a system message packet. In the preferred embodiment, the method thereof comprises the steps of transmitting an INTA command first, then a second system chip upstreams an INTR/system-management command to a first system chip. After that, the first system chip downstreams an EOI/system-management command to the second system chip."
7793029,"An apparatus and method for selectively configuring a first PCI Express connector and a second PCI Express connector. The apparatus includes a PCB (printed circuit board) having a PCI Express first connector and a PCI Express second connector mounted thereon. A translation device connector and a bridge component are also mounted on the PCB. The bridge component is coupled to the first connector, the second connector, and the translation device connector. The translation device connector is adapted to couple to a translation device in either a first orientation or a second orientation, wherein the first orientation configures the first connector for a first number of lanes and the second orientation configures the first connector and the second connector for a second number of lanes."
7793150,"A system, method, and computer program product are provided for saving an unprocessed portion of as push buffer in response to an error. In use, operation of hardware is controlled utilizing a push buffer. Furthermore, an error is detected. In response to the error, an unprocessed portion of the push buffer is saved, at least in part."
7796135,"Coherence of displayed images is provided for a graphics processing systems having multiple processors operating to render different portions of a current image in parallel. As each processor completes rendering of its portion of the current image, it generates a local ready event, then pauses its rendering operations. A synchronizing agent detects the local ready event and generates a global ready event after all of the graphics processors have generated local ready events. The global ready signal is transmitted to each graphics processor, which responds by resuming its rendering activity."
7796137,"Disclosed are an apparatus, a system, a method, a graphics processing unit (“GPU”), a computer device, and a computer medium to implement a pool of independent enhanced tags to, among other things, decouple a dependency between tags and cachelines. In one embodiment, an enhanced tag-based cache structure includes a tag repository configured to maintain a pool of enhanced tags. Each enhanced tag can have a match portion configured to form an association between the enhanced tag and an incoming address. Also, an enhanced tag can have a data locator portion configured to locate a cacheline in the cache in response to the formation of the association. The data locator portion enables the enhanced tag to locate multiple cachelines. Advantageously, the enhanced tag-based cache structure can be formed to adjust the degree of reusability of the enhanced tags independent from the degree of latency tolerance for the cacheline repository."
7796191,"One embodiment of an edge-preserving vertical interpolation system constructs a de-interlaced video frame on a pixel-by-pixel basis using an edge-preserving vertical interpolation technique. Pixels within a pixel window centered about a selected pixel determine the direction of an intensity gradient associated with the selected pixel. A first pixel is constructed by interpolating between pixels that are perpendicular to the direction of the intensity gradient and a confidence factor is computed that indicates the likelihood that there is only one edge within the pixel window. A second pixel is constructed using a non-edge-preserving vertical interpolation technique. Interpolating between the first pixel and the second pixel based on the confidence factor generates a pixel in the de-interlaced video frame corresponding to the selected pixel. Unlike prior art techniques, the present invention does not attempt to correlate between pixel features and is therefore more robust to noisy pixel data than prior art techniques."
7796465,"A memory controller provided according to an aspect of the present invention uses a slower clock signal during write leveling compared to when performing write operations thereafter. Due to such use of a slower clock signal, the various desired delays can be determined accurately and/or easily. In an embodiment, the frequency of the slower clock signal is determined based on the maximum fly-by delay (generally the delay between sending of a signal on the shared sequential path and the receipt at the memory unit in the sequence) that may be present in the memory system. For example, if the fly by delay can be M (an integer) times the time period of the clock signal during normal write operations, the slower clock signal may have a time period of M times that of the clock signal during write operation."
7796692,"A video coding apparatus, a decoder and a method for deferring the decoding of blocks of pixel data not yet ready for decoding during which other blocks of pixel data can be decoded nearly immediately. By deferring decoding and allowing the decoder to continue to successive blocks, the decoder can reduce stalls in the decoding process, which in turn, can decrease idle time in the decoder as well as power consumption that otherwise occurs during such idle time. In one embodiment, an exemplary method decodes a bit stream representing video images. The method includes deblocking blocks of a first frame as first frame blocks, determining a block of a second frame depends on a reference block of the blocks, and deferring decoding of the block. In at least one embodiment, the method can include decoding other blocks of the second frame at least partially concurrent with deferring decoding of the block."
7797258,A graphics system includes a transposer. A read scheduler utilizes a minimum cost analysis to schedule a read transfer order for the transposer to minimize the total number of passes required to process a set of input vectors.
7797510,"In a virtual memory system, address translation information is provided using a cluster that is associated with some range of virtual addresses and that can be used to translate any virtual address in its range to a physical address, where the sizes of the ranges mapped by different clusters may be different. Clusters are stored in an address translation table that is indexed by virtual address so that, starting from any valid virtual address, the appropriate cluster for translating that address can be retrieved from the translation table. The clusters are dynamically created from a fragmented pool of physical addresses as new virtual address mappings are requested by consumers of the virtual memory space."
7797561,An embodiment of the invention includes receiving an indicator of an activity-level of a functional block within an electronic chip. The functional block is included in a processing pipeline having a plurality of functional blocks. Each functional block from the plurality is configured to receive a clock signal from a clock signal generator. A status of the functional block is determined based on the activity-level. The clock signal to at least a portion of the functional block is disabled when the status is an inactive status.
7797824,A method for decreasing impedance of a power source in a printed circuit board includes: (a) forming a first metal plane over a first layer of the printed circuit board; (b) forming a second metal plane and a third metal plane over a second layer of the printed circuit board; (c) forming a dielectric layer between the first layer and the second layer of the printed circuit board for insulating the first layer from the second layer; and (d) connecting the second metal plane to an electric potential different from an electric potential of the first metal plane and the third metal plane.
7800699,"Field-based detection of 3:2 pulldown in a sequence of digital video fields using a programmable graphics processor is described. The detection is performed using a threshold value to determine equivalence between a pair of fields of digital video data. Furthermore, additional threshold values may be used to control switching into a mode where duplicated fields of digital video data are identified and not displayed and out of the mode where duplicated fields of digital video data are identified and not displayed. Look ahead can be used to detect when to switch into or out of the mode where duplicated fields of digital video data are identified and not displayed, reducing the occurrence of visual artifacts."
7800905,"A flat vapor chamber apparatus and method are provided for transferring heat between integrated circuits. In use, a flat vapor chamber is provided with a first end in thermal communication with a first integrated circuit and a second end in thermal communication with a second integrated circuit."
7802108,Aspects for securely storing program code of an embedded system includes accepting a digitation file from a distribution source into on-chip memory of an adaptive computing engine (ACE). The digitation file is then secured and transferred to off-chip memory.
7802118,An embodiment of the invention includes receiving an indicator of a flow of data associated with a graphics processing stage within a graphics pipeline of a graphics processor. A clock signal to a portion of the graphics processing stage is modified based on a status of the flow of data. The clock signal is received from a clock signal generator within the graphics processor.
7802147,"Method and apparatus for channel monitoring, channel throughput restoration and system testing in relation to channel monitoring and channel throughput restoration is described. A failure status of a channel is identified. The channel and at least one engine associated with the failure status is disabled. A client application assigned such a channel is notified that the channel has been disabled. The at least one engine and the channel associated with the failure status is restored. Additionally, the client application is allowed to destroy and reconstruct command status and state of the channel. Additionally, error information for the failure status is stored. Other aspects include: error injection which may be used for testing ability to detect an error and recover; and a graphical user interface for rendering mode selection for increasing channel throughput."
7802207,A method for generating a user-sharable network user interface is provided. A management interface is displayed. The management interface allows a user to select and manage information displayed on an information screen. The user is allowed to select information available in content sources. The selected information of the content source is marked and stored. The marked information is retrieved and displayed on the information screen. A second user is allowed to see the window of the information screen of the first user if the second user is authorized. The user is allowed to interact with customization tools via a wireless device for customizing the management interface. A pattern can be replayed for retrieving data for display. An application can be invoked for providing data for display. The information can also be translated.
7804499,"The current invention involves new systems and methods for providing variable rasterization performance suited to the size and shape of the primitives being rendered. Portions of pixel tiles that are fully covered by a graphics primitive are encoded and processed by the system as rectangles, rather than expanding to explicit samples. This accelerates the rendering of large primitives without increasing the computation resources used for rasterization. In some embodiments, these fully-covered regions can be rendered compressed without ever expanding into samples."
7804692,"A method and system for placing multiple loads in a high-speed system are disclosed. In one embodiment, the first load and the second load are placed on the first side and the second side of the printed circuit board, respectively. In addition, the first signal pin of the first load is vertically aligned with the second signal pin of the second load with an offset; the terminating end of a trace, which is connected to a driver on the printed circuit board, the first signal pin, and the second signal pin are connected at a T-point. The printed circuit also includes the first decoupling capacitor on the second side and the second decoupling capacitor on the first side. The first decoupling capacitor is connected to the first power pin of the first load. Similarly, the second decoupling capacitor is connected to a second power pin of the second load."
7805573,"Systems and methods for storing stack data for multi-threaded processing in a specialized cache reduce on-chip memory requirements while maintaining low access latency. An on-chip stack cache is used store a predetermined number of stack entries for a thread. When additional entries are needed for the thread, entries stored in the stack cache are spilled, i.e., moved, to remote memory. As entries are popped off the on-chip stack cache, spilled entries are restored from the remote memory. The spilling and restoring processes may be performed while the on-chip stack cache is accessed. Therefore, a large stack size is supported using a smaller amount of die area than that needed to store the entire large stack on-chip. The large stack may be accessed without incurring the latency of reading and writing to remote memory since the stack cache is preemptively spilled and restored."
7805587,"Embodiments of the present invention enable virtual-to-physical memory address translation using optimized bank and partition interleave patterns to improve memory bandwidth by distributing data accesses over multiple banks and multiple partitions. Each virtual page has a corresponding page table entry that specifies the physical address of the virtual page in linear physical address space. The page table entry also includes a data kind field that is used to guide and optimize the mapping process from the linear physical address space to the DRAM physical address space, which is used to directly access one or more DRAM. The DRAM physical address space includes a row, bank and column address. The data kind field is also used to optimize the starting partition number and partition interleave pattern that defines the organization of the selected physical page of memory within the DRAM memory system."
7808447,"A system, method, and computer program product are provided. In use, a unique monoscopic output is received from a graphics processor. The unique monoscopic output includes a first frame for display utilizing a first display, and a second frame for display utilizing a second display. Thus, a plurality of displays may be driven utilizing the unique monoscopic output."
7808507,Systems and methods for determining a compression tag state prior to memory client arbitration may reduce the latency for memory accesses. A compression tag is associated with each portion of a surface stored in memory and indicates whether or not the data stored in each portion is compressed or not. A client uses the compression tags to construct memory access requests and the size of each request is based on whether or not the portion of the surface to be accessed is compressed or not. When multiple clients access the same surface the compression tag reads are interlocked with the pending memory access requests to ensure that the compression tags provided to each client are accurate. This mechanism allows for memory bandwidth optimizations including reordering memory access requests for efficient access.
7808512,"In a raster unit of a graphics processor, a method for bounding region accumulation for graphics rendering. The method includes receiving a plurality of graphics primitives for rasterization in a raster stage of a graphics processor and rasterizing the graphics primitives to generate a plurality pixels related to the graphics primitives and a plurality of respective bounding regions related to the graphics primitives. Upon receiving an accumulation start command, the bounding regions are accumulated in an accumulation register. The accumulation continues until an accumulation stop command is received. The operation results in an accumulated bounding region. Access to the accumulated bounding region is enabled to facilitate a subsequent graphics rendering operation."
7808849,"Read leveling of memory units designed to receive access requests in a sequential chained topology writing a data pattern to the memory array. In an embodiment, a memory controller first writes a desired pattern into the memory array of a memory unit and then iteratively determines the accurate calibrated delay by setting a compensation delay to a test value, reading a data portion from the memory array based on the test value for the compensation delay, comparing the data portion with an expected data, determining that the test value is a calibrated compensation delay for the memory unit if the data portion equals the expected value."
7809782,"A method for selecting a set of parameters from a parameter space of a contemplated implementation of a pipelined processor for configuring the processor to generate an output word in response to each of a set of input words. The method includes determining a mapping between each set of parameters in the parameter space and the area of an integrated circuit implementation of the processor, and searching the parameter space to select a preferred set of the parameters that minimizes the area of the integrated circuit implementation subject to the constraints that each of the input word and the output word has specified format and that the preferred set of the parameters results in no more than a specified maximum error between the function of each of the input values and the approximation of the function of said each of the input values."
7809904,"Circuits, methods, and apparatus that pre-load data that may be needed by a graphics processor to render upcoming scenes. One example determines one or more possible upcoming scenes or views. To save computing resources, the possible upcoming scenes are not fully rendered, but the addresses, and corresponding pages, of data that would be needed to render the scenes are determined. Page usage information is also gathered. Pages that would be needed to render the upcoming scenes, but which are not resident in memory, are read in from a disk drive and stored in memory before they are needed. Pages that are infrequently used are removed from physical memory. In this way, when the scene changes, a large number of page faults do not occur in one frame, rather, they are distributed among several frames."
7809928,"One embodiment of an instruction decoder includes an instruction parser configured to process a first non-operative instruction and to generate a first event signal corresponding to the first non-operative instruction, and a first event multiplexer configured to receive the first event signal from the instruction parser, to select the first event signal from one or more event signals and to transmit the first event signal to an event logic block. The instruction decoder may be implemented in a multithreaded processing unit, such as a shader unit, and the occurrences of the first event signal may be tracked when one or more threads are executed within the processing unit. The resulting event signal count may provide a designer with a better understanding of the behavior of a program, such as a shader program, executed within the processing unit, thereby facilitating overall processing unit and program design."
7812737,"An apparatus, method, and computer program product are provided for conditionally actuating an illuminator, based on a connector status. In use, a status is determined for a connector adapted for being releasably connected to an input line. Further, an illuminator is conditionally actuated, based on the status."
7813204,"Memory component temperature information is used to implement a method for ODT (on die termination) thermal load management. A respective temperature of a plurality of memory components are accessed, and based on this temperature, an ODT cycle is directed to a first of the memory components to avoid imposing a thermal load from the ODT cycle on a second of the memory components."
7814020,"A system, method and computer program product are provided for carrying out a transaction. Initially, a transaction pattern reflecting a transaction is stored in memory. Thereafter, the transaction pattern is executed to carry out the transaction in an automated manner."
7814253,"An aspect of the present invention provides an arbiter which grants a request (to access a resource) in the same clock cycle as in which the requests from requesters is received. In one embodiment, such a feature may be provided in case of arbitration policies requiring state information from previous grants. In another embodiment, such a feature may be provided when the arbitration policy is programmable such that the same arbiter can be used for different arbitration policies."
7817154,"A graphics system has output states corresponding to a transformation of a user state of a software application to a graphics hardware state. The graphics system utilizes a technique, such as a conventional output state cache, to recognize that the overall state vector has taken on a previously-seen value. Additionally, a transition cache maps transitions in changing input state to changing output state. The transition cache is used to provide an alternative technique to determine output states based on transitions of input state."
7817165,"A computer-implemented graphics system has a mode of operation in which primitive coverage information is generated for real sample locations and virtual sample locations for use in anti-aliasing. An individual pixel includes a single real sample location and at least one virtual sample location. A block of real sample locations can be selected to delineate and encompass a region containing a number of virtual sample locations. Pixel attribute values (e.g., z-depth or stencil values) associated with the block of selected real sample locations can be used to associate each virtual sample location within the region with one of the selected real sample locations. The virtual sample location assumes the pixel attribute value of the real sample location with which it is associated."
7818806,Diagnostic software often requires pattern matching scanning to be performed to detect problems such as computer viruses or unwanted intruders. A computing system offloads pattern matching scanning from a central processing unit to a graphics processing unit.
7821517,"One embodiment of a video processor includes a first media processing device coupled to a first memory and a second media processing device coupled to a second memory. The second media processing device is coupled to the first media processing device via a scalable bus. A software driver configures the media processing devices to provide video processing functionality. The scalable bus carries video data processed by the second media processing device to the first media processing device where the data is combined with video data processed by the first media processing device to produce a processed video frame. The first media processing device transmits the combined video data to a display device. Each media processing device is configured to process separate portions of the video data, thereby enabling the video processor to process video data more quickly than a single-GPU video processor."
7821518,An apparatus and method for fairly arbitrating between clients with varying workloads. The clients are configured in a pipeline for processing graphics data. An arbitration unit selects requests from each of the clients to access a shared resource. Each client provides a signal to the arbitration unit for each clock cycle. The signal indicates whether the client is waiting for a response from the arbitration unit and whether the client is not blocked from outputting processed data to a downstream client. The signals from each client are integrated over several clock cycles to determine a servicing priority for each client. Arbitrating based on the servicing priorities improves performance of the pipeline by ensuring that each client is allocated access to the shared resource based on the aggregate processing load distribution.
7821520,"A new, useful, and non-obvious shader processor architecture having a shader register file that acts both as an internal storage register file for temporarily storing data within the shader processor and as a First-In First-Out (FIFO) buffer for a subsequent module. Some embodiments include automatic, programmable hardware conversion between numeric formats, for example, between floating point data and fixed point data."
7825835,"Embodiments of the claimed subject matter provide a method and system for performing data compression by encoding input into Exp-Golomb code. In one embodiment, data compression of data input is achieved via encoding as unsigned Exp-Golomb code. The method is achieved by converting the input, determining the position of the most significant bit in the converted input having a non-zero value (MSB), deriving information from the position of the MSB and arithmetically encoding the information to derive a compressed output."
7825933,"Systems and methods for compiling high-level primitive programs are used to generate primitive program micro-code for execution by a primitive processor. A compiler is configured to produce micro-code for a specific target primitive processor based on the target primitive processor's capabilities. The compiler supports features of the high-level primitive program by providing conversions for different applications programming interface conventions, determining output primitive types, initializing attribute arrays based on primitive input profile modifiers, and determining vertex set lengths from specified primitive input types."
7825935,"A system, method and computer program product are provided for retrieving instructions from memory utilizing a texture module in a graphics pipeline. During use, an instruction request is sent to memory utilizing a texture module in a graphics pipeline. In response thereto, instructions are received from the memory in response to the instruction request utilizing the texture module in the graphics pipeline."
7825936,"A method and system for optimizing graphics program execution by allowing the sharing of shader resources is disclosed. The method includes accessing a graphics program using a shader pipeline. If a texture projective instruction is included in the graphics program, a determination is made as to whether a texture projective parameter q indicates a non-projective texture. If the texture projective parameter indicates a non-projective texture, the texture projective instruction is demoted and a resulting demoted texture instruction is executed using a plurality of interpolators of the shader pipeline, which requires fewer shader resources."
7825937,"One embodiment of the present invention sets forth an improved method for computing a cube map blur function. The method begins with a rendered cube map of the surrounding scene using conventional environment rendering techniques. The method then proceeds with three successive cylindrical blurs around each axis of a coordinate frame. The three blur operations accumulate results from each predecessor operation for the different pixels of the cube map, thereby generating a high quality cube map blur. One advantage of this technique is that a relatively low computational effort yields a blur function involving a relatively large number of source pixels for each resulting pixel. Therefore, the resulting cube map can be computed in real-time and is suitable for use in a wide range of lighting effects."
7826838,"A method and apparatus for reducing a contention window range of a client device located in a wireless network is described. In one embodiment, network conditions present in the wireless network are monitored. The network conditions are subsequently utilized to determine if the wireless network is small or if traffic in the wireless network is low. Afterwards, the contention window range of the client device is reduced if either of the wireless network is small or if the traffic in the wireless network is low."
7827333,"One embodiment of the present invention sets forth a technique to determine a bus address for an add-in card on a System Management bus (SMbus) that includes a hybrid microcontroller (hEC) and discrete graphics processing unit (dGPU). A graphics driver requests the System Basic Input/Output System (SBIOS) for a list of available slave addresses. The graphics driver receives the list and selects an available slave address to be assigned to the hEC. The graphics driver assigns the selected address to the hEC through an Inter-Integrated Circuit bus backdoor. The graphics driver then passes the selected address back to the SBIOS and the selected address is removed from the list of available addresses. Advantageously, this approach to dynamically assigning bus addresses provides compatibility with different types of hECs as well as with different motherboard configurations and other SMbus devices."
7830175,An apparatus includes a single-rail input connected to a low-voltage domain and a voltage-transition circuit connected to the single-rail input. The voltage-transition circuit is configured to convert a voltage of the low-voltage domain received via the single-rail input to a voltage of the high-voltage domain.
7830386,"Systems and methods for using a graphics processor as a coprocessor to a general purpose processor to perform register transfer level simulations may improve simulation performance compared with using only the general purpose processor. The internal state of memory elements of an RTL model of an electronic circuit are stored as surface data for each simulation timestep. Transform functions are used to determine a next state based on the current state and simulation inputs. The transfer functions are expressed as a graphics program, such as a shader or vertex program that may be executed by a programmable graphics processor."
7830392,"The number of crossbars in a graphics processing unit is reduced by assigning each of a plurality of pixels to one of a plurality of pixel shaders based at least in part on a location of each of the plurality of pixels within an image area, generating an attribute value for each of the plurality of pixels using the plurality of pixel shaders, mapping the attribute value of each of the plurality of pixels to one of a plurality of memory partitions, and storing the attribute values in the memory partitions according to the mapping. The attribute value generated by a particular one of the pixel shaders is mapped to the same one of the plurality of memory partitions."
7831780,"A computer system utilizes subsystem supplemental memory resources to implement operating system supplemental disk caching. A main system processor (e.g., a central processing unit) processes information associated with main system functions. A bulk memory (e.g., a hard disk) stores the information. A main system memory (e.g., a main RAM) caches portions of the bulk information. A subsystem supplemental memory (e.g., a graphics subsystem RAM) provides storage capacity for subsystem operations (e.g., graphics operations) and supplemental storage for portions of said bulk information associated with main system functions (e.g., functions performed by the main system processor). Information (e.g., main system information) cached in the subsystem supplemental memory can be accessed by the main system processor directly."
7834881,"An apparatus and method for simulating a multi-ported memory using lower port count memories as banks. A collector units gather source operands from the banks as needed to process program instructions. The collector units also gather constants that are used as operands. When all of the source operands needed to process a program instruction have been gathered, a collector unit outputs the source operands to an execution unit while avoiding writeback conflicts to registers specified by the program instruction that may be accessed by other execution units."
7835301,A system and methods for wireless computing devices to become mesh member nodes within a self-configuring mesh network includes mechanisms for neighbor discovery and sharing of a common topology database including mesh topology and mesh network information. Each mesh node may use the topology database to determine optimized routing paths within the mesh network. Mesh member nodes are configured to detect and communicate topology changes and measured mesh network attributes to other members of the self-configuring wireless network.
7836116,"A linear transform such as a Fast Fourier Transform (FFT) is performed on an input data set having a number of points using one or more arrays of concurrent threads that are capable of sharing data with each other. Each thread of one thread array reads two or more of the points, performs an appropriate “butterfly” calculation to generate two or more new points, then stores the new points in a memory location that is accessible to other threads of the array. Each thread determines which points it is to read based at least in part on a unique thread identifier assigned thereto. Multiple transform stages can be handled by a single thread array, or different levels can be handled by different thread arrays."
7836118,"The present invention enables efficient matrix multiplication operations on parallel processing devices. One embodiment is a method for mapping CTAs to result matrix tiles for matrix multiplication operations. Another embodiment is a second method for mapping CTAs to result tiles. Yet other embodiments are methods for mapping the individual threads of a CTA to the elements of a tile for result tile computations, source tile copy operations, and source tile copy and transpose operations. The present invention advantageously enables result matrix elements to be computed on a tile-by-tile basis using multiple CTAs executing concurrently on different streaming multiprocessors, enables source tiles to be copied to local memory to reduce the number accesses from the global memory when computing a result tile, and enables coalesced read operations from the global memory as well as write operations to the local memory without bank conflicts."
7836276,"A SIMD processor efficiently utilizes its hardware resources to achieve higher data processing throughput. The effective width of a SIMD processor is extended by clocking the instruction processing side of the SIMD processor at a fraction of the rate of the data processing side and by providing multiple execution pipelines, each with multiple data paths. As a result, higher data processing throughput is achieved while an instruction is fetched and issued once per clock. This configuration also allows a large group of threads to be clustered and executed together through the SIMD processor so that greater memory efficiency can be achieved for certain types of operations like texture memory accesses performed in connection with graphics processing."
7836318,"Circuits, methods, and apparatus for slowing clock circuits on a graphics processor integrated circuit in order to reduce power dissipation. An exemplary embodiment of the present invention provides a graphics processor having two memory clocks, specifically, a switched memory clock and an unswitched memory clock. The switched memory clock frequency is reduced under specific conditions, while the unswitched memory clock frequency remains fixed. In a specific embodiment, the switched memory clock frequency is reduced when related graphics, display, scaler, and frame buffer circuits are not requesting data, or are such data requests can be delayed. Further refinements to the present invention provide circuits, methods, and apparatus for ensuring that the switched and unswitched memory clock signals remain in-phase and aligned with each other."
7838999,"An integrated circuit/substrate interconnect apparatus and method of manufacture are provided. Included is a substrate with a plurality of wells and a landing pad formed in each of the wells. The substrate further includes a seed layer deposited in each of the wells over the landing pad, and a metalized layer deposited in each of the wells over the seed layer. Before assembly, an upper surface of the metalized layer forms a well."
7839170,"One embodiment of the present invention sets forth a technique for shifting the voltage level of signals from a low voltage domain to a high voltage domain, where VDDH is the supply voltage of the high voltage domain and VDDL is the supply voltage of the low voltage domain. A level shifting circuit uses a single input rather than dual rail inputs and does not produce a direct current flow in order to reduce the power consumption. The voltage level shifting circuit may also be used to shift a clock signal since the delays of the rising and falling edges of the clock signal are matched by using a delay element."
7839410,"One embodiment of the invention is a method for accessing and updating data in a buffer object during the execution of a shader program. The method includes loading a plurality of data portions in the buffer object, initiating a first execution of a shader program that accesses a first portion of data in the buffer object, receiving a request to update the first portion of data in the buffer object; updating a version of the first portion of data in the buffer object to reflect the update, initiating a second execution of a shader program that accesses the updated version of the first portion of data in the buffer object, wherein the second execution of the shader program occurs without waiting for the execution of the first shader program to complete."
7840706,"A method and system for supporting Wake-on-LAN (WOL) in a team of network interface cards (NICs) in a computing device is disclosed. One embodiment of the present invention sets forth a method, which includes the steps of programming each of the NICs on the team with a team Media Access Control (MAC) address after having backed up the NIC MAC addresses of the NICs but before the computing device enters a low power state, and causing modification of address resolution protocol (ARP) caches associated with a plurality of client devices coupled to the team of NICs to use the team MAC address."
7842948,"A device and method for providing access to a signal of a flip chip semiconductor die. A hole is bored into a semiconductor die to a test probe point. The hole is backfilled with a conductive material, electrically coupling the test probe point to a signal redistribution layer. A conductive bump of the signal redistribution layer is electrically coupled to a conductive contact of a package substrate. An external access point of the package substrate is electrically coupled to the conductive contact, such that signals of the flip chip semiconductor die are accessible for measurement at the external access point."
7843458,"Circuits, methods, and apparatus that are capable of processing graphics information and wirelessly transmitting processed graphics information to a monitor. In order to achieve a high bandwidth, one embodiment of the present invention provides a graphics processor chip that includes multiple RF transmitters such that processed graphics information can be transmitted using the cumulative bandwidth of multiple wireless channels. These transmitters can use one or more RF standards or proprietary signaling schemes."
7843463,"One embodiment of the present invention sets forth a technique to setup efficient bump mapping using a geometry shader. This approach uses a vertex shader, a primitive assembly unit, and a geometry shader. The vertex shader performs vertex operations, such as calculating a per-vertex normal vector, and emits vertex data. The primitive assembly unit processes the vertex data and constructs primitives. Each primitive includes a series of one or more vertices, each of which may be shared amongst multiple primitives, and state information defining the primitive. The geometry shader processes each primitive, calculating an object-space to texture-space mapping for each vertex of the primitive and, subsequently, using this mapping to transform the object-space view vector and the object-space light vectors associated with each vertex of the primitive to texture-space equivalents. Advantageously, this approach to setting up bump mapping fully utilizes the GPU, thereby optimizing both hardware resources and performance."
7843468,"In a raster stage of a graphics pipeline, a method for accelerated start tile rasterization. The method includes defining a window for clipping a generated image and receiving a graphics primitive for rasterization in a raster stage of a graphics processor. A binary search related to the window is performed to determine a start tile having at least a partial coverage of the graphics primitive, wherein the start tile comprises a plurality of pixels. Based upon the start tile, the raster stage rasterizes the graphics primitive by generating a plurality of adjacent tiles having at least a partial coverage of the graphics primitive."
7843971,"A modular expandable telecommunication system having a main cabinet and at least one expansion cabinet that are interconnected with each other to obtain an extended telecommunication system with increased connection possibilities for extensions and trunks. The main cabinet and each expansion cabinet have a transmission interface unit allowing connection of the expansion cabinet(s) to the main cabinet via a single transmission link conveying voice/data channels and low level signaling for mutual synchronization and clock recovery for all interconnected cabinets. The main cabinet has a master clock device, a CPU for running software applications and a DSP for routing the higher level messages issued by the CPU depending on the physical location of the expansion cabinet."
7844408,"A time domain reflectometry (“TDR”) testing method that includes storing test data resulted from a TDR test applied on an electronic component, displaying the test data, identifying a distinctive portion of the test data corresponding to a defective location in the electronic component, modifying the distinctive portion of the test data, and computing the modified test data to verify whether a predetermined requirement is satisfied."
7844880,"Systems and methods are disclosed to detect and correct errors in a flash memory using an error correction cache that provides error correction information by accessing data from a physical block number (PBN) of the flash memory; and if a data error occurred, applying error correction information stored in the cache corresponding to the accessed PBN to correct the data error."
7847802,"A graphics system coalesces Z data and color data for a raster operations stage. The Z data and color data are stored in a memory aligned tile format. In one embodiment, rendering modes in which the tile does not have a data capacity corresponding to Z data or color data for a whole number of pixels have data for at least one pixel split across entries to improve packing efficiency. Rendering modes having a number of bits for Z data or color data that does not equal a power of two such as 24 bits, 48 bits, and 96 bits, may be implemented with a high packing efficiency in tile formats having a data capacity corresponding to a power of 2 bits."
7849332,"The present invention facilitates maintenance of processor speed by voltage level adjustment. In one embodiment, a present invention voltage adjustment system includes a speed analysis component that compares an actual speed of a processing unit to a directed speed. If the actual speed is lower than the directed speed, a voltage control component directs offset adjustments in a voltage level of a power signal to the processor. For example, the voltage control component directs an increases in a voltage level of a power signal. The voltage level can be altered to compensate for variations in hardware tolerance variations. In one embodiment of the present invention, a voltage sensor measures the actual voltage of the processing unit."
7849336,Embodiments for generating a boost voltage in a computing platform are disclosed.
7849342,"A method and system for implementing a generalized system stutter are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of blocking a first request received from a first of a plurality of bus masters during a low power state of a computing device for as long as permissible by the timing requirements of the computing device, wherein the first request is capable of triggering the computing device to transition out of the low power state, and during an active state of the computing device, servicing the first request along with other pending requests from the rest of the plurality of bus masters before the computing device transitions back to the low power state."
7849510,"A data storage system providing transparent encryption. The data storage system has a hardware encryption/decryption engine and a register coupled to the hardware encryption/decryption engine. The register is for securely storing a key for encrypting and decrypting data. The key may not be read from outside the data storage system. More specifically, the key may not be read by the operating system. The user does not have access to the encryption key, but may have a password that is passed to a controller coupled to the encryption/decryption engine. The controller verifies the password and causes data received from main memory to be encrypted by the hardware encryption/decryption engine using the key. The controller also transfers the encrypted data to the data storage device."
7852340,"A scalable shader architecture is disclosed. In accord with that architecture, a shader includes multiple shader pipelines, each of which can perform processing operations on rasterized pixel data. Shader pipelines can be functionally removed as required, thus preventing a defective shader pipeline from causing a chip rejection. The shader includes a shader distributor that processes rasterized pixel data and then selectively distributes the processed rasterized pixel data to the various shader pipelines, beneficially in a manner that balances workloads. A shader collector formats the outputs of the various shader pipelines into proper order to form shaded pixel data. A shader instruction processor (scheduler) programs the individual shader pipelines to perform their intended tasks. Each shader pipeline has a shader gatekeeper that interacts with the shader distributor and with the shader instruction processor such that pixel data that passes through the shader pipelines is controlled and processed as required."
7852341,"A method and system for patching instructions in a 3-D graphics pipeline. Specifically, in one embodiment, instructions to be executed within a scheduling process for a shader pipeline of the 3-D graphics pipeline are patchable. A scheduler includes a decode table, an expansion table, and a resource table that are each patchable. The decode table translates high level instructions to an appropriate microcode sequence. The patchable expansion table expands a high level instruction to a program of microcode if the high level instruction is complex. The resource table assigns the units for executing the microcode. Addresses within each of the tables can be patched to modify existing instructions and create new instructions. That is, contents in each address in the tables that are tagged can be replaced with a patch value of a corresponding register."
7852345,"One embodiment of the invention is a method of accessing a bindable uniform variable bound to a buffer object that includes the steps of creating a linked program object comprising one or more shader programs, where each shader program includes instructions written in a high-level shader language, and where the linked program object includes a reference to a bindable uniform variable and indicates which shader programs use the bindable uniform variable. The method also includes determining a memory size to support the bindable uniform variable, allocating a buffer object having the memory size, binding the buffer object to the bindable uniform variable, populating the buffer object with values for the bindable uniform variable, and accessing the values of the bindable uniform with one or more of the shader programs in the linked program object."
7852346,"A programmable graphics processor including an execution pipeline and a texture unit is described. The execution pipeline processes graphics data as specified by a fragment program. The fragment program may include one or more opcodes. The texture unit includes one or more sub-units which execute the opcodes to perform specific operations such as an LOD computation, generation of sample locations used to read texture map data, and address computation based on the sample locations."
7852347,"The current invention involves new systems and methods for increasing texture filtering performance by reorganizing a texture sampling order used to read and filter texels when anisotropic filtering is used. Texel read performance is improved for anisotropic filtering by reorganizing texel reads when a texel cache is used. The texel reads are paired based on a major axis alignment in pixel space. The paired texel reads for a pixel footprint may also be ordered to improve texel coherency, thereby improving a texture cache hit rate."
7852412,"Circuits, methods, and apparatus for measuring a video signal's noise level. The determination can be made based on pixel values for a single video image frame, for example, by comparing pixel color values, luminance, or other parameter for a first and second group of pixels in the frame. Each group of pixels may be part of a line in the frame, and several such measurements may be made along each line of the frame. These measurements can then be further refined depending on the measure noise level. Once a video noise level is determined, a decision on how to further process the video signal can be made. For example, the picture can be filtered or sharpened. The amount of noise filtering can be made dependent on the amount of noise measured."
7853044,"An image processing system including a plurality of image processors. Each image processor is configured to carry out a different image processing operation. The system also includes a motion estimator. For image processor, the motion estimator is configured to obtain motion information for a pixel or pixels being applied as a processing input to the image processor."
7859541,"A graphics system utilizes page table entries to provide information on the storage format used to store graphics data. The page table entries, in turn, may be used for address translation. Exemplary kinds of storage format information include compression mode, a packing mode for storing Z data in tiles or color data in tiles, and a mode for allocating tile data among partitions in a partitioned memory."
7859542,"A method for synchronizing two of more graphics processing units. The method includes the steps of determining whether the phase of a first timing signal of a first graphics processing unit and the phase of a second timing signal of a second graphics processing unit are synchronized, and adjusting the frequency of the first timing signal to the frequency of the second timing signal if the first timing signal and the second timing signal are not synchronized."
7859548,"Systems and methods for performing cube mapping computations using a shader program may reduce the need for fixed function cube mapping computation units in graphics processors. Therefore, die area is used more efficiently since a general purpose processing unit may be configured using shader program instructions to perform the cube mapping computations and other computations. The general purpose processing unit is configured to perform floating point computations to identify the cube map face that will be read and process the cube map coordinates. A fixed function unit is also configured to identify the cube map face that will be read to avoid passing the cube map face information from the general purpose processing unit to the fixed function unit."
7860912,"An embodiment of the invention includes a first pseudo-random number generator that is configured to produce a first sequence of values at a first clock rate. Also, a second pseudo-random number generator is configured to produce a second sequence of values at a second clock rate. The second clock rate is based on the first sequence of values and the first clock rate. A logical module is connected to the first pseudo-random number generator and the second pseudo-random number generator. The logical module is configured to produce an output value based on at least a portion of a value from the first sequence of values and at least a portion of a value from the second sequence of values."
7861060,"Parallel data processing systems and methods use cooperative thread arrays (CTAs), i.e., groups of multiple threads that concurrently execute the same program on an input data set to produce an output data set. Each thread in a CTA has a unique identifier (thread ID) that can be assigned at thread launch time. The thread ID controls various aspects of the thread's processing behavior such as the portion of the input data set to be processed by each thread, the portion of an output data set to be produced by each thread, and/or sharing of intermediate results among threads. Mechanisms for loading and launching CTAs in a representative processing core and for synchronizing threads within a CTA are also described."
7861067,"The present invention utilizes an asynchronous pipeline cycle to facilitate increased average pipeline processing speed. Present invention adjustable cycle pipeline systems and methods minimize “stalls” in execution stages that would otherwise be required to compensate for differences in execution periods. In one embodiment, an adjustable cycle pipeline system includes a fetch stage, a decode stage, an execution stage, and a write stage. The fetch stage fetches information associated with an operation. The decode stage decodes the instructions including determining an instruction execution period. The execution stage executes instructions in accordance with the execution period and the write stage writes the results. In one exemplary implementation the instruction execution period corresponds to a particular number execution sub-clock cycles and the decode stage includes a decode operation timetable for indicating a period of time to complete execution of an operation. The sub-clock controls operations of the execution stage."
7864183,A graphics system includes a graphics memory. The graphics system includes a high performance mode and at least one power savings mode. A termination impedance and switching threshold of the graphics memory are selected based on an operating mode of the graphics system.
7864185,"A graphics processing unit can queue a large number of texture requests to balance out the variability of texture requests without the need for a large texture request buffer. A dedicated texture request buffer queues the relatively small texture commands and parameters. Additionally, for each queued texture command, an associated set of texture arguments, which are typically much larger than the texture command, are stored in a general purpose register. The texture unit retrieves texture commands from the texture request buffer and then fetches the associated texture arguments from the appropriate general purpose register. The texture arguments may be stored in the general purpose register designated as the destination of the final texture value computed by the texture unit. Because the destination register must be allocated for the final texture value as texture commands are queued, storing the texture arguments in this register does not consume any additional registers."
7864203,"A system, method, and computer program product are provided for adjusting a viewing experience associated with a display device. During use, a user interface capable of being used for adjusting the viewing experience associated with the display device is automatically displayed, in response to an event that potentially affects the viewing experience associated with the display device."
7865638,"One embodiment of the invention sets forth a method for performing a queue allocation operation that includes receiving a memory address associated with a queue allocation aperture, where the memory address is read by a client to request memory space in a memory queue for a payload, computing a payload size based on the memory address, determining an insertion pointer for the payload based on a first position of a horizon pointer, where the insertion pointer indicates a location within the memory queue for the client to insert the payload, adjusting the horizon pointer to a second position based on the payload size, and returning the insertion pointer to the client. Such an approach enables multiple clients to advantageously request and obtain space within a shared memory queue in a single atomic operation, thereby allowing clients to share a memory queue more efficiently relative to prior art approaches."
7865894,"Embodiments of the present invention facilitate distributing processing tasks within a processor. In one embodiment, processing clusters keep track of resource requirements. If sufficient resources are available within a particular processing cluster, the available processing cluster asserts a ready signal to a dispatch unit. The dispatch unit is configured to pass a processing task (such as a cooperative thread array or CTA) to an available processing cluster that asserted a ready signal. In another embodiment, a processing task is passed around a ring of processing clusters until a processing cluster with sufficient resources available accepts the processing task."
7868891,"Embodiments of methods, apparatuses, devices, and/or systems for load balancing two processors, such as for graphics and/or video processing, for example, are described."
7868901,"Embodiments of the present invention sets forth a method and system for reducing memory bandwidth requirements for an anti-aliasing operation. The first virtual coverage information for a pixel involved in an anti-aliasing operation is maintained in memory. If a certain operating condition of the anti-aliasing operation deterministically implies the second virtual coverage information for this pixel, the second virtual coverage information, as opposed to the first virtual coverage information, is used in the anti-aliasing operation. In such situations, since the virtual coverage information is implied, it does not have to be accessed from memory, thereby improving overall system performance."
7868902,"A system and method for a row forwarding of pixel data in a 3-D graphics pipeline. Specifically, in one embodiment a data write unit capable of row forwarding in a graphics pipeline includes a first memory and logic. The first memory stores a plurality of rows of pixel information associated with a pixel. The plurality of rows of pixel information includes data related to surface characteristics of the pixel and includes a first row, e.g., a front row, and a second row, e.g., a rear row. A data write unit includes first logic for accessing a portion of the second row and for storing data accessed therein into a portion of the first row. The data write unit also comprises logic for recirculating the plurality of rows of pixel information to an upstream pipeline module for further processing thereof."
7869666,"An image processing system and method, in which a plurality of image processing operations are dynamically controlled based on dynamically changing tag data associated with pixels being processed."
7869835,"Embodiments of the present invention recite a method and system for pre-loading and executing code within the cache. In one embodiment, an indication to operate an electronic device in a sleep state is received. At least one instance of code is loaded into a cache memory in response to receiving the indication. The at least one instance of code is for causing the electronic device to operate in said sleep state. In embodiments of the present invention, the at least one instance of code further comprises a registry setting for a memory controller. The at least one instance of code is then accessed from the cache memory."
7870350,"A write buffer for read-write interlocks improves memory access performance by minimizing the latency needed to avoid a read-after-write hazard when a read follows a write to the same memory location. Rather than waiting until a write has been stored in the memory location, the write buffer provides an acknowledgement signal before the data has been stored in memory in order for a subsequent read of the memory location to proceed. The write buffer merges the data to be written with any data that is stored in memory for the read request to return the current data for the read request."
7870524,"A method and system for automating unit performance testing in integrated circuit design is disclosed. One embodiment of the present invention sets forth a method, which includes the steps of generating a first performance data for the unit to operate on a workload, embedding the first performance data in the workload for a register transfer level (RTL) implementation of the unit to operate on, and determining whether the expected performance of the unit is achieved based on the comparison between the first performance data and a second performance data, wherein the second performance data is generated after the RTL implementation of the unit operates on the workload."
7872657,"Systems and methods for addressing memory where data is interleaved across different banks using different interleaving granularities improve graphics memory bandwidth by distributing graphics data for efficient access during rendering. Various partition strides may be selected to modify the number of sequential addresses mapped to each DRAM and change the interleaving granularity. A memory addressing scheme is used to allow different partition strides for each virtual memory page without causing memory aliasing problems in which physical memory locations in one virtual memory page are also mapped to another virtual memory page. When a physical memory address lies within a virtual memory page crossing region, the smallest partition stride is used to access the physical memory."
7872668,"This document discusses, among other things, systems and methods for receiving a local input video signal, processing the video signal, and providing a processed video signal to a local digital television display panel. A communications port includes an Ethernet or other communications network connector for allowing access to the video signal processing system by a remote device. This allows a remote user to remotely diagnose, debug, and even modify operation of the video signal processing system. In certain examples, this involves downloading a Lua script that can take partial or complete control over operation of the video signal processing system from resident instruction code. In certain examples, the video signal processing system includes pipelined image analysis or processing stages. Video signal data intermediate to such processing, or the processed video signal being provided to the local display can be communicated to the remote user."
7873881,"A reconfigurable bit-manipulation node is disclosed. The node includes an execution unit configured to perform a number of bit-oriented functions and a control unit configured to control the execution unit to allow one of the bit-oriented functions to be performed. The execution unit includes a number of elements interconnected with one another to allow the bit-oriented functions to be performed. The elements include a programmable butterfly unit, a number of non-programmable butterfly units, a number of data path elements, a look-up table memory, and a reorder memory. The execution unit is capable of engaging in one of a number of operating modes to perform the bit-oriented functions. The operating modes include a programmable mode and a number of fixed operating modes including Viterbi decoding, turbo decoding and variable length encoding and decoding. The data path elements include a programmable shifter and a programmable combiner."
7876327,"Display data and video data are stored within a graphics processing unit to reduce power consumed by the computing device during video playback. Storing display data and video data within the GPU reduces power consumption, because bus transaction activity is reduced and the need to read data from a larger, common main memory is avoided."
7876332,"A computer-implemented graphics system that includes a rasterizer and a shader has a mode of operation in which primitive coverage information is generated for real sample locations and virtual sample locations for use in anti-aliasing. An individual pixel includes a single real sample location and at least one virtual sample location. In some instances, a primitive may cover only virtual sample locations and does not cover a real sample location. These instances can be identified in the coverage information sent from the rasterizer to the shader, so that the shader can determine whether or not it can write color information, depth information and/or stencil information for the real sample location to a framebuffer."
7876378,"Video filtering using a programmable graphics processor is described. The programmable graphics processor may be programmed to complete a plurality of video filtering operations in a single pass through a fragment-processing pipeline within the programmable graphics processor. Video filtering functions such as deinterlacing, chroma up-sampling, scaling, and deblocking may be performed by the fragment-processing pipeline. The fragment-processing pipeline may be programmed to perform motion adaptive deinterlacing, wherein a spatially variant filter determines, on a pixel basis, whether a “bob”, a “blend”, or a “weave” operation should be used to process an interlaced image."
7876996,"A method and system for time-shifting video. Specifically, in the method a digital input video signal is received at a processor unit, such as a video processor unit (VPU). A live feed of the digital input video signal is provided as a digital output video signal for display. In parallel, the digital input video signal is stored as video frames. Also, the digital input video signal is recorded for time-shifting. An instruction is received to display a previously seen frame of the digital output video signal. The previously seen frame is repeatedly accessed and provided from that the stored video frames. The previously seen frame that was recorded is accessed when available. Thereafter, the method switches from the previously seen frame stored as video frames to the previously seen frame that was recorded for providing as an output for display."
7877565,Systems and methods for using multiple versions of programmable constants within a multi-threaded processor allow a programmable constant to be changed before a program using the constants has completed execution. Processing performance may be improved since programs using different values for a programmable constant may execute simultaneously. The programmable constants are stored in a constant buffer and an entry of a constant buffer table is bound to the constant buffer. When a programmable constant is changed it is copied to an entry in a page pool and address translation for the page pool is updated to correspond to the old version (copy) of the programmable constant. An advantage is that the constant buffer stores the newest version of the programmable constant.
7877573,"One embodiment of the present invention sets forth a technique for computing a parallel prefix sum using one or more cooperative thread arrays (CTA) within a graphics processing unit. The prefix sum input list is partitioned and distributed to each CTA. Within each CTA, the input list is further partitioned for processing by individual threads in a way that avoids access conflicts to memory. Each list partition within the CTA is assigned to one of a plurality of concurrent threads, which executes a prefix sum operation the partition. The final values of the prefix sum operations form a list that is then subjected to a second prefix sum operation. Each element of the second prefix sum operation is added to each element of the subsequent partition, completing the prefix sum operation within the CTA. This technique may be extended to prefix sum operations that span two or more CTAs."
7877585,"One embodiment of a computing system configured to manage divergent threads in a SIMD thread group includes a stack configured to store state information for processing control instructions. A parallel processing unit is configured to perform the steps of determining if one or more threads diverge during execution of a conditional control instruction. A disable mask allows for the use of conditional return and break instructions in a multithreaded SIMD architecture. Additional control instructions are used to set up thread processing target addresses for synchronization, breaks, and returns."
7880631,"A coordinate-based system, method, and computer program product are provided for disabling a device. In use, a power down state of a device is detected. In response to the power down state, a first set of coordinates of the device is stored. Additionally, a power up state of the device is detected. In response to the power up state, a second set of coordinates of the device is identified. Further, the first set of coordinates and the second set of coordinates are compared. To this end, the device may be conditionally disabled based on the comparison."
7880747,"A technique for handling floating-point special values, e.g., Infinity, NaN, −Zero, and denorms, during blend operations is provided so that blend operations on fragment color values that contain special values can be performed in compliance with special value handling rules. In particular, the presence of special values is detected or the potential presence of special values is detected. This information is used to qualify when blend optimizations may be performed, so that floating point blend operations can remain conformant to special value handling rules."
7882292,"An arbiter decides to grant access from multiple clients to a shared resource (e.g. memory) using efficiency and/or urgency terms. Urgency for a client may be determined based on an “in-band” request identifier transmitted from the client to the resource along with the request, and an “out-of-band” request identifier that is buffered by the client. A difference between the out-of-band request identifier and the in-band request identifier indicates the location of the request in the client buffer. A small difference indicates that the request is near the end of the buffer (high urgency), and a large difference indicates that the request is far back in the buffer (low urgency). Efficiency terms include metrics on resource overhead, such as time needed to switch between reading/writing data from/to memory via a shared memory bus, or bank management overhead such as time for switching between DRAM banks."
7882295,"Disclosed are a method and apparatus of non-system bus width data transfer executable at a non-aligned system bus address. In one embodiment, a method of a controller is described. The method includes applying a FIFO buffer having a buffer width (e.g., determined using a transfer algorithm) that is wider than that of a system bus width. A system bus that permits transfer of data amounts which are non-integer multiples of a width of the system bus is used. The system bus is designed such that it supports any non-aligned system bus address. Data is transferred between devices coupled to the system bus."
7882296,"Circuits, apparatus, and methods for avoiding deadlock conditions in a bus fabric. One exemplary embodiment provides an address decoder for determining whether a received posted request is a peer-to-peer request. If it is, the posted request is sent as a non-posted request. A limit on the number of pending non-posted requests is maintained and not exceed, such that deadlock is avoided. Another exemplary embodiment provides an arbiter that tracks a number of pending posted requests. When the number pending posted requests reaches a predetermined or programmable level, a Block Peer-to-Peer signal is sent to the arbiter's clients, again avoiding deadlock."
7882369,"The present invention performance enhancement and reliability maintenance system and method pushes a processor to its maximized performance capabilities when performing processing intensive tasks (e.g., 3D graphics, etc). For example, a clock speed and voltage are increased until an unacceptable error rate begins to appear in the processing results and then the clock speed and voltage are backed off to the last setting at which excessive errors did not occur, enabling a processor at its full performance potential. The present invention also includes the ability to throttle back settings which facilitates the maintenance of desired reliability standards. The present invention is readily expandable to provide adjustment for a variety of characteristics in response to task performance requirements. For example, a variable speed fan that is software controlled can be adjusted to alter the temperature of the processor in addition to clock frequency and voltage."
7882380,"A system and method for enabling or disabling clocks to one or more portions of hardware circuitry, for example a display sub-system of a personal computer. A processor generates a command or data to a first circuit configured to perform a function based at least on the command or data. A clock generator selectively supplies clocks to the first circuit and a second circuit configured to perform a second function. A software interface circuit coupled to the processor and the clock generator autonomously determines based at least on the command or data whether the second circuit will perform the second function or be idle in an upcoming period and disables one or more of the clocks to the second circuit if the second circuit will be idle in the upcoming period."
7884742,"A system for compressing digital data by representing a portion of it predictionally and transformationally as a block of transform coefficients, then quantizing that block selectively into a set of encoding symbols based on an indication whether the transform coefficients represent the portion as having a particular characteristic, and then by encoding the set of encoding symbols into a data bit stream. In particular, frequency may be used as the characteristic of the digital data in many applications."
7884829,"A graphics system has a partitioned graphics memory that includes memory elements. The system supports having an non-power of two number of active memory elements. In one implementation, the memory elements are dynamic random access memories (DRAMs) and the system supports having a non-power of two number of active DRAMs."
7884830,"A graphics system supports arrays of cube map textures. In one implementation, a cube map texture is utilized as an index into a set of cube map textures. The set of cube map textures may further be arranged into an atlas of two-dimensional textures."
7884831,"Circuits, methods, and apparatus that provide texture caches and related circuits that store and retrieve texels in a fast and efficient manner. One such texture circuit provides an increased number of bilerps for each pixel in a group of pixels, particularly when trilinear or aniso filtering is needed. For trilinear filtering, texels in a first and second level of detail are retrieved for a number of pixels during a clock cycle. When aniso filtering is performed, multiple bilerps can be retrieved for each of a number of pixels during one clock cycle."
7885062,"The present invention pertains to a computer chassis with improved airflow to reduce the occurrence of trapped air pockets and increase heat transfer from components within the chassis. The computer chassis includes a plurality of chambers, wherein each of the chambers is separated by a partition. The partitions are operable to reduce the occurrence of trapped air pockets and increase heat transfer from components of the chassis by causing air to flow through each of the chambers. The computer chassis further includes at least two air vents, wherein each of the chambers is coupled to at least one of the at least two air vents through which air enters the chamber, and wherein each of the chambers is coupled to at least one of the at least two air vents through which air exits the chamber."
7885063,"A heat exchanger carrier system, method, and computer program product are provided. Included is a circuit board with components mounted thereon. Further included is a carrier coupled to the circuit board. Also included is a plurality of heat exchangers coupled to the carrier for transferring heat from the components."
7885458,Methods and systems for processing image data are described. A scene classifier determines the probabilities that various scene classes are associated with the image data. A gamut mapper determines the probabilities that various combinations of illuminant color and scene class are associated with the image data. The probabilities from the scene classifier are used to weight the probabilities from the gamut mapper. The weighted results can be used to select an illuminant color. The image data can be adjusted to compensate for the selected illuminant color.
7886094,A system for implementing handshaking configuration to enable coordinated data execution in a computer system. The system includes a core logic component coupled to a system memory and a graphics processor coupled to the core logic component via a graphics bus. The graphics processor and the core logic component implement a configuration communication to selectively configure coordinated data execution between the graphics processor and the core logic component via communication across the graphics bus.
7886116,"Embodiments of the present invention set forth systems and methods for compressing thread group data written to frame buffer memory to increase overall memory performance. A compression/decompression engine within the frame buffer memory interface includes logic configured to identify situations where the threads of a thread group are writing similar scalar values to memory. Upon recognizing such a situation, the engine is configured to compress the scalar data into a form that allows all of the scalar data to be written to or read from the frame buffer memory in fewer clock cycles than would be required to transmit the data in uncompressed form to or from memory. Consequently, the disclosed systems and methods are able to effectively increase memory performance when executing thread group STORE and LOAD operations."
7886164,"The present invention facilitates processor speed adjustments within acceptable temperature ranges. In one embodiment, a present invention system includes a temperature sensor that senses the temperature of the processor. When the temperature sensor senses the processor temperature approaching predetermined levels one or more adjustments are performed. For example, the adjustment can include automatically increasing or decreasing a voltage level in response to crossing a temperature threshold."
7886337,"Method and apparatus for protecting image content. In an embodiment, tags are used to identify how to alter image content. A graphics processor is configured to process the tags and to alter the image responsive to the tags. In another embodiment, a graphics processor is configured to alter image content unless a key is provided to the graphics processor."
7889208,"A system, method and computer program product are provided for computer graphics processing. In use, a value is modified based on an algorithm. An operation is subsequently performed on pixel data taking into account the modified value."
7889233,"This document discusses, among other things, systems and methods for receiving a local input video signal, processing the video signal, and providing a processed video signal to a local digital television display panel. A communications port includes an Ethernet or other communications network connector for allowing access to the video signal processing system by a remote device. This allows a remote user to remotely diagnose, debug, and even modify operation of the video signal processing system. In certain examples, this involves downloading a Lua script that can take partial or complete control over operation of the video signal processing system from resident instruction code. In certain examples, the video signal processing system includes pipelined image analysis or processing stages. Video signal data intermediate to such processing, or the processed video signal being provided to the local display can be communicated to the remote user."
7890925,"A structured INF source language that can coexist natively within higher level language source files is used to improve the consistency and quality of custom driver package components. A common source code file includes machine readable instructions in the structured inf source language for building various components of the custom driver packages for different target customer platforms. The number of errors introduced when changes are made for particular features, configuration, and customization keys is reduced by using a single source code file. The source code is parsed to automate the production of installation scripts, online internal documentation, and enabling per device, per platform, per operating system, and per customer control. An approval process with a security feature is used to ensure that the changes to the source code are authorized."
7891012,"Embodiments of the present invention are directed to a method and computer-usable medium for determining the authorization status of object code. In one embodiment, an application program embodied in an executable file is executed to periodically send a first data packet to a driver. A counter is decremented for each periodic interval in which the data packet is not received, and is reset in response to the data packet being received. The authorized status of the executable file is revoked if the counter reaches a predetermined value. In another embodiment, an application program generates a second data packet by creating a signature of the executable file and then encrypting that signature. The second data packet is sent to a driver for comparison with a previously-obtained packet. Thereafter, the authorized status of the executable file is revoked if a portion of the second data packet does not match the previously-obtained packet."
7894002,"Field-based detection of 3:2 pulldown in a sequence of digital video fields using a programmable graphics processor is described. The detection is performed using a threshold value to determine equivalence between a pair of fields of digital video data. Furthermore, additional threshold values may be used to control switching into a mode where duplicated fields of digital video data are identified and not displayed and out of the mode where duplicated fields of digital video data are identified and not displayed. Look ahead can be used to detect when to switch into or out of the mode where duplicated fields of digital video data are identified and not displayed, reducing the occurrence of visual artifacts."
7895385,"In accordance with an aspect of the present invention, a slave device enters a state suitable for establishing communication with a host device only if additional information is received on a serial bus after receiving a reset signal on the same bus. Such a feature may avoid or reduce disruption to applications executing on a slave device when false reset signals are received, for example, when the slave device is connected to a dumb charger on a USB interface for charging."
7895411,"One embodiment of the invention sets forth a hardware-based physics processing unit (PPU) having unique architecture designed to efficiently generate physics data. The PPU includes a PPU control engine (PCE), a data movement engine and a floating point engine (FPE). The PCE manages the overall operation of the PPU by allocating memory resources and transmitting graphics processing commands to the FPE and data movement commands to the DME. The FPE includes multiple vector processors that operate in parallel and perform floating point operations on data received from a host unit to generate physics simulation data. The DME facilitates the transmission of data between the host unit and the FPE by performs data movement operations between memories internal and external to the PPU."
7895608,"One embodiment of the invention is an architecture for improving the performance of a computer system containing a plurality of hardware input/output devices. The architecture implements an operating system configured to perform all related input/output operations within the operating system kernel. Thus, the operating system enables a first device driver that produces data to pass data directly to a second device driver that consumes data, without a context switch. One advantage of this approach is that computer system performance may be substantially increased due to a reduction in context switching."
7898543,"A system, method, and computer program product are provided for carrying out texture retrieval operations. In use, it is determined whether at least one texture retrieval operation is to be performed in a predetermined mode. Based on such determination, the texture retrieval operation is performed utilizing predetermined derivatives."
7898544,"Multiple graphics processors in a graphics processing system are interconnected in a unidirectional or bidirectional ring topology, allowing pixels to transferred from any one graphics processor to any other graphics processor. The system can automatically identify one or more “master” graphics processors to which one or more monitors are connected and configures the links of the ring such that one or more other graphics processors can deliver pixels to the master graphics processor, facilitating distributed rendering operations. The system can also automatically detect the connections or lack thereof between the graphics processors."
7898545,"An integrated circuit includes at least two different types of processors. At least one operation is supported by both types of processors, which permits a commonly supported operation to be scheduled on either processor."
7898546,A graphics processing unit is designed to have validation logic utilizing a reduced memory space shadow memory as a source of state information for performing validation of commands. A semantic analysis is performed to generate the validation logic such that the reduced memory space shadow memory has a size small than a memory size required to store a full representation of a set of state variables associated with a class of commands.
7898549,"A graphics processing subsystem defines a bounding area as the portion of the display buffer and other memory buffers occupied by one or more rendered objects. When clearing the memory buffers, only the portions of the buffers corresponding to the bounding area need to be cleared. A graphics pipeline includes a bounding area memory to store bounding area values. The bounding area values are modified during rendering so that each rendered primitive falls within the bounding area values. The graphics processing subsystem clears a portion of the memory buffer in response to a clear command specifying a bounding area. The clear command may include a set of bounding area values defining the bounding area, or alternatively a reference to the bounding area memory. For applications that draw objects in isolation, the bounding area will be smaller than the window, resulting in a decreased time requirement for clearing the memory buffer."
7899913,"A system and method are provided for establishing network connections. Initially, an attempt to establish a connection on a network is identified. A portion of memory is then allocated for storing data associated with the connection."
7899995,An array of streaming multiprocessors shares data via a shared memory. A flushing mechanism is used to guarantee that data required for dependent computations is available in the shared memory.
7903116,"A graphics system adapts a performance level to be sufficient to maintain a performance criterion in an acceptable range. In one embodiment, at least one utilization parameter of the core clock domain and the memory clock domain is monitored. In response to detecting an over-utilization condition, the performance level is increased to maintain the desired minimum number of frames per second. In response to detecting an under-utilization condition, the performance level is decreased to reduce power consumption and increase the lifetime of the graphics system."
7903123,"A programmable system for dithering video data. The system is operable in at least two user-selectable modes which can include a small kernel mode and a large kernel mode. In some embodiments, the system is operable in at least one mode in which it applies two or more kernels (each from a different kernel sequence) to each block of video words. Each kernel sequence repeats after a programmable number of the blocks (e.g., a programmable number of frames containing the blocks) have been dithered. The period of repetition is preferably programmable independently for each kernel sequence. The system preferably includes a frame counter for each kernel sequence. Each counter generates an interrupt when the number of frames of data dithered by kernels of the sequence has reached a predetermined value. In response to the interrupt, software can change the kernel sequence being applied. Typically, the system performs both truncation and dithering on words of video data. For example, some embodiments produce dithered 6-bit color components in response to 8-bit input color component words. Preferably, the inventive system is optionally operable in either a normal mode (in which dithering is applied to all pixels in accordance with the invention) or in an anti-flicker mode. Another aspect of the invention is a computer system in which the dithering system is implemented as a subsystem of a pipelined graphics processor or display device. Another aspect of the invention is a display device that includes an embodiment of the dithering system."
7903413,"A system and method are provided including a first thermal component adapted for thermal communication with an integrated circuit, and a second thermal component adapted for thermal communication with the first thermal component upon engagement therewith. Further provided is a coupler slidably coupled to the first thermal component and/or the second thermal component. In use, such coupler is capable of a first orientation for disengaging, the first thermal component and the second thermal component, and a second orientation for engaging the first thermal component and the second thermal component."
7905610,"A system and method are provided for projecting an image onto a three-dimensional object. In use, after an image is received, such image is processed utilizing a graphics processor for projecting the image onto the three-dimensional object in various embodiments, the image may be processed as a function of three-dimensional information associated with the three-dimensional object, for improving projection."
7907145,"Multiple output buffers are supported in a graphics processor. Each output buffer has a unique identifier and may include data represented in a variety of fixed and floating-point formats (8-bit, 16-bit, 32-bit, 64-bit and higher). A fragment program executed by the graphics processor can access (read or write any of the output buffers. Each of the output buffers may be read from and used to process graphics data by an execution pipeline within the graphics processor. Likewise, each output buffer may be written to by the graphics processor, storing graphics data such as lighting parameters, indices, color, and depth."
7911470,An apparatus and method for fairly arbitrating between clients with varying workloads. The clients are configured in a pipeline for processing graphics data. An arbitration unit selects requests from each of the clients to access a shared resource. Each client provides a signal to the arbitration unit for each clock cycle. The signal indicates whether the client is waiting for a response from the arbitration unit and whether the client is not blocked from outputting processed data to a downstream client. The signals from each client are integrated over several clock cycles to determine a servicing priority for each client. Arbitrating based on the servicing priorities improves performance of the pipeline by ensuring that each client is allocated access to the shared resource based on the aggregate processing load distribution.
7911471,"A method and apparatus for executing loop and branch program instructions in a programmable graphics shader. The programmable graphics shader converts a sequence of instructions comprising a portion of a shader program and selects a first set of fragments to be processed. Subsequent sequences of instructions are converted until all of the instructions comprising the shader program have been executed on the first set of fragments. Each remaining set of fragments is processed by the shader program until all of the fragments are processed in the same manner. Furthermore, the instructions can contain one or more loop or branch program instructions that are conditionally executed. Additionally, when instructions within a loop as defined by a loop instruction are being executed a current loop count is pipelined through the programmable graphics shader and used as an index to access graphics memory."
7912889,"The present invention enables efficient matrix multiplication operations on parallel processing devices. One embodiment is a method for mapping CTAs to result matrix tiles for matrix multiplication operations. Another embodiment is a second method for mapping CTAs to result tiles. Yet other embodiments are methods for mapping the individual threads of a CTA to the elements of a tile for result tile computations, source tile copy operations, and source tile copy and transpose operations. The present invention advantageously enables result matrix elements to be computed on a tile-by-tile basis using multiple CTAs executing concurrently on different streaming multiprocessors, enables source tiles to be copied to local memory to reduce the number accesses from the global memory when computing a result tile, and enables coalesced read operations from the global memory as well as write operations to the local memory without bank conflicts."
7913148,"A RAID disk drive controller (FIG. 33) implements disk storage operations, including striping and redundancy operations with multiple disk drives connected via respective SATA ports (520). Configurable data path switch logic (460) provides dynamic configuration of two or more attached drives into one or more arrays. Data transfers are synchronized locally by leveraging the SATA port transport layer FIFO (530). Synchronous transfers allow on-the-fly redundancy (XOR) operations (FIG. 36) for improved performance and reduced hardware complexity. XOR accumulator hardware (FIG. 42-FIG. 43) reduces buffer requirements for multiple DMA channels otherwise required for synchronization, and various narrow and wide striping modes are supported."
7913294,"Method and apparatus for network protocol filtering of a packet is described. An index to a table is obtained and stored to travel with the packet. The index is obtainable to access the table to obtain packet information. In particular, a method for inbound network address translation packet filtering and a method for outbound packet filtering are described."
7915925,"The present invention relates to scannable D flip-flops, which are improved to solve the problem of the conventional designs and provides a small and fast scannable D flip-flop without compensating its testability. The embodiment of the present invention provides a scannable D flip-flop, comprising a source coupled logic, comprising a trigger circuit for reading a clock input; a scannable input circuit coupled to the trigger circuit having four NMOS transistors; a first feedback circuit for a first output; and a second feedback circuit for a second output; a latch circuit coupled to the source coupled logic; and an output buffer coupled to the latch circuit. Another embodiment of the present invention provides a scannable D flip-flop, comprising: a cascade dynamic logic, comprising: a first stage circuit; a second stage circuit coupled to the first stage circuit; a third stage circuit coupled to the second stage circuit; and a scannable input circuit coupled to the first stage circuit having four NMOS transistors for reading a data input and scannable inputs; a latch circuit coupled to the second stage circuit; and an output buffer coupled to the latch circuit."
7916146,"In a processing pipeline having a plurality of units, an interface unit is provided between a first, upstream pipeline unit that needs to be drained prior to a context switch and a second, downstream pipeline unit that might halt prior to a context switch. The interface unit redirects data that are drained from the first pipeline unit and to be received by the second pipeline unit, to a buffer memory provided in the front end of the processing pipeline. The contents of the buffer memory are subsequently dumped into memory reserved for the context that is being stored. When the processing pipeline is restored with this context, the data that were dumped into memory are retrieved back into the buffer memory and provided to the interface unit. The interface unit receives these commands and directs them to the second pipeline unit."
7916149,"A method of organizing memory for storage of texture data, in accordance with one embodiment of the invention, includes accessing a size of a mipmap level of a texture map. A block dimension may be determined based on the size of the mipmap level. A memory space (e.g., computer-readable medium) may be logically divided into a plurality of whole number of blocks of variable dimension. The dimension of the blocks is measured in units of gobs and each gob is of a fixed dimension of bytes. A mipmap level of a texture map may be stored in the memory space. A texel coordinate of said mipmap level may be converted into a byte address of the memory space by determining a gob address of a gob in which the texel coordinate resides and determining a byte address within the particular gob."
7916151,"Circuits, methods, and apparatus that provide for partial texture load instructions. Instead of one instruction that may take several shader passes to complete, several instructions are issued, where each instruction is an instruction to retrieve a part or portion of a texture. While each instruction is performed, the other shader circuits can perform other instructions, thus increasing the utilization of the shader circuits when large textures are read from memory. Since several shader passes may be required to read a texture, if a particular instruction needs the texture, one exemplary embodiment reorders instructions such that other instructions are performed before the particular instruction that needs the texture."
7916153,"Embodiments of the present invention generally provide m Methods and apparatus for reducing power consumption of backlit displays are described. Power consumption is reduced by dimming backlighting by a first scale factor and boosting pixel values by a second scale factor to compensate for the dimming. The scale factors may be constant values. Alternately, one or both of the scale factors may be determined based on pixel values for one or more frames to be displayed and/or one or more frames that have been displayed. For example, scale factors may be calculated based on an average linear amplitude of one or more frames of pixel values or from a maximum pixel value of one or more frames of pixel values. A graphical processing system is described including an integrated circuit capable of transforming a pixel value from a gamma-compensated space to a linear space."
7916155,"Systems and methods for producing anti-aliased images use a sub-pixel sample pattern set that includes two or more unique sub-pixel sample patterns that are complementary. The sub-pixel sample patterns are offset from each pixel center and used to produce images that are combined to produce the anti-aliased image. In addition to providing sub-pixel coverage information, the sub-pixel sample pattern sets may be used to produce sub-pixel shading information. Furthermore, the sub-pixel sample pattern sets may be used in single processor systems or in multiprocessor systems to produce anti-aliased images."
7916864,"A graphics processing unit is programmed to carry out cryptographic processing so that fast, effective cryptographic processing solutions can be provided without incurring additional hardware costs. The graphics processing unit can efficiently carry out cryptographic processing because it has an architecture that is configured to handle a large number of parallel processes. The cryptographic processing carried out on the graphics processing unit can be further improved by configuring the graphics processing unit to be capable of both floating point and integer operations."
7917671,"A scalable port controller architecture supporting data streams of different speeds. In an embodiment, a port controller contains high speed receptor units and low speed receptor units, and a port routing logic connecting each external device (on corresponding port) to one of the receptors according to various registers. The port routing logic may connect an external device to one of the receptors, which determines the data rate at which data on a corresponding virtual connection from the external device is being received/sent. If the receptor does not have sufficient capacity (based on the data rate) to communicate with the external device, the connection is moved to other receptors, potentially in another control unit."
7917736,A synchronization mechanism is used to synchronize events across multiple execution pipelines that process transaction streams. A common set of state configuration is included in each transaction stream to control processing of data that is distributed between the different transaction streams. Portions of the state configuration correspond to portions of the data. Execution of the transaction streams is synchronized to ensure that each portion of the data is processed using the state configuration that corresponds to that portion of the data. The synchronization mechanism may be used for multiple synchronizations and when the synchronization signals are pipelined to meet chip-level timing requirements.
7920701,A digital content system is disclosed. A security engine disposed in a bridge provides cryptographic services. Clear text digital data received from a central processing unit is encrypted and transferred via the bridge over unsecured data paths as cipher text.
7920749,"Systems and methods for representing high dynamic range data in compressed formats with a fixed size block allow high dynamic range data to be stored in less memory. The compressed formats use 8 bits per pixel. A first compressed format includes two endpoint values and compressed indices for the pixels in the block. A second compressed format includes four endpoint values, a partition index that specifies a mask for each pair of the four endpoint values, and compressed indices for the pixels in the block. The two formats may be used for various blocks within a single compressed image and mode bits are included to distinguish between the two formats. Furthermore, each endpoint value may be encoded using an endpoint compression mode that is also specified by the mode bits. Compressed high dynamic range values represented in either format may be efficiently decompressed in hardware."
7924181,"A system, method, and computer program product are provided for estimating a clock signal. Specifically, during use, a clock signal associated with an audio signal is digitally estimated."
7924290,"A method and system for performing a texture operation with user-specified offset positions are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of deriving a first destined texel position based on an original sample position associated with a pixel projected in a texture map and a first offset position specified by a user and fetching texel attributes at the first destined texel position for the texture operation."
7924868,"A novel network architecture that integrates the functions of an Internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though, in one embodiment, it is sharing the same chip."
7925860,"In parallel processing devices, for streaming computations, processing of each data element of the stream may not be computationally intensive and thus processing may take relatively small amounts of time to compute as compared to memory accesses times required to read the stream and write the results. Therefore, memory throughput often limits the performance of the streaming computation. Generally stated, provided are methods for achieving improved, optimized, or ultimately, maximized memory throughput in such memory-throughput-limited streaming computations. Streaming computation performance is maximized by improving the aggregate memory throughput across the plurality of processing elements and threads. High aggregate memory throughput is achieved by balancing processing loads between threads and groups of threads and a hardware memory interface coupled to the parallel processing devices."
7925907,"Circuits, methods, and systems that reduce or eliminate the number of data transfers between a system memory and a graphics processor under certain conditions. After inactivity by a user of an electronic device is detected, the color fidelity of pixels being displayed is reduced. Color fidelity can be reduced by compressing pixel values, and the compression may be non-lossless, for example, pixel data bits may be truncated. The degree of compression can be progressively increased for longer durations of inactivity, and this progression may be limited by a threshold. Inactivity may be detected by a lack of input from devices such as a keyboard, pen, mouse, or other input device. Once activity is resumed, uncompressed pixel data, or pixel data that is compressed in a lossless manner, is displayed."
7925931,"Embodiments of the present invention provide a method for handling errors in data servers. Generally, embodiments of the invention enable a data packet that is marked as erroneous to be handled so that it is not committed to permanent storage. One or more components are configured to recognize a poisoned data indicator, and to respond to the indicator by taking programmed actions to delete the data, to stop the data from being transmitted, to notify upstream components, and to purge related data from downstream components."
7928988,"A method and system for implementing transfers of texture data in a computer system. The method includes the step of accessing a first block of texture data in a low latency memory, the first block having a predetermined size and accessing a second block of texture data in high latency memory, the second block having the predetermined size. The first block of texture data is copied from the low latency memory to a transfer space in high latency memory having the predetermined size. The second block of texture data is written from the high latency memory to the low latency memory, wherein the second block overwrites the first block. What used to be the transfer space is now treated as the first block now placed in high latency memory, and what used to be the second block is now treated to be the new transfer space."
7928989,"One embodiment of the invention is a method for storing transformed vertex attributes that includes the steps of allocating memory space for a transform feedback buffer, selecting one or more transformed vertex attributes to store in the transform feedback buffer independently of any shader programs executing on any processing units in the graphics rendering pipeline, configuring the transform feedback buffer to store the one or more transformed vertex attributes, and initiating a processing mode wherein vertex data is processed in the graphics rendering pipeline to produce the transformed vertices, the attributes of which are then written to the transform feedback buffer. One advantage is that the transform feedback buffer can be used to store and access transformed vertices, without having to convert the vertex data to a pixel format, store the pixels in a frame buffer, and then convert the pixels back to a vertex format."
7928997,"Digital Image compositing using a programmable graphics processor is described. The programmable graphics processor supports high-precision data formats and can be programmed to complete a plurality of compositing operations in a single pass through a fragment processing pipeline within the programmable graphics processor. Source images for one or more compositing operations are stored in graphics memory, and a resulting composited image is output or stored in graphics memory. More-complex compositing operations, such as blur, warping, morphing, and the like, can be completed in multiple passes through the fragment processing pipeline. A composited image produced during a pass through the fragment processing pipeline is stored in graphics memory and is available as a source image for a subsequent pass."
7932912,A graphics system has virtual memory and a partitioned graphics memory that supports having an non-power of two number of dynamic random access memories (DRAMs). The graphics system utilizes page table entries to support addressing Tag RAMs used to store tag bits indicative of a compression status.
7932914,"Systems and methods for storing high dynamic range image data in a low dynamic range format may be used to store the high dynamic range image data in less memory. The memory bandwidth needed to access the high dynamic range data is reduced and processing performance may be improved when performance is limited by memory bandwidth. The high dynamic range image data is scaled and compressed into a low dynamic range format for storage in a render target. If the compressed high dynamic range image data contains multiple data samples per pixel, the data may be processed to produce filtered compressed high dynamic range image data with only one sample per pixel. The high dynamic range image may be reconstructed from the low dynamic range format data and further processed as high dynamic range format data for a range of applications."
7934255,"A computing system offloads packet classification from a central processing unit to a graphics processing unit. In one implementation input data packets to be classified are represented as a first texture, classification rules are represented as a second texture, and a shading operation is performed to classify packets."
7936355,A method for visually representing an object by simulating the object as a particle with fewer degrees of freedom than those visually represented comprises simulating an object as a particle having linear motion. The method also comprises deriving an angular component of the particle from the linear motion of the particle. The method also comprises representing the object visually based on the linear motion and the derived angular component of the particle.
7937359,"A method of operating a Linear Complementarity Problem (LCP) solver is disclosed, where the LCP solver is characterized by multiple execution units operating in parallel to implement a competent computational method adapted to resolve physics-based LCPs in real-time."
7937567,"Parallelism in a parallel processing subsystem is exploited in a scalable manner. A problem to be solved can be hierarchically decomposed into at least two levels of sub-problems. Individual threads of program execution are defined to solve the lowest-level sub-problems. The threads are grouped into one or more thread arrays, each of which solves a higher-level sub-problem. The thread arrays are executable by processing cores, each of which can execute at least one thread array at a time. Thread arrays can be grouped into grids of independent thread arrays, which solve still higher-level sub-problems or an entire problem. Thread arrays within a grid, or entire grids, can be distributed across all of the available processing cores as available in a particular system implementation."
7937606,"Generally, the present disclosure concerns systems and methods for shadowing status for a circuit with a shadow unit. In one aspect, a system comprises a first circuit in a first dynamic clock domain of a plurality of dynamic clock domains, a processor configured to execute software instructions to generate a request for a status of the first circuit, and a second circuit coupled to the first circuit and to the processor. The second circuit, outside the first dynamic clock domain, is configured to shadow a status of the first circuit and to respond to the request for the status of the first circuit with the shadowed status."
7937710,"A context switch request is made from a host unit to a processing engine separately from the method stream to that processing engine and does not require the host unit to know what context the processing engine is currently working on. Upon receiving the request, the processing engine compares the requested context with the context that it is currently working on, and if the two are different, performs the context switch to the requested context. On the other hand, if the two are the same, the engine does not perform the context switch and continues working on the current context."
7941037,"A system and method are provided for time scaling playback of digital audio signals with associated digital video signals. Initially, the digital video signals and the digital audio signals are received. Next, the digital audio signals are processed for the time scaling thereof while substantially preserving the frequency pitch of the digital audio signals. The processed audio signals are then encoded. Such encoded audio signals are then outputted for accelerated playback with the associated digital video signals."
7941645,"An isochronous processor includes a state register, a functional unit, a control module, and an activation unit. The state register includes an arm buffer and an active buffer. The functional unit performs a transformation operation on the data stream in response to an active value of the control parameter obtained from the active buffer. The control module updates the arm value of the control parameter in the arm buffer in response to control instructions. The activation unit detects a load event propagating with the data stream and transfers the parameter value from the arm buffer to the active buffer in response to the load event. During this transfer, the control module is inhibited from updating the arm buffer."
7944452,"Methods and systems for reusing memory addresses in a graphics system are disclosed, so that instances of address translation hardware can be reduced. One embodiment of the present invention sets forth a method, which includes mapping a footprint in screen space to a group of contiguous physical memory locations in a memory system, determining a first physical memory address for a first transaction associated with the footprint, wherein the first physical memory address is within the group of contiguous physical memory locations, determining a second transaction that is also associated with the footprint, determining a set of least significant bits associated with the second transaction, and combining a portion of the first physical memory address with the set of least significant bits associated with the second transaction to generate a second physical memory address for the second transaction, thereby avoiding a second full address translation."
7944453,A multi-threaded graphics processor is configured to use to extrapolate low resolution mipmaps stored in physical memory to produce extrapolated texture values while high resolution mipmaps are retrieved from a high latency storage resource. The extrapolated texture values provide an improved image that appears sharper compared with using the low resolution mipmap level texture data in place of the temporarily unavailable high resolution mipmap level texture data.
7944733,"A system and method for self-tracking data in a read operation of a SRAM are disclosed. The self-tracking data selection SRAM comprises: a plurality of memory cell arrays, comprising: a plurality of memory cells each generating a first signal and outputting a first read data; a plurality of first buffers each receiving the first signal outputting a second signal; a first multiplexer receiving the plurality of first read data and the first signals; a plurality of second buffers each receiving the second signals and outputting a third signal; and a second multiplexer receiving a plurality of second read data from the plurality of memory cell arrays and outputting a third signals."
7945757,"A system and method for using an array structure to abstract the addressing of device memory allows for larger amounts of device memory to be accessed compared with using conventional pointers to access a 32 bit memory space. Additionally, the memory organization may be changed for optimal performance based on the underlying memory subsystem and characteristics of the accesses without impacting the array structure."
7948495,"Systems and methods used for binding texture state stored in independent structures may be used by more than one graphics applications programming interface (API). A texture header portion of the texture state defines texture data characteristics and is stored in a first structure. A texture sampler portion of the texture state specifies texture processing attributes and is stored in a second structure. A single unified structure is emulated for use by APIs that store the texture state in a single structure. Therefore, a graphics processor may support more than one graphics API for processing texture data."
7948498,"Circuits, methods, and apparatus that store a large number of texture states in an efficient manner. A level-one texture cache includes cache lines that are distributed throughout a texture pipeline, where each cache line stores a texture state. The cache lines can be updated by retrieving data from a second-level texture state cache, which in turn is updated from a frame buffer or graphics memory. The second-level texture state cache can prefetch texture states using a list of textures that are needed for a shader program or program portion."
7948500,A multi-threaded graphics processor is configured to use to extrapolate low resolution mipmaps stored in physical memory to produce extrapolated texture values while high resolution nonresident mipmaps are retrieved from a high latency storage resource and converted into resident mipmaps. The extrapolated texture values provide an improved image that appears sharper compared with using the low resolution mipmap level texture data in place of the temporarily unavailable high resolution mipmap level texture data. An extrapolation threshold LOD is used to determine when extrapolated magnification or minification texture filtering is used. The extrapolation threshold LOD may be used to smoothly transition from using extrapolated filtering to using interpolated filtering when a nonresident mipmap is converted to a resident mipmap.
7949855,"A processor buffers asynchronous threads. Instructions requiring operations provided by a plurality of execution units are divided into phases, each phase having at least one computation operation and at least one memory access operation. Instructions within each phase are qualified and prioritized. The instructions may be qualified based on the status of the execution unit needed to execute one or more of the current instructions. The instructions may also be qualified based on an age of each instruction, status of the execution units, a divergence potential, locality, thread diversity, and resource requirements. Qualified instructions may be prioritized based on execution units needed to execute instructions and the execution units in use. One or more of the prioritized instructions is issued per cycle to the plurality of execution units."
7952579,"Z-buffer rendering of three-dimensional scenes is made more efficient through a method for occlusion culling by which occluded geometry is removed prior to rasterization. The method uses hierarchical z-buffering to reduce the quantity of image and depth information that needs to be accessed. A separate culling stage in the graphics pipeline culls occluded geometry and passes visible geometry on to a rendering stage. The culling stage maintains its own z-pyramid in which z-values are stored at low precision (e.g., in 8 bits). The efficiency of hierarchical z-buffering is improved through hierarchical evaluation of line and plane equations."
7957379,"A system and method are provided for processing packets received via a network. In use, data packets and control packets are received via a network. Further, the data packets are processed in parallel with the control packets."
7958483,An embodiment of the invention includes receiving an indicator of an activity-level of a functional block within an electronic chip. The functional block is configured to receive a clock signal from a clock signal generator. The clock signal to at least a portion of a functional block is disabled for a number of inactive clock cycles during a clock segment of the clock signal. The clock segment has a specified number of clock cycles and the number of inactive clock cycles is defined based on the activity-level and the specified number of clock cycles of the clock segment.
7958498,"Methods and systems for processing a geometry shader program developed in a high-level shading language are disclosed. Specifically, in one embodiment, after having received the geometry shader program configured to be executed by a first processing unit in a programmable execution environment, the high-level shading language instructions of the geometry shader program is converted into low-level programming language instructions. The low-level programming language instructions are then linked with the low-level programming language instructions of a domain-specific shader program, which is configured to be executed by a second processing unit also residing in the programmable execution environment. The linked instructions of the geometry shader program are directed to the first processing unit, and the linked instructions of the domain-specific shader program are directed to the second processing unit."
7961178,"One embodiment of the present invention sets forth a method and system for reordering a plurality of pixel data returned by a frame buffer in a display system. The method includes the steps of recording the order of a plurality of requests for pixel data arriving at the frame buffer as a first sequence, wherein the plurality of requests is further associated with a first request stream, associating each pixel data returned by a frame buffer partition in the frame buffer in response to the plurality of requests with an independently operating data thread, wherein each of the data threads is further associated with the first request stream and the frame buffer partition, and retrieving the pixel data for display in a same sequence as the first sequence from the data threads."
7961192,"A system and method are provided including a first graphic processor in communication with a content source. In operation, the first graphics processor is adapted for processing content from the content source. Further included is a second graphics processor in communication with the first graphics processor utilizing a network. The second graphics processor is adapted for further processing the content for display purposes."
7961195,Methods and systems for compressing and decompressing data are described. A first value of N+1 bits and a second value of N+1 bits are reduced to strings of N bits each. The first and second strings of N bits are stored in a particular order relative to one another in a compression block. The particular order in which the first and second strings of N bits are stored in the compression block is used to derive a bit value that is then used in combination with one of the strings of N bits to reconstruct that string as N+1 bits.
7961197,"Method and apparatus for display image adjustment is described. More particularly, handles associated with polygon vertices of a polygon rendered image are provided as a graphical user interface (GUI). These handles may be selected and moved by a user with a cursor pointing device to adjust a displayed image for keystoning, among other types of distortion. This GUI allows a user to adjust a projected image for position of a projector with respect to imaging surface, as well as for imaging surface contour, where such contour may be at least substantially planar, cylindrical, or spherical and where such contour may comprise multiple imaging surfaces. This advantageously may be done without special optics or special equipment. An original image is used as texture for rendering polygons, where the image is applied to the rendered polygons."
7961733,"A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though, in one embodiment, it is sharing the same chip."
7962808,"The present application describes a method and system for testing the compliance of a PCIE expansion system to verify that data signals transmitted through multiple data lanes in the expansion system comply with the PCIE requirements. The method for testing a PCIE expansion system comprises delivering the data signals from the data lanes to a compliance board that is configured to loop back at least a first portion of the data signals and transmit a complementary second portion of the data signals to a testing device, and testing a compliance of the second portion of the data signals with the PCIE requirements. The first portion of the data signals is then tested through a second compliance board that is configured to loop back the second portion of the data signals and transmit the first portion of the data signals to the testing device."
7964422,A method for controlling a semiconductor fabrication process includes the steps of analyzing process-data related to an intermediate-process-step in the fabrication process and adjusting a metal-layer-parameter corresponding to the metal layer based on the process-data.
7965289,A graphics processing unit calculates transformation matrices for changes to the position and orientation of objects. The graphics processing unit applies the transformation matrices to vertices of objects to be rendered.
7965291,A graphics system utilizes a graphics processing unit to implement marching tetrahedra extraction of an isosurface. In one embodiment locations of tetrahedral grids are represented as groups of four vertices for processing in the graphics processing unit.
7965506,"A heat sink apparatus and method are provided for allowing air to flow directly to an integrated circuit package thereunder. In use, a heat sink is provided including an upper portion with a plurality of fins, and a lower portion configured for allowing air to flow directly to an integrated circuit package thereunder."
7965895,"Methods, circuits, and apparatus for reducing memory bandwidth used by a graphics processor. Uncompressed tiles are read from a display buffer portion of a graphics memory and received by an encoder. The uncompressed tiles are compressed and written back to the graphics memory. When a tile is needed again before it has been modified, the compressed version is read from memory, uncompressed, and displayed. To reduce the number of unnecessary writes of compressed tiles to memory, a tile is only written to memory if it has remained static for some number of refresh cycles. Also, to prevent a large number of compressed tiles being written to the display buffer in one refresh cycle, the encoder can be throttled after a number of tiles have been written. Validity information can be stored for use by a CRTC. If a tile is updated, the validity information is updated such that invalid compressed data is not read from memory and displayed."
7965898,"A system and method for decoding high definition video content using multiple processors reduces the likelihood of dropping video frames. Each of the multiple processors produces and stores a portion of a decoded video frame in its dedicated frame buffer. A region of a reference frame that is needed to produce a first portion of a decoded video frame, but that is not stored in the frame buffer coupled to the processor that will decode the first portion, is copied to the frame buffer. The size of the region needed may vary based on a maximum possible motion vector offset. The size of the region that is copied may be dynamic and based on a maximum motion vector offset for each particular reference frame."
7966361,"Several different approaches to performing the modulus operation are presented. In one, a method of performing the modulus operation upon a dividend and a divisor within a limited range is discussed. The method involves storing a reference value, receiving a dividend value, and calculating a number of derived inputs. Each of the derived inputs corresponds to the dividend value minus the reference value, and is then further modified by a multiple of the divisor. Using the divisor to select between these derived inputs provides the answer."
7966439,A system controller includes a memory controller and a host interface residing in different clock domains. There is a time delay between the time when the memory controller issues a read command to a memory and the data becoming present and available at the host interface. The memory controller generates an alarm message at or near the time that it issues the read command. The alarm message indicates to the host interface the time that the data is available for transfer to a host.
7966468,"A speculative transfer mechanism transfers a source synchronous read request from a first clock domain to a second clock domain. The address portion having address information is transferred to the second clock domain in response to detecting a source synchronous address strobe latching signal. A pointer is generated in response to detecting the address strobe latching signal and passed into the second clock domain. In one embodiment, a pointer is retimed to be stable for a timing window for which a crossover of the address portion may be performed in the second clock domain. Request logic in the second clock domain generates a read command based on the address portion and the pointer."
7966509,"A system and method for performing dynamic trimming. Specifically, the system comprises a clock for generating a reference clock signal. The reference clock signal comprises a first frequency that is a factor of a second frequency of a signal (e.g., data clock signal from DDR memory). A counter is coupled to the clock and generates a plurality of clock pulses based on pulses of the reference clock signal. The plurality of clock pulses is generated at a slower frequency from the first frequency for low power operation. A phase length detector is coupled to the counter and comprises a trimmer chain for detecting an average length of at least one of the generated plurality of clock pulses. A transformation module is coupled to the phase length detector for transforming the average length to a phase delay of the signal."
7967208,"A system, method and computer program product are provided for marking an article of manufacture. After marking an article of manufacture with a first identifier that describes at least one aspect of the article, such article is further marked with a supplemental identifier that describes the at least one aspect of the article."
7969436,"Z-buffer rendering of three-dimensional scenes is made more efficient through a method for occlusion culling by which occluded geometry is removed prior to rasterization. The method uses hierarchical z-buffering to reduce the quantity of image and depth information that needs to be accessed. A separate culling stage in the graphics pipeline culls occluded geometry and passes visible geometry on to a rendering stage. The culling stage maintains its own z-pyramid in which z-values are stored at low precision (e.g., in 8 bits). The efficiency of hierarchical z-buffering is improved through hierarchical evaluation of line and plane equations."
7969443,A system and method are provided for dynamically selecting one or more modules of a graphics processor for processing content to support communication of the content over a wireless network link for subsequent display of the content utilizing a display.
7969444,"A method and apparatus for distributing the workload of rendering an image where texture mapping is involved among multiple graphics processing units (GPUs) are provided. The method generally entails dividing a texture map among multiple GPUs, performing texture mapping in each GPU to render image data in each GPU's frame buffer, combining the image data from each frame buffer, and scanning out the combined image to a display."
7969445,"A system, method, and computer program product are provided for broadcasting write operations in a multiple-target system. In use, a write operation is received at one of a plurality of apertures of an address space. Such write operation is then replicated to produce a plurality of write operations. To this end, the write operations may be broadcasted to a plurality of targets. At least one of the targets includes another one of the apertures that produces at least one additional write operation."
7969446,A graphics processor is disclosed having a programmable Arithmetic Logic Unit (ALU) stage for processing pixel packets. Scalar arithmetic operations are performed in the ALUs to implement a graphics function.
7969733,"A heat transfer system, method, and computer program product are provided for use with multiple circuit board environments. In use, a heat transfer component configured to be situated between a first circuit board and a second circuit board is provided. Such heat transfer component is in thermal communication with a first processor of the first circuit board and a second processor of the second circuit board. Furthermore, the heat transfer component is situated between the first circuit board and the second circuit board."
7971045,"Embodiments of the invention provide a method for selecting a network boot device using a hardware class identifier. Generally, embodiments of the invention enable a diskless client to communicate a hardware class identifier in a network connection request. The hardware class identifier is used to determine the proper boot server to provide a boot image to the diskless client."
7973802,"An apparatus and method for converting color data from one color space to another color space. A driver determines that a set of shader program instructions perform a color conversion function and the set of shader program instructions are replaced with either a single shader program instruction or a flag is set within an existing shader program instruction to specify that output color data is represented in a nonlinear color format. The output color data is converted to the nonlinear color format prior to being stored in a frame buffer. Nonlinear color data read from the frame buffer is converted to a linear color format prior to shading, blending, or raster operations."
7974209,"Method and apparatus for packet processing by re-insertion into network interface circuitry. A method for handling a burst of packets sent to network interface circuitry includes checking for a connection table entry for received packets, and responsive to non-existence of the connection table entry for the received packets, sending the packets to network interface software for processing. The network interface software processing includes: building the connection table entry; processing the packets; and sending the packets as processed to the network interface circuitry. Additionally, a method for re-inserting a packet responsive to an active audit mode is described."
7974485,"Split-frame post-processing techniques are used in a programmable video post processing engine. A frame of video data is divided into a processing region and a control region that contain either different portions of the frame or copies of a portion of the frame. Post-processing operations are performed for the processing region but not for the control region. The processing and control regions are then displayed simultaneously on the same display device (e.g., side by side), facilitating visual comparisons of images with and without post-processing."
7978204,"A1A system embodying the invention includes a controlling device and a set of rendering devices, with the effect that the controlling device can distribute a set of objects to the rendering devices. Each rendering device computes a (2D) image in response to the objects assigned to it, including computing multiple overlapping images and using a graphics processor to blend those images into a resultant image. To interface with the graphics processor, each rendering device spoofs the α-value with a pixel feature other than opacity (opacity is expected by the graphics processor), with the effect that the graphics processor delivers useful α-values, while still delivering correct color values, for each pixel. This has the effect that the resultant images include transparency information sufficient to combine them using transparency blending."
7978921,"Systems and methods for representing low dynamic range data in compressed formats with a fixed size block allow low dynamic range data to be stored in less memory. The compressed formats use 8 bits per pixel to represent 24 bits of low dynamic range data for each pixel. The compressed format includes four or six endpoint values, a partition index that specifies a mask for each pair of the endpoint values, and an index for each pixel in the block. The indices are compressed to allow more bits for the endpoint values. Mode bits are included to distinguish between the different encodings and various blocks within a single compressed image may be encoded differently. Compressed low dynamic range values may be efficiently decompressed in hardware."
7979526,"A system and method are provided for establishing network connections. Initially, an attempt to establish a connection on a network is identified. A portion of memory is then allocated for storing data associated with the connection."
7979683,"Graphics processing elements are capable of processing multiple contexts simultaneously, reducing the need to perform time consuming context switches compared with processing a single context at a time. Processing elements of a graphics processing pipeline may be configured to support all of the multiple contexts or only a portion of the multiple contexts. Each processing element may be allocated to process a particular context or a portion of the multiple contexts in order to simultaneously process more than one context. The allocation of processing elements to the multiple contexts may be determined dynamically in order to improve graphics processing throughput."
7979860,A process for scheduling operations using a cost function is provided. A number of scheduling options are determined for an operation and a cost is computed for each scheduling option. The process then schedules the operation based on a computed cost.
7982745,"Trilinear optimization is a technique to reduce the number of texture samples used to determine a texture value associated with a graphics fragment. Bilinear interpolations replace some trilinear interpolations, thereby reducing the number of texture samples read and simplifying the filter computation. A programmable trilinear slope is used to control replacement of a trilinear computation with a bilinear computation, permitting a user to determine a balance between improved texture map performance and texture filtering quality."
7983498,"Systems and methods for representing low dynamic range data in compressed formats with a fixed size block allow low dynamic range data to be stored in less memory. The compressed formats use 8 bits per pixel to represent 24 bits of low dynamic range data for each pixel. The compressed format includes four or six endpoint values, a partition index that specifies a mask for each pair of the endpoint values, and an index for each pixel in the block. The indices are compressed to allow more bits for the endpoint values. Mode bits are included to distinguish between the different encodings and various blocks within a single compressed image may be encoded differently. Compressed low dynamic range values may be efficiently decompressed in hardware."
7983772,"Embodiments of the present invention provide an audio system having wholly independent audio processing modules. The audio system includes a plurality of audio processing modules, a clock manager, a sample rate converter and a buffer. The audio processing modules are communicatively coupled to the clock manager and the buffer. The sample rate converter is communicatively coupled to the clock manager and the buffer. The buffer provides for storing audio data generated and consumed by the audio processing modules. The clock manager provides for determining the clock source of each audio processing module. The clock manager also provides for configuring the audio processing modules and the sample rate converter as a function the clock source of each audio processing module. The sample rate converter provides for synchronizing a flow rate of audio data generated by a first audio processing module and a flow rate of audio data consumed by a second audio processing module, when the clock source of the first and second audio processing modules are different."
7984446,"A method and system for multitasking BIOS initialization tasks are disclosed. The BIOS utilizes preemptive multitasking and cooperative multitasking. The preemptive multitasking and the cooperative multitasking increase utilization of the processing power of a processor and ensure higher priority valued tasks are executed with less interruption than lower priority valued tasks. During execution, each task is able to request a particular waiting period."
7986325,"One embodiment of the present invention sets forth a technique for improving the flexibility and programmability of a graphics pipeline by enabling full access to integer texture maps within a graphics processing unit (GPU). A new mechanism for loading and unloading integer texture images is disclosed that enables the shader units within the GPU to have full access to integer values stored within an integer image buffer in a GPU local memory. New integer formats are added to the graphics API that indicate that data should be loaded and processed without the prior art conversion to a floating-point representation, thereby enabling the use of these new integer data types."
7986327,Embodiments of the present invention set forth a technique for optimizing the on-chip data path between a memory controller and a display controller within a graphics processing unit (GPU). A row selection field and a sector mask are included within a memory access command transmitted from the display controller to the memory controller indicating which row of data is being requested from memory. The memory controller responds to the memory access command by returning only the row of data corresponding to the requested row to the display controller over the on-chip data path. Any extraneous data received by the memory controller in the process of accessing the specifically requested row of data is stripped out and not transmitted back to the display controller. One advantage of the present invention is that the width of the on-chip data path can be reduced by a factor of two or more as a result of the greater operational efficiency gained by stripping out extraneous data before transmitting the data to the display controller.
7987065,"A method and system for automatically verifying the quality of multimedia rendering are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of directing a command intended for a first driver to both the first driver and a second driver in parallel as the multimedia application issues the command and in response to a condition indicative of having available data to compare, comparing a first output generated by a first processing unit associated with the first driver and a second output generated by a second processing unit associated with the second driver."
7991918,A method and apparatus for transmitting commands between a TCP stack and an offload unit and for communicating receive and transmit data buffer locations is described. A command ring buffer stored in system memory is used to transmit commands from the TCP stack to the offload unit and to transmit command status from the offload unit to the TCP stack. A notification ring buffer is used to transmit connection information from the offload unit to the TCP stack. Other ring buffers are used to transmit locations of transmit buffers or receive buffers stored in system memory from the TCP stack to the offload unit.
7991939,"Circuits, methods, and apparatus that provide transactions to wake an external device from a low-power state before a data transfer. This prevents an interruption that would be caused if the external device exited the low-power state during the data transfer. One example monitors a need for data by a first device. At a predetermined time before data is needed, the first device sends a transaction to a second device. The transaction is intended to wake the second device from a low-power state. If the first device has information to indicate that the second device is not in a low-power state, this transaction can be skipped. The first device then requests data. Later transactions to the second device do not result in the second device exiting the low-power state and therefore do not interrupt or cause delays in the data transfer."
7992137,"Embodiments of the invention provide a data communications protocol and client server architecture used for the performance analysis and debugging of a graphics application running on a remote device. The remote device may be a hand-held video game console, a mobile phone, or convergence device, but may also be a personal computer system. A graphical application debugger may include a host component and a target component. The host component executes on a host system and presents a debugging interface to a developer. The target component may record data related to the performance of a graphics pipeline on the target device and transmit this data back to the host system over a communication link. The target component may be included as part of an instrumented version of a graphics device driver."
7995003,"One embodiment of the present invention sets forth a technique for displaying high-resolution images using multiple graphics processing units (GPUs). The graphics driver is configured to present one virtual display device, simulating a high-resolution mosaic display surface, to the operating system and the application programs. The graphics driver is also configured to partition the display surface amongst the GPUs and transmit commands and data to the local memory associated with the first GPU. A video bridge automatically broadcasts this information to the local memories associated with the remaining GPUs. Each GPU renders and displays only the partition of the display surface assigned to that particular GPU, and the GPUs are synchronized to ensure the continuity of the displayed images. This technique allows the system to display higher resolution images than the system hardware would otherwise support, transparently to the operating system and the application programs."
7995056,"A culling data selection system and method are presented in accordance with embodiments of the present invention. In one embodiment, an occlusion prediction graphics processing method is utilized to predict which pixels are eventually occluded before intermediate processing stages are performed on the pixels. Culling information utilized to predict which pixel are occluded is selected and compressed in accordance with embodiments of the present invention. In one embodiment, cull data for a pixel culling area is retrieved and an end of pipe depth occlusion data associated with a prediction area within the pixel culling area is received. A selection metric for analyzing adjustments to cull data is established and a cull data adjustment decision is made based upon the selection metric. In one exemplary implementation the possible occlusion volumes associated with “old” culling data, “new” culling data (e.g., based upon an occlusion value received from a stage later in a graphics processing pipeline) and “merged” culling data are determined. The culling data associated with the greatest volume is selected for culling operations."
7995150,"Field-based detection of 3:2 pulldown in a sequence of digital video fields using a programmable graphics processor is described. The detection is performed using a threshold value to determine equivalence between a pair of fields of digital video data. Furthermore, additional threshold values may be used to control switching into a mode where duplicated fields of digital video data are identified and not displayed and out of the mode where duplicated fields of digital video data are identified and not displayed. Look ahead can be used to detect when to switch into or out of the mode where duplicated fields of digital video data are identified and not displayed, reducing the occurrence of visual artifacts."
7995465,"A hash engine in a network device driver maintains data on the utilization and error rate for each network interface card (“NIC”) within a local computing device. From this data, the hash engine intelligently selects transmit NICs and receive NICs based on various networking parameters provided from a software driver program. Transmit packets sent from the operating system in a local computing device to a remote computing device are intercepted, modified and redirected to transmit NICs selected by the hash engine for transmission to remote computing devices. Similarly, address resolution protocol (“ARP”) response packets sent by the operating system in response to ARP request packets are intercepted, modified and redirected to receive NICs selected by the hash engine for transmission. By selecting receive NICs and transmit NICs in this fashion, the hash engine is able to intelligently load balance transmit and receive traffic in the local computing device, thereby improving overall network performance relative to prior art techniques."
7996568,"An offload system, method, and computer program product are provided. Included is a host with a processor and memory for receiving data from a network. In addition, a network interface is utilized for transferring the data to the memory via direct memory access (DMA)."
7996592,"A cross bar multipath resource controller system and method permit multiple processors in a computer system to access various resource of the computer system, such as memory or peripherals, with zero blocking access. In particular, each processor has its own bus so that the processors can each independently access different resources in the computer system simultaneously."
7996622,"In the event of a cache miss, data is written from main memory to the cache. To select a cache line to write the data to, cache lines in the cache that are not referenced during a certain interval are identified. One of the identified cache lines is selected and the data can be written to that cache line."
7999801,"A system for adjusting display data orientation. The system includes graphics circuitry to send and receive control signals over a set of control lines. The exchange of control signals is governed by a communication protocol. The graphics circuitry is configured to request orientation information via the set of control lines upon detecting a modulation of the set of control lines that is undefined by or illegal under the communication protocol. Based on the orientation information received in response to the request, the graphics circuitry adjusts the orientation of display data transmitted by the graphics circuitry."
7999808,"A system, method, and computer program product are provided for executing node traversal or primitive intersection using a parallel processing architecture. In operation, it is determined whether a plurality of threads in a parallel processing architecture are to execute node traversal or primitive intersection. Additionally, the node traversal or the primitive intersection is executed, based on the determination."
7999817,"An apparatus and method for buffering graphics data are described. In one embodiment, a graphics processing apparatus includes a memory and a buffering unit that is connected to the memory. The buffering unit is configured to buffer vertex attributes en route to the memory. The buffering unit is configured to coalesce a subset of the vertex attributes to be stored within a common range of addresses in the memory, and the buffering unit is configured to issue a single write request to the memory on behalf of the subset of the vertex attributes."
7999820,"Methods and systems for reusing memory addresses in a graphics system are disclosed, so that instances of address translation hardware can be reduced. One embodiment of the present invention sets forth a method, which includes mapping a footprint on a display screen to a group of contiguous physical memory locations in a memory system, determining an anchor physical memory address from a first transaction associated with the footprint, wherein the anchor physical memory address corresponds to an anchor in the group of contiguous physical memory locations, determining a second transaction that is also associated with the footprint, determining a set of least significant bits (LSBs) associated with the second transaction, and combining the anchor physical memory address with the set of LSBs associated with the second transaction to generate a second physical memory address for the second transaction, thereby avoiding a second full address translation."
7999821,"Circuits, methods, and apparatus that provide texture caches and related circuits that store and retrieve texels in an efficient manner. One such texture circuit can provide a configurable number of texel quads for a configurable number of pixels. For bilinear filtering, texels for a comparatively greater number of pixels can be retrieved. For trilinear filtering, texels in a first LOD are retrieved for a number of pixels during a first clock cycle, during a second clock cycle, texels in a second LOD are retrieved. When aniso filtering is needed, a greater number of texels can be retrieved for a comparatively lower number of pixels."
8001490,"A system, method and computer program product are provided for managing content for output on a wireless device. Content selected for output on a wireless device is displayed on a management screen substantially as it will be displayed on the wireless device. Organization and formatting of the content is allowed. A method for structuring navigation data in a wireless publisher is provided. Content selected for output on a wireless device is aggregated in a habitat having views with windows. An identifier of each of the views and windows is depicted in a navigation tree. Links of the windows are displayed under the identifiers of the associated windows. Linking from one window in one view to another window in another view using the navigation tree is allowed. In a further embodiment of the present invention, a method for presenting a preview of content on a display of a wireless device is provided."
8001531,"Embodiments of the invention provide a debugging tool configured to translate a pre-compiled binary shader as part of debugging a graphics application running on a remote device. An instrumented driver may capture and serialize each graphics API call invoked by a graphics application running on the remote device along with any pre-compiled binary shader programs supplied by the graphics application. The graphical application debugger may translate the shader program into a form appropriate for graphics hardware present on the host system. By replaying the same sequence of API calls invoked on the target device using the same shader programs, the graphical application debugger may generate and display the same image displayed on the target device without the latency of waiting for a full set of framebuffer data to be transmitted over the communication link for each frame rendered on the target device."
8004515,"A system and method that produces stereoscopic images modifies a vertex shader program that was intended to produce a single monoscopic image. When executed, the modified vertex shader program generates a first image of a stereoscopic image pair based on a first viewpoint and generates a second image of the stereoscopic image pair based on a second viewpoint."
8004520,"An occlusion prediction graphics processing system and method are presented in accordance with embodiments of the present invention. An occlusion prediction graphics processing method is utilized to predict which pixel values are eventually occluded before intermediate processing stages are performed on the pixel values. For example, occlusion results are predicted before the occlusion stage of a graphics pipeline. The occlusion prediction results are based upon an occlusion value received from later in a graphics processing pipeline (e.g., a raster operation stage). A convex polygonal prediction area can be established and a nearest vertex of the convex polygonal prediction area is selected for prediction analysis. Pixel values are removed or discarded from the pipeline based upon the occlusion prediction results and do not unnecessarily occupy processing resources. Removal of the pixel values from the pipeline includes pixels values associated with pixels in the convex polygonal prediction area. Pixel shading is performed on the remaining pixels."
8004522,The boundary of a surface can be represented as a series of line segments. A number of polygons are successively superimposed onto the surface. The polygons utilize a common reference point and each of the polygons has an edge that coincides with one of the line segments. Coverage bits are associated with respective sample locations within a pixel. A value of a coverage bit is changed each time a sample location associated with the coverage bit is covered by one of the polygons. Final values of the coverage bits are buffered after all of the polygons have been processed. The values of the coverage bits can be used when the surface is subsequently rendered.
8004523,An apparatus and method for translating fixed function state into a shader program. Fixed function state is received and stored and when a new shader program is detected the fixed function state is translated into shader program instructions. Registers specified by the program instructions are allocated for processing in the shader program. The registers may be remapped for more efficient use of the register storage space.
8004565,"A system and method for tracking objects between multiple frames of a video is described. One method for tracking objects begins with a viewer initially identifying an object in a frame of video. If the viewer requires zooming, he can also select a scale factor for the identified object. Once the user has identified an object for tracking, the computer system identifies a reference point on the object and identifies the motion vectors for that reference point. Using the motion vectors, the computer system can track the identified object as it moves across the screen and can reposition an image acquisition area to track the location of the identified object in subsequent video frames."
8004613,"Field-based detection of 3:2 pulldown in a sequence of digital video fields using a programmable graphics processor is described. The detection is performed using a threshold value to determine equivalence between a pair of fields of digital video data. Furthermore, additional threshold values may be used to control switching into a mode where duplicated fields of digital video data are identified and not displayed and out of the mode where duplicated fields of digital video data are identified and not displayed. Look ahead can be used to detect when to switch into or out of the mode where duplicated fields of digital video data are identified and not displayed, reducing the occurrence of visual artifacts."
8005885,"A processor, an instruction set architecture, an instruction, a computer readable medium and a method for implementing optimal per-instruction encoding of rounding control to emulate directed rounding are disclosed. In one embodiment, an apparatus designed to perform directed rounding includes an instruction decoder configured to decode an instruction, which includes a rounding control information to calculate a result boundary. The apparatus also includes a directed rounding emulator configured to adjust the result boundary to form an adjusted result boundary as a function of the rounding control bit. The adjusted result boundary establishes an endpoint for an interval that includes a result. In one embodiment, the directed round emulator is further configured to emulate a round-to-negative infinity rounding mode and a round-to-positive infinity rounding mode based on at least the single rounding control bit."
8006062,A computing system has a mode of operation in which at least two different memory parameter profiles are read by a BIOS to configure memory. In one implementation the memory parameter profiles are stored in a serial presence detect memory using an extended serial presence detect format.
8006106,"A method and system for flexibly supplying power to a high-end graphics card is described. The graphics system includes the high-end graphics card and also a configurable power supply module, which is physically separated to the graphics card and connected to a power source external to the graphics system. The configurable power supply module converts a first voltage from the power source to a second voltage for the graphics card, wherein the second voltage satisfies a set of power supply specifications required by the graphics card."
8006232,"Embodiments of the invention provide a debugging tool configured to serialize function calls made to a graphics API on a remote device such as a hand-held videogame system. Embodiments of the invention may be used to emulate the performance of the same graphics API calls made on the remote device to generate a given display frame. An instrumented driver may capture and serialize each graphics API call invoked by a graphics application running on the remote device. Thus, the host component of the graphical application debugger may generate and display the same image as displayed on the target device without the latency of waiting for a set of framebuffer data to be transmitted over the communication link for each frame rendered on the target device."
8006236,"Systems and methods for compiling high-level primitive programs are used to generate primitive program micro-code for execution by a primitive processor. A compiler is configured to produce micro-code for a specific target primitive processor based on the target primitive processor's capabilities. The compiler supports features of the high-level primitive program by providing conversions for different applications programming interface conventions, determining output primitive types, initializing attribute arrays based on primitive input profile modifiers, and determining vertex set lengths from specified primitive input types."
8009962,"Apparatus and method for processing an audio/video program is described. In one embodiment, the apparatus includes a preferences module configured to coordinate the specification of a presentation setting with a portion of the audio/video program. The apparatus also includes a presentation module coupled to the preferences module. The presentation module is configured to selectively apply the presentation setting to the portion of the audio/video program during subsequent playback of the audio/video program."
8010944,"One embodiment of the invention includes a method for extending an object-oriented programming language to include support for a shading language vector data type. The method generally includes defining a template class for a shading language vector, defining a template class for a swizzled vector, and partially specializing the vector template class for vectors of one, two, three, and four elements. The partial specialization includes a union of instances of the vector swizzle template, where each instance represents a desired vector swizzle. In addition to defining the vector and vector swizzle data types, the templates classes may overload operators provided by the object-oriented programming language to perform operations corresponding to operations of the operators in the shading language."
8010945,"One embodiment of the invention includes a method for extending an object-oriented programming language to include support for a shading language vector data type. The method generally includes defining a template class for a shading language vector, defining a template class for a swizzled vector, and partially specializing the vector template class for vectors of one, two, three, and four elements. The partial specialization includes a union of instances of the vector swizzle template, where each instance represents a desired vector swizzle. In addition to defining the vector and vector swizzle data types, the templates classes may overload operators provided by the object-oriented programming language to perform operations corresponding to operations of the operators in the shading language."
8017520,"An integrated circuit and method of fabricating the same are provided. Included are an active circuit, and a metal layer disposed, at least partially, above the active circuit. Further provided is a bond pad disposed, at least partially, above the metal layer. To prevent damage incurred during a bonding process, the aforementioned metal layer may define a frame with an outer periphery and an inner periphery."
8018463,"A video processor according to the invention is dynamically configurable as to the attributes of the video data upon which the processor operates. Some embodiments dynamically configure the processor via a sequence of instructions, where the instructions include information on the attributes of the current video data. Some embodiments include a dynamically configurable adder array that computes difference functions thereby generating error vectors. Some embodiments include a dynamically configurable adder array that computes filtering functions applied to the video data, e.g. interpolation or decimation of the incoming video prior to motion detection. Some embodiments of the invention provide dynamically configurable hardware searches, for example, for detecting motion. Some embodiments of the invention are implemented using an adaptive computing machines (ACMs). An ACM includes a plurality of heterogeneous computational elements, each coupled to an interconnection network."
8018467,"A method and apparatus which includes a graphics accelerator, circuitry responsive to pixel texture coordinates to select texels and generate therefrom a texture value for any pixel the color of which is to be modified by a texture, a cache to hold texels for use by the circuitry to generate texture value for any pixel, a stage for buffering the acquisition of texel data, and control circuitry for controlling the acquisition of texture data, storing the texture data in the cache, and furnishing the texture data for blending with pixel data."
8019978,"A unit status reporting protocol may also be used for context switching, debugging, and removing deadlock conditions in a processing unit. A processing unit is in one of five states: empty, active, stalled, quiescent, and halted. The state that a processing unit is in is reported to a front end monitoring unit to enable the front end monitoring unit to determine when a context switch may be performed or when a deadlock condition exists. The front end monitoring unit can issue a halt command to perform a context switch or take action to remove a deadlock condition and allow processing to resume."
8020150,"A system, method, and computer program product are provided for controlling a driver. In use, at least one script is received. Further, control code is generated based on the script. The control code is then executed during runtime for controlling a driver."
8021193,"A display adapter for a digital connector and an analog connector. The display adapter includes a PCB (printed circuit board). A first connector and a second connector are both mounted on the PCB. The first connector and second connectors can be VGA, DVI-I, DVI-D, or HDMI format. The PCB is configured to communicatively couple video signals between the first connector having one format and the second connector having a different format."
8021194,"A display adapter for a digital connector and an analog connector. The display adapter includes a PCB (printed circuit board). A first connector and a second connector are both mounted on the PCB. The first connector and second connectors can be VGA, DVI-I, DVI-D, or HDMI format. The PCB is configured to communicatively couple video signals between the first connector having one format and the second connector having a different format."
8023752,"Systems and methods compress and decompress 16 bit data. The 16 bit data may be signed or unsigned and represented in a fixed point or floating point format. A fixed block size of data is compressed into a fixed length format. Data compressed using a medium quality compression scheme may be efficiently decompressed in hardware. Data may be efficiently compressed and decompressed in hardware using a high quality compression scheme. The high quality compression scheme has a lower compression ratio compared with the medium quality compression scheme, but is near lossless in terms of quality."
8026515,"A platform-independent temperature controller system and method are provided. Included is a sensor is in communication with an integrated circuit. Further, a platform-independent temperature controller is in communication, with the sensor for controlling a temperature of the integrated circuit."
8026912,"One embodiment of the present invention sets forth a technique for efficiently creating and accessing an A-Buffer with a GPU. The A-Buffer is organized in arrays of uniformly-sized tiles. Each array represents a group of pixels, and each tile within an array includes the set of fragments at a specific depth complexity that are associated with the pixels in the pixel group represented by the array. The size of the tiles may be selected to be the minimum necessary for efficient memory access. The GPU determines the number of tiles in each array by calculating the maximum of the depth complexity associated with the pixels in the pixel group represented by the array and creates a corresponding prefix sum image to allow the GPU to efficiently locate the array associated with a given pixel group in the A-Buffer for addressing purposes. Advantageously, structuring the A-Buffer by both pixel proximity and depth complexity improves memory locality, thereby improving the overall rendering performance of the graphics pipeline."
8031197,"Disclosed are a GPU video data preprocessor, a computer device, an apparatus and a method for facilitating expeditious video transfer to graphics memory for enhancing display and video capture applications, among other things. In one embodiment, a graphics preprocessor is used to preprocess video for transit via a graphics processing unit (“GPU”) directly to graphics memory without invoking a graphics driver. The graphics preprocessor includes an input configured to receive video data. It also includes a native data formatter coupled to the input and configured to format the video data as GPU data to conform with the architecture of the GPU. In at least one embodiment, the graphics preprocessor also includes a command execution unit, which can be configured to transmit an instruction executable by the GPU as a transmitted instruction to perform a graphics pipeline operation on the GPU data."
8031198,"An apparatus and method for servicing multiple graphics processing channels are described. In one embodiment, a graphics processing apparatus includes a scheduler configured to direct servicing of a graphics processing channel by issuing an index related to the graphics processing channel. The graphics processing apparatus also includes a processing core connected to the scheduler. The processing core is configured to service the graphics processing channel by: (i) correlating the index with a memory location at which an instance block for the graphics processing channel is stored; and (ii) accessing the instance block stored at the memory location."
8031204,"Systems and methods used for bilinear texture filtering may also be used to perform font filtering. Font data stored as a texture is read from memory in blocks that are coarsely aligned. Font alignment units may be used to provide a finely aligned region of the font data within a font filter footprint. The finely aligned region is then filtered using bilinear filtering to produce font coverage information representing a grayscale value for a pixel. Using existing bilinear filtering engines in conjunction with font alignment and sample units reduces the need for having a specific engine to perform each of the font filtering operations, possibly saving die area in a graphics system."
8031969,"Methods and apparatuses for selecting appropriate anisotropic filtering levels for images. An image is obtained, that image is Fourier transformed into its frequency components, and then those frequency components are normalized. The Fourier transformed into its frequency components are assigned to Fourier buckets (or bins) having dimensions selected in accord with the number of available anisotropic filtering levels. A predetermined threshold value is used to select one of the Fourier buckets by comparing the predetermined threshold value with the contents of the Fourier buckets. The selected Fourier bucket is used to determine an appropriate anisotropic filtering level for the image. Some embodiments of the present invention can provide for an automatic selection and setting of the appropriate anisotropic filtering level."
8032354,"A method and system for communicating between two independent software components of the WINDOWS® SIDESHOW™ device are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of independently queuing an incoming packet from a second software component via an emulated serial transport in a first software component before parsing and responding to the incoming packet and independently queuing an outgoing packet in the first software component before transmitting the outgoing packet to the second software component also via the emulated serial transport."
8035645,"Multichip graphics processing subsystems include at least three distinct graphics devices (e.g., expansion cards) coupled to a high-speed bus (e.g., a PCI Express bus) and operable in a distributed rendering mode. One of the graphics devices provides pixel data to a display device, and at least one of the other graphics devices transfers the pixel data it generates to another of the devices via the bus to be displayed. Where the high-speed bus provides data transfer lanes, allocation of lanes among the graphics devices can be optimized."
8035647,"A raster operations (ROP) unit interleaves read and write requests for efficiently communicating with a frame buffer via a PCI Express (PCI E) link or other system bus that provides separate upstream and downstream data transfer paths. One example of a ROP unit processes pixels in groups, performing read modify writeback sequences for each group. The read requests associated with pixels in a second group are advantageously interleaved with the writeback requests for pixels in the first group prior to sending the requests on the system bus."
8035648,"A method, in accordance with an embodiment of the invention, includes detecting a memory page miss associated with a thread operating on a Graphics Processing Unit (GPU). A request can be issued to receive the memory page associated with the memory page miss. There can be a switch into a runahead mode. During the runahead mode, a future memory page miss can be detected. During the runahead mode, a request can be issued to receive the future memory page associated with the future memory page miss."
8035750,"Field-based detection of 3:2 pulldown in a sequence of digital video fields using a programmable graphics processor is described. The detection is performed using a threshold value to determine equivalence between a pair of fields of digital video data. Furthermore, additional threshold values may be used to control switching into a mode where duplicated fields of digital video data are identified and not displayed and out of the mode where duplicated fields of digital video data are identified and not displayed. Look ahead can be used to detect when to switch into or out of the mode where duplicated fields of digital video data are identified and not displayed, reducing the occurrence of visual artifacts."
8037119,"A multipurpose arithmetic functional unit selectably performs planar attribute interpolation, unary function approximation, and double-precision arithmetic. In one embodiment, planar interpolation operations for coordinates (x, y) are executed by computing A*x+B*y+C, and unary function approximation operations for operand x are executed by computing F2(xb)*xh2+F1(xb)*xh+F0(xb), where xh=x−xb. Shared multiplier and adder circuits are advantageously used to implement the product and sum operations for unary function approximation and planar interpolation; the same multipliers and adders are also leveraged to implement double-precision multiplication and addition."
8037391,"One embodiment of the present invention sets forth a technique for performing RAID-6 computations using simple arithmetic functions and two-dimensional table lookup operations. Four lookup tables are computed and saved prior to normal operation of a RAID-6 disk array. During normal operation of the RAID-6 disk array, all RAID-6 related computations may be performed using a small set of simple arithmetic operations and a set of lookup operations to three of the four previously saved lookup tables. Greater computational efficiency is gained by reducing the RAID-6 computations to simple operations that are performed efficiently on a typical central processing unit or graphics processing unit."
8037480,A first process executing in a computer system creates thread-level message hooks within a second process executing in the computer system. A copy of a global notification hook of the first process is created in the second process. The copy detects a triggering message passed to or from a thread of the second process and determines when and whether to activate a thread-level message hook within the second process; the thread-level message hook is configured to monitor subsequent messages passed to or from the thread of the second process and may take various actions in response to any such messages.
8040349,"One embodiment of the present invention sets forth a technique for efficiently creating and accessing an A-Buffer with a GPU. The A-Buffer is organized in arrays of uniformly-sized tiles. Each array represents a group of pixels, and each tile within an array includes the set of fragments at a specific depth complexity that are associated with the pixels in the pixel group represented by the array. The size of the tiles may be selected to be the minimum necessary for efficient memory access. The GPU determines the number of tiles in each array by calculating the maximum of the depth complexity associated with the pixels in the pixel group represented by the array and creates a corresponding prefix sum image to allow the GPU to efficiently locate the array associated with a given pixel group in the A-Buffer for addressing purposes. Advantageously, structuring the A-Buffer by both pixel proximity and depth complexity improves memory locality, thereby improving the overall rendering performance of the graphics pipeline."
8040351,A system and method uses the capabilities of a geometry shader unit within the multi-threaded graphics processor to execute a geometry shader program and perform a Hough transform.
8040357,"Embodiments of the present invention pixel processing system and method provide convenient and efficient processing of pixel information. In one embodiment, quotient-remainder information associated with barycentric coordinate information indicating the location of a pixel is received. In one exemplary implementation quotient-remainder information is associated with barycentric coordinate information through the relationship c divided by dcdx, where c is the barycentric coordinate for a particular edge and dcdx is the derivative of the barycentric coordinate in the screen horizontal direction. The relationship of a pixel with respect to a primitive edge is determined based upon the quotient-remainder information. For example, a positive quotient can indicate a pixel is inside a triangle and a negative quotient can indicate a pixel is outside a triangle. Pixel processing such as shading is performed in accordance with the relationship of the pixel to the primitive."
8041550,"One embodiment of the present invention sets forth a technique for computing two-way rigid body coupling in a two-dimensional height field simulation, such as a shallow water simulation. Coupling from a rigid body to a fluid is computed using fluid displacement of the body in each grid cell. The body is projected onto a simulation plane to determine which grid cells are covered by the body. Fluid displacement from the body is computed for each grid cell based on displacement within a corresponding vertical column of fluid. Fluid displacement is distributed to neighboring grid cells prior to a height field computation. Coupling from the fluid to the rigid body is computed by integrating forces imparted on the body by the fluid at each grid cell. The integrated forces are used to compute a new position for the body in a subsequent simulation time step."
8041841,"Method and interface for configuring a link is described. A transceiver has configuration registers. The configuration registers are read to determine capability of the transceiver. An application is selected, and the configuration registers of the transceiver are configured responsive to the application selected. A protocol having initialization, transmit and receive portions is described to facilitate configuration operations, such as reads and writes of configuration registers, for such a link."
8044922,"Embodiments of the present invention generally provide m Methods and apparatus for reducing power consumption of backlit displays are described. Power consumption is reduced by dimming backlighting by a first scale factor and boosting pixel values by a second scale factor to compensate for the dimming. The scale factors may be constant values. Alternately, one or both of the scale factors may be determined based on pixel values for one or more frames to be displayed and/or one or more frames that have been displayed. For example, scale factors may be calculated based on an average linear amplitude of one or more frames of pixel values or from a maximum pixel value of one or more frames of pixel values. A graphical processing system is described including an integrated circuit capable of transforming a pixel value from a gamma-compensated space to a linear space."
8044923,"Embodiments of the present invention generally provide m Methods and apparatus for reducing power consumption of backlit displays are described. Power consumption is reduced by dimming backlighting by a first scale factor and boosting pixel values by a second scale factor to compensate for the dimming. The scale factors may be constant values. Alternately, one or both of the scale factors may be determined based on pixel values for one or more frames to be displayed and/or one or more frames that have been displayed. For example, scale factors may be calculated based on an average linear amplitude of one or more frames of pixel values or from a maximum pixel value of one or more frames of pixel values. A graphical processing system is described including an integrated circuit capable of transforming a pixel value from a gamma-compensated space to a linear space."
8044924,"Embodiments of the present invention generally provide m Methods and apparatus for reducing power consumption of backlit displays are described. Power consumption is reduced by dimming backlighting by a first scale factor and boosting pixel values by a second scale factor to compensate for the dimming. The scale factors may be constant values. Alternately, one or both of the scale factors may be determined based on pixel values for one or more frames to be displayed and/or one or more frames that have been displayed. For example, scale factors may be calculated based on an average linear amplitude of one or more frames of pixel values or from a maximum pixel value of one or more frames of pixel values. A graphical processing system is described including an integrated circuit capable of transforming a pixel value from a gamma-compensated space to a linear space."
8044944,Systems and methods for identifying defective pixels and adjusting an input to control display of the defective pixels may improve the quality of the image viewed on a flat panel display including one or more defective pixels. The screen position of each defective pixel is identified and stored. Adjustment information is also stored for each defective pixel. The adjustment information is used to modify a stored color value for each defective pixel or to disable one or more color components of each defective pixel prior to displaying an image on a flat panel display device including the defective pixels.
8044951,"One embodiment of the present invention sets forth a technique for improving the flexibility and programmability of a graphics pipeline by adding application programming interface (API) extensions to the OpenGL Shading Language (GLSL) that provide native support for integer data types and operations. The integer API extensions span from the API to the hardware execution units within a graphics processing unit (GPU), thereby providing native integer support throughout the graphics pipeline."
8044956,"One embodiment of the present invention sets forth a technique for improving antialiasing quality, while minimizing performance degradation, by adaptively selecting between multisampling and supersampling on a per pixel basis. The resulting performance may be generally comparable to multisampling. At the same time, however, the resulting quality may be generally comparable to supersampling. The antialiasing technique disclosed herein determines whether to use multisampling or supersampling on a particular pixel being rendered, based on the specific coverage of the associated geometry primitive. Because many pixel centers are covered by a geometry primitive, a statistical performance advantage is gained when pixels in a rendered image can be generating using multisampling rather than supersampling. The cases where pixel centers are not covered tend to be less frequent, but are very significant to image quality. High image quality is maintained by rendering these cases using supersampling."
8044966,"Method and apparatus for display image adjustment is described. More particularly, handles associated with polygon vertices of a polygon rendered image are provided as a graphical user interface (GUI). These handles may be selected and moved by a user with a cursor pointing device to adjust a displayed image for keystoning, among other types of distortion. This GUI allows a user to adjust a projected image for position of a projector with respect to imaging surface, as well as for imaging surface contour, where such contour may be at least substantially planar, cylindrical, or spherical and where such contour may comprise multiple imaging surfaces. This advantageously may be done without special optics or special equipment. An original image is used as texture for rendering polygons, where the image is applied to the rendered polygons."
8045330,"A method and apparatus for providing an alternative power source for a graphics card are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of laying a set of gold fingers on a printed circuit board according to an industrial standard bus interface, positioning a wire in a middle layer of the printed circuit board, attaching a first end of the wire to a specific gold finger, and attaching the alternative power source to a second end of the wire, wherein the second end of the wire is an electroplated contact protruded external to the printed circuit board."
8046586,"A method and system are implemented for verifying connection status information associated with a specific display attachment location. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of receiving a first signature representative of a first set of connection states tracked by a graphics subsystem associated with the display attachment location, authenticating whether the integrity of a content path including the display attachment location is maintained based on the first signature, and deciding whether to continue sending the content to the display attachment location so that requirements associated with protecting the content are satisfied."
8049761,"One embodiment of the present invention sets forth a protocol for packing and transferring pixel data between integrated circuits. The data transfer protocol may be used between a graphics processing unit and a video output encoder unit. The data transfers may include up to 20 pixels per arbitration cycle. By packing pixel data for transfer over a bus with a relatively small set of output pins, overall package pin count is reduced, while maintaining sufficient bandwidth to carry the pixel data the output pins. By moving the analog circuitry to a separate device, linked to the GPU via the bus, noise from the GPU may be effectively mitigate through physical separation."
8051123,"A multipurpose arithmetic functional unit selectively performs planar attribute interpolation, unary function approximation, double-precision arithmetic, and/or arbitrary filtering functions such as texture filtering, bilinear filtering, or anisotropic filtering by iterating through a multi-step multiplication operation with partial products (partial results) accumulated in an accumulation register. Shared multiplier and adder circuits are advantageously used to implement the product and sum operations for unary function approximation and planar interpolation; the same multipliers and adders are also leveraged to implement double-precision multiplication and addition."
8051126,"A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though, in one embodiment, it is sharing the same chip."
8051279,"A method and system for enabling an auxiliary system to retrieve the system information from a computing device are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of requesting for the system information from an embedded controller of the computing device through a first bi-directional data bus if the computing device is shut down, requesting for the system information from the computing device through the first bi-directional bus during the boot-up sequence of the computing device, and requesting for the system information from the computing device through a general purpose input/output (GPIO) after the computing device completes the boot-up sequence."
8054316,"A system and method for adjusting pictures minimizes the impact on graphics processing performance of a discrete processor. A hybrid system configuration includes the discrete processor and an integrated processor, where the discrete processor typically consumes more power and provides greater processing performance compared with the integrated processor. A picture is produced by a video or graphics engine of a discrete processor within a hybrid system. Each picture is then transferred to a back buffer in the host processing memory. The picture is analyzed to produce picture analysis results that are used to generate adjustment settings. The back buffer is swapped to become the front buffer and the adjustment settings are applied to the picture by an integrated processor to display an adjusted picture. The adjustment may be used in conjunction with power saving techniques to maintain the image quality when display backlighting is reduced."
8055842,"Systems and methods for using RAID with ATA mass storage devices can benefit from operating system optimizations for avoiding unaligned write accesses. When the ATA mass storage devices in the RAID array have different physical sector sizes, the largest physical sector size is reported as the physical sector size for the single disk represented by the RAID array. The operating system can optimize accesses that are aligned with all of the physical sector sizes within the RAID array. Additionally, any storage devices that have a first logical sector that does not have an offset of zero, are configured to ignore all logical sectors in the first physical sector. Accesses to the first logical sector are mapped to the second physical sector. A logical sector alignment of zero is then reported to the operating system for the RAID array, enabling the operating system to avoid unaligned writes."
8055856,"A system and method for locking and unlocking access to a shared memory for atomic operations provides immediate feedback indicating whether or not the lock was successful. Read data is returned to the requestor with the lock status. The lock status may be changed concurrently when locking during a read or unlocking during a write. Therefore, it is not necessary to check the lock status as a separate transaction prior to or during a read-modify-write operation. Additionally, a lock or unlock may be explicitly specified for each atomic memory operation. Therefore, lock operations are not performed for operations that do not modify the contents of a memory location."
8055871,"A synchronous memory device is configured to switch into and out of a full speed mode to change speed the speed of data transactions without significantly disturbing the frequency of a clock input to a PLL or DLL that provides the internal clock for the synchronous memory device. Since the PLL or DLL receives a clock signal whether or not the synchronous memory device is in a non-full speed mode, the PLL or DLL does not need to settle or relock when the clock signal is reapplied to exit a different speed mode and return to the full speed mode. Therefore, the latency incurred to switch into and out of different speed modes is reduced by eliminating or substantially reducing the time for settling or relocking the PLL or DLL."
8056088,"The invention sets forth an approach to context switching that utilizes scan chains modified to perform context switching operations. The design requires substantially less additional silicon area and design engineering effort than existing context switch approaches, while operating substantially faster and providing additional debug observability during context switching operations."
8056093,An embodiment of the invention includes directing a kernel-mode driver to process at least a portion of a command stream configured to cause a graphics processing unit to perform an operation. The kernel-mode driver is used to issue a request to trigger creation of an asynchronous thread for processing the portion of the command stream.
8059086,"Embodiments of the present invention generally provide m Methods and apparatus for reducing power consumption of backlit displays are described. Power consumption is reduced by dimming backlighting by a first scale factor and boosting pixel values by a second scale factor to compensate for the dimming. The scale factors may be constant values. Alternately, one or both of the scale factors may be determined based on pixel values for one or more frames to be displayed and/or one or more frames that have been displayed. For example, scale factors may be calculated based on an average linear amplitude of one or more frames of pixel values or from a maximum pixel value of one or more frames of pixel values. A graphical processing system is described including an integrated circuit capable of transforming a pixel value from a gamma-compensated space to a linear space."
8059123,"A system, method, and computer program product are provided for postponing the execution of primitive intersection. In operation, at, least one node traversal operation and at least one primitive intersection operation is executed, utilizing a parallel processing architecture. Additionally, the execution of the at least one primitive intersection operation is postponed."
8059128,"A method of performing a blit operation in a parallel processing system includes dividing a blit operation into batches of pixels, performing reads of pixels associated with a first batch in any order, confirming that all reads of pixels associated with the first batch are completed, and performing writes of pixels associated with the first batch in any order. The pixels of the first batch and pixels of additional batches are applied to parallel processors, where the parallel processors include a corral defined by entry points and exit points distributed across the parallel processors."
8059131,"A tiled graphics memory permits graphics data to be stored in different tile formats. One application is selecting a tile format optimized for the data generated for particular graphical surfaces in different rendering modes. Consequently, the tile format can be selected to optimize memory access efficiency and/or packing efficiency. In one embodiment a first tile format stores pixel data in a format storing two different types of pixel data whereas a second tile format stores one type of pixel data. In one implementation, a z-only tile format is provided to store only z data but no stencil data. At least one other tile format is provided to store both z data and stencil data. In one implementation, z data and stencil data are stored in different portions of a tile to facilitate separate memory accesses of z and stencil data."
8059680,"An offload system, method, and computer program product are provided for handling transport layer processing of a connection between a local host and a remote host via at least one network. A network interface associated with the local host is utilized for such purpose. A plurality of ports allow communication between the local host and the at least one network. The communications corresponding with the connection are monitored and the connection is associated with at least one port. At least one of the ports receiving the communications corresponding with the connection are identified."
8060700,"A system and method for cleaning dirty data in an intermediate cache are disclosed. A dirty data notification, including a memory address and a data class, is transmitted by a level 2 (L2) cache to frame buffer logic when dirty data is stored in the L2 cache. The data classes include evict first, evict normal and evict last. In one embodiment, data belonging to the evict first data class is raster operations data with little reuse potential. The frame buffer logic uses a notification sorter to organize dirty data notifications, where an entry in the notification sorter stores the DRAM bank page number, a first count of cache lines that have resident dirty data and a second count of cache lines that have resident evict_first dirty data associated with that DRAM bank. The frame buffer logic transmits dirty data associated with an entry when the first count reaches a threshold."
8060765,"A power monitor for electronic devices, such as computer chips, is used to estimate the power consumption and to compare the estimated power consumption against the power budget. The estimated power consumption is based on activity signals from various functional blocks of the computer chip. The activity signals that are monitored correlate accurately to the total number of flip-flops that are active at a given time. If the estimated power consumption exceeds the power budget, the speed of the clock signals supplied to the computer chip is reduced."
8063903,"The edge evaluation technique, in accordance with one embodiment of the present technology, includes determining a number of edges of a given primitive to be evaluated. The technique also includes sequencing evaluation of a first edge by a first edge evaluation circuit and a second edge by a second edge evaluation circuit during a first clock cycle. The technique further includes sequencing evaluation of a third edge by the first edge evaluation circuit and a fourth edge by the second edge evaluation circuit during a second clock cycle if three or more edges are to be evaluated."
8063908,"A system, method, and computer program product are provided for validating a graphics processor design. In operation, a test image is identified. Additionally, a reference image is automatically selected from a set of reference images. Furthermore, a graphics processor design is validated using the test image and the selected reference image."
8064726,"An apparatus and method are provided for approximating a convolution function (e.g. a diffusion profile, etc.) utilizing a sum of Gaussian functions. In use, results of a plurality of Gaussian functions are calculated. The results of the Gaussian functions are further summed. To this end, an approximation of a convolution function is generated based on the sum. Further, an image is rendered utilizing the approximation."
8065288,"A system, method, and computer program product are provided for testing a query against multiple sets of objects. In operation, a query is tested against a first set of objects, utilizing a single instruction multiple data processing architecture. Additionally, a second set of objects is selected based on a result of testing the query against the first set of objects. Furthermore, the query is tested against the second set of objects, utilizing the single instruction multiple data processing architecture."
8065354,"Systems and methods compress and decompress 16 bit data. The 16 bit data may be signed or unsigned and represented in a fixed point or floating point format. A fixed block size of data is compressed into a fixed length format. Data compressed using a medium quality compression scheme may be efficiently decompressed in hardware. Data may be efficiently compressed and decompressed in hardware using a high quality compression scheme. The high quality compression scheme has a lower compression ratio compared with the medium quality compression scheme, but is near lossless in terms of quality."
8065439,"A system, method, and related data structure are provided for transmitting data in a network. Included is a data object (i.e. metadata) for communicating between a first network protocol layer and a second network protocol layer. In use, the data object facilitates network communication management utilizing a transport offload engine."
8065465,"One embodiment of the invention sets forth a control crossbar unit that is designed to transmit control information from control information generators to destination components within the computer system. The control information may belong to various traffic paradigms, such as short-latency data traffic, narrow-width data traffic or broadcast data traffic. The physical connections within the control crossbar unit are categorized based on the different types of control information being transmitted through the control crossbar unit. The physical connections belong to the following categories: one-to-one (OTO) connections, one-to-many (OTM) connections, valid-to-one (VTO) connections, valid-to-many (VTM) connections wire-to-one (WTO) connections and wire-to-many (WTM) connections."
8065590,"A RAID disk drive controller (FIG. 33) implements disk storage operations, including striping and redundancy operations with multiple disk drives connected via respective SATA ports (520). Configurable data path switch logic (460) provides dynamic configuration of two or more attached drives into one or more arrays. Data transfers are synchronized locally by leveraging the SATA port transport layer FIFO (530). Synchronous transfers allow on-the-fly redundancy (XOR) operations (FIG. 36) for improved performance and reduced hardware complexity. XOR accumulator hardware (FIG. 42-FIG. 43) reduces buffer requirements for multiple DMA channels otherwise required for synchronization, and various narrow and wide striping modes are supported."
8066515,A system provides a digital multi-bit connection between two or more graphics adapters. Each graphics adapter is manufactured as a printed circuit board including a finger-type edge connector. When two or more graphics adapters are installed in a system the edge connectors of each graphics adapter may be coupled to each other via a connection device that provides a portion of the digital multi-bit connection. The remainder of the digital multi-bit connection is provided by conductive traces coupling each finger of the edge connector to a graphics processing unit that is affixed to the graphics adapter. The connection device may be installed by an end-user as each additional graphics adapter is installed in the system.
8068118,"Systems and methods for modifying the number of texture samples used to produce an anisotropically filtered texture mapped pixel may improve texture mapping performance. When the number of texture samples is reduced, fewer texels are read and fewer filtering computations are needed to produce a texture value for an anisotropic footprint. The number of texture samples is reduced based on the mip map level weight. The number of texture samples may also be modified using specific parameters for the coarse and/or fine mip map levels. The spacing between the texture samples along the major axis of anisotropy may be modified to improve image quality or texture cache performance."
8068181,"Field-based detection of 3:2 pulldown in a sequence of digital video fields using a programmable graphics processor is described. The detection is performed using a threshold value to determine equivalence between a pair of fields of digital video data. Furthermore, additional threshold values may be used to control switching into a mode where duplicated fields of digital video data are identified and not displayed and out of the mode where duplicated fields of digital video data are identified and not displayed. Look ahead can be used to detect when to switch into or out of the mode where duplicated fields of digital video data are identified and not displayed, reducing the occurrence of visual artifacts."
8069355,"A data path controller, a computer device, an apparatus and a method are disclosed for integrating power management functions into a data path controller to manage power consumed by processors and peripheral devices. By embedding power management within the data path controller, the data path controller can advantageously modify its criteria in-situ so that it can adapt its power management actions in response to changes in processors and peripheral devices. In addition, the data path controller includes a power-managing interface that provides power-monitoring ports for monitoring and/or quantifying power consumption of various components. In one embodiment, the data path controller includes a power-monitoring interface for selectably monitoring power of a component. It also includes a controller for adjusting operational characteristics of the component for modifying the power consumed by the component to comply with a performance profile, which generally specifies permissible power consumption levels for the component."
8069449,"A method and system for enabling an auxiliary system, such as a WINDOWS® SIDESHOW™ device, to support enhanced features is provided. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of emulating a physical communication channel to establish a virtual communication channel, encapsulating data associated with a first function defined by a first Application Programming Interface (API) and utilized to implement an enhanced feature, and sending the encapsulated data through the virtual communication channel for an embedded operation system (OS) to manage hardware resources of the auxiliary system to perform the enhanced feature."
8072454,"A system, method, and computer program product are provided for selecting a ray tracing entity from a group of ray tracing entities for processing by a parallel processing architecture. In operation, it is determined whether at least one thread in a parallel processing architecture has completed processing a ray tracing entity. Further, an additional ray tracing entity is selected from a group of ray tracing entities for processing by the parallel processing architecture, based on the determination."
8072460,"A system, method, and computer program product are provided for generating a ray tracing data structure utilizing a parallel processor architecture. In operation, a global set of data is received. Additionally, a data structure is generated utilizing a parallel processor architecture including a plurality of processors. Such data structure is adapted for use in performing ray tracing utilizing the parallel processor architecture, and is generated by allocating the global set of data among the processors such that results of processing of at least one of the processors is processed by another one of the processors."
8072462,"A system, method, and computer program product are provided for preventing display of unwanted content stored in a frame buffer. In use, unwanted content stored in a frame buffer is identified. Furthermore, display of the unwanted content is prevented based on the identification of the unwanted content."
8072463,"A graphics system utilizes virtual memory pages and has a partitioned graphics memory that includes memory elements. The system supports having an non-power of two number of active memory elements. Additionally, a partition swizzling operation is used to adjust the partition numbers associated with individual units of virtual memory allocation on particular virtual memory pages to achieve a selected partition interleaving pattern."
8073002,"An offload system, method, and computer program product are provided. Based on an identified data structure, it is determined whether a hardware network interface is operating in a first mode or a second mode. The hardware network interface is coupled between a network and a processor. If it is determined that the hardware network interface is operating in the first mode, the packets are processed utilizing the processor. If it is determined that the hardware network interface is operating in the second mode, the packets are processed utilizing the hardware network interface."
8073675,"A RAID storage device controller provides a host interface for interfacing the controller to a host system bus. The host interface is isolated from the attached storage devices, for example IDE disk drives, so that the actual attached drives are not limited in number or interface protocol. Various device ports can be implemented, and various RAID strategies, e.g., level 3 and level 5, can be used. In all the cases, the host interface provides a standard, uniform interface to the host, namely an ATA interface, and preferably a dual channel ATA interface. The host interface emulates the ATA single or dual channel interface and emulates one or two attached IDE devices per channel, regardless of the actual number of devices physically connected to the controller. Thus, for example, five or seven IDE drives can be deployed in RAID level 5 protocol without changing the standard BIOS in a PCI host machine. Thus the RAID controller is transparent relative to a standard dual channel ATA controller board."
8074149,"A RAID disk drive controller (FIG. 33) implements disk storage operations, including striping and redundancy operations with multiple disk drives connected via respective SATA ports (520). Configurable data path switch logic (460) provides dynamic configuration of two or more attached drives into one or more arrays. Data transfers are synchronized locally by leveraging the SATA port transport layer FIFO (530). Synchronous transfers allow on-the-fly redundancy (XOR) operations (FIG. 36) for improved performance and reduced hardware complexity. XOR accumulator hardware (FIG. 42-FIG. 43) reduces buffer requirements for multiple DMA channels otherwise required for synchronization, and various narrow and wide striping modes are supported."
8074224,"Embodiments of the present invention facilitate dynamically adapting to state information changes in a graphics processing environment. In one embodiment, a master register holds state information corresponding to units of work (threads) to be performed. The state information in the master register is copied to a per-group state register when a group of threads is to be launched. The per-group state register is coupled to processing engines configured to process the threads, so that the processing engines read state information from the per-group state register rather than the master register. In another embodiment, a number of master registers may be used to store state information for different types of threads."
8077174,"Apparatuses and methods are presented for a hierarchical processor. The processor comprises, at a first level of hierarchy, a plurality of similarly structured first level components, wherein each of the plurality of similarly structured first level components includes at least one combined function module capable of performing multiple classes of graphics operations, each of the multiple classes of graphics operations being associated with a different stage of graphics processing. The processor comprises, at a second level of hierarchy, a plurality of similarly structured second level components positioned within each one of the plurality of similarly structured first level components, wherein each of the plurality of similarly structured second level components is capable of carrying out different operations from the multiple classes of graphics operations, wherein each first level component is adapted to distribute work to the plurality of similarly structured second level components positioned within the first level component."
8077181,"Systems and methods for balancing a load among multiple graphics processors that perform different portions of a rendering task. A rendering task is partitioned into portions for each of two (or more) graphics processors. The graphics processors perform their respective portions of the rendering task and return feedback data indicating completion of the assigned portion. Based on the feedback data, an imbalance can be detected between respective loads of two of the graphics processors. In the event that an imbalance exists, the rendering task is re-partitioned to increase the portion assigned to the less heavily loaded processor and to decrease the portion assigned to the more heavily loaded processor."
8078656,"Methods and systems for decompressing data are described. The relative magnitudes of a first value and a second value are compared. The first value and the second value represent respective endpoints of a range of values. The first value and the second value each have N bits of precision. Either the first or second value is selected, based on the result of the comparison. The selected value is scaled to produce a third value having N+1 bits of precision. A specified bit value is appended as the least significant bit of the other (non-selected) value to produce a fourth value having N+1 bits of precision."
8078844,"A system, method, and computer program product are provided for removing a register of a processor from an active state. In operation, an aspect of a portion of a processor capable of simultaneously processing a plurality of threads is identified. Additionally, a register of the processor is conditionally removed from an active state, based on the aspect."
8081184,"Systems and methods for assembling pixel shader program threads for execution based on resource limitations of a multithreaded processor may improve processing throughput. Pixels to be processed by the pixel shader program are assembled into a launch group for processing by the multithreaded processor as multiple shader program threads. The pixels are assembled based on parameter storage resource limitations of the multithreaded processor so that common parameters shared by multiple pixels are not stored separately for each pixel. Therefore, the limited parameter storage resources are efficiently used, allowing more shader program threads to execute simultaneously."
8082381,"In accordance with an aspect of the present invention, a corresponding list of muxes is maintained for each combination of a peripheral and a mux option. The list is then retrieved to program the required muxes to connect the communication paths from a peripheral on the corresponding mux option, based on which the list is retrieved. In an embodiment, the information is maintained in the form of a table, with each entry storing the data corresponding to a mux and mux option. The entries are linked by appropriate pointers to form the linked list."
8085217,"A system, method, and computer program product are provided for compensating for crosstalk during the display of stereo content. In use, display content is received for being outputted utilizing a display system. Such display system inherently exhibits crosstalk, whereby an amount of left eye display content is displayed to a right eye of a user and an amount of right eye display content is displayed to a left eye of the user. Thus, prior to outputting the display content utilizing the display system, the display content is processed utilizing a graphics processor to compensate for the amount of the left eye display content to be displayed to the right eye of the user and the amount of the right eye display content to be displayed to the left eye of the user. In one embodiment where the crosstalk is a function of pixel location, the compensation may also be a function of pixel location. [e.g. in the case of a liquid crystal display (LCD), etc.]."
8085239,"Embodiments of the present invention generally provide methods and apparatus for reducing power consumption of backlit displays are described. Power consumption is reduced by dimming backlighting by a first scale factor and boosting pixel values by a second scale factor to compensate for the dimming. The scale factors may be constant values. Alternately, one or both of the scale factors may be determined based on pixel values for one or more frames to be displayed and/or one or more frames that have been displayed. For example, scale factors may be calculated based on an average linear amplitude of one or more frames of pixel values or from a maximum pixel value of one or more frames of pixel values. A graphical processing system is described including an integrated circuit capable of transforming a pixel value from a gamma-compensated space to a linear space."
8085264,A method for multiple queue output buffering in a raster stage of a graphics processor. The method includes receiving a graphics primitive for rasterization in a raster stage of a graphics processor. The graphics primitive is rasterized at a first level to generate a plurality of tiles of pixels related to the graphics primitive. Each tile is then rasterized to determine related sub-portions of each tile. The related sub-portions are transferred to a plurality of output queues. The related sub-portions are subsequently output on a per queue basis and on a per clock cycle basis.
8085272,"A method and system for improving data coherency in a parallel rendering system is disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of receiving a common input stream, tracking a periodic event associated with the common input stream, generating a plurality of fragment streams from the common input stream, inserting a marker based on an occurrence of the periodic event in a first fragment stream in the multiple fragment streams, and utilizing the marker to influence the processing of the first fragment stream so that a plurality of raster operation (ROP) request streams maintains substantially the same coherence as the common input stream. Each fragment stream is independently processed and corresponds to one of the ROP request streams."
8085275,"A push buffer-related system, method and computer program product are provided. Initially, an entry is obtained from a buffer storage describing a size and location of a portion of a push buffer. To this end, the portion of the push buffer is capable of being retrieved, utilizing the entry from the buffer storage."
8086806,"One embodiment of the present invention sets forth a technique for efficiently and flexibly performing coalesced memory accesses for a thread group. For each read application request that services a thread group, the core interface generates one pending request table (PRT) entry and one or more memory access requests. The core interface determines the number of memory access requests and the size of each memory access request based on the spread of the memory access addresses in the application request. Each memory access request specifies the particular threads that the memory access request services. The PRT entry tracks the number of pending memory access requests. As the memory interface completes each memory access request, the core interface uses information in the memory access request and the corresponding PRT entry to route the returned data. When all the memory access requests associated with a particular PRT entry are complete, the core interface satisfies the corresponding application request and frees the PRT entry."
8086828,"Heterogeneous processors can cooperate for distributed processing tasks in a multiprocessor computing system. Each processor is operable in a “compatible” mode, in which all processors within a family accept the same baseline command set and produce identical results upon executing any command in the baseline command set. The processors also have a “native” mode of operation in which the command set and/or results may differ in at least some respects from the baseline command set and results. Heterogeneous processors with a compatible mode defined by reference to the same baseline can be used cooperatively for distributed processing by configuring each processor to operate in the compatible mode."
8087029,"Resources to be used by concurrent threads in a multithreaded processor are allocated based on thread types of the threads, and thread-type-based criteria governing resource allocation decisions are dynamically modified based on feedback information indicating the degree to which various thread types are using the resource. For each of at least two thread types, an amount of the resource is reserved, and amounts currently allocated are tracked. When an allocation request for a new thread is received, the allocation is made or not based on the new thread's type, the amount of the resource reserved for that type, and the amount currently allocated to threads of that type. If, based on feedback information from the allocation decision, the amount of the resource reserved for one thread type is determined to be insufficient, the reserved amounts are modified to better meet the demand."
8093854,"A system for controlling the fan speed is described. Specifically, one embodiment of the present invention set forth a computing system, which includes a first processing unit including a first sensor, wherein the first processing unit is configured to generate a first pulse-width modulation signal, and a first transmission line further including a first direct current voltage converter configured to convert the first pulse-width modulation signal to a first direct current voltage and a first diode coupled to the first direct current voltage converter, wherein the first diode determines whether the first direct current voltage passes through the first diode. The computing system further includes an amplifier coupled to the first diode, wherein the amplifier is configured to amplify a selected direct current voltage to drive a fan."
8094151,"One embodiment of the present invention sets forth a technique for performing dual depth peeling, which is useful for order-independent transparency blending. Multiple rendering passes are performed on a graphics scene. After each rendering pass, the front-most and back-most layer of pixels are peeled away by computing a reference window. In subsequent rendering passes, only pixels within the reference window survive depth sorting. In each subsequent rendering pass, the reference window is narrowed by the front most and back most surviving pixels. By performing depth peeling in two directions simultaneously, the number of rendering passes needed to generate a completed graphics image is reduced from L to 1+L/2, which results in improved rendering performance."
8094152,"One embodiment of the present invention sets forth a technique for performing dual depth peeling, which is useful for order-independent transparency blending. Multiple rendering passes are performed on a graphics scene. After each rendering pass, the front-most and back-most layer of pixels are peeled away by computing a reference window. In subsequent rendering passes, only pixels within the reference window survive depth sorting. In each subsequent rendering pass, the reference window is narrowed by the front most and back most surviving pixels. By performing depth peeling in two directions simultaneously, the number of rendering passes needed to generate a completed graphics image is reduced from L to 1+L/2, which results in improved rendering performance."
8094157,"One embodiment of the present invention sets forth a technique for efficiently performing a radix sort operation on a graphics processing unit (GPU). The radix sort operation is conducted on an input list of data using one or more passes of a series of three processing phases. In each processing phase, thread groups are each associated with one segment of input data. In the first phase, occurrences of each radix symbol are counted and stored in a list of counters. In the second phase, the list of counters is processed by a parallel prefix sum operation to generate a list of offsets. In the third phase, the list of offsets is used to perform re-ordering on the list of data, according to the current radix symbol. To maintain sort stability, the one or more passes proceed from least significant data to most significant data in the sort key."
8094158,Systems and methods for using multiple versions of programmable constants within a multi-threaded processor allow a programmable constant to be changed before a program using the constants has completed execution. Processing performance may be improved since programs using different values for a programmable constant may execute simultaneously. The programmable constants are stored in a constant buffer and an entry of a constant buffer table is bound to the constant buffer. When a programmable constant is changed it is copied to an entry in a page pool and address translation for the page pool is updated to correspond to the old version (copy) of the programmable constant. An advantage is that the constant buffer stores the newest version of the programmable constant.
8094164,"Systems and methods that decompress block compressed texture data may decompress the texture data while simplifying computations to reduce die area while maintaining the required accuracy. Reducing the die area permits more texture data to be decompressed in the same die area compared with a more accurate decompression, thereby increasing texture decompression throughput. Computations are simplified by combining denominators for linear interpolation with format conversion to decompress texture data components compressed using conventional block compression formats."
8094239,"Field-based detection of 3:2 pulldown in a sequence of digital video fields using a programmable graphics processor is described. The detection is performed using a threshold value to determine equivalence between a pair of fields of digital video data. Furthermore, additional threshold values may be used to control switching into a mode where duplicated fields of digital video data are identified and not displayed and out of the mode where duplicated fields of digital video data are identified and not displayed. Look ahead can be used to detect when to switch into or out of the mode where duplicated fields of digital video data are identified and not displayed, reducing the occurrence of visual artifacts."
8094670,"A novel network architecture that integrates the functions of an internet protocol (IP) router into a network processing unit (NPU) that resides in a host computer's chipset such that the host computer's resources are perceived as separate network appliances. The NPU appears logically separate from the host computer even though, in one embodiment, it is sharing the same chip."
8095715,"Systems and methods for accessing host bus adapter (HBA) management features for Small Computer System Interface (SCSI) based HBAs produced by different vendors use a standard interface. A virtual SCSI target is created to emulate each HBA in a system, representing the HBA as a logical unit. Standard commands specified for logical units are used by an HBA device driver to perform HBA management operations. The standard commands may be used to access HBA management features for any HBA regardless of the vendor. Therefore, the HBA communication interface is standardized for HBA devices, permitting efficient access regardless of the operating system or HBA vendor."
8095746,"A system and method for using an array structure to abstract the addressing of device memory allows for larger amounts of device memory to be accessed compared with using conventional pointers to access a 32 bit memory space. Additionally, the memory organization may be changed for optimal performance based on the underlying memory subsystem and characteristics of the accesses without impacting the array structure."
8095761,"A synchronous memory device is configured to switch into and out of a full speed mode to change speed the speed of data transactions without significantly disturbing the frequency of a clock input to a PLL or DLL that provides the internal clock for the synchronous memory device. Since the PLL or DLL receives a clock signal whether or not the synchronous memory device is in a non-full speed mode, the PLL or DLL does not need to settle or relock when the clock signal is reapplied to exit a different speed mode and return to the full speed mode. Therefore, the latency incurred to switch into and out of different speed modes is reduced by eliminating or substantially reducing the time for settling or relocking the PLL or DLL."
8095762,"A synchronous memory device is configured to switch into and out of a full speed mode to change speed the speed of data transactions without significantly disturbing the frequency of a clock input to a PLL or DLL that provides the internal clock for the synchronous memory device. Since the PLL or DLL receives a clock signal whether or not the synchronous memory device is in a non-full speed mode, the PLL or DLL does not need to settle or relock when the clock signal is reapplied to exit a different speed mode and return to the full speed mode. Therefore, the latency incurred to switch into and out of different speed modes is reduced by eliminating or substantially reducing the time for settling or relocking the PLL or DLL."
8095782,"Graphics processing elements are capable of processing multiple contexts simultaneously, reducing the need to perform time consuming context switches compared with processing a single context at a time. Processing elements of a graphics processing pipeline may be configured to support all of the multiple contexts or only a portion of the multiple contexts. Each processing element may be allocated to process a particular context or a portion of the multiple contexts in order to simultaneously process more than one context. The allocation of processing elements to the multiple contexts may be determined dynamically in order to improve graphics processing throughput."
8095829,"A global processor operating mode is used select whether a processor stops processing when an error is detected or ignores the error and continues processing while overriding values as needed to recover from the error. When a soldier-on mode is enabled the system attempts to recover from the error while also recording the error state of the first error in on-chip registers for later analysis. When the soldier-on mode is not enabled and an error occurs, the system stops processing and the error is reported up to the operating system."
8098254,"Display data and video data are stored within a graphics processing unit to reduce power consumed by the computing device during video playback. Storing display data and video data within the GPU reduces power consumption, because bus transaction activity is reduced and the need to read data from a larger, common main memory is avoided."
8098257,"Floating-point texture filtering units leverage existing fixed-point filter circuits. Groups of floating-point texture values are converted to products of a fixed-point mantissa and a scaling factor that is the same for each texture value in the group. The fixed-point mantissas are filtered using a fixed-point filter circuit, and the filtered mantissa is combined with the scaling factor to determine a floating-point filtered value. Multiple floating-point filter results may be combined in a floating-point accumulator circuit. The same fixed-point filter circuit may also be used to filter fixed-point texture data by providing fixed-point input path that bypasses the format conversion and a fixed-point accumulator."
8099529,Systems and methods for performing native command queuing according to the protocol specified by Serial ATA II for transferring data between a disk and system memory are described. Native command queuing context for queued commands is maintained by a host controller device driver and is provided to the host controller as needed to process the queued commands. The host controller is simplified since it only stores the context of the one command being processed. The host controller generates a backoff interrupt when a command cannot be queued. The host controller generates a DMA transfer context request interrupt to request programming of the registers that store the context for the one command being processed.
8099584,"Parallelism in a parallel processing subsystem is exploited in a scalable manner. A problem to be solved can be hierarchically decomposed into at least two levels of sub-problems. Individual threads of program execution are defined to solve the lowest-level sub-problems. The threads are grouped into one or more thread arrays, each of which solves a higher-level sub-problem. The thread arrays are executable by processing cores, each of which can execute at least one thread array at a time. Thread arrays can be grouped into grids of independent thread arrays, which solve still higher-level sub-problems or an entire problem. Thread arrays within a grid, or entire grids, can be distributed across all of the available processing cores as available in a particular system implementation."
8099650,"One embodiment of the present invention sets forth a method for implementing ECC protection in an on-chip L2 cache. When data is written to or read from an external memory, logic within the L2 cache is configured to generate ECC check bits and store the ECC check bits in the L2 cache in space typically allocated for storing byte enables. As a result, data stored in the L2 cache may be protected against bit errors without incurring the costs of providing additional storage or complex hardware for the ECC check bits."
8100543,"A display system and method are provided for displaying an object utilizing at least one mirror. In use, a first angular dimension, a second angular dimension, and a curvature of the mirror are controlled for manipulating the display of the object. By this design, a variety of applications may be provided."
8102393,"One embodiment of the present invention sets forth a technique to perform fine-grained rendering predication using an IGPU and a DGPU. A graphics driver divides a 3D object into batches of triangles. The IGPU processes each batch of triangles through a modified rendering pipeline to determine if the batch is culled. The IGPU writes bits into a bitstream corresponding to the visibility of the batches. The DGPU reads bits from the bitstream and performs full-blown rendering, including shading, but only on the batches of triangles whose bit indicates that the batch is visible. Advantageously, this approach to rendering predication provides fine-grained culling without adding unnecessary overhead, thereby optimizing both hardware resources and performance."
8103803,"According to an aspect of the present invention, the communication between processors and peripheral controllers is provided using packets. In an embodiment, the access requests are specified according to a common format such that all the information required for performing each access request is included in a single packet and sent to the peripheral controller. The peripheral controller performs the access request on the external device and generates a response. According to another aspect, the packet format enables the peripheral controller to send responses, requests originating from the external devices and interrupt requests. According to yet another aspect, the packets from processors are first stored in a random access memory (RAM) and a DMA controller retrieves the packets and delivered to the respective peripheral controllers."
8106904,"A method and computer program product are provided for generating a shader program. Included is a file associated with a graphics effect. In use, a shader program is generated based on processing of the file to apply the graphics effect to an object."
8106913,"Circuits, methods, and apparatus for graphically displaying performance metrics of processors such as graphics processing units in multiple processor systems. Embodiments of the present invention may provide metric information regarding operations in alternate-frame rendering, split-frame rendering, or other modes of operation. One embodiment of the present invention provides data in split-frame rendering mode including load balancing, graphics processing unit utilization, frame rate, and other types of system information in a graphical manner. Another exemplary embodiment of the present invention provides graphical information regarding graphics processing unit utilization, frame rate, and other system information while operating in the alternate-frame rendering mode."
8106914,"A functional unit is added to a graphics processor to provide direct support for double-precision arithmetic, in addition to the single-precision functional units used for rendering. The double-precision functional unit can execute a number of different operations, including fused multiply-add, on double-precision inputs using data paths and/or logic circuits that are at least double-precision width. The double-precision and single-precision functional units can be controlled by a shared instruction issue circuit, and the number of copies of the double-precision functional unit included in a core can be less than the number of copies of the single-precision functional units, thereby reducing the effect of adding support for double-precision on chip area."
8106916,"One embodiment of the invention sets forth a computing system for performing cryptographic computations. The computing system comprises a central processing unit, a graphics processing unit, and a driver. The central processing requests a cryptographic computation. In response, the driver downloads microcode to perform the cryptographic computation to the graphics processing unit and the graphics processing unit executes microcode. This offloads cryptographic computations from the CPU. As a result, cryptographic computations are performed faster and more efficiently on the GPU, freeing resources on the CPU for other tasks."
8108610,"One embodiment of the invention sets forth a mechanism for efficiently processing atomic operations transmitted from multiple general processing clusters to an L2 cache. A tag look-up unit tracks the availability of each cache line in the L2 cache, reserves the necessary cache lines for the atomic operations and transmits the atomic operations to an ALU for processing. The tag look-up unit also increments a reference counter associated with a reserved cache line each time an atomic operation associated with that cache line is received. This feature allows multiple atomic operations associated with the same cache line to be pipelined to the ALU. A ROP unit that includes the ALU may request additional data necessary to process an atomic operation from the L2 cache. Result data is stored in the L2 cache and may also be returned to the general processing clusters."
8108625,"Concurrent threads in a multithreaded processor share access to a memory, with any location in the shared memory being accessible by any thread. In one embodiment, the shared memory has multiple independently-addressable memory banks, and one location per bank can be accessed in parallel. Parallel processing engines executing the threads generate a group of parallel memory access requests. Address conflict logic determines whether the requests can be satisfied in parallel (e.g., based on bank access constraints) and serializes the requests to the extent needed to avoid conflicts. In some embodiments, data read from one address in the shared memory can be broadcast to multiple processing engines."
8108659,"Thread synchronization techniques are used to control access to a memory resource (e.g., a counter) that is shared among multiple threads. Each thread has a unique identifier and threads are assigned to instances of the shared resource so that at least one instance is shared by two or more threads. Each thread assigned to a particular instance of the shared resource has a unique ordering index. A thread is allowed to access its assigned instance of the resource at a point in the program code determined by its ordering index. The threads are advantageously synchronized (explicitly or implicitly) so that no more than one thread attempts to access the same instance of the resource at a given time."
8108872,"Resources to be used by concurrent threads in a multithreaded processor are allocated based on thread types of the threads. For each of at least two thread types, an amount of the resource is reserved, and amounts currently allocated are tracked. When a request to allocate some of the resource to a new thread is received, a determination as to whether the allocation can be made is based on the thread type of the new thread, the amount of the resource reserved for that thread type, and the amount currently allocated to threads of that type."
8108879,"A processor having multiple independent engines can concurrently support a number of independent processes or operation contexts. The processor can independently schedule instructions for execution by the engines. The processor can independently switch the operation context that an engine supports. The processor can maintain the integrity of the operations performed and data processed by each engine during a context switch by controlling the manner in which the engine transitions from one operation context to the next. The processor can wait for the engine to complete processing of pipelined instructions of a first context before switching to another context, or the processor can halt the operation of the engine in the midst of one or more instructions to allow the engine to execute instructions corresponding to another context. The processor can affirmatively verify completion of tasks for a specific operation context."
8112614,"Parallel data processing systems and methods use cooperative thread arrays (CTAs), i.e., groups of multiple threads that concurrently execute the same program on an input data set to produce an output data set. Each thread in a CTA has a unique identifier (thread ID) that can be assigned at thread launch time. The thread ID controls various aspects of the thread's processing behavior such as the portion of the input data set to be processed by each thread, the portion of an output data set to be produced by each thread, and/or sharing of intermediate results among threads. Mechanisms for loading and launching CTAs in a representative processing core and for synchronizing threads within a CTA are also described."
8112675,A system for handling debug log messages in a computerized device under test that has a filesystem and a communications link. A virtual debug folder provides one or more virtual folders wherein the debug log messages are stored as synthesized filenames. The virtual folders are then viewable via the communications link as if actual folders of the filesystem and the synthesized filenames are viewable via the communications link as if actual filenames of the filesystem.
8115775,"A method comprises encoding information in a texture map, and enhancing texturing utilizing the information, where the information identifies at least one region in at least one texture. Additionally, a texture data structure is embodied on a non-transitory computer readable medium and comprises a texture map with encoded information that identifies at least one region in at least one texture. In addition, an apparatus comprises a processor for encoding information in a texture map to enhance texturing, where the information identifies at least one region in at least one texture."
8115778,"A method for selecting a pixel output format includes selecting a first pixel to be output, and determining whether the first pixel to be output overlaps with a second pixel. The second pixel is available in the first format from a first source, and in a second format from a second source. The method further includes converting the second pixel in the second format to the first format to produce a converted second pixel. The converted second pixel is compared to the second pixel having the first format, and the second pixel having the first format or the second pixel having the second format is selected for output based upon the comparison."
8118440,"A capture system and method are provided for capturing an object utilizing at least one mirror. In use, a first angular dimension, a second angular dimension, and a curvature of the mirror are controlled for manipulating the capture of the object. By this design, a variety of applications may be provided."
8120607,A system and method for stitching a boundary transition region of a patch produces a graphics primitive topology for the boundary transition region of the patch. A first number of vertices is computed for an inside edge of the boundary transition region using a first tessellation level of detail (LOD) of the inside edge. A second number of vertices is computed for an outside edge of the boundary transition region using a second tessellation LOD of the outside edge. A portion of the first number of vertices and the second number of vertices are merged based on a stitching pattern to produce a set of vertices for the boundary transition region. The set of vertices is stitched to produce an ordered list representing the graphics primitive topology.
8120614,"One embodiment of the invention sets forth a technique for compressing and storing display data and optionally compressing and storing cursor data in a memory that is local to a graphics processing unit to reduce the power consumed by a mobile computing device when refreshing the screen. Compressing the display data and optionally the cursor data also reduces the relative cost of the invention by reducing the size of the local memory relative to the size that would be necessary if the display data were stored locally in uncompressed form. Thus, the invention may improve mobile computing device battery life, while keeping additional costs low."
8120621,"A method and system are implemented to measure quantitative changes in display frame content for dynamically controlling a display refresh rate. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of composing a first display frame from a first set of rendered image surfaces, composing a second display frame from a second set of rendered image surfaces, dividing the first display frame and the second display frame into a same number of frame regions. Also, for each of the frame regions, the method also includes the steps of calculating a first set of numerical codes and a second set of numerical codes representative of the content associated with the frame region in the first and second display frame, respectively; and determining an amount of changes in content between the first display frame and the second display frame based on the results of comparing the first set of numerical codes against the second set of numerical code."
8121221,"An apparatus for calibrating gain of an radio frequency receiver (“Rx”) is disclosed to provide, among other things, a structure for performing in-situ gain calibration of an RF integrated circuit over time and/or over temperature without removing the RF integrated circuit from its operational configuration, especially when the gain of the RF integrated circuit is susceptible to variations in process, such as inherent with the CMOS process. In one embodiment, an exemplary apparatus includes a thermal noise generator configured to generate thermal noise as a calibrating signal into an input of an Rx path of an RF integrated circuit. The apparatus also includes a calibrator configured to first measure an output signal from an output of the Rx path, and then adjust a gain of the Rx path based on the thermal noise. In one embodiment, the thermal noise generator further includes a termination resistance and/or impedance."
8125488,An interface device having a video BIOS component. The device includes a substrate for implementing a mother board connection and implementing a GPU (graphics processor unit) connection. A video BIOS component is mounted on the substrate for providing video BIOS functions for the computer system.
8125489,"A processing pipeline employs one or more bypass caches to allow a transaction that is dependent on the results of a prior transaction to be processed before the prior transaction has completed processing. Each bypass cache is coupled to the input and the output of one of the sections of the processing pipeline so that results of a transaction from that section can be written into or read from the bypass cache as soon as that transaction has been completely processed through that section. With such a configuration, more transactions can be processed by the processing pipeline in a shorter amount of time. This is especially true for very deep pipelines."
8125491,"One embodiment of the present invention sets forth a system for generating multiple video output signals from a single video pipeline within a graphics processing unit. Pixel data from more than one display surface is retrieved and multiplexed before being transmitted to a video pipeline for processing. The resulting video pixel data is routed to video output encoders, which selectively accept the video pixel data for transmission to attached display devices."
8126402,"One embodiment of the invention sets forth a technique for using a resonator as a common-mode filter for attenuating unwanted common-mode frequencies in a differential signal. Filtering these unwanted frequencies may reduce electromagnetic interference from the differential signal pair in nearby electronic devices. Since common-mode filtering is employed, the resonator reduces the unwanted common-mode noise at specific frequencies without distorting the information-carrying differential signals. Further, since the filter is implemented as a PWB resonator, the incremental cost of including this filter on the PWB is relatively small."
8126949,"A reconfigurable filter node including an input data memory adapted to store a plurality of input data values, a filter coefficient memory adapted to store a plurality of filter coefficient values, and a plurality of computational units adapted to simultaneously compute filter data values. Filter data values are the outputs of a filter in response to input data values or a second plurality of filter coefficients to be used in subsequent filter data value computations. First and second input data registers load successive input data values input data memory or from adjacent computational units. Each computational unit comprises a pre-adder adapted to output either the sum two input data values stored in the computational unit or alternately to output a single input data value, and a multiply-and-accumulate unit adapted to multiply the output of the pre-adder by a filter coefficient and accumulate the result."
8126952,"The present invention provides a unified inverse discrete cosine transform (IDCT) microcode processor engine, which is able to process IDCT with different video standards and also achieves the processing speed requirement. The microcode processor engine comprises a read unit for reading input data; a shift left unit comprising: a first shift left block for left-shifting input data; and a second shift left block for left-shifting input data; an add unit for adding data output from the shift left unit; and a shift right unit for right-shifting data output from the add unit. The present invention also provides a system of inverse discrete cosine transform."
8126993,"A system, method, and computer program product are provided for communicating sub-device state information. In use, a plurality of sub-devices of a device is exposed to an application, utilizing a driver. A request may then be received from the application for state information associated with at least one of the sub-devices. In response to the request, the state information is provided to the application."
8127181,"Processing units are configured to capture the unit state in unit level error status registers when a runtime error event is detected in order to facilitate debugging of runtime errors. The reporting of warnings may be disabled or enabled to selectively monitor each processing unit. Warnings for each processing unit are propagated to an exception register in a front end monitoring unit. The warnings are then aggregated and propagated to an interrupt register in a front end monitoring unit in order to selectively generate an interrupt and facilitate debugging. A debugging application may be used to query the interrupt, exception, and unit level error status registers to determine the cause of the error. A default error handling behavior that overrides error conditions may be used in conjunction with the hardware warning protocol to allow the processing units to continue operating and facilitate in the debug of runtime errors."
8130223,"One embodiment of the present invention sets forth a technique for efficiently creating and accessing an A-Buffer that supports multi-sample compression techniques. The A-Buffer is organized in stacks of uniformly-sized tiles, wherein the tile size is selected to facilitate compression techniques. Each stack represents the samples included in a group of pixels. Each tile within a stack represents the set of sample data at a specific per-sample rendering order index that are associated with the group of pixels represented by the stack. Advantageously, each tile includes tile compression bits that enable the tile to maintain data using existing compression formats. As the A-Buffer is created, a corresponding stack compression buffer is also created. For each stack, the stack compression buffer includes a bit that indicates whether all of the tiles in the stack are similarly compressed and, consequently, whether the GPU may operate on the stack at an efficient per pixel granularity."
8130227,"Multiprocessor graphics systems support distributed antialiasing. In one embodiment, two (or more) graphics processors each render a version of the same image, with a difference in the sampling location (or locations) used for each pixel. A display head combines corresponding pixels generated by different graphics processors to produce an antialiased image. This distributed antialiasing technique can be scaled to any number of graphics processors."
8130825,"A video processor uses attributes of video data to perform encoding and decoding. Some embodiments dynamically configure the processor via a sequence of instructions, where the instructions include information on the attributes of the current video data. Some embodiments include a dynamically configurable adder array that computes difference functions thereby generating error vectors. Some embodiments include a dynamically configurable adder array that computes filtering functions applied to the video data, e.g. interpolation or decimation of the incoming video prior to motion detection. Some embodiments of the invention provide dynamically configurable hardware searches, for example, for detecting motion. Some embodiments of the invention are implemented using an adaptive computing machines (ACMs). An ACM includes a plurality of heterogeneous computational elements, each coupled to an interconnection network."
8131770,"A system, method, and computer program product are provided for importance sampling of partitioned domains. In operation, a domain is partitioned into a plurality of sets. Additionally, a probability is assigned to each of the plurality of sets. Furthermore, samples are generated from the plurality of sets, the samples being generated according to the probability of a corresponding set."
8131931,"One embodiment of the invention is a method for evicting data from an intermediary cache that includes the steps of receiving a command from a client, determining that there is a cache miss relative to the intermediary cache, identifying one or more cache lines within the intermediary cache to store data associated with the command, determining whether any of data residing in the one or more cache lines includes raster operations data or normal data, and causing the data residing in the one or more cache lines to be evicted or stalling the command based, at least in part, on whether the data includes raster operations data or normal data. Advantageously, the method allows a series of cache eviction policies based on how cached data is categorized and the eviction classes of the data. Consequently, more optimized eviction decisions may be made, leading to fewer command stalls and improved performance."
8132015,"One embodiment of the present invention sets forth a method for loading a secure firmware update onto an adapter device in a computer system. The method includes the steps of sending a duplet of encrypted data conveying a same portion of an encrypted update image along a transfer path to the adapter device, restoring two portions of source data from the duplet, and determining whether to accept the source data based on the result of a comparison of the two portions of source data."
8134543,"A system, method, and computer program product are provided for driving a display utilizing a compensated refresh rate. In use, a pixel clock is received. The present technique compensates for an error associated with the pixel clock. Further, a refresh rate is calculated based on such compensation. To this end, a display may be driven utilizing the refresh rate."
8134566,"Systems and methods for providing a unified instruction set allow shader programs of different types to use a common instruction set. The unified instruction set provides easy access for new graphics hardware features and faster compile times for shader programs. Programmers may use the unified instruction set to write fragment, vertex, or geometry programs. Functions that use the unified instruction set can be included in shader, vertex, or geometry programs without modification. Existing shader programs may be compiled to produce shader microcode based on the unified instruction set. The shader microcode may then be executed by processing units designed to support the unified instruction set."
8134567,One embodiment of the present invention sets forth a system for computing and error checking configuration parameters related to raster image generation within a graphics processing unit. Input parameters are validated by a hardware-based error checking engine. A hardware-based pre-calculation engine uses validated input parameters to compute additional private configuration parameters used by the raster image generation circuitry within a graphics processing unit.
8134568,"A system and method for representing multiple prefetchable memory resources, such as frame buffers coupled to graphics devices, as a unified prefetchable memory space for access by a software application. A graphics surface may be processed by multiple graphics devices, with portions of the surface residing in separate frame buffers, each frame buffer coupled to one of the multiple graphics devices. One or more redirection regions may be specified within the unified prefetchable memory space. Accesses within a redirection region are transmitted to a prefetchable memory of a single graphics device. Accesses within the unified prefetchable memory space, but outside of any redirection region may be broadcast to all of the prefetchable memories of the multiple graphics devices."
8134570,"A system, method and computer program product are provided for packing graphics attributes. In use, a plurality of graphics attributes is identified. Such graphics attributes are packed, such that the packed graphics attributes are capable of being processed utilizing a pixel shader."
8134928,"A method for identifying a failed network interface card in a system having two NICs configured as a team includes the steps of transmitting a first data packet from the first NIC to a third NIC, wherein the third NIC is not a member of the team, and transmitting a second data packet from the first NIC to the second NIC or from the second NIC to the third NIC, depending on whether the third NIC responds to the transmission of the first data packet. One advantage of the disclosed method is that it specifically identifies which NIC within the team has failed, which is something that cannot be determined by simply exchanging packets between the two NICs."
8135842,"The claimed invention herein provides a simple, economical, and safe way to connect a new class of Internet-ready devices and appliances to the Internet without the use of a personal computer (PC). The claimed invention herein provides an Internet dial-tone, so to speak, to applications ranging from toys and entertainment consoles to electronic books and health equipment just as a traditional telephone jack provides a plain old telephone system (POTS) dial-tone for phones, modems, and fax machines. The invention herein features a modem, network stack, and application protocols alleviating the need for sophisticated logic within attached devices. With one-touch, appliances can quickly and easily connect to the Internet."
8135885,"A data packer of an input/output hub of a computer system packs and formats write data that is supplied to it before the write data is written into a memory unit of the computer system. More particularly, the data packer accumulates write data received from lower bandwidth clients for delivery to a high bandwidth memory interface. Also, the data packer aligns the write data, so that when the write data is read out from the write data packer, no further alignment is needed."
8135926,"One embodiment of the invention sets forth a mechanism for efficiently processing atomic operations transmitted from multiple general processing clusters to an L2 cache. A tag look-up unit tracks the availability of each cache line in the L2 cache, reserves the necessary cache lines for the atomic operations and transmits the atomic operations to an ALU for processing. The tag look-up unit also increments a reference counter associated with a reserved cache line each time an atomic operation associated with that cache line is received. This feature allows multiple atomic operations associated with the same cache line to be pipelined to the ALU. A ROP unit that includes the ALU may request additional data necessary to process an atomic operation from the L2 cache. Result data is stored in the L2 cache and may also be returned to the general processing clusters."
8135964,"An apparatus, system, method, and computer program product are provided for executing a program provided a second party utilizing a processor to generate keys for decrypting content of a third party. In operation, content and a program to confidentially generate keys for decrypting the content of the third party are received at a processor. Additionally, the second party's program is executed utilizing the processor-derived keys to decrypts the third party's content."
8139069,"A method and system for improving data coherency in a parallel rendering system is disclosed. Specifically, one embodiment of the present invention sets forth a method for managing a plurality of independently processed texture streams in a parallel rendering system that includes the steps of maintaining a time stamp for a group of tiles of work that are associated with each of the plurality of the texture streams and are associated with a specified area in screen space, and utilizing the time stamps to counter divergences in the independent processing of the plurality of texture streams."
8139071,"An apparatus and method for buffering graphics data are described. In one embodiment, a graphics processing apparatus includes a storage unit and a reorder control unit that is connected to the storage unit. The reorder control unit is configured to coordinate storage of vertex attributes in the storage unit so as to convert the vertex attributes from an initial order to a modified order. The reorder control unit is configured to identify a subset of the vertex attributes to be stored within a common range of addresses in the storage unit, and the reorder control unit is configured to access the storage unit such that the subset of the vertex attributes is written into the storage unit substantially in parallel."
8139073,Systems and methods for determining a compression tag state prior to memory client arbitration may reduce the latency for memory accesses. A compression tag is associated with each portion of a surface stored in memory and indicates whether or not the data stored in each portion is compressed or not. A client uses the compression tags to construct memory access requests and the size of each request is based on whether or not the portion of the surface to be accessed is compressed or not. When multiple clients access the same surface the compression tag reads are interlocked with the pending memory access requests to ensure that the compression tags provided to each client are accurate. This mechanism allows for memory bandwidth optimizations including reordering memory access requests for efficient access.
8140608,"One embodiment of the present invention sets forth a technique for performing fast integer division using commonly available arithmetic operations. The technique may be implemented in a two-stage process using a single-precision floating point reciprocal in conjunction with integer addition and multiplication. Furthermore, the technique may be fully pipelined on many conventional processors for performance that is comparable to the best available high-performance alternatives."
8149234,"A system is presented that is configured to reduce power consumption when performing processing tasks. The system includes a first processing entity capable of performing a set of operations, and a second processing entity configured to consume less power than the first processing entity and capable of performing a subset of operations that is part of the set of operations. During system operation, the second processing entity is configured to perform the subset of operations instead of the first processing entity."
8149243,"A three dimensional (3D) graphics applications programming interface (API) extension provides support for specifying images in a packed float format. In the packed float format, floating point values of three color components are represented as N bits, where N is less than the total number of bits required for a standard half-precision or full precision format. For example, the blue, green, and red components may each be encoded to have a 5-bit exponent and a 5- or 6-bit mantissa with an implied leading 1. The packed float format is used to represent high dynamic range textures in a compact encoding to reduce the memory footprint needed to store the image data compared with other high dynamic range formats."
8149247,"One embodiment of the present invention sets forth a method, which includes the steps of generating a first rendered image associated with a first application, independently generating a second rendered image associated with a second application, applying a first set of blending weights to the first rendered image to establish a first weighted image, applying a second set of blending weights to the second rendered image to establish a second weighted image, and blending the first weighted image and the second weighted image before scanning out a blended result to a first display device."
8150455,"A method and system are implemented for controlling the position of a cursor on a display screen of a remote host device with a mobile communication device. The method comprises establishing a communication link between the mobile communication device and the selected remote host device, detecting an amount of displacement of the mobile communication device, converting the detected amount of displacement into displacement data of the cursor in a coordinate format compatible with the display screen of the host device, and transmitting the displacement data to the remote host device."
8151095,"One embodiment of the present invention sets forth a technique for associating arbitrary parallel processing unit (PPU) contexts with a given central processing unit (CPU) thread. The technique introduces two operators used to manage the PPU contexts. The first operator is a PPU context push, which causes a PPU driver to store the current PPU context of a calling thread on a PPU context stack and to associate a named PPU context with the calling thread. The second operator is a PPU context pop, which causes the PPU driver to restore the PPU context of a calling function to the PPU context at the top of the PPU context stack. By performing a PPU context push at the beginning of a function and a PPU context pop prior to returning from the function, the function may execute within a single CPU thread, but operate on a two distinct PPU contexts."
8154554,"Systems and methods for providing a unified instruction set allow shader programs of different types to use a common instruction set. The unified instruction set provides easy access for new graphics hardware features and faster compile times for shader programs. Programmers may use the unified instruction set to write fragment, vertex, or geometry programs. Functions that use the unified instruction set can be included in shader, vertex, or geometry programs without modification. Existing shader programs may be compiled to produce shader microcode based on the unified instruction set. The shader microcode may then be executed by processing units designed to support the unified instruction set."
8154556,"One embodiment of the present invention sets forth a system for generating multiple video output signals from a single video pipeline within a graphics processing unit. Pixel data from more than one display surface is retrieved and multiplexed before being transmitted to a video pipeline for processing. The resulting video pixel data is routed to video output encoders, which selectively accept the video pixel data for transmission to attached display devices."
8155316,"A method of displaying an image includes generating a contract in the display engine, transferring the contract to the memory controller before the end of a sweep, generating a contract amendment in response to changes in the display engine, transferring the contract amendment to the memory controller, making a decision whether the contract amendment can be processed, fetching data from the memory controller according to the contract incorporating the contract amendment if the decision is that the contract amendment can be processed, sending the fetched data to the display engine in an isochronous stream; and processing the fetched data using the display engine."
8156404,"One embodiment of the present invention sets forth a method for implementing ECC protection in an on-chip L2 cache. When data is written to or read from an external memory, logic within the L2 cache is configured to generate ECC check bits and store the ECC check bits in the L2 cache in space typically allocated for storing byte enables. As a result, data stored in the L2 cache may be protected against bit errors without incurring the costs of providing additional storage or complex hardware for the ECC check bits."
8159496,"Methods and apparatus for subdividing a shader program into regions or “phases” of instructions identifiable by phase identifiers (IDs) inserted into the shader program are provided. The phase IDs may be used to constrain execution of the shader program to prohibit texture fetches in later phases from being executed before a texture fetch in a current phase has completed. Other operations (e.g., math operations) within the current phase, however, may be allowed to execute while waiting for the current phase texture fetch to complete."
8159612,"Apparatus, system, and method for processing digital audio/video signals are described. In one embodiment, a decoder is configured to process an input signal having an analog television format. The decoder includes a signal detector, and the signal detector is configured to determine whether the input signal incorporates a digital television signal. The decoder also includes a signal extractor connected to the signal detector, and the signal extractor is configured to extract the digital television signal from the input signal based on determining that the input signal incorporates the digital television signal."
8160983,A user data engine residing on an endpoint machine generates a current user context reflecting a specific flow of operations performed by an end-user when interacting with a software application. A context engine residing on a sever machine compares the current user context to one or more stored user contexts included in a context database and generates a similarity value based on each comparison. A resource engine identifies resources in a resource database that are associated with the stored user contexts and then generates a relevance score for each resource based on the similarity scores corresponding to the stored user contexts with which those resources are associated. The resource engine transmits a resource list reflecting the identified resources to the user data engine based on the relevance scores. The user data engine displays on a display screen of the endpoint machine information associated with resources reflected in the resource list.
8161252,"Devices and methods provide data from multiple storage locations to a processor. A data block containing data required by a processor is stored in two or more locations, e.g., in a local memory and a system memory, both of which are accessible to the processor's memory interface. The memory interface directs each read request for mirrored data to one or another of the mirror locations. Selection of a mirror location to be read is based on substantially real-time information about which mirror location is best able to handle the request. For instance, the selection of a mirror location to access can be based at least in part on information about the level of activity on various buses that connect the processor to the mirror locations."
8169437,"A system and method for dividing three-dimensional patches into tasks for processing receives control points defining a three dimensional patch and determines if a number of vertices of the three dimensional patch is greater than a maximum value. When the number of vertices is not greater than the maximum value, the three dimensional patch is output as a single task. When the number of vertices is greater than the maximum value, the three dimensional patch is divided into multiple tasks that each include a number of vertices that is not greater than the maximum value and the multiple tasks are output."
8169467,"A system, method, and computer program product are provided for enhancing a viewing experience when display content is viewed utilizing stereo glasses. In use, display content is received for being outputted utilizing a display. Further, a duration of a vertical blanking interval associated with the display content is increased for enhancing a viewing experience when the display content is viewed utilizing the stereo glasses."
8169789,"Apparatus and methods for mounting of a processor coupled to a circuit board include use of a frame disposed around the processor. The frame decreases flexibility of the circuit board around the processor. Further, the frame may act as a mechanical stop limiting tilting of a heat sink coupled to the processor."
8171461,"Systems and methods for compiling high-level primitive programs are used to generate primitive program micro-code for execution by a primitive processor. A compiler is configured to produce micro-code for a specific target primitive processor based on the target primitive processor's capabilities. The compiler supports features of the high-level primitive program by providing conversions for different applications programming interface conventions, determining output primitive types, initializing attribute arrays based on primitive input profile modifiers, and determining vertex set lengths from specified primitive input types."
8174531,"A processing unit includes multiple execution pipelines, each of which is coupled to a first input section for receiving input data for pixel processing and a second input section for receiving input data for vertex processing and to a first output section for storing processed pixel data and a second output section for storing processed vertex data. The processed vertex data is rasterized and scan converted into pixel data that is used as the input data for pixel processing. The processed pixel data is output to a raster analyzer."
8175160,"A system, method, and computer program product are provided for refining motion vectors. In operation, a plurality of motion vectors associated with a current frame and a first resolution are created. Furthermore, the motion vectors are refined utilizing information including at least one of first information describing motion vectors associated with a previous frame and second information describing motion vectors associated with the current frame and a second resolution."
8176265,"A memory is used by concurrent threads in a multithreaded processor. Any addressable storage location is accessible by any of the concurrent threads, but only one location at a time is accessible. The memory is coupled to parallel processing engines that generate a group of parallel memory access requests, each specifying a target address that might be the same or different for different requests. Serialization logic selects one of the target addresses and determines which of the requests specify the selected target address. All such requests are allowed to proceed in parallel, while other requests are deferred. Deferred requests may be regenerated and processed through the serialization logic so that a group of requests can be satisfied by accessing each different target address in the group exactly once."
8176545,"A system and method are provided for validating a security service associated with packets communicated on a network. A hash of a security service associated with packets communicated on a network is generated. In use, the security service associated with the packets is validated utilizing the hash."
8179388,"A display refresh system, method and computer program product are provided. In use, a refresh rate is adjusted for power saving purposes, and/or any other purpose(s) for that matter. Further, various embodiments are provided for reducing visual manifestations associated with a transition between a first refresh rate and a second refresh rate."
8179394,"One embodiment of the present invention sets forth a technique to perform fine-grained rendering predication using an IGPU and a DGPU. A graphics driver divides a 3D object into batches of triangles. The IGPU processes each batch of triangles through a modified rendering pipeline to determine if the batch is culled. The IGPU writes bits into a bitstream corresponding to the visibility of the batches. The DGPU reads bits from the bitstream and performs full-blown rendering, including shading, but only on the batches of triangles whose bit indicates that the batch is visible. Advantageously, this approach to rendering predication provides fine-grained culling without adding unnecessary overhead, thereby optimizing both hardware resources and performance."
8180943,"A method and apparatus for providing latency based thread scheduling. A thread attribute, e.g., latency of a process, is used in effecting the scheduling of the thread."
8180998,"A system for performing data-parallel operations and task-parallel operations. A first switch fabric node (SFN) includes first and second lane processing engines (LPEs). The first LPE includes a first set of lane processing units (LPUs) configured to perform data-parallel operations, where each LPU performs a set of operations, and each LPU uses a different set of data for the set of operations, and each LPU within the first set of LPUs uses a different set of data for the set of operations. The second LPE includes a second set of LPUs configured to perform task-parallel operations, where each LPU performs a different set of operations. A processing control engine (PCE) is configured to distribute instructions and data to the first LPE and the second LPE. Advantageously, data parallel operations and task parallel operations are able to be performed on the same processor simultaneously."
8185585,"A method comprises displaying a mail server information screen, and receiving connection information via the mail server information screen. Further, the method comprises displaying an address page, and receiving recipient information via the address page. In addition, the method comprises displaying a content page, and receiving content in the content page. Additionally, an electronic mail message having the content is compiled, and the electronic mail message is sent to a recipient utilizing the connection information and recipient information."
8189009,"A method for generating a texture buffer object configured for storing and manipulating texture data for graphics processing operations includes the steps of creating a buffer object configured to store the texture data, binding the buffer object to a texture buffer object, binding the texture buffer object to one of a plurality of texture targets included within a texture image unit, and binding a shader program to a processing unit within a graphics rendering pipeline. One advantage of the disclosed method is that, once a texture buffer object is bound as the target of a texture image unit, shader programs may read and/or write to the buffer object referenced by the texture buffer object, without having to rebind that texture buffer object."
8189107,"A system, method and computer program product are provided. After receipt of visual data, an aspect of the frequency response associated with the visual data is changed. Thereafter, subsequent processing is performed on the visual data, based on information extracted from and related to the aspect of the frequency response change."
8190412,A method of stimulating a deformable object comprises modeling deformable elasticity for the object by defining an actual shape and a goal shape and pulling points in the goal shape towards corresponding points in the goal shape.
8190668,An Inverse Hadamard Transform (IHT) converter and system includes a first group of registers for receiving coefficients inputted to the IHT converter; a first adder for adding selected the coefficients stored in the first group of registers; a second group of registers for receiving results from the first adder; and a second adder for adding selected the results stored in the second group of registers.
8190669,"Multipurpose arithmetic functional units can perform planar attribute interpolation and unary function approximation operations. In one embodiment, planar interpolation operations for coordinates (x, y) are executed by computing A*x+B*y+C, and unary function approximation operations for operand x are executed by computing F2(xb)*xh2+F1(xb)*xh+F0(xb), where xh=x−xb. Shared multiplier and adder circuits are advantageously used to implement the product and sum operations for both classes of operations."
8190767,"Described are data structures, and methodology for forming same, for network protocol processing. A method for creating data structures for firewalling and network address translating is described. A method for creating data structures for physical layer addressing is described. A method for security protocol support using a data structure is described. A method for creating at least one data structure sized responsive to whether a firewall is activated is described. A data structure for routing packets is described. A method of forming hashing table chains is described. Additionally, method and apparatus for tracking packet states is described. More particularly, Transmission Control Protocol (“TCP”) tracking of states for packets is described. In an embodiment, a division between software states and hardware states is made as a packet is processed by both software and hardware. Additionally, method and apparatus for network protocol processing are described. For example, a packet for network address translation having a media access control header is obtained, from which information, including the media access control header, is obtained. The information is parsed into one or more data structures. It is determined whether a network processing unit is in a first round processing mode, or a second round pass-through mode."
8190937,"One embodiment of the present invention sets forth a method for managing a power state of an audio device resident in a graphics processing unit. The method includes the steps of directing audio data originated from a client application via an audio path in an audio driver stack to the audio device, determining whether an active stream of audio data along the audio path is present in response to a notification of an attempt to shut down the graphics processing unit, and requesting a plug and play manager to disable the audio device, if no active stream of audio data is present along the audio path."
8190974,"One embodiment of the present invention sets forth a technique for protecting data with an error correction code (ECC). The data is accessed by a processing unit and stored in an external memory, such as dynamic random access memory (DRAM). Application data and related ECC data are advantageously stored in a common page within a common DRAM device. Application data and ECC data are transmitted between the processor and the external common DRAM device over a common set of input/output (I/O) pins. Eliminating I/O pins and DRAM devices conventionally associated with transmitting and storing ECC data advantageously reduces system complexity and cost."
8194065,"A system and method are provided for changing a display refresh rate. A first register is provided for storing at least one first refresh parameter in association with a first refresh rate. Additionally, a second register is provided for storing at least one second refresh parameter in association with a second refresh rate. Furthermore, logic is in communication with the first register and the second register. Such logic is adopted for selecting the first refresh parameter or the second refresh parameter, for the purpose of reducing artifacts resulting from a change from the first refresh rate and the second refresh rate."
8194085,"A memory hub permits a graphics processor to access random access memories, such as dynamic random access memories (DRAMs). In one implementation, the memory hub permits an increase in effective memory bandwidth by aggregating the memory of two or more memories. In another implementation, the memory hub permits a graphics processor to offload memory access interfacing operations to the memory hub."
8194812,"A data sampling apparatus and associated method are provided, including a first inverter receiving a data signal, and inverting the data signal to produce a trigger signal, a first flip-flop receiving the trigger signal, and outputting an output signal, a second flip-flop and a third-flop flop each receiving the output signal from the first flip-flop, the second flip-flop further receiving a strobe signal, and a second inverter inverting the strobe signal, and outputting the inverted strobe signal to the third flip-flop. An output of the second flip-flop indicates a value of the output signal output from the first flip-flop when the strobe signal is of a first state and an output of the third flip-flop indicates a value of the output signal output from the first flip-flop when the strobe signal is of a second state."
8195432,"A media capture system, method, and computer program product are provided for assessing processing capabilities utilizing cascaded memories. In use, media data is captured from a system in accordance with predetermined criteria. Additionally, the media data is stored in a plurality of cascaded memories separate from the system. Further, the media data is used for assessing media processing capabilities of the system, based on the predetermined criteria."
8195731,"A system, method, and computer program product are provided for determining at least one root of an n-dimensional function, utilizing triangulation. In operation, an n-dimensional function is received. Additionally, at least one root of the n-dimensional function is determined utilizing triangulation."
8195858,"One embodiment of the present invention sets forth a mechanism to schedule read data transmissions and write data transmissions to/from a cache to frame buffer logic on the L2 bus. When processing a read or a write command, a scheduling arbiter examines a bus schedule to determine that a read-read conflict, a read-write conflict or a write-read exists, and allocates an available memory space in a read buffer to store the read data causing the conflict until the read return data transmission can be scheduled. In the case of a write command, the scheduling arbiter then transmits a write request to a request buffer. When processing a write request, the request arbiter examines the request buffers to determine whether a write-write conflict. If so, then the request arbiter allocates a memory space in a request buffer to store the write request until the write data transmission can be scheduled."
8196169,"A system, method and computer program product are provided. In use, a plurality of coordinates of a set top box is identified. In addition, a policy associated with usage of the set top box is enforced utilizing the coordinates."
8198727,"An integrated circuit/substrate interconnect apparatus and method are provided. Included is an integrated circuit including a plurality of bond pads, and a substrate including a plurality of landing pads and a mask. Such mask is spaced from the landing pads for defining areas therebetween. Further provided is a plurality of interconnects connected between the bond pads of the integrated circuit and the landing pads of the substrate. The interconnects include metal projections extending from the bond pads and a solder material for connecting the metal projections and the landing pads of the substrate."
8199155,"A system, method, and computer program product are provided for enabling or disabling a graphics processor during runtime. In use, a command is received to disable or enable a graphics processor. Such graphics processor is enabled or disabled during runtime, in response to the command."
8199255,"A system, method, and computer program product are provided for configuring a plurality of devices to process content. In use, content information associated with received content is identified in addition to device information associated with a plurality of devices adapted for processing such content. To this end, the plurality of devices may be configured to process the content, utilizing the content information and the device information."
8200594,"A system, method, and computer program product are provided for accelerating a game artificial intelligence process. In one embodiment, a graphics processor is provided, the graphics processor being capable of accelerating a game artificial intelligence process. In another embodiment, a graphics processor is provided, the graphics processor being capable of accelerating a navigational planning artificial intelligence process."
8200940,A system and method for successfully performing reduction operations in a multi-threaded SIMD (single-instruction multiple-data) system while one or more threads are disabled allows for the reduction operations to be performed without a performance penalty compared with performing the same operation with all of the threads enabled. The source data for each intermediate computation of the reduction operation is remapped by a configurable crossbar as needed to avoid using invalid data from the disabled threads. The remapping function is transparent to the user and enables correct execution of order invariant reduction operations and order dependent prefix-reduction operations.
8200947,"One embodiment of the present invention sets forth a technique for efficiently performing voting operations within a multi-threaded parallel-processing system. A group of related parallel program threads executes within a processor core together in parallel. A new instruction, called a “vote” instruction, is introduced that enables a parallel program thread to post an individual vote within the context of the group of related threads and to receive the result of the vote. In this fashion, the vote instruction advantageously reduces overhead associated with inter-thread communication, thereby improving overall system performance."
8200949,"A multi-threaded processor system, method, and computer program product capable of utilizing a register file cache are provided for simultaneously processing a plurality of threads. A processor capable of simultaneously processing a plurality of threads is provided. The processor includes a register file and a register file cache in communication with the register file."
8201014,"A system and method are provided for decoding an audio signal. In one embodiment, a first pulse is identified with a predetermined relative duration with respect to a second pulse. A sampling frequency is then calculated based on such identification. In another embodiment, an audio signal is decoded utilizing a threshold. In still yet another embodiment, a decoder is provided for decoding an audio signal utilizing a clock that is independent of the audio signal."
8201172,"Systems and methods storing data for multi-threaded processing permit multiple execution threads to store data in a single first-in first-out (FIFO) memory. Threads are assigned to classes, with each class including one or more threads. Each class may be allocated dedicated entries in the FIFO memory. A class may also be allocated shared entries in the FIFO memory. The shared entries may be used by any thread. Data for a first thread may be stored in the FIFO memory while data for a second thread is read from the FIFO memory, even when the first thread and the second thread are not in the same class. The FIFO memory may include a speculative read and a speculative write capability. The FIFO memory is shared between the threads to conserve die area, however each thread may be executed independently, as if each thread has a dedicated FIFO memory."
8203562,"An integrated circuit includes at least two different types of processors, such as a graphics processor and a video processor. At least one operation is commonly by supported by two different types of processors. For each commonly supported operation that is scheduled, a decision is made to determine which type of processor will be selected to implement the operation."
8203563,"A system, method, and computer program product are provided for adjusting at least one aspect of a programmable graphics and/or audio processor. In use, at least one input parameter and at least one output parameter of a programmable graphics and/or audio processor are identified. Thereafter, at least one aspect of the programmable graphics and/or audio processor may thus be dynamically adjusted. Such adjustment is performed as a function of both the at least one input parameter and the at least one output parameter."
8203573,"A method for assembling image data for transport across a digital video interface includes receiving and converting first-formatted pixel data to a second-formatted pixel data. The second-formatted pixel data is readable by a rendering device, the second-formatted pixel data having a bit width that differs from an input bit width standard of the digital video interface. The second-formatted pixel data is assembled into a transport packet having a bit width which is equal to the input bit width standard of the digital video interface. The digital video interface is operable to receive the transport packet comprising the second-formatted pixel data, and thereby communicate the second-formatted pixel data to the rendering device."
8204725,"One embodiment of the present invention sets forth a technique for efficiently simulating breaking waves in real-time. A two-dimensional shallow water height field simulation generates height and velocity information used to generate a wave line for each wave within the height field that satisfies criteria for overturning. For each overturning wave, a wave sheet is created from particles generated relative to points on the respective wave line. Each wave sheet may move separately from an underlying wave that gave rise to the wave sheet, allowing the wave sheet to fall and break, creating a realistic appearance. As a falling wave sheet collides with the underlying wave or water surface, free particles may be generated to simulation spray visible on a real breaking wave."
8205095,"A method for conducting a remote debugging session comprises setting a secure connection link with a failed client machine, receiving status information from the client machine through the connection link in response to a debug instruction sent to the client machine, displaying the status information in a readable form, requesting a user to enter a cryptographic key in response to a request for saving the status information, and generating a secured file containing the status information encrypted with the cryptographic key."
8207975,"One embodiment of the present invention sets forth a graphics pipeline architecture for optimizing graphics rendering efficiency by advancing the Z-test operation prior to shading operations whenever possible, as determined by an upstream pipeline configuration unit. Each processing engine within the graphics pipeline maintains independent state for both early Z-mode and late Z-mode operations and also may maintain state common to both modes. The processing engines receive work transactions that include a Z-mode flag indicating whether the work transaction should be processed in late Z-mode or early Z-mode. The Z-mode flag is also used to dynamically route any resulting outbound data, so that the appropriate data flow for either early Z or late Z processing is dynamically constructed for each work transaction. The shader engine is advantageously relieved of unnecessary work whenever possible by discarding occluded samples whose z-values are not altered by shading operations before they enter the shader engine."
8207977,"A system, method, and computer program product are provided for changing a refresh rate of a display system. In use, an aspect of hardware of a display system is identified. To this end, a refresh rate of the display system may be changed based on the identified aspect."
8209673,"One embodiment of the present invention sets forth a system and method for implementing a scalable link interface (SLI) approval policy using a database. The resource manager within a GPU driver incorporates a database, which may be used to determine whether the current computer system configuration is approved for running in SLI mode. The database of specific approved configurations may be embedded within the GPU driver or stored in a separate file, which may be modified by an authorized user. The database may be encrypted to prevent unauthorized users from modifying to the database contents. When a given computer system configuration is an approved configuration within the database, the system may be enabled to operate in SLI mode."
8212816,"A system, method, and computer program product are provided for parallel ray tracing traversal and intersection utilizing a single instruction multiple data (SIMD) processing architecture. In operation, a ray tracing traversal operation is performed utilizing one or more processing elements of the SIMD architecture. Additionally, a ray tracing intersection operation is performed in parallel with the ray tracing traversal operation, utilizing the same one or more processing elements. Furthermore, at least a portion of code utilized for performing the ray tracing traversal operation is the same as at least a portion of code utilized for performing the ray tracing intersection operation."
8212824,A graphics processing unit includes a first processing controller controlling a first set of multi-threaded processors. A second processing controller controls a second set of multi-threaded processors. A serial bus connects the first processing controller to the second processing controller. The first processing controller gathers first state information from the first set of multi-threaded processors in response to a context switch token and then passes the context switch token over the serial bus to the second processing controller. The second processing controller gathers second state information from the second set of multi-threaded processors in response to the context switch token.
8212825,"One embodiment of the present invention sets forth a technique for more effectively utilizing graphics hardware by allowing the developer to exploit parallelism at the primitive-level. In this technique, an algorithm is analyzed to break the total work associated with processing one primitive into discrete portions of work. The results of this analysis are used to program a geometry shader group that includes multiple geometry shaders. Upon receiving a single input primitive, the geometry shader group launches multiple parallel threads, one thread in each geometry shader in the group corresponding to each discrete portion of work. As each thread completes, the output of the thread is stored in on-chip GPU memory for processing by the next stage in the graphics pipeline. Since the overall work associated with a given input primitive is distributed across multiple threads, the output of each thread is smaller and, thus, the total memory required to implement the algorithm is reduced."
8212826,"Disclosed are an apparatus, a computer device, a system, computer readable media and a method for using graphics processing unit (“GPU”)-generated data to characterize, in-situ, the ability of a cable to reliably carry digitized video, among other things. In one embodiment, a computing device includes a processor coupled via a system bus to a graphics engine and a video cable-testing apparatus. This apparatus has an input port configured to couple to the digitized video cable to receive pixel data generated by the graphics engine. It also has a signal integrity evaluator (“SIE”) configured to identify the digitized video cable as the source an amount of data corruption, the amount of data corruption being a function of the pixel data. The signal integrity evaluator includes a classifier to classify the amount of data corruption into classes that each represents various degrees of degradation of the computer-generated video images."
8212831,"A system and method for remapping and redirecting accesses to a memory space shared between graphics devices permits a single device driver to interface between an application program and multiple graphics devices. Each graphics device provides configuration information to the BIOS (basic input/output system), particularly memory space requirements for prefetchable and non-prefetchable memory spaces. A memory space allocation for the graphics devices is determined based on the configuration information. A switch device, interfacing between a host processor and each graphics device, is programmed to redirect accesses to a portion of the allocated memory space to only one of the graphics devices. Accesses to another portion of the allocated memory space may be remapped to all of the graphics devices or a subset of the graphics devices."
8212835,"One embodiment of the present invention sets forth a technique for transitioning from bilinear sampling to filter-4 sampling, while avoiding the visual artifacts along the boundary between the two different types of filters. The technique may be implemented using a linear transition function or an arbitrary transition function stored in a lookup table. The transition to filter-4 sampling occurs when the view of a textured object includes both minified and magnified levels of texture detail. Using this technique, high image quality is maintained for texture mapped images that include both highly minified pixels as well as highly magnified pixels, without suffering the performance penalty associated with using a filtering operation such as filter-4 sampling across all pixels."
8214625,"One embodiment of the present invention sets forth a technique for efficiently performing voting operations within a multi-threaded parallel-processing system. A group of related parallel program threads executes within a processor core together in parallel. A new instruction, called a “vote” instruction, is introduced that enables a parallel program thread to post an individual vote within the context of the group of related threads and to receive the result of the vote. In this fashion, the vote instruction advantageously reduces overhead associated with inter-thread communication, thereby improving overall system performance."
8214654,"One embodiment of the present invention sets forth a method for loading a secure firmware update onto an adapter device in a computer system. The method includes the steps of sending a duplet of encrypted data conveying a same portion of an encrypted update image along a transfer path to the adapter device, restoring two portions of source data from the duplet, and determining whether to accept the source data based on the result of a comparison of the two portions of source data."
8217954,"Circuits, methods, and apparatus that provide texture caches and related circuits that store and retrieve texels in an efficient manner. One such texture circuit can provide a configurable number of texel quads for a configurable number of pixels. For bilinear filtering, texels for a comparatively greater number of pixels can be retrieved. For trilinear filtering, texels in a first LOD are retrieved for a number of pixels during a first clock cycle, during a second clock cycle, texels in a second LOD are retrieved. When aniso filtering is needed, a greater number of texels can be retrieved for a comparatively lower number of pixels."
8218555,"A gigabit Ethernet adapter provides a provides a low-cost, low-power, easily manufacturable, small form-factor network access module which has a low memory demand and provides a highly efficient protocol decode. The invention comprises a hardware-integrated system that both decodes multiple network protocols in a byte-streaming manner concurrently and processes packet data in one pass, thereby reducing system memory and form factor requirements, while also eliminating software CPU overhead. A preferred embodiment of the invention comprises a plurality of protocol state machines that decode network protocols such as TCP, IP, User Datagram Protocol (UDP), PPP, Raw Socket, RARP, ICMP, IGMP, iSCSI, RDMA, and FCIP concurrently as each byte is received. Each protocol handler parses, interprets, and strips header information immediately from the packet, requiring no intermediate memory. The invention provides an Internet tuner core, peripherals, and external interfaces. A network stack processes, generates and receives network packets. An internal programmable processor controls the network stack and handles any other types of ICMP packets, IGMP packets, or packets corresponding to other protocols not supported directly by dedicated hardware. A virtual memory manager is implemented in optimized, hardwired logic. The virtual memory manager allows the use of a virtual number of network connections which is limited only by the amount of internal and external memory available."
8219371,"One embodiment of the present invention sets forth a technique for efficiently performing N-body computations using parallel computation systems. The technique involves a first processing step whereby a force matrix is partitioned into tiles, which are assigned to a one or more thread groups for processing. An off-diagonal tile may be aligned to include no diagonal cells, while an on-diagonal tile includes diagonal cells. One approach for computing either type of tile involves assigning each row from a tile to a thread within a thread group. Each thread operates on an offset pattern to avoid access conflicts to a shared memory. A net force for each atom within an N-body system is then computed by efficiently adding constituent forces stored within the force matrix using reduction operations on the force matrix."
8219372,"One embodiment of the present invention sets forth a technique for efficiently performing N-body computations using parallel computation systems. The technique involves a first processing step whereby a force matrix is partitioned into tiles, which are assigned to a one or more thread groups for processing. An off-diagonal tile may be aligned to include no diagonal cells, while an on-diagonal tile includes diagonal cells. One approach for computing either type of tile involves assigning each row from a tile to a thread within a thread group. Each thread operates on an offset pattern to avoid access conflicts to a shared memory. A net force for each atom within an N-body system is then computed by efficiently adding constituent forces stored within the force matrix using reduction operations on the force matrix."
8219786,"Sequential fetch requests from a set of fetch requests are combined into longer coalesced requests that match the width of a system memory interface in order to improve memory access efficiency for reading the data specified by the fetch requests. The fetch requests may be of different classes and each data class is coalesced separately, even when intervening fetch requests are of a different class. Data read from memory is ordered according to the order of the set of fetch requests to produce an instruction stream that includes the fetch requests for the different classes."
8223150,An apparatus and method for translating fixed function state into a shader program. Fixed function state is received and stored and when a new shader program is detected the fixed function state is translated into shader program instructions. Registers specified by the program instructions are allocated for processing in the shader program. The registers may be remapped for more efficient use of the register storage space.
8223158,"A method and system for connecting multiple shaders are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of configuring a set of shaders in a user-defined sequence within a modular pipeline (MPipe), allocating resources to execute the programming instructions of each of the set of shaders in the user-defined sequence to operate on the data unit, and directing the output of the MPipe to an external sink."
8223159,"One embodiment of the present invention sets forth a system configured for transferring data between independent application programming interface (API) contexts on one or more graphics processing units (GPUs). Each API context may derive from an arbitrary API. Data is pushed from one API context to another API context using a peer-to-peer buffer “blit” operation executed between buffers allocated in the source and target API context memory spaces. The source and target API context memory spaces may be located within the frame buffers of the source and target GPUs, respectively, or located within the frame buffer of a single GPU. The data transfers between the API contexts are synchronized using semaphore operator pairs inserted in push buffer commands that are executed by the one or more GPUs."
8224635,"One embodiment of the present invention sets forth a technique for efficiently performing N-body computations using parallel computation systems. The technique involves a first processing step whereby a force matrix is partitioned into tiles, which are assigned to a one or more thread groups for processing. An off-diagonal tile may be aligned to include no diagonal cells, while an on-diagonal tile includes diagonal cells. One approach for computing either type of tile involves assigning each row from a tile to a thread within a thread group. Each thread operates on an offset pattern to avoid access conflicts to a shared memory. A net force for each atom within an N-body system is then computed by efficiently adding constituent forces stored within the force matrix using reduction operations on the force matrix."
8225076,"A scoreboard memory for a processing unit has separate memory regions allocated to each of the multiple threads to be processed. For each thread, the scoreboard memory stores register identifiers of registers that have pending writes. When an instruction is added to an instruction buffer, the register identifiers of the registers specified in the instruction are compared with the register identifiers stored in the scoreboard memory for that instruction's thread, and a multi-bit value representing the comparison result is generated. The multi-bit value is stored with the instruction in the instruction buffer and may be updated as instructions belonging to the same thread complete their execution. Before the instruction is issued for execution, this multi-bit value is checked. If this multi-bit value indicates that none of the registers specified in the instruction have pending writes, the instruction is allowed to issue for execution."
8228328,The current invention involves new systems and methods for computing per-sample post-z test coverage when the memory is organized in multiple partitions that may not match the number of shaders. Shaded pixels output by the shaders can be processed by one of several z raster operations units. The shading processing capability can be configured independent of the number of memory partitions and number of z raster operations units. The current invention also involves new systems and method for using different z test modes with multiple render targets with a single or multiple memory partitions. Rendering performance may be improved by using an early z testing mode is used to eliminate non-visible samples prior to shading.
8228337,"One embodiment of the present invention sets forth a method for dynamically load balancing rendering operations across an IGPU and a DGPU. For each frame, the graphics driver configures the IGPU to pre-compute Z-values for a portion of the display surface and to write feedback data to the system memory indicating the time that the IGPU used to process the frame. The graphics driver then configures the DGPU to use the pre-computed Z-values while rendering to the complete display surface and to write feedback data to the system memory indicating the time that the DGPU used to process the frame. The graphics driver uses the feedback data from the IGPU and DGPU in conjunction with the percentage of the display surface that the IGPU Z-rendered for the frame to scale the portion of the display surface that the IGPU Z-renders for one or more subsequent frames. In this fashion, overall processing within the graphics pipeline is optimized across the IGPU and DGPU."
8228338,A method and system for overriding state information programmed into a processor using an application programming interface (API) avoids introducing error conditions in the processor. An override monitor unit within the processor stores the programmed state for any setting that is overridden so that the programmed state can be restored when the error condition no longer exists. The override monitor unit overrides the programmed state by forcing the setting to a legal value that does not cause an error condition. The processor is able to continue operating without notifying a device driver that an error condition has occurred since the error condition is avoided.
8228877,"A multi-user detector (200) and method (300) for use in a cellular CDMA system (100) based on: estimating (210) spare code resource available in a first cell of the system; selecting (220) at least a second cell neighbouring the first cell; selecting (230) from codes associated with the second cell at least one additional code; and performing (240) multi-user detection processing in the first cell with the at least one additional code. On the downlink, codes from other users in the same cell may be treated with the same level of priority as those of users from neighbour cells, codes allocated to the UE having the highest priority; on the uplink, codes of all users in the same cell may have the same priority which is higher than that of neighbour cell users. This provides the advantage(s) that multi-user detector capacity arising from operating under high interference conditions is employed to accommodate users from neighbour cells, with the result that both intracell and intercell interference may be mitigated."
8229008,"An Orthogonal Frequency Division Multiplex (OFDM) communication system comprises OFDM transmitters, an OFDM receiver, and a subcarrier status data controller for transmitting subcarrier status data to the OFDM receiver. The subcarrier status data indicates the active subcarriers of the OFDM transmitters. The OFDM receiver comprises a receiver, a subcarrier status processor, a channel estimator, and an interference mitigation processor."
8229218,"A processor generating a histogram of a set of data values receives a data value, and sets a corresponding register in each of two sets of registers based respectively on a decoded value represented by bits in a first and second set of positions in the received data value. The processor then simultaneously increments/updates each of multiple frequency counters (specifying frequency of occurrence of respective data values/ranges) by a value of a corresponding register in one of the two sets of registers if a value of a corresponding register in the other one of the two sets of registers is set. As a result, histogram generation is made efficient and fast. In an embodiment, 32 frequency counters are updated in 16 operations."
8229346,A method of providing multimedia broadcast multicast services (MBMS) over a communication system that comprises a shared network and a proprietary network comprises allocating a first portion of logic elements of a broadcast multicast service centre (BM-SC) to support MBMS content delivery over the shared network and allocating a second portion of logic elements of the BM-SC to support MBMS content delivery over the proprietary network.
8232991,The current invention involves new systems and methods for computing per-sample post-z test coverage when the memory is organized in multiple partitions that may not match the number of shaders. Shaded pixels output by the shaders can be processed by one of several z raster operations units. The shading processing capability can be configured independent of the number of memory partitions and number of z raster operations units. The current invention also involves new systems and method for using different z test modes with multiple render targets with a single or multiple memory partitions. Rendering performance may be improved by using an early z testing mode is used to eliminate non-visible samples prior to shading.
8233000,"One embodiment of the present invention sets forth a technique for dynamically switching between a power-saving integrated graphics processing unit (IGPU) and a higher-performance discrete graphics processing unit (DGPU). This technique uses a single graphics driver and a single digital-to-analog converter (DAC) and leverages the GPU switching capability of the operating system to ensure a seamless transition. When additional graphics performance is desired, the system enters a hybrid graphics mode. In this mode, the DGPU is powered-up, and the graphics driver maintains the current display, while the operating system switches applications running on the IGPU to the DGPU. While in the hybrid graphics mode, the DGPU performs the graphics processing, and the graphics driver transmits the rendered images from the DGPU to the IGPU local memory and, then, to the IGPU DAC. This image transmission allows applications to fully exploit the processing capabilities of the DGPU, while using the display device connected to the IGPU."
8233004,"One embodiment of the present invention sets forth a technique for improving graphics rendering efficiency by processing pixels in a compressed format whenever possible within a multi-sampling graphics pipeline. Each geometric primitive is rasterized into fragments, corresponding to screen space pixels covered at least partially by the geometric primitive. Fragment coverage represents the pixel area covered by the geometric primitive and determines the weighted contribution of a fragment color to the corresponding screen space pixel. Samples associated with a given fragment are called sibling samples and have the same color value. The property of sibling samples having the same color value is exploited to compress and process multiple samples, thereby reducing the size of the associated logic and the amount of data written to and read from the frame buffer."
8233061,"A memory system, method, and computer program product are provided. In use, a plurality of portions of memory is arranged contiguously. Further, a number of requests required to retrieve the portions of memory is reduced utilizing the arrangement. In one possible embodiment, such technique may be used in the context of film grain technology (FGT), such that the portions of memory include portions of a film grain image stored in a film grain database (FGDB)."
8234458,"A method and system for maintaining cache coherency across a serial interface bus such as a Peripheral Component Interconnect Express (PCIe) bus. The method includes generating a snoop request (SNP) to determine whether first data stored in a local memory is coherent relative to second data stored in a data cache, the snoop request including destination information that identifies the data cache on the serial interface bus, and causing the snoop request to be transmitted over the serial interface bus to a second processor. The method further includes extracting a cache line address from the snoop request, determining whether the second data is coherent, generating a complete message (CPL) indicating that the first data is coherent with the second data, and causing the complete message to be transmitted over the bus to the first processor. The snoop request and complete messages may be vendor defined messages."
8234478,"One embodiment of the invention sets forth a mechanism for using the L2 cache as a buffer for data associated with read/write commands that are processed by the frame buffer logic. A tag look-up unit tracks the availability of each cache line in the L2 cache, reserves necessary cache lines for the read/write operations and transmits read commands to the frame buffer logic for processing. A data slice scheduler transmits a dirty data notification to the frame buffer logic when data associated with a write command is stored in an SRAM bank. The data slice scheduler schedules accesses to the SRAM banks and gives priority to accesses requested by the frame buffer logic to store or retrieve data associated with read/write commands. This feature allows cache lines reserved for read/write commands that are processed by the frame buffer logic to be made available at the earliest clock cycle."
8234488,"One embodiment of the present invention sets forth a technique for controlling mode switches in hardware. The resource manager includes an “is mode possible” function that evaluates a given mode in conjunction with the limitations of the hardware to determine if the given mode is feasible. The display driver is configured to call this function to validate a proposed mode before generating commands specifying the state changes for the display heads. The display software interface hardware module within the GPU processes these commands and follows a standard sequence of steps to implement the mode switch. The steps may include interrupts to the resource manager to re-validate the proposed mode, again calling the “is mode possible” function, or perform operations that are not yet supported in the hardware. Advantageously, controlling mode switches in hardware enables less error-prone, more efficient, and more discerning mode switches relative to controlling mode switches in software."
8237705,"Apparatuses and methods are presented for a hierarchical processor. The processor comprises, at a first level of hierarchy, a plurality of similarly structured first level components, wherein each of the plurality of similarly structured first level components includes at least one combined function module capable of performing multiple classes of graphics operations, each of the multiple classes of graphics operations being associated with a different stage of graphics processing. The processor comprises, at a second level of hierarchy, a plurality of similarly structured second level components positioned within each one of the plurality of similarly structured first level components, wherein each of the plurality of similarly structured second level components is capable of carrying out different operations from the multiple classes of graphics operations, wherein each first level component is adapted to distribute work to the plurality of similarly structured second level components positioned within the first level component."
8237725,"A vertex cache within a graphics processor is configured to operate as a conventional round-robin streaming cache when per-vertex state changes are not used and is configured to operate as a random access storage buffer when per-vertex state changes are used. Batches of vertices that define primitives and state changes are output to parallel processing units for processing according to vertex shader program. In addition to allowing per-vertex state changes, the vertex cache is configured to store vertices for primitive topologies that use anchor points, such as triangle strips, line loops, and polygons."
8237738,"A method and system for smooth rasterization of graphics primitives. The method includes receiving a graphics primitive for rasterization in a raster stage of a processor, rasterizing the graphics primitive by generating a plurality of fragments related to the graphics primitive, and determining a coverage value for each of the plurality of fragments. If one edge of the graphics primitive lies within a predetermined inter-pixel distance from a pixel center, the one edge is used to calculate the coverage value by using a distance to the pixel center. If two edges of the graphics primitive lie within the predetermined inter-pixel distance from the pixel center, a distance to the pixel center of each edge is used individually to calculate the coverage value. The resulting coverage values for the plurality of fragments are output to a subsequent stage of the processor for rendering."
8239938,"A method for providing an operating system access to devices, including enumerating hardware devices and virtualized devices, where resources associated with a first hardware device are divided into guest physical resources creating a software virtualized device, and multiple instances of resources associated with a second hardware device are advertised thereby creating a hardware virtualized device. First and second permission lists are generated that specify which operating systems are permitted to access the software virtualized device and the hardware virtualized device, respectively. First and second sets of virtual address maps are generated, where each set maps an address space associated with either the software virtualized device or the hardware virtualized device into an address space associated with each operating system included in the corresponding permission list. The method further includes arbitrating access requests from each of the plurality of operating systems based on the permission lists and the virtual address maps."
8243064,"A physics software development kit (PSDK) provides scalable physics content as a “vertical” that defines one or more physics simulations for a graphics asset in a graphics scene. The vertical and the graphics asset may be provided in a verticals library associated with the PSDK or generated using the PSDK. The PSDK integrates the vertical into an existing graphics application to generate physically-realistic graphics content. The vertical may be scaled by a user according to the capabilities of a computer system that executes the PSDK or, alternatively, may be scaled by the PSDK based on received hardware capabilities information. The PSDK selectively offloads the physics simulations associated with the vertical to a physics processing unit to optimize usage of processor resources. In addition, the PSDK provides a technique to extract a graphics asset based on an existing 3D model of the object. The graphics asset may then be simulated with a vertical to provide a physical simulation of the 3D model of the object."
8243069,The current invention involves new systems and methods for computing per-sample post-z test coverage when the memory is organized in multiple partitions that may not match the number of shaders. Shaded pixels output by the shaders can be processed by one of several z raster operations units. The shading processing capability can be configured independent of the number of memory partitions and number of z raster operations units. The current invention also involves new systems and method for using different z test modes with multiple render targets with a single or multiple memory partitions. Rendering performance may be improved by using an early z testing mode is used to eliminate non-visible samples prior to shading.
8243082,"One embodiment of the present invention sets forth a method for accessing display configuration information in a multi-GPU system, which includes the steps directing the display configuration information of a display device, coupled to a discrete GPU (dGPU), to a controller capable of accessing a display data bus, if the dGPU is unavailable, wherein the controller is capable of making the display configuration information available via a system interface, and validating the display configuration information prior to availing the dGPU or the display device as an option to be selected."
8243083,"A system, method, and computer program product are provided for converting a scan algorithm to a segmented scan algorithm in an operator independent manner. In operation, a scan algorithm and a limit index data structure are identified. Utilizing the limit index data structure, the scan algorithm is converted to a segmented scan algorithm in an operator-independent manner. Additionally, the segmented scan algorithm is performed to produce an output."
8243086,"A system and method uses the capabilities of a geometry shader unit within the multi-threaded graphics processor to offload data compression computations from a central processing unit (CPU), reduce the memory needed to store image data, and reduce the bandwidth needed to transfer image data between graphics processors and between a graphics processor and a system memory. The multi-threaded graphics processor is also configured to compress data for use in memory paging and when data is relocated to lie within an accessible memory aperture. The data is losslessly compressed using a geometry shading program to produce variable length compressed data."
8243092,"A system, method, and computer program product are provided for approximating a pixel color. In operation, an average color value and a number of fragments are identified for each of a plurality of pixels. Additionally, a color of each pixel is approximated, based on such average color value and number of fragments."
8243709,"A method (400) and arrangement (200) for mitigation of intercell and intracell interference in a 3GPP cellular communication system (100) by, in a receiver in a cell of the system, deriving for a first channel in the cell a signal, representative of first channel transfer function (A(1)); deriving for at least a second channel originating in a different cell a signal (A(2 . . . M)), representative of second channel transfer function, based on: deriving a cell specific scrambling code (s), deriving a channel impulse response (h), and deriving a channelization code (c); and performing multi-user detection using the first and second signals. Where the channelization code is unknown, a substitute channelization code is preferably substituted. It will be appreciated that the technique can be applied to both downlink and uplink. This provides the advantage that both intra-cell interference and intercell interference are mitigated."
8244984,"In one embodiment, a method for managing information related to dirty data stored in an intermediate cache coupled to one or more clients and to an external memory includes receiving a dirty data notification related to dirty data residing in the intermediate cache, the dirty data notification including a memory address indicating a location in the external memory where the dirty data should be stored and a data type associated with the dirty data, and extracting a bank page number from the memory address that identifies a bank page within the external memory where the dirty data should be stored. The embodiment also includes incrementing a first count associated with a first entry in a notification sorter that is affirmatively associated with the bank page, determining that the dirty data has a first data type, and incrementing a second count associated with the first entry."
8245307,"Methods, devices, and systems of protecting a secret are provided. Access to the secret is designed to be restricted to a code with a specific signature, or fingerprint. The signature of that code is used in the encryption of the secret, and other codes are prevented from using this signature to decrypt the secret. This restricted access to the secret prevents the secret from being easily compromised, for example, by preventing a change in the code."
8248433,"Error accumulation dithering is used to generate images of lower color resolution from input data of higher color resolution. A target color is received at high resolution for a current pixel of the image. The target color is intermediate between a first color and a second color at a low color resolution. One of the first color and the second color is selected as a final pixel color, based on whether an accumulated error determined from previous pixels is above or below a threshold amount. After selecting the final pixel color, an updated accumulated error is provided to the next pixel."
8248806,"A system and method are provided for directly coupling a chassis and a heat sink. A circuit board is provided with at least one processor mounted thereon. Additionally, a heat sink is provided, the heat sink being mechanically coupled to at least one of the circuit board and the processor for providing thermal communication between the heat sink and the circuit board. Furthermore, a mount is provided, the mount being coupled to the heat sink for providing a direct mechanical coupling with a chassis."
8249819,"An electronic device is assigned to a virtual bin by setting an operating voltage of the electronic device to a first voltage, determining an operating frequency and an operating power consumption level for the electronic device, determining an operating frequency differential equal to the absolute value of difference between the operating frequency and a minimum operating frequency of the physical bin, determining a power consumption level differential equal to the absolute value of difference between the operating power consumption level and a maximum operating power consumption level of the physical bin, and assigning a virtual bin identifier to the electronic device to identify the operating voltage of the electronic device if the operating frequency is greater than or equal to the minimum operating frequency of the physical bin and the operating power consumption level is less than or equal to the maximum power consumption level of the physical bin."
8250439,"A memory module includes a plurality of register files. Each register file is associated with a set of error-correcting code (ECC) bits and ECC check/correct logic that can provide error-correcting functionality, if required. When error-correcting functionality is not required, ECC bits are grouped together to form additional register files, thereby providing additional storage space."
8253737,"A system, method, and computer program product are provided for generating a disparity map. In use, a z-buffering operation is performed. In addition to such z-buffering operation, a plurality of disparity values are calculated, such that a disparity map may be generated utilizing the disparity values. To this end, such disparity map may be used for displaying stereoscopic content."
8253748,"One embodiment of a system for collecting performance data for a multithreaded processing unit includes a plurality of independent performance registers, each configured to count hardware-based and/or software-based events. Functional blocks within the multithreaded processing unit are configured to generate various event signals, and subsets of the events are selected and used to generate one or more functions, each of which increments one of the performance registers. By accessing the contents of the performance registers, a user may observe and characterize the behavior of the different functional blocks within the multithreaded processing unit when one or more threads are executed within the processing unit. The contents of the performance registers may also be used to modify the behavior of the program running on the multithreaded processing unit, to modify a global performance register or to trigger an interrupt."
8253749,"One embodiment of the present invention sets forth a set of application programming interface (API) extensions that enable a software application to control the processing work assigned to each GPU in a multi-GPU system. The software application enumerates a list of available GPUs, sets an affinity mask from the enumerated list of GPUs and generates an affinity device context associated with the affinity mask. The software application can then generate and utilize an affinity rendering context that directs rendering commands to a set of explicitly selected GPUs, thus allocating work among specifically selected GPUs. The software application is empowered to use domain specific knowledge to better optimize the work assigned to each GPU, thus achieving greater overall processing efficiency relative to the prior art techniques."
8253750,"Circuits, methods, and apparatus that provide highly integrated digital media processors for digital consumer electronics applications. These digital media processors are capable of performing the parallel processing of multiple format audio, video, and graphics signals. In one embodiment, audio and video signals may be received from a variety of input devices or appliances, such as antennas, VCRs, DVDs, and networked devices such as camcorders and modems, while output audio and video signals may be provided to output devices such as televisions, monitors, and networked devices such as printers and networked video recorders. Another embodiment of the present invention interfaces with a variety of devices such as navigation, entertainment, safety, memory, and networking devices. This embodiment can also be configured for use in a digital TV, set-top box, or home server. In this configuration, video and audio streams may be received from a number of cable, satellite, Internet, and consumer devices."
8254190,"A system, method, and computer program product are provided for driving a memory circuit. In one embodiment, the memory circuit is driven utilizing a first resistance value in a first mode of operation. Further, in a second mode of operation, the memory circuit is driven utilizing a second resistance value. In another embodiment, a device is provided for driving a memory circuit without active termination utilizing a resistor."
8254701,"A system and method uses the capabilities of a geometry shader unit within the multi-threaded graphics processor to offload data compression computations from a central processing unit (CPU), reduce the memory needed to store image data, and reduce the bandwidth needed to transfer image data between graphics processors and between a graphics processor and a system memory."
8255623,"An ordered storage structure implemented based on a content addressable memory (CAM). In an embodiment, a set of identifiers are formed with an order matching a desired access order for items. Each item is stored with a corresponding identifier in an entry of the CAM, with the identifiers being stored in the searchable fields/columns of the CAM. Thus, the items can be retrieved in the desired access order by providing the identifiers as search key inputs to the CAM in the desired access order."
8259119,"One embodiment of the present invention sets forth a technique for dynamically switching between a power-saving integrated graphics processing unit (IGPU) and a higher-performance discrete graphics processing unit (DGPU). This technique uses a single graphics driver and a single digital-to-analog converter (DAC) and leverages the GPU switching capability of the operating system to ensure a seamless transition. When additional graphics performance is desired, the system enters a hybrid graphics mode. In this mode, the DGPU is powered-up, and the graphics driver maintains the current display, while the operating system switches applications running on the IGPU to the DGPU. While in the hybrid graphics mode, the DGPU performs the graphics processing, and the graphics driver transmits the rendered images from the DGPU to the IGPU local memory and, then, to the IGPU DAC. This image transmission allows applications to fully exploit the processing capabilities of the DGPU, while using the display device connected to the IGPU."
8259122,"A system, method and article of manufacture are provided for programmable processing in a computer graphics pipeline. Initially, data is received from a source buffer. Thereafter, programmable operations are performed on the data in order to generate output. The operations are programmable in that a user may utilize instructions from a predetermined instruction set for generating the same. Such output is stored in a register. During operation, the output stored in the register is used in performing the programmable operations on the data."
8260380,"A headset phone for use with an audio system. A conventional 4-tap, combo phone connector is provided that has a sleeve tap, a tip tap, a first ring tap, and a second ring tap. A first speaker element is connected across the sleeve and tip taps and a second speaker element is connected across the sleeve and first ring taps. A microphone is connected across the sleeve and second ring tap. At least one control unit, other than a mute control, is also connected across the sleeve and second ring taps, such that operation of any control unit changes the impedance across the sleeve and second ring tap that is seen by the audio system."
8261121,"A method includes operating an arbitration logic of a memory controller at a core clock frequency lower than that of a memory clock frequency. The memory controller is configured to generate a command sequence including a number of commands in accordance with a number of external requests to access the memory. The method also includes parallelizing the number of commands in the command sequence based on a timing requirement for a non-first command in the command sequence defined by a memory-access protocol being satisfied at a rising edge or a falling edge of the core clock relative to a previous command in the command sequence. Further, the method includes ensuring, through the parallelizing, availability of the number of commands in the command sequence to a memory interface operating at the memory clock frequency at a command rate equal to the memory clock frequency."
8261234,"A system, method, and computer program product are provided for compiling code adapted to execute utilizing a first processor, for executing the code utilizing a second processor. In operation, code adapted to execute utilizing a first processor is identified. Additionally, the code is compiled for executing the code utilizing a second processor that is different from the first processor and includes a central processing unit. Further, the code is executed utilizing the second processor."
8264484,"A system, method, and computer program product are provided for organizing a plurality of rays. In operation, a plurality of rays is identified. Additionally, the rays are organized, utilizing a bounding volume."
8264491,"A system, method, and computer program product are provided for controlling a shader to gather statistics. In use, instructions are received utilizing a programmable interface. A shader is then controlled to gather statistics based on the instructions. Such statistics are further output to memory utilizing the shader."
8264492,"A system, method and article of manufacture are provided for programmable processing in a computer graphics pipeline. Initially, data is received from a source buffer. Thereafter, programmable operations are performed on the data in order to generate output. The operations are programmable in that a user may utilize instructions from a predetermined instruction set for generating the same. Such output is stored in a register. During operation, the output stored in the register is used in performing the programmable operations on the data."
8264851,"A Multi-configuration Processor-Memory device for coupling to a PCB (printed circuit board) interface. The device comprises a substrate that supports multiple configurations of memory components and a processor while having a single, common interface with a PCB interface of a printed circuit board. In a first configuration, the substrate supports a processor and a first number of memory components. In a second configuration, the substrate supports a processor and an additional number of memory components. The memory components can be pre-tested, packaged memory components mounted on the substrate. The processor can be a surface mounted processor die. Additionally, the processor can be mounted in a flip chip configuration, side-opposite the memory components. In the first configuration, a heat spreader can be mounted on the memory components and the processor to dissipate heat. In the second, flip chip, configuration, the processor face can be soldered onto a non-functional area of the PCB interface of the printed circuit board to dissipate heat."
8266382,"One embodiment of the present invention sets forth a technique for arbitrating requests received from one of the multiple clients of an L1 cache and for providing hints to the client to assist in arbitration. The L1 cache services multiple clients with diverse latency and bandwidth requirements and may be reconfigured to provide memory spaces for clients executing multiple parallel threads, where the memory spaces each have a different scope."
8266383,"One embodiment of the present invention sets forth a technique for processing cache misses resulting from a request received from one of the multiple clients of an L1 cache. The L1 cache services multiple clients with diverse latency and bandwidth requirements, including at least one client whose requests cannot be stalled. The L1 cache includes storage to buffer pending requests for caches misses. When an entry is available to store a pending request, a request causing a cache miss is accepted. When the data for a read request becomes available, the cache instructs the client to resubmit the read request to receive the data. When an entry is not available to store a pending request, a request causing a cache miss is deferred and the cache provides the client with status information that is used to determine when the request should be resubmitted."
8266448,"A system, method, and computer program product are provided for generating and securing a program, and secrets including confidential keys, capable of being executed utilizing a processor to decrypt content. In operation, a second party's program for decrypting content from a third party is generated by a second party, and then secured in a process involving the second party in such a manner that it can be subsequently executed on the processor, without revealing the contents of the second party's program, nor any secrets provided by third party, or used by the second party, in securing the program, nor any portion of the third party's content while being handled by the program."
8266623,"A system, method, and computer program product are provided for decomposing a sampling task into a plurality of jobs. In operation, a sampling task is identified. Additionally, the sampling task is decomposed into a plurality of jobs. Further, each of the plurality of jobs are processed in parallel. Still yet, each of the plurality of jobs are allowed to terminate independently of the other plurality of jobs."
8269768,"Z-buffer rendering of three-dimensional scenes is made more efficient through a method for occlusion culling by which occluded geometry is removed prior to rasterization. The method uses hierarchical z-buffering to reduce the quantity of image and depth information that needs to be accessed. A separate culling stage in the graphics pipeline culls occluded geometry and passes visible geometry on to a rendering stage. The culling stage maintains its own z-pyramid in which z-values are stored at low precision (e.g., in 8 bits). The efficiency of hierarchical z-buffering is improved through hierarchical evaluation of line and plane equations."
8269769,"An occlusion prediction compressing system and method are presented in accordance with embodiments of the present invention. In one embodiment, an occlusion prediction graphics processing method is utilized to predict which pixels are eventually occluded before intermediate processing stages are performed on the pixels. Culling information utilized to predict which pixel are occluded is compressed in accordance with embodiments of the present invention. In one embodiment, a cull value for a pixel culling area is retrieved and an end of pipe depth value associated with a prediction area within the pixel culling area is received. A determination is made if the end of pipe depth value is within a threshold range of the cull value. The cull value is updated based upon the relationship of the end of pipe depth value to offsets from the cull value. The cull value is associated with a mask which indicates if a plurality of prediction areas are at or in front of the cull value."
8271252,"An efficient and cost effective mechanism for generating test files for automatic verification of a device model is disclosed. Uncompleted coverage goals determined based upon simulating processing of a test file by a design model may be expressed as negative assertions for input to a test data generator, where output from the test data generator may used to create a test file for completing all or some of the uncompleted coverage goals. The test data generator may indicate data which causes a property to fail, and therefore, may indicate test data which causes the uncompleted coverage goal to succeed. The initial test file may represent zero code coverage and/or zero functional coverage, thereby enabling the test data generator to automatically create one or more test files for accomplishing the more extensive code coverage goals and/or functional coverage goals. Functional coverage goals may be automatically generated by the test data generator."
8271734,"A system and method for converting data from one format to another in a processing pipeline architecture. Data is stored in a shared cache that is coupled between one or more clients and an external memory. The shared cache provides storage that is used by multiple clients rather than being dedicated to separately convert the data format for each client. Each client may interface with the memory using a different format, such as a compressed data format. Data is converted to the format expected by the particular client as it is read from the cache and output to the client during a read operation. Bytes of a cache line may be remapped to bytes of an unpack register for output to a naïve client, which may be configured to perform texture mapping operations. Data is converted from the client format to the memory format as it is stored into the cache during a write operation."
8271746,"Efficient memory management can be performed using a computer system that includes a client which requests access to a memory, a memory interface coupled to the client and to the memory, wherein the memory interface comprises an arbiter to arbitrate requests received from the client to access data stored in the memory, a look ahead structure for managing the memory, a request queue for queuing memory access requests, and wherein the look ahead structure is located before the arbiter so that the look ahead structure communicates with the memory through the arbiter. Efficient memory management can also be performed by sending a memory access request from a client to a look ahead structure and to a request queue, wherein the look ahead structure comprises a row bank direction queue and a tiering logic, checking state of memory being requested using the tiering logic, prioritizing memory requests according to the memory state, selecting a location to be precharged with a precharge arbiter, selecting a location to be activated using an activate arbiter, selecting a location to read or write using a read/write arbiter, and precharging, activating and reading or writing according the selections according to availability of the memory."
8271763,One embodiment of the present invention sets forth a technique for unifying the addressing of multiple distinct parallel memory spaces into a single address space for a thread. A unified memory space address is converted into an address that accesses one of the parallel memory spaces for that thread. A single type of load or store instruction may be used that specifies the unified memory space address for a thread instead of using a different type of load or store instruction to access each of the distinct parallel memory spaces.
8274448,"A stereoscopic display system, method and computer program product are provided. In use, display content intended for a first eye is displayed utilizing a first portion of a display. Further, display content intended for a second eye is displayed utilizing a second portion of the display that is different from the first portion of the display."
8274513,"A system, method, and computer program product are provided for obtaining a boundary attribute value from a polygon mesh, during voxelization. In operation, voxelization is performed. Furthermore, during the voxelization, a boundary attribute value is obtained from a polygon mesh. Additionally, the boundary value includes a value of a boundary attribute of an object that is capable of being linearly interpolated across a boundary of a polygon mesh."
8276129,"One embodiment of the present invention sets forth a system that allows a software developer to perform shader debugging and performance tuning. The system includes an interception layer between the software application and the application programming interface (API). The interception layer is configured to intercept and store source code versions of the original shaders included in the application. For each object in the frame, the interception layer makes shader source code available to the developer, so that the developer can modify the source code as needed, re-compile only the modified shader source code, and run the application. Consequently, shader debugging and performance tuning may be carried out in a manner that is more efficient and effective relative to prior art approaches."
8276132,"One embodiment of the present invention sets forth a technique for representing and managing a multi-architecture co-processor application program. Source code for co-processor functions is compiled in two stages. The first stage incorporates a majority of the computationally intensive processing steps associated with co-processor code compilation. The first stage generates virtual assembly code from the source code. The second stage generates co-processor machine code from the virtual assembly. Both the virtual assembly and co-processor machine code may be included within the co-processor enabled application program. A co-processor driver uses a description of the currently available co-processor to select between virtual assembly and co-processor machine code. If the virtual assembly code is selected, then the co-processor driver compiles the virtual assembly into machine code for the current co-processor."
8276133,"A system, method, and computer program product are provided for determining a plurality of application settings utilizing a mathematical function. In operation, a plurality of application parameters are identified. Additionally, the application parameters are defined as a mathematical function. Furthermore, a plurality of application settings are determined utilizing the mathematical function."
8276180,"A system, method, and computer program product are provided for delivering video content over a wide area network (WAN). Included is at least one server for transcoding or transrating the video content for delivery over the WAN."
8278894,"A DC-DC converter adopted in a mobile device, for converting a DC input voltage to a DC output voltage is provided. The converter comprises an input circuit, a control circuit, and a switch. The input circuit is connected in series with a line for supplying the DC input voltage and includes a parallel connection of a first capacitor and a snubber circuit. The control circuit is provided for producing a control signal. The switch, connected with the input circuit, is adapted to turn ON or OFF in accordance with the control signal, so as to produce the DC output voltage."
8279220,"Systems and methods for estimating light transport between respective points includes selecting a plurality of first sub-paths extending the first point A, and selecting a plurality of second sub-paths extending from a second point B. A plurality of transport paths are constructed, wherein each one of the plurality of the first sub-paths is coupled to a respective one of the plurality of second paths, and wherein each transport path comprises one first sub-path and one second sub-path. Two or more of the transport paths are sampled, and a light transport value for each of the sampled transport paths is calculated to estimate the light transported between first point A and second point B."
8279229,"A system, method, and computer program product are presented for providing access to graphics processor central processing unit (CPU) cores, to both a graphics processor and a central processing unit. In operation, access is provided to a plurality of central processing unit cores of a graphics processor, to both the graphics processor and a central processing unit. Additionally, first requests are received from the central processing unit to execute first code utilizing at least one of the central processing unit cores of the graphics processor. Furthermore, second requests are received from the graphics processor to execute second code utilizing at least one of the central processing unit cores of the graphics processor. Still yet, there is arbitrating among the first requests and the second requests."
8279231,"Read completion buffer space is allocated in accordance with a preset limit. When a read request is received from a client, the sum of a current allocation of the read completion buffer space and a new allocation of the read completion buffer space required by the read request is compared with the preset limit. If the preset limit is not exceeded, read completion buffer space is allocated to the read request. If the preset limit is exceeded, the read request is suspended until sufficient data is read out from the read completion buffer."
8279893,"A system and method are provided for communicating data over a network. In some embodiments relating to data transmission, data is divided into a plurality of portions, such that the portions may be transmitted utilizing a plurality of different types of data connections. In other embodiments relating to data receipt, a plurality of portions of data is received utilizing a plurality of different types of data connections, after which the portions may be reassembled."
8279992,"An adaptive bandwidth clock and data recovery circuit and method are provided. The adaptive bandwidth clock and data recovery circuit includes a voltage controlled oscillator for outputting a phase of a clock. In addition, a phase detector is included for determining a phase difference between received data and the clock. Further, a charge pump is included for outputting a current as a function of the phase difference, the current utilized for generating a control voltage provided to the voltage controlled oscillator. Still yet, an adaptive bandwidth control is included for providing the voltage controlled oscillator with an adaptive bandwidth based on the phase difference."
8280385,Embodiments of the invention provide for allocating spectrum in a wireless communication system that supports simultaneously at least a first mode of operation and a second mode of operation. Logic is arranged for determining a proportion of spectrum required for the wireless communication unit to operate simultaneously in both the first mode of operation and the second mode of operation. Logic for allocating spectrum allocates a temporary guard band between a first portion of spectrum for the first mode of operation and a second portion of spectrum for the second mode of operation for use while the wireless communication unit operates simultaneously in the first mode of operation and second mode of operation.
8280864,"A system, method, and computer program product are provided for retrieving presentation settings from a database. In use, presentation capabilities information associated with media hardware is received. Further, a plurality of presentation settings is retrieved from a database, utilizing the presentation capabilities information."
8281067,"A disk array controller apparatus (10) is disclosed having at least two logical ports (Logical Port #0-Logical Port #3) for interfacing with a host (12) and having one or more physical ports (Physical Port #0-Physical Port #4), each physical port arranged for attaching at least one disk drive to the controller, and the controller including a switch (26), the switch providing dynamically configurable data paths (30) between the logical data ports and physical data ports, responsive to the contents of a Mapping Register (24). The Mapping Register defines a desired disk drive array by specifying an association of each logical port to one of the physical ports. The mapping register can be organized as a logical mapping register, comprising a field for each logical port of the controller, and includes provision for designating a redundant array for RAID operations."
8281294,"One embodiment of the present invention sets forth a technique for representing and managing a multi-architecture co-processor application program. Source code for co-processor functions is compiled in two stages. The first stage incorporates a majority of the computationally intensive processing steps associated with co-processor code compilation. The first stage generates virtual assembly code from the source code. The second stage generates co-processor machine code from the virtual assembly. Both the virtual assembly and co-processor machine code may be included within the co-processor enabled application program. A co-processor driver uses a description of the currently available co-processor to select between virtual assembly and co-processor machine code. If the virtual assembly code is selected, then the co-processor driver compiles the virtual assembly into machine code for the current co-processor."
8284152,"Embodiments of the present invention generally provide m Methods and apparatus for reducing power consumption of backlit displays are described. Power consumption is reduced by dimming backlighting by a first scale factor and boosting pixel values by a second scale factor to compensate for the dimming. The scale factors may be constant values. Alternately, one or both of the scale factors may be determined based on pixel values for one or more frames to be displayed and/or one or more frames that have been displayed. For example, scale factors may be calculated based on an average linear amplitude of one or more frames of pixel values or from a maximum pixel value of one or more frames of pixel values. A graphical processing system is described including an integrated circuit capable of transforming a pixel value from a gamma-compensated space to a linear space."
8284188,"A ray tracing system, method, and computer program product are provided for simultaneously traversing a hierarchy of rays and a hierarchy of objects. In operation, a hierarchy of rays and a hierarchy of objects are simultaneously traversed. Additionally, ray tracing is performed, based on the traversal."
8284210,"A bandwidth-driven system, method, and computer program product are provided for changing a refresh rate of a display system. In use, a bandwidth associated with a display system is identified. To this end, a refresh rate of the display system may be changed for controlling the bandwidth."
8284620,"Circuits, methods, and apparatus that adaptively control 1T and 2T timing for a memory controller interface. An embodiment of the present invention provides a first memory interface as well as an additional memory interface, each having a number of address and control lines. The address and control lines of the redundant memory interface may be individually enabled and disabled. If a line in the additional interface is enabled, it and its corresponding line in the first interface drive a reduced load and may operate at the higher 1T data rate. If a line in the additional interface is disabled, then its corresponding line in the first interface drives a higher load and may operate at the slower 2T data rate. In either case, the operating speed of the interface may also be considered in determining whether each line operates with 1T or 2T timing."
8284782,"A method for establishing a network connection between two computing devices within the same computer network includes the steps of generating a masquerade IP address request, where the masquerade IP address request includes a masquerade MAC address, transmitting the masquerade IP address request to a DHCP server, and receiving a masquerade IP address from the DHCP server. The masquerade IP address is then used as the sender's IP address in an ARP broadcast request transmitted to set up the network connection. Since the masquerade IP address is unique relative to the computer network, computing devices within the network do no overwrite existing IP-to-MAC relationships in their respective ARP caches with the IP-to-MAC relationship reflected in the ARP broadcast request. Thus, the method enables a network connection to be initiated between two computing devices in the same computer network while avoiding ARP cache pollution on other computing devices in that network."
8284783,"A method of avoiding cache corruption when establishing a network connection includes the steps of transmitting a request to a computing device, where the request includes a masquerade layer-3 address, and receiving a reply transmitted by the computing device in response to the request, where the reply includes a MAC address associated with the computing device. Since the masquerade layer-3 address is unique relative to the computer network, computing devices within the network do no overwrite existing layer-3-to-MAC relationships in their respective caches with the layer-3-to-MAC relationship reflected in the request. Thus, the method enables a network connection to be initiated between two computing devices in the same computer network while avoiding neighbor cache pollution on other computing devices in that network."
8285877,"A method and system for performing intelligent background data conversion are disclosed. Specifically, one embodiment of the present invention sets forth a method that includes the steps of generating a task list associated with a source data and, according to the task list, converting the source data to target data as specified in a predetermined profile at any time a processing unit inactive state is detected."
8289324,"A system, method, and computer program product are provided for spatial hierarchy traversal. In operation, a spatial hierarchy is traversed for ray tracing. Additionally, a number of nodes traversed in each of a plurality of levels of the spatial hierarchy is stored."
8290357,"An image processor, which determines appropriate exposure parameters for a shutter assembly in a camera. The image processor may computationally determine a region of interest in a scene sought to be captured, and set the parameters to ensure that the exposure parameters are set to capture an image of the scene with the region of interest having a desired brightness level. In an embodiment, pixel values of multiple frames (each frame with a corresponding set of configuration parameters of the shutter assembly) may be examined to determine the frame having pixel values with the region having the desired brightness level. The shutter assembly may be configured with the parameters corresponding to such a frame to provide an auto-exposure feature."
8291122,"Uninterrupted Media Change (UMC) is a solution for changing between input channels such that complete segments of content are observed in the output channel. UMC provides for seamless switching between concurrent, multi-segment, media data streams. Media data streams are input channels composed of discrete segments of information, which may include audio, images or video content. Segments are defined by points that mark the beginning and end of content within the input data stream. When a UMC event is selected by a user, the next segment beginning for the target input channel is detected and that target segment is buffered until the end of the current active segment is reached, at which point the buffered target segment is made the new active segment and presented to the user from its buffered beginning."
8294714,"One embodiment of the invention sets forth a mechanism for interleaving consecutive display frames rendered at complementary reduced resolutions. The GPU driver configures a command stream associated with a frame received from a graphics application for reduced frame rendering. The command stream specifies a nominal resolution at which the frame should be rendered. The reduced resolution associated with the frame is determined based on the reduced resolution of an immediately preceding frame (i.e., the complementary reduced resolution), if one exists, or on GPU configuration information. The GPU driver then modifies the command stream to specify the reduced resolution. The GPU driver also inserts an upscale command sequence specifying the nominal resolution into the command stream. Once the command stream is configured in such a manner, the GPU driver transmits the command stream to the GPU for reduced rendering."
8294821,A software or hardware agent running on a personal computing device provides allows application programs to interact with consumer electronic devices using standardized controls. The consumer electronic devices appear to be directly connected to the personal computing device rather than being connected over a high definition multimedia interface (HDMI) network. This enables a user to control the consumer electronic devices using a single interface rather than a separate interface for each consumer electronic device. The agent enumerates a universal serial bus (USB) human interface device (HID) for each consumer electronic device reported on the HDMI network. The USB HIDs represent the specific capabilities of the each one of the consumer electronic devices.
8295621,"A system and method uses the capabilities of a geometry shader unit within the multi-threaded graphics processor to offload data compression computations from a central processing unit (CPU), reduce the memory needed to store image data, and reduce the bandwidth needed to transfer image data between graphics processors and between a graphics processor and a system memory. The multi-threaded graphics processor is also configured to perform decompression of the variable length compressed data using the geometry shader unit."
8296515,"One embodiment of the present invention sets forth a technique for performing RAID-6 computations using simple arithmetic functions and two-dimensional table lookup operations. A set of threads within a multi-threaded processor are assigned to perform RAID-6 computations in parallel on a stripe of RAID-6 data. A set of lookup tables are stored within the multi-threaded processor for access by the threads in performing the RAID-6 computations. During normal operation of a related RAID-6 disk array, RAID-6 computations may be performed by the threads using a small set of simple arithmetic operations and a set of lookup operations to the lookup tables. Greater computational efficiency is gained by reducing the RAID-6 computations to simple operations that are performed efficiently on a multi-threaded processor, such as a graphics processing unit."
8296738,"One embodiment of the present invention sets forth a system that allows a software developer to perform shader debugging and performance tuning. The system includes an interception layer between the software application and the application programming interface (API). The interception layer is configured to intercept and store source code versions of the original shaders included in the application. For each object in the frame, the interception layer makes shader source code available to the developer, so that the developer can modify the source code as needed, re-compile only the modified shader source code, and run the application. Consequently, shader debugging and performance tuning may be carried out in a manner that is more efficient and effective relative to prior art approaches."
8296764,"The disclosure describes internal synchronization in adaptive integrated circuitry which utilizes a data flow model for data processing. Task initiation and execution are controlled based upon data consumption measured in data buffer units, with initiation of and transitions between tasks based on a determined boundary condition within the data stream. When a data processing task is selected for synchronization, a boundary condition in a data stream is determined for commencement of the selected data processing task. Then, a timing marker for the commencement of the selected data processing task is determined relative to the data stream. The timing marker is dual-valued, providing a designated buffer unit and a designated byte or bit location within the designated buffer. The timing marker is communicated to the selected data processing task, which then commences data processing at a location in the data stream designated by the timing marker."
8296781,"A system, method, and computer program product are provided for determining parameters for an application based on hardware specifications. In operation, a plurality of hardware specifications associated with a system are identified. Additionally, at least one application associated with the system is identified. Furthermore, at least one parameter for the application is determined based on the hardware specifications. Still yet, the parameter is applied to the application."
8300647,"A hash engine in a network device driver maintains data on the utilization and error rate for each network interface card (“NIC”) within a local computing device. From this data, the hash engine intelligently selects transmit NICs and receive NICs based on various networking parameters provided from a software driver program. Transmit packets sent from the operating system in a local computing device to a remote computing device are intercepted, modified and redirected to transmit NICs selected by the hash engine for transmission to remote computing devices. Similarly, address resolution protocol (“ARP”) response packets sent by the operating system in response to ARP request packets are intercepted, modified and redirected to receive NICs selected by the hash engine for transmission. By selecting receive NICs and transmit NICs in this fashion, the hash engine is able to intelligently load balance transmit and receive traffic in the local computing device, thereby improving overall network performance relative to prior art techniques."
8301980,"One embodiment of the present invention sets forth a technique for protecting data with an error correction code (ECC). The data is accessed by a processing unit and stored in an external memory, such as dynamic random access memory (DRAM). Application data and related ECC data are advantageously stored in a common page within a common DRAM device. Application data and ECC data are transmitted between the processor and the external common DRAM device over a common set of input/output (I/O) pins. Eliminating I/O pins and DRAM devices conventionally associated with transmitting and storing ECC data advantageously reduces system complexity and cost."
8306998,"A method comprises displaying a mail server information screen, and receiving connection information via the mail server information screen. Further, the method comprises displaying an address page, and receiving recipient information via the address page. In addition, the method comprises displaying a content page, and receiving content in the content page. Additionally, an electronic mail message having the content is compiled, and the electronic mail message is sent to a recipient utilizing the connection information and recipient information."
8307165,"One embodiment of the invention sets forth a mechanism for increasing the number of read commands or write commands transmitted to an activated bank page in the DRAM. Read requests and dirty notifications are organized in a read request sorter or a dirty notification sorter, respectively, and each sorter includes multiple sets with entries that may be associated with different bank pages in the DRAM. Read requests and dirty notifications are stored in read request lists and dirty notification lists, where each list is associated with a specific bank page. When a bank page is activated to process read requests, read commands associated with read requests stored in a particular read request list are transmitted to the bank page. When a bank page is activated to process dirty notifications, write commands associated with dirty notifications stored in a particular dirty notification list are transmitted to the bank page."
8310482,"A system for distributed of plane equation calculations. A work distribution unit is configured to receive a set of vertex data that includes meta data associated with each vertex in a modeled three-dimensional scene, to divide the set of vertex data into a plurality of batches of vertices, and to distribute the plurality of batches of vertices to one or more general processing clusters (GPCs). A processing cluster array includes the one or more (GPCs), where each GPC includes one or more shader-primitive-controller units (SPMs), and each SPM is configured to calculate plane equation coefficients for a subset of the vertices included in a batch of vertices. Advantageously, a distributed configuration of multiple plane equation calculation units decreases the size of the data bus that carries plane equation coefficients and increases overall processing throughput."
8311127,"A method to detect (identify) wrongly decoded data (I type macro-blocks), which can be subsequently concealed by error concealment techniques, thereby improving the visual quality of a decoded stream, is provided. Additionally, a method is provided. In use, a set of macro-block data is selected for validation. Additionally, a set of suspicious macro blocks is selected from the set of macro-block data based on location information for each suspicious macro block."
8312254,"An indirect branch instruction takes an address register as an argument in order to provide indirect function call capability for single-instruction multiple-thread (SIMT) processor architectures. The indirect branch instruction is used to implement indirect function calls, virtual function calls, and switch statements to improve processing performance compared with using sequential chains of tests and branches."
8314803,"An arithmetic logic stage in a graphics processor unit pipeline includes a number of arithmetic logic units (ALUs) and at least one buffer that stores pixel data for a group of pixels. Each clock cycle, the buffer stores one row of a series of rows of pixel data. A deserializer deserializes the rows of pixel data before the pixel data is placed in the buffer. After the buffer accumulates all rows of pixel data for a pixel, then the pixel data for the pixel can be operated on by the ALUs."
8315385,"The present invention provides a system and method for introducing white noises into a digital audio signal so that there is progressive and cumulative degradation in audio quality after each successive reproduction of the audio sound signal in a fashion analogous to analog audio reproduction. The invention provides a white noise generator, and a digital entroping unit. In a preferred embodiment, the white noise generator is implemented by a hardware random number generator. The digital entroping unit controls the magnitude of white noise desired based on a random number generated by the random number generator, and adds the white noise to the input audio sound signal to produce a degraded audio sound signal. The magnitude of white noise can be controlled by using various masking and formatting of random number data."
8316256,"The present invention sets forth a method and a system for powering a graphics processing unit (GPU) with a power supply subsystem. In one embodiment, the method includes generating an offset in response to an operating voltage need of the GPU; and applying the offset to information associated with a first operating voltage of the GPU; wherein the offset causes the first operating voltage to change to a second operating voltage of the GPU."
8319780,"A system, method, and computer program product are provided for synchronizing operation of a first graphics processor and a second graphics processor in order to secure communication therebetween. A first graphics processor is provided for processing video data. In addition, a second graphics processor is provided for processing the video data. Furthermore, a data structure is provided for use in synchronizing operation of the first graphics processor and the second graphics processor in order to secure communication therebetween."
8319783,A system and method for performing zero-bandwidth-clears reduces external memory accesses by a graphics processor when performing clears and subsequent read operations. A set of clear values is stored in the graphics processor. Each portion of a color or z buffer may be configured using a zero-bandwidth-clear command to reference a clear value without writing the external memory. The clear value is provided to a requestor without accessing the external memory when a read access is performed.
8320250,"A communication entity is located at one end of a high latency communication link to support Transmission Control Protocol (TCP) communications between a first transceiver entity and a second transceiver entity. The communication entity comprises proxy logic arranged to inspect a received segment and, in response to identifying that the received segment does not contain data, the proxy logic transparently allows a plurality of synchronizing segments to pass between the first transceiver entity and the second transceiver entity through the proxy logic such that the proxy logic generates locally at least one acknowledgement message based on the synchronizing segments and the inspected received segment."
8320741,"A media capture system, method, and computer program product are provided for assessing processing capabilities. In use, media data is captured from a system. Additionally, the media data is stored in memory separate from the system. Further, the media data is fed back to the system for assessing media processing capabilities of the system in real-time or non-real-time."
8320749,"Methods, systems and computer-readable medium for changing video playback speed are disclosed. Video playback speed may be changed by determining a first frame rate and a second frame rate for which a frame rate transition is to be made. An instantaneous frame rate is calculated to produce a calculated instantaneous frame rate, wherein the calculated instantaneous frame rate is between the first frame rate and the second frame rate. A timestamp of a frame is adjusted based on the calculated instantaneous frame rate to produce an adjusted timestamp. Graphical data for the frame is provided in accordance with the adjusted timestamp to enable display of the frame. Thereafter, the frame may be displayed in accordance with the adjusted timestamp."
8321492,"A system, method, and computer program product are provided for converting a reduction algorithm to a segmented reduction algorithm. In operation, a reduction algorithm is identified. Additionally, the reduction algorithm is converted to a segmented reduction algorithm. Furthermore, the segmented reduction algorithm is performed to produce an output."
8321618,"One embodiment of the present invention sets forth a mechanism to schedule read data transmissions and write data transmissions to/from a cache to frame buffer logic on the L2 bus. When processing a read or a write command, a scheduling arbiter examines a bus schedule to determine that a read-read conflict, a read-write conflict or a write-read exists, and allocates an available memory space in a read buffer to store the read data causing the conflict until the read return data transmission can be scheduled. In the case of a write command, the scheduling arbiter then transmits a write request to a request buffer. When processing a write request, the request arbiter examines the request buffers to determine whether a write-write conflict. If so, then the request arbiter allocates a memory space in a request buffer to store the write request until the write data transmission can be scheduled."
8321761,"A memory module includes a plurality of register files. Each register file is associated with a set of error-correcting code (ECC) bits and ECC check/correct logic that can provide error-correcting functionality, if required. When error-correcting functionality is not required, ECC bits are grouped together to form additional register files, thereby providing additional storage space."
8321849,"A virtual architecture and instruction set support explicit parallel-thread computing. The virtual architecture defines a virtual processor that supports concurrent execution of multiple virtual threads with multiple levels of data sharing and coordination (e.g., synchronization) between different virtual threads, as well as a virtual execution driver that controls the virtual processor. A virtual instruction set architecture for the virtual processor is used to define behavior of a virtual thread and includes instructions related to parallel thread behavior, e.g., data sharing and synchronization. Using the virtual platform, programmers can develop application programs in which virtual threads execute concurrently to process data; virtual translators and drivers adapt the application code to particular hardware on which it is to execute, transparently to the programmer."
8321872,"Hardware resources sharing for a computer system running software tasks. A controller stores records including a mutex ID tag and a waiter flag in a cache. Lock and unlock registers are readable by the controller and loadable by the tasks with a mutex ID specifying a hardware resource. The controller monitors whether the lock register for loading with a mutex ID, and then determines whether it corresponds with the tag of a record in the cache. If so, it sets the record's waiter flag. If not, it adds a record having a tag corresponding with the mutex ID. The controller also monitors whether the unlock register for loading with a mutex ID, and then determines whether it corresponds with the tag of a record in the cache. If so, it determines whether that record's waiter flag is set and, if so, it clears that record from the cache."
8325193,"One embodiment of the invention sets forth a mechanism for controlling the initialization order of an iGPU and a dGPU in a hybrid graphics processing environment to ensure that the iGPU is recognized by the operating system as the primary GPU. When the device initialization request associated with the dGPU is received, the interface module determines whether the iGPU has already been initialized. If the iGPU has already been initialized, then the interface module transmits the device initialization request to the dGPU driver for dGPU initialization. However, if the iGPU flag indicates that the iGPU has not yet been initialized, then the interface module terminates the device initialization request and transmits an initialization failure notification to the operating system. In such a manner, the dGPU is initialized only after the iGPU has previously been initialized, thereby ensuring that the iGPU is recognized by the operating system as the primary GPU."
8325194,"One embodiment of the invention sets forth a control crossbar unit that is designed to transmit control information from control information generators to destination components within the computer system. The control information may belong to various traffic paradigms, such as short-latency data traffic, narrow-width data traffic or broadcast data traffic. The physical connections within the control crossbar unit are categorized based on the different types of control information being transmitted through the control crossbar unit. The physical connections belong to the following categories: one-to-one (OTO) connections, one-to-many (OTM) connections, valid-to-one (VTO) connections, valid-to-many (VTM) connections wire-to-one (WTO) connections and wire-to-many (WTM) connections."
8325203,"In a graphics pipeline of a graphics processor, a method for caching pixel data. The method includes receiving a graphics primitive for rasterization in a raster stage of a graphics processor and rasterizing the graphics primitive to generate a plurality of tiles of pixels related to the graphics primitive. A subpixel sample group related to each of the plurality of tiles is determined. The plurality of tiles and the corresponding plurality of subpixel sample groups are stored into a frame buffer memory. A set of tiles and a set of corresponding subpixel sample groups from the frame buffer memory are stored in a rasterization cache, wherein the rasterization cache is configured for access by the raster stage to enable a subpixel anti-aliasing operation."
8327071,"In a multiprocessor system level 2 caches are positioned on the memory side of a routing crossbar rather than on the processor side of the routing crossbar. This configuration permits the processors to store messages directly into each other's caches rather than into system memory or their own coherent caches. Therefore, inter-processor communication latency is reduced."
8327123,"In parallel processing devices, for streaming computations, processing of each data element of the stream may not be computationally intensive and thus processing may take relatively small amounts of time to compute as compared to memory accesses times required to read the stream and write the results. Therefore, memory throughput often limits the performance of the streaming computation. Generally stated, provided are methods for achieving improved, optimized, or ultimately, maximized memory throughput in such memory-throughput-limited streaming computations. Streaming computation performance is maximized by improving the aggregate memory throughput across the plurality of processing elements and threads. High aggregate memory throughput is achieved by balancing processing loads between threads and groups of threads and a hardware memory interface coupled to the parallel processing devices."
8327173,"In an integrated circuit device, a circuit for maintaining asserted values on an input output pin of the device when a functional block of the device is placed in a sleep mode. The circuit includes an interface for coupling a functional block of a processor to an input and output pin and an output storage element coupled to the interface for storing a current value of the input output pin. The circuit further includes a sleep mode enable for controlling the output storage element to store the current value of the input output pin prior to the functional block being entering a sleep mode and cause the current value of the input output pin to remain asserted after the functional block is in sleep mode. The sleep mode enable is also to deactivate the storage element when the sleep mode is exited."
8327388,"A method of executing a physics simulation is performed in a system comprising a computational platform, a main application stored in the computational platform, a secondary application stored in the computational platform, and a cloth application programming interface (API) implemented in the computational platform. The method defines a cloth simulation call in the cloth API, and by operation of the main application, invokes a software routine using the cloth simulation call. Additionally, by operation of the secondary application, a state of the physics simulation is updated in response to the software routine."
8330766,A system and method for performing zero-bandwidth-clears reduces external memory accesses by a graphics processor when performing clears and subsequent read operations. A set of clear values is stored in the graphics processor. Each region of a color or z buffer may be configured using a zero-bandwidth-clear command to reference a clear value without writing the external memory. The clear value is provided to a requestor without accessing the external memory when a read access is performed.
8334857,"A method and system are implemented to dynamically control a display refresh rate. Specifically, one embodiment of the present invention sets forth a method, which comprises the steps of driving a display device at a first refresh rate over a period of time, measuring a number of first content frames with changes in content out of a plurality of content frames that are generated over the period of time for the display device, and driving the display device at a second refresh rate if the number of the first content frames meets a first condition associated with a first threshold reference, and optionally driving the display device at a third refresh rate if the number of first content frames meets a second condition associated with a second threshold reference."
8335892,"One embodiment of the present invention sets forth a technique for arbitrating requests received by an L1 cache from multiple clients. The L1 cache outputs bubble requests to a first one of the multiple clients that cause the first one of the multiple clients to insert bubbles into the request stream, where a bubble is the absence of a request. The bubbles allow the L1 cache to grant access to another one of the multiple clients without stalling the first one of the multiple clients. The L1 cache services multiple clients with diverse latency and bandwidth requirements and may be reconfigured to provide memory spaces for clients executing multiple parallel threads, where the memory spaces each have a different scope."
8339406,A VLC data transfer interface is presented that allows digital data to be packed and assembled according to a format selectable from a number of formats while the data is being transferred to a desired destination.
8340058,"A headphone having ability to communicate using Internet Protocol (IP) standard. The capability may be used as a basis to facilitate a user to conduct voice calls using voice over IP (VOIP). The headphone may also facilitate voice calls with users connected via cellular networks (e.g., GSM, CDMA, etc.). In an embodiment, the headphone is provided a wireless LAN (WLAN) network interface such that VOIP calls are conducted using wireless medium. Similarly, a Bluetooth protocol type interface is also provided to communicate with a cellular phone and the communication forms the basis for the voice calls between the headphone and other cellular phones connected via the cellular network."
8340512,"Multiple sets of pixel values representing a captured image of a scene are received, with each set representing an image captured with a corresponding degree of focus. An image processor may identify a region of interest in the captured image, automatically determine the configuration parameters for a lens assembly to provide a desired degree of focus for the region of interest, and generate signals to configure a lens assembly. In an embodiment, the region of interest is a face, the desired degree of focus of the face is determined by computing a rate of variation of luminance of pixels representing the face, and the desired degree is the degree of the image having the maximum degree of focus."
8341358,"One embodiment of the invention sets forth a mechanism for efficiently write dirty data from the L2 cache to a DRAM. A dirty data notification, including a memory address of the dirty data, is transmitted by the L2 cache to a frame buffer logic when dirty data is stored in the L2 cache. The frame buffer logic uses a page-stream sorter to organize dirty data notifications based on the bank page associated with the memory addresses included in the dirty data notifications. The page-stream sorter includes multiple sets with entries that may be associated with different bank pages in the DRAM. The frame buffer logic transmits dirty data associated with an entry that has a maximum threshold of dirty data notifications to the DRAM. The frame buffer logic also transmits dirty data associated with the oldest entry when the number of entries in a set reaches a maximum threshold."
8341380,"One embodiment of the present invention sets forth a system and method for supporting high-throughput virtual to physical address translation using compressed TLB cache lines with variable address range coverage. The amount of memory covered by a TLB cache line depends on the page size and page table entry (PTE) compression level. When a TLB miss occurs, a cache line is allocated with an assumed address range that may be larger or smaller than the address range of the PTE data actually returned. Subsequent requests that hit a cache line with a fill pending are queued until the fill completes. When the fill completes, the cache line's address range is set to the address range of the PTE data returned. Queued requests are replayed and any that fall outside the actual address range are reissued, potentially generating additional misses and fills."
8345052,"A method and system for using a graphics processing unit (“GPU”) frame buffer in a multi-GPU computing device as cache memory are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of designating a first GPU subsystem in the multi-GPU computing device as a rendering engine, designating a second GPU subsystem in the multi-GPU computing device as a cache accelerator, and directing an upstream memory access request associated with an address from the first GPU subsystem to a port associated with a first address range, wherein the address falls within the first address range. The first and the second GPU subsystems include a first GPU and a first frame buffer and a second GPU and a second frame buffer, respectively."
8345769,"One embodiment of the present invention sets forth a technique that enables a user to reverse through video content based on scene transitions. By employing a graphics processing unit to compute one or more frame-to-frame correlation coefficients that measure the consistency of sequential images and a central processing unit to analyze the one or more correlation coefficients, a list of scene transitions may be generated in real-time. The list of scene transitions forms the basis for a content-based reverse user control within the playback application. The content-based reverse user control enables a more natural mechanism for reversing through video content, providing the user with a superior overall viewing experience."
8346807,"A method and system for registering and activating content are described. Ownership of instances of content is registered in a registry of accounts associated with various users. Responsive to a user selecting an instance of content from a content distributor, the user's account is updated by adding therein an identifier uniquely associated therewith. Responsive to the user requesting access to an instance of content, the identity of the user is authenticated. The request conveys a unique identifier of the instance of content and a key for activating the content. The content activating key is compared with the registry to identify the user's ownership level in the instance of content. Upon associating the user identity with the user's ownership level, the instance of content is activated to allow the user to access the instance of content according to the corresponding ownership level."
8347064,"A method of accessing memory, in accordance with one embodiment, includes receiving a memory access request that includes a virtual address. An address of a given page table is determined utilizing a page directory stored in a particular one of a plurality of computing device-readable media. A given one of the plurality of computing device-readable media that stores the given page table is determined from a table aperture attribute in the page directory. A given physical address of a page is determined utilizing the given page table stored in the given computing device-readable media. A corresponding one of the plurality of computing device-readable media that stores the page is determined from a page aperture attribute in the given page table. The corresponding computing device-readable media at the given physical address is then accessed."
8347115,"A data storage system providing transparent encryption. The data storage system has a hardware encryption/decryption engine and a register coupled to the hardware encryption/decryption engine. The register is for securely storing a key for encrypting and decrypting data. The key may not be read from outside the data storage system. More specifically, the key may not be read by the operating system. The user does not have access to the encryption key, but may have a password that is passed to a controller coupled to the encryption/decryption engine. The controller verifies the password and causes data received from main memory to be encrypted by the hardware encryption/decryption engine using the key. The controller also transfers the encrypted data to the data storage device."
8347118,"One embodiment of the present invention sets forth a method for managing a power state of an audio device resident in a graphics processing unit. The method includes the steps of directing audio data originated from a client application via an audio path in an audio driver stack to the audio device, determining whether an active stream of audio data along the audio path is present in response to a notification of an attempt to shut down the graphics processing unit, and requesting a plug and play manager to disable the audio device, if no active stream of audio data is present along the audio path."
8347310,"One embodiment of the present invention sets forth a technique for representing and managing a multi-architecture co-processor application program. Source code for co-processor functions is compiled in two stages. The first stage incorporates a majority of the computationally intensive processing steps associated with co-processor code compilation. The first stage generates virtual assembly code from the source code. The second stage generates co-processor machine code from the virtual assembly. Both the virtual assembly and co-processor machine code may be included within the co-processor enabled application program. A co-processor driver uses a description of the currently available co-processor to select between virtual assembly and co-processor machine code. If the virtual assembly code is selected, then the co-processor driver compiles the virtual assembly into machine code for the current co-processor."
8350780,"A system, method and computer program product are provided for controlling stereoscopic glasses. In use, at least one aspect of a display is identified. Further, a delay is selected based on the at least one aspect. Thus, the stereoscopic glasses may be controlled as a function of the delay."
8350900,"A method includes reducing a red rivalry through adjusting a color temperature on a first image, converting the first image from the RGB domain to a YCbCr domain, shifting a hue of a red color in the first image towards a magenta color to reduce a red color vibrancy, and adjusting a blue color in the first image such that a dark blue visible through a second lens corresponding to a second image is at least partially visible through a first lens corresponding to the first image. The method also includes reducing the red rivalry through adjusting a tone of the red color in the first image towards a brown color, converting the first image from the YCbCr domain back to the RGB domain, adjusting a color saturation in the first image, and combining the first image with the second image in a processor to generate an anaglyph image."
8351776,"Multiple sets of pixel values representing a captured image of a scene are received, with each set representing an image captured with a corresponding degree of focus. An image processor may identify a region of interest in the captured image, automatically determine the configuration parameters for a lens assembly to provide a desired degree of focus for the region of interest, and generate signals to configure a lens assembly. In an embodiment, the region of interest is a face, the desired degree of focus of the face is determined by computing a rate of variation of luminance of pixels representing the face, and the desired degree is the degree of the image having the maximum degree of focus."
8352709,"A memory access technique, in accordance with one embodiment of the present invention, includes caching segmentation data. The technique utilizes a separate memory for storing a plurality of context specifiers and an MMU. The MMU includes an on-chip cache and a segmentation unit. The MMU receives a location of a particular context specifier and a corresponding context index for each of one or more of the plurality of context specifiers stored in the separate memory. The segmentation unit retrieves the particular context specifier and caches it locally. The segmentation unit also binds the cache location of the particular context specifier to the corresponding context index. After caching one or more context specifiers and generating a corresponding binding, the segmentation unit may receive a memory access request that includes a given context index. A given context specifier that is cached locally is accessed by the segmentation unit using the context index to get a base address. The base address from the given context specifier is utilized by the segmentation unit to generate a virtual address for the memory access request."
8355449,"The present invention includes a method and system for encoding video data by accessing a picture to be encoded, wherein the picture comprises a plurality of macro-blocks. A plurality of programmable counters are associated with each macro-block to be encoded. A counter associated with a macro-block of the plurality of macro-blocks is accessed and a value of the counter is determined. The method further includes determining whether to encode the macro-block as an Intra or non-Intra based on the value of the counter. If the macro-block is encoded as Intra, its counter is reset. If the macro-block is encoded as non-Intra, its counter value is updated. The counter value may be reset with a random number. Counters can be programmed such that a region of interest is defined for updating associated macro-blocks with greater frequency."
8356128,"A digital processing system employing multiple arbiters, all designed to allocate a resource to a same entity in response to a same condition. In an embodiment, the entities needing the resource may send a request to all the arbiters, and the specific entity to which the resource is allocated, receives indication of the allocation from a closest one of the arbiters. As a result, the latency in receipt of indication of allocation may be reduced. The features are described in the context of a bus as a resource."
8356142,"A memory controller for non-sequentially prefetching data for a processor of a computer system. The memory controller performs a method including the step of storing a plurality of address pairs in a table data structure, wherein the address pairs include a first address and a second address. The first address and the second address are non-sequential as fetched by a processor of a computer system. The address pairs are prioritized in accordance with a frequency of use for each of the address pairs. A system memory of the computer system is accessed and a plurality of cache lines corresponding to the address pairs are stored in a prefetch cache. Upon a cache hit during a subsequent access by the processor, data is transferred from the cache lines stored in the prefetch cache to the processor."
8356143,"A system and method for optimizing memory bus bandwidth, is achieved by utilization of the memory bus, either by utilizing the idle time of the memory bus, or by prioritizing prefetch requests to exploit the bank structure of the external memory. When a bus master of the memory bus makes a request to access a particular line in a memory device, the memory controller generates a request for accessing a line next to the current line that is requested by the bus master. Data corresponding to the next line is retrieved from the memory device and stored in the memory-controller when the memory bus is idle. The stored data may be served to a bus master upon request for the data. However, the memory bus is not engaged when the data stored in the memory controller is served. Therefore idle time of the memory bus is utilized."
8357931,"A device and method for providing access to a signal of a flip chip semiconductor die. A hole is bored into a semiconductor die to a test probe point. The hole is backfilled with a conductive material, electrically coupling the test probe point to a signal redistribution layer. A conductive bump of the signal redistribution layer is electrically coupled to a conductive contact of a package substrate. An external access point of the package substrate is electrically coupled to the conductive contact, such that signals of the flip chip semiconductor die are accessible for measurement at the external access point."
8358381,"One embodiment of the present invention sets forth a technique that enables a user to reverse through video content based on scene transitions. By employing a graphics processing unit to compute one or more frame-to-frame correlation coefficients that measure the consistency of sequential images and a central processing unit to analyze the one or more correlation coefficients, a list of scene transitions may be generated in real-time. The list of scene transitions forms the basis for a content-based reverse user control within the playback application. The content-based reverse user control enables a more natural mechanism for reversing through video content, providing the user with a superior overall viewing experience."
8359332,The present invention facilitates convenient and secure distribution of proprietary content. A present secure content enabled drive system and method permits flexible use of storage medium for both protected distribution of information and user definable storage use. In one embodiment a digital right management method includes creating a secure content enabled drive with protected storage locations and unprotected storage locations. Initial digital rights authorization is established to access secure content stored in said protected storage locations. The initial digital rights authorization to access secure content stored in said protected storage locations can be revised.
8359454,"A memory access technique, in accordance with one embodiment of the present invention, includes selectively overriding attributes contained in a translation lookaside buffer or page table data structure with attributes contained in a context specifier."
8365015,"The present disclosure provides memory level error correction methods and apparatus. A memory controller is intermediate the memory devices, such as DRAM chips or memory modules, and a processor, such a graphics processor or a main processor. The memory controller can provide error correction. In an example, the memory controller includes a buffer to store instructions and data for execution by the controller and a replay buffer to store the instructions such that operations can be replayed to prior state before the error. An error detector receives data read from the memory devices and if no error is detected outputs the data. If an error is detected, the error detector signals the memory controller to replay the instructions stored in the replay buffer."
8365403,"A method for providing an alternative power source for a graphics card are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of laying a set of gold fingers on a printed circuit board according to an industrial standard bus interface, positioning a wire in a middle layer of the printed circuit board, attaching a first end of the wire to a specific gold finger, and attaching the alternative power source to a second end of the wire, wherein the second end of the wire is an electroplated contact protruded external to the printed circuit board."
8368416,"Methods and systems for testing an integrated circuit during an assembly process are described. The integrated circuit is received from inventory. The integrated circuit is placed in a socket on a first circuit board for system-level testing. The system-level testing is performed prior to placement and permanent attachment of the integrated circuit onto a second circuit board. Provided the integrated circuit passes the system-level testing, the placement and permanent attachment of the integrated circuit to the second circuit board is the next step following the system-level testing in the assembly process."
8370552,"A scheduler provided according to an aspect of the present invention provides higher priority for data units in a low priority queue upon occurrence of a starvation condition, and to packets in a high priority queue otherwise. The scheduler permits retransmission of a data unit in the lower priority queue when in the starvation condition, but clears the starvation condition when the data unit is retransmitted a pre-specified number of times. As a result, the data units in the higher priority queue would continue to be processed, thereby avoiding a deadlock at least in certain situations."
8370663,"A central processing unit (CPU) can specify an initial (e.g., baseline) frequency for a clock signal used by a device to perform a task. The CPU is then placed in a reduced power mode. The device performs the task after the CPU is placed in the reduced power mode until a triggering event causes the device to send an interrupt to the CPU. In response to the interrupt, the CPU awakens to dynamically adjust the clock frequency. If the clock frequency is reset to the baseline value, then the CPU is again placed in the reduced power mode."
8370705,"One or more embodiments of the invention set forth techniques to perform integer division using addition operations in order to provide address translation capabilities to a processor. The processor supports a memory that maintains checksum information such that address requests received by the processor need to be translated to a checksum address and an actual data address that accounts for use of portions of the memory to store checksum information. Once the checksum address and the actual data address are computed, the processor can confirm the integrity of the data stored in the actual data address and correct any errors if need be, based on the checksum information stored in the checksum address."
8370845,"One embodiment of the present invention sets forth a technique for synchronizing the execution of multiple cooperative thread arrays (CTAs) implementing a parallel algorithm that is mapped onto a graphics processing unit. An array of semaphores provides synchronization status to each CTA, while one designated thread within each CTA provides updated status for the CTA. The designated thread within each participating CTA reports completion of a given computational phase by updating a current semaphore within the array of semaphores. The designated thread then polls the status of the current semaphore until all participating CTAs have reported completion of the current computational phase. After each CTA has completed the current computational phase, all participating CTAs may proceed to the next computational phase."
8373483,One embodiment of the present invention sets forth a technique for capturing and holding a level of an input signal using a low-clock-energy latch circuit that is fully static. The clock is only coupled to a first clock-activated pull-up or pull-down transistor and a second clock-activated pull-down or pull-up transistor. The level of the input signal is captured by a storage sub-circuit on one of the rising or the falling clock edge and stored to generate an output signal until the clock transitions. The level of the input signal is propagated to the output signal when the storage sub-circuit is not enabled. The storage sub-circuit is enabled and disabled by the first clock-activated transistor and a propagation sub-circuit is activated and deactivated by the second clock-activated transistor.
8373707,"One embodiment of the present invention sets forth a technique for selecting a boot VGA adapter in a multiple VGA adapter system by controlling the system boot process using the VBIOS display detection service and boot flags that are stored in non-volatile platform memory. The SBIOS initiates a first boot that selects the motherboard integrated graphics processing unit (MGPU) as the boot VGA adapter. During this first boot, if the SBIOS determines that there are display devices attached to the MGPU, then the first boot completes normally. Otherwise, the SBIOS aborts the first boot and initiates a second boot that selects a secondary, discrete graphics processing unit GPU (DGPU) as the boot VGA adapter. During this second boot, if the SBIOS determines that there are display devices attached to the DGPU, then the second boot completes normally. Otherwise, the SBIOS aborts the second boot, and initiates and completes a third system boot that selects the MGPU as the boot VGA adapter while setting flags to ensure that the overall process does not repeat."
8373708,"A video processing system, method, and computer program product are provided for encrypting communications between a plurality of graphics processors. A first graphics processor is provided. Additionally, a second graphics processor in communication with the first graphics processor is provided for collaboratively processing video data. Furthermore, such communication is encrypted."
8373717,"The symmetrical properties of a group of vertices are leveraged to reconstruct the group using vertex data for a subset of the vertices and a set of control data. The subset of vertices is symmetrical to one or more other subsets of vertices in the group, and the control data includes information to reconstruct the one or more other subsets using the vertex data for the first set of vertices and symmetrical characteristics of the group. In some embodiments, reconstruction is performed using a geometry shader in a graphics processor to compute the additional vertices."
8373718,"Embodiments of the claimed subject matter provide a system and process for enhancing the display of color in a graphical display. In one embodiment, a process is provided for color enhancement using a detection volume and a shift volume. In one embodiment, input from pixels, as color data, is compared to a detection volume. If the color data of an input is detected in the detection volume, the color data is modified to a corresponding position in the shift volume, the modification consisting of an enhancement to the original color."
8374619,Embodiments of the invention provide for allocating spectrum in a wireless communication system that supports simultaneously at least a first mode of operation and a second mode of operation. Logic is arranged for determining a proportion of spectrum required for the wireless communication unit to operate simultaneously in both the first mode of operation and the second mode of operation. Logic for allocating spectrum allocates a temporary guard band between a first portion of spectrum for the first mode of operation and a second portion of spectrum for the second mode of operation for use while the wireless communication unit operates simultaneously in the first mode of operation and second mode of operation.
8375163,"One embodiment of the invention sets forth a mechanism to transmit commands received from an L2 cache to a bank page within the DRAM. An arbiter unit determines which commands from a command sorter to transmit to a command queue. An activate command associated with the bank page related to the commands is also transmitted to an activate queue. The last command in the command queue is marked as “last.” An interlock counter stores a count of “last” commands in the read/write command queue. A DRAM controller transmits activate and commands from the activate queue and the command queue to the DRAM. Each time a command marked as “last” is encountered, the DRAM controller decrements the interlock counter. If the count in the interlock counter is zero, then the command marked as “last” is marked as “auto-precharge.” The “auto-precharge” command, when processed, causes the bank page to be closed."
8375176,"A system and method for locking and unlocking access to a shared memory for atomic operations provides immediate feedback indicating whether or not the lock was successful. Read data is returned to the requestor with the lock status. The lock status may be changed concurrently when locking during a read or unlocking during a write. Therefore, it is not necessary to check the lock status as a separate transaction prior to or during a read-modify-write operation. Additionally, a lock or unlock may be explicitly specified for each atomic memory operation. Therefore, lock operations are not performed for operations that do not modify the contents of a memory location."
8375306,"A method comprises displaying a mail server information screen, and receiving connection information via the mail server information screen. Further, the method comprises displaying an address page, and receiving recipient information via the address page. In addition, the method comprises displaying a content page, and receiving content in the content page. Additionally, an electronic mail message having the content is compiled, and the electronic mail message is sent to a recipient utilizing the connection information and recipient information."
8379022,"A fragment shader and method of operation are provided for a hybrid ray tracing system. The method includes determining whether a fragment is to be rasterized or raytraced. If a determination is made that the fragment is to be rasterized, a predetermined value for the fragment is stored into a rasterization target, the predetermined value indicating that the fragment is to be excluded from raytracing operations. If a determination is made that the fragment is to be raytraced, a primitive identifier of the fragment is stored into a rasterization target."
8379033,"A method and system for improving data coherency in a parallel rendering system is disclosed. Specifically, one embodiment of the present invention sets forth a method for managing a plurality of independently processed texture streams in a parallel rendering system that includes the steps of maintaining a time stamp for a group of tiles of work that are associated with each of the plurality of the texture streams and are associated with a specified area in screen space, and utilizing the time stamps to counter divergences in the independent processing of the plurality of texture streams."
8380778,"A system, method, and computer program product are provided for assigning elements of a matrix to processing threads. In use, a matrix is received to be processed by a parallel processing architecture. Such parallel processing architecture includes a plurality of processors each capable of processing a plurality of threads. Elements of the matrix are assigned to each of the threads for processing, utilizing an algorithm that increases a contiguousness of the elements being processed by each thread."
8380895,"A data packer of an input/output hub of a computer system packs and formats write data that is supplied to it before the write data is written into a memory unit of the computer system. More particularly, the data packer accumulates write data received from lower bandwidth clients for delivery to a high bandwidth memory interface. Also, the data packer aligns the write data, so that when the write data is read out from the write data packer, no further alignment is needed."
8380896,"A data packer of an input/output hub of a computer system packs and formats write data that is supplied to it before the write data is written into a memory unit of the computer system. More particularly, the data packer accumulates write data received from lower bandwidth clients for delivery to a high bandwidth memory interface. Also, the data packer aligns the write data, so that when the write data is read out from the write data packer, no further alignment is needed."
8381203,"A compiler is configured to determine a set of points in a flow graph for a software program where multithreaded execution synchronization points are inserted to synchronize divergent threads for SIMD processing. MIMD execution of divergent threads is allowed and execution of the divergent threads proceeds until a synchronization point is reached. When all of the threads reach the synchronization point, synchronous execution resumes. The synchronization points are needed to ensure proper execution of the certain instructions that require synchronous execution as defined in some graphics APIs and when synchronous execution improves performance based on a SIMD architecture."
8384736,"One embodiment of the present invention sets forth a technique for generating a batch clip state stored in clip state machine (CSM) associated with a batch of vertices. Per-vertex clip state is generated for each vertex in the batch of vertices based on the position of each vertex relative to each clip plane. For a given vertex, per-vertex clip state indicates whether the vertex is inside or outside each of the one or more clip planes. The per-vertex clip states of all the vertices in the batch of vertices are coalesced into a batch clip state by determining whether each vertex in the batch of vertices is inside every clip plane, each vertex is outside at least one clip plane or neither. The batch clip state is stored in the CSM associated with the thread group that processes the batch of vertices that can be accessed by further stages of the graphics pipeline."
8386648,"A hardware support system for implementing accelerated disk I/O for a computer system. The system includes a bus interface for interfacing with a processor and a system memory of the computer system, a disk I/O engine coupled to the bus interface, and a device interface coupled to the disk I/O engine for interfacing the disk I/O engine with a disk drive. The disk I/O engine is configured to cause a start up of the disk drive upon receiving a disk start up command from the processor. The disk I/O engine is further configured to execute a disk transaction by processing the disk transaction information from a bypass register coupled to the disk I/O engine."
8386797,"A data storage system providing transparent encryption. The data storage system has a hardware encryption/decryption engine and a register coupled to the hardware encryption/decryption engine. The register is for securely storing a key for encrypting and decrypting data. The key may not be read from outside the data storage system. More specifically, the key may not be read by the operating system. The user does not have access to the encryption key, but may have a password that is passed to a controller coupled to the encryption/decryption engine. The controller verifies the password and causes data received from main memory to be encrypted by the hardware encryption/decryption engine using the key. The controller also transfers the encrypted data to the data storage device."
8390619,"An occlusion prediction graphics processing system and method are presented in accordance with embodiments of the present invention. An occlusion prediction graphics processing method is utilized to predict which pixel values are eventually occluded before intermediate processing stages are performed on the pixel values. For example, occlusion results are predicted before the occlusion stage of a graphics pipeline. The occlusion prediction results are based upon an occlusion value received from later in a graphics processing pipeline (e.g., a raster operation stage). A convex polygonal prediction area can be established and a nearest vertex of the convex polygonal prediction area is selected for prediction analysis. Pixel values are removed or discarded from the pipeline based upon the occlusion prediction results and do not unnecessarily occupy processing resources. Removal of the pixel values from the pipeline includes pixels values associated with pixels in the convex polygonal prediction area. Pixel shading is performed on the remaining pixels."
8390645,"A method for rendering a plurality of line primitives. The method includes the step of accessing a first line primitive and a second line primitive of a line strip. For a junction between the first line primitive and the second line primitive, the first line primitive and the second line primitive are geometrically modified to generate an abutting edge between the first line primitive and the second line primitive. A majority status is assigned to a pixel on the abutting edge. A first color of the first line primitive or a second color of the second line primitive is allocated to the pixel in accordance with the majority status."
8392667,"Deadlocks are avoided by marking read requests issued by a parallel processor to system memory as “special.” Read completions associated with read requests marked as special are routed on virtual channel 1 of the PCIe bus. Data returning on virtual channel 1 cannot become stalled by write requests in virtual channel 0, thus avoiding a potential deadlock."
8392669,"One embodiment of the present invention sets forth a technique for efficiently and flexibly performing coalesced memory accesses for a thread group. For each read application request that services a thread group, the core interface generates one pending request table (PRT) entry and one or more memory access requests. The core interface determines the number of memory access requests and the size of each memory access request based on the spread of the memory access addresses in the application request. Each memory access request specifies the particular threads that the memory access request services. The PRT entry tracks the number of pending memory access requests. As the memory interface completes each memory access request, the core interface uses information in the memory access request and the corresponding PRT entry to route the returned data. When all the memory access requests associated with a particular PRT entry are complete, the core interface satisfies the corresponding application request and frees the PRT entry."
8392727,"A data storage system providing transparent encryption. The data storage system has a hardware encryption/decryption engine and a register coupled to the hardware encryption/decryption engine. The register is for securely storing a key for encrypting and decrypting data. The key may not be read from outside the data storage system. More specifically, the key may not be read by the operating system. The user does not have access to the encryption key, but may have a password that is passed to a controller coupled to the encryption/decryption engine. The controller verifies the password and causes data received from main memory to be encrypted by the hardware encryption/decryption engine using the key. The controller also transfers the encrypted data to the data storage device."
8392989,"A method of anti-malware scanning includes providing, in a computing system including a central processor, a multimedia processor including a number of processors to operate in parallel with one another. The anti-malware scanning further includes executing an anti-malware algorithm using the multimedia processor to free the central processor for a non-anti-malware related task."
8395619,"One embodiment of the present invention sets forth a method for pre-computing Z-values using an IGPU and, subsequently, conveying these Z-values to a DGPU. The graphics driver partitions the display into rectangular M-by-N tiles of pixels. For each tile, the graphics driver generates a quad geometry that encompasses the corresponding pixels. For each image frame, the graphics driver configures the IGPU to generate and down-sample a Z-buffer, creating a coarse Z-texture that contains a Z-value for each tile. The graphics driver transfers the coarse Z-texture to the system memory and configures the DGPU to apply the coarse Z-texture to the quad geometries, thereby generating a coarse Z-buffer in which the M-by-N pixels included in each tile are assigned the Z-value for the particular tile. Among other things, this technique enables the IGPU to pre-compute Z-values for the DGPU without straining the system memory bandwidth or defeating the Z-buffer compression techniques used by the DGPU."
8395631,One or more embodiments of the invention set forth techniques to allocate a memory buffer in the system memory of a computer system that is shared among a plurality of graphics processing units (GPUs) in the computer system. The GPUs are able to engage in Direct Memory Access (DMA) with the memory buffer thereby eliminating additional copying steps that have been needed to combine data output of the various GPUs without such a shared memory buffer.
8396993,"A data packer of an input/output hub of a computer system packs and formats write data that is supplied to it before the write data is written into a memory unit of the computer system. More particularly, the data packer accumulates write data received from lower bandwidth clients for delivery to a high bandwidth memory interface. Also, the data packer aligns the write data, so that when the write data is read out from the write data packer, no further alignment is needed."
8402012,"Embodiments of the present invention include a computer-controlled method of determining the risk of results of a search engine query before presentation to a client. In one embodiment of the invention, the method comprises accessing the results of the search engine query at a server side and scanning the results for software developed to harm a computer system, e.g., virus software, malware, etc. The method further includes determining a risk ranking associated with accessing one or more of the results and returning the results and the associated risk to a client, e.g., in a web page result display. Results exceeding a client specified threshold may be eliminated from the results display."
8402171,One embodiment of the present invention provides a universal storage bus adaptor that can interface a host computer's bus to any of multiple types of storage devices. The universal serial bus adaptor provides transport layer functionality in such a way that a separate transport layer does not have to be provided for each type of storage device. Another embodiment of the present invention includes a file management system (or storage stack) that has a read/write chimney configured to enable a READ/WRITE operation to bypass the exception processing and management functionalities of the file management system. Bypassing these functionalities increases the processing efficiency of READ/WRITE operations.
8402229,"One embodiment of the present invention sets forth a method for sharing graphics objects between a compute unified device architecture (CUDA) application programming interface (API) and a graphics API. The CUDA API includes calls used to alias graphics objects allocated by the graphics API and, subsequently, synchronize accesses to the graphics objects. When an application program emits a “register” call that targets a particular graphics object, the CUDA API ensures that the graphics object is in the device memory, and maps the graphics object into the CUDA address space. Subsequently, when the application program emits “map” and “unmap” calls, the CUDA API respectively enables and disables accesses to the graphics object through the CUDA API. Further, the CUDA API uses semaphores to synchronize accesses to the shared graphics object. Finally, when the application program emits an “unregister” call, the CUDA API configures the computing system to disregard interoperability constraints."
8402280,"A system, method, and computer program product are provided for buffering an audio video (AV) stream, audio/video header information, and an audio/video elementary stream for hardware audio/video digital rights management (DRM) processing. In operation, an AV stream encrypted under a shared symmetric key in an M2TS format is buffered, where the AV stream includes content including at least one of audio or video and all content data associated with the AV stream is removed at picture level and below, with the exception of content headers associated with the content data. Additionally, content header information encrypted under the shared symmetric key is buffered, the content header information indicating locations of the content headers associated with the content data. Further, a content elementary stream encrypted under a hardware secret key is buffered for consumption of a hardware bit stream decoding engine."
8402283,"The present invention facilitates convenient and secure distribution of proprietary content. A present secure content enabled drive system and method permits flexible use of storage medium for both protected distribution of information and user definable storage use. In one embodiment, a computer readable storage medium includes an unprotected information portion, a protected information portion and a protection interface. The unprotected portion stores unprotected information. The protected content portion stores protected information. The protection interface protects information in the protected content portion from unauthorized access."
8402322,"Methods and systems of initiating a data backup process on a computer system are described. One method calls for the data to be backed up to be identified. The computer system is monitored for the occurrence of a backup trigger event. If the trigger occurs, a data backup process is initiated."
8402418,"Embodiments of the claimed subject matter are directed to methods and a system that use a standardized grid of clock buffers to automatically route clocks according to a uniform clock grid throughout an ASIC of a non-uniform arrangement of non-uniformly sized logic partitions. According to one embodiment, clock sources and sinks are mapped to grid point locations and a novel grid routing process is performed to link them together. A clock routing macro is assigned to a corresponding partition and associated with the corresponding partition or logic unit according to a partition hierarchy. The underlying routing structure and resources of a clock routing macro are automatically renamed to correspond to the local partition in a script or schedule of programmed instructions, or a routing map. The position of blockages within a partition may also be detected and alternate routes for traversing the blockage may be preemptively determined as well."
8405665,"A processing unit includes multiple execution pipelines, each of which is coupled to a first input section for receiving input data for pixel processing and a second input section for receiving input data for vertex processing and to a first output section for storing processed pixel data and a second output section for storing processed vertex data. The processed vertex data is rasterized and scan converted into pixel data that is used as the input data for pixel processing. The processed pixel data is output to a raster analyzer."
8407443,Systems and methods for dynamically allocating memory for thread processing may reduce memory requirements while maintaining thread processing parallelism. A memory pool is allocated to store data for processing multiple threads that does not need to be large enough to dedicate a fixed size portion of the memory pool to each thread that may be processed in parallel. Fixed size portions of the memory pool are dynamically allocated and deallocated to each processing thread. Different fixed size portions may be used for different types of threads to allow greater thread parallelism compared with a system that requires allocating a single fixed portion of the memory pool to each thread. The memory pool may be shared between all of the thread types or divided to provide separate memory pools dedicated to each particular thread type.
8411088,"Methods, systems and computer program code (software) products executable in a computer processor element include computing, in the processor element, a minimal axis-aligned bounding box of the intersection of a given axis-aligned bounding box and a triangle under linear motion, and/or traversing, in the processor element, a ray tracing acceleration hierarchy for a given set of rays, wherein the traversing includes computing decisions for a representative form of the rays, without requiring a traversing of all rays in turn."
8411093,A discrete graphics system (DGS) for executing 3D graphics instructions for a computer system is disclosed. The discrete graphics system includes a GPU for executing 3D graphics instructions and a DGS system chassis configured to house the GPU. A serial bus connector coupled is to the GPU and the DGS chassis. The serial bus connector is configured to removably connect the DGS and the GPU to the computer system. The GPU of the DGS accesses the computer system via the serial bus connector to execute the 3D graphics instructions for the computer system.
8411096,"Embodiments for programming a graphics pipeline, and modules within the graphics pipeline, are detailed herein. Several of these embodiments utilize offset registers associated with the instruction tables for the modules within the pipeline. The offset register serves as a pointer to locations in the instruction table, which allows instructions to be written to be instruction table, without requiring that the shader programs have explicit addresses. One embodiment describes a method of programming a graphics pipeline. This method involves accessing the shader program stored in memory. A shader instruction is generated from this shader program, and loaded into an instruction table associated with a target module graphics pipeline. The shader instruction is loaded into the instruction table at the location indicated by an offset register."
8411103,"One embodiment of the invention sets forth a CROP configured to perform both color raster operations and atomic transactions. Upon receiving an atomic transaction, the distribution unit within the CROP transmits a read request to the L2 cache for retrieving the destination operand. The distribution unit also transmits the source operands and the operation code to the latency buffer for storage until the destination operand is retrieved from the L2 cache. The processing pipeline transmits the operation code, the source and destination operands and an atomic flag to the blend unit for processing. The blend unit performs the atomic transaction on the source and destination operands based on the operation code and returns the result of the atomic transaction to the processing pipeline for storage in the internal cache. The processing pipeline writes the result of the atomic transaction to the L2 cache for storage at the memory location associated with the atomic transaction."
8411105,"A method and system for computing pixel parameters is disclosed. In one embodiment, the rasterizing of a geometric primitive comprising a plurality of vertices wherein each vertex comprises a respective color value, is performed by a rasterization module of a graphics pipeline. The rasterizing includes interpolating a respective color value for each pixel of the geometric primitive, wherein the respective color value is of a first bit width. The rasterizing also includes transforming the respective color value to a second bit width to produce a respective transformed color value for each pixel. Additionally, the rasterizing includes altering the respective transformed color value using a screen-location based dither table to produce a dithered transformed color value for each pixel. After the rasterizing, propagating the respective dithered transformed color value of each pixel to downstream modules of the graphics pipeline is performed."
8411751,"A method includes projecting motion vectors describing a transformation from a previous video frame to a future video frame onto a plane between the previous video frame and the future video frame, detecting potential artifacts at the plane based on an intersection of a cover region and an uncover region on the plane, and analyzing a dissimilarity between a trial video frame and both the previous video frame and the future video frame. The trial video frame is generated between the previous video frame and the future video frame based on a frame rate conversion ratio derived from a source frame rate and a desired frame rate. The method also includes estimating reliability of the projected motion vectors based on the potential artifact detection and the dissimilarity analysis."
8412212,"A method, user equipment, network equipment and a system for initiating a wireless connection and subsequent communication over a shared physical resource in a wireless communication system between user equipment and network equipment comprising: processing a UE-derived temporary identifier; determining a set of channels that the user equipment will monitor; implicitly or explicitly communicating this channel set; communicating the temporary identifier as an identifier to the network equipment; communicating a downlink message on a channel belonging to the determined channel set conveying the temporary identifier and a description of a scheduled resource on a shared channel, the scheduled resource comprising a resource allocated to the user equipment by the network equipment; and communicating data on the scheduled resource in response to the downlink message."
8412213,"A method, user equipment, network equipment and a system for initiating a wireless connection and subsequent communication over a shared physical resource in a wireless communication system between user equipment and network equipment comprising: processing a UE-derived temporary identifier; determining a set of channels that the user equipment will monitor; implicitly or explicitly communicating this channel set; communicating the temporary identifier as an identifier to the network equipment; communicating a downlink message on a channel belonging to the determined channel set conveying the temporary identifier and a description of a scheduled resource on a shared channel, the scheduled resource comprising a resource allocated to the user equipment by the network equipment; and communicating data on the scheduled resource in response to the downlink message."
8412214,"A method, user equipment, network equipment and a system for initiating a wireless connection and subsequent communication over a shared physical resource in a wireless communication system between user equipment and network equipment comprising: processing a UE-derived temporary identifier; determining a set of channels that the user equipment will monitor; implicitly or explicitly communicating this channel set; communicating the temporary identifier as an identifier to the network equipment; communicating a downlink message on a channel belonging to the determined channel set conveying the temporary identifier and a description of a scheduled resource on a shared channel, the scheduled resource comprising a resource allocated to the user equipment by the network equipment; and communicating data on the scheduled resource in response to the downlink message."
8412215,"A method, user equipment, network equipment and a system for initiating a wireless connection and subsequent communication over a shared physical resource in a wireless communication system between user equipment and network equipment comprising: processing a UE-derived temporary identifier; determining a set of channels that the user equipment will monitor; implicitly or explicitly communicating this channel set; communicating the temporary identifier as an identifier to the network equipment; communicating a downlink message on a channel belonging to the determined channel set conveying the temporary identifier and a description of a scheduled resource on a shared channel, the scheduled resource comprising a resource allocated to the user equipment by the network equipment; and communicating data on the scheduled resource in response to the downlink message."
8412216,"A method, user equipment, network equipment and a system for initiating a wireless connection and subsequent communication over a shared physical resource in a wireless communication system between user equipment and network equipment comprising: processing a UE-derived temporary identifier; determining a set of channels that the user equipment will monitor; implicitly or explicitly communicating this channel set; communicating the temporary identifier as an identifier to the network equipment; communicating a downlink message on a channel belonging to the determined channel set conveying the temporary identifier and a description of a scheduled resource on a shared channel, the scheduled resource comprising a resource allocated to the user equipment by the network equipment; and communicating data on the scheduled resource in response to the downlink message."
8412217,"A method, user equipment, network equipment and a system for initiating a wireless connection and subsequent communication over a shared physical resource in a wireless communication system between user equipment and network equipment comprising: processing a UE-derived temporary identifier; determining a set of channels that the user equipment will monitor; implicitly or explicitly communicating this channel set; communicating the temporary identifier as an identifier to the network equipment; communicating a downlink message on a channel belonging to the determined channel set conveying the temporary identifier and a description of a scheduled resource on a shared channel, the scheduled resource comprising a resource allocated to the user equipment by the network equipment; and communicating data on the scheduled resource in response to the downlink message."
8412218,"A method, user equipment, network equipment and a system for initiating a wireless connection and subsequent communication over a shared physical resource in a wireless communication system between user equipment and network equipment comprising: processing a UE-derived temporary identifier; determining a set of channels that the user equipment will monitor; implicitly or explicitly communicating this channel set; communicating the temporary identifier as an identifier to the network equipment; communicating a downlink message on a channel belonging to the determined channel set conveying the temporary identifier and a description of a scheduled resource on a shared channel, the scheduled resource comprising a resource allocated to the user equipment by the network equipment; and communicating data on the scheduled resource in response to the downlink message."
8412872,"The present invention pertains to a graphics processing unit. The graphics processing unit includes a graphics processing core configured for graphics processing. A single-ended I/O interface configured to implement single-ended communication with a frame buffer memory is included in the graphics processing unit. The graphics processing unit further includes a differential I/O interface having a first portion and a second portion. In a first configuration, the first portion and the second portion implement a PCI-Express interface with a computer system. In a second configuration, the first portion implements a PCI-Express interface with the computer system and the second portion implements differential communication with a coupled device."
8413151,"One embodiment of the present invention sets forth a technique for selectively spawning threads within a multiprocessing system. A computation work distributor (CWD), within the system, is responsible for performing the detailed work needed to spawn a thread grid. A request to the CWD to spawn a thread grid includes a predicate table, which includes an array of flags used to indicate which thread indices should have an associated thread block spawned and which should not. Greater efficiency is achieved by only spawning thread blocks that should perform useful computation."
8416242,"A method determining LOD values for a geometric primitive, in accordance with one embodiment of the present invention, includes accessing a plurality of geometric parameters of a vertex. An LOD value for a vertex is calculated as a function of the plurality of parameters of the vertex in a setup module. In a raster module an LOD value for a pixel is interpolated as a function of the LOD value of the pixel corresponding to the vertex and a view distance of the non-vertex pixel."
8416251,A stream based memory access system for a video processor for executing video processing operations. The video processor includes a scalar execution unit configured to execute scalar video processing operations and a vector execution unit configured to execute vector video processing operations. A frame buffer memory is included for storing data for the scalar execution unit and the vector execution unit. A memory interface is included for establishing communication between the scalar execution unit and the vector execution unit and the frame buffer memory. The frame buffer memory comprises a plurality of tiles. The memory interface implements a first sequential access of tiles and implements a second stream comprising a second sequential access of tiles for the vector execution unit or the scalar execution unit.
8417735,"One embodiment of the present invention sets forth a technique for performing a parallel scan operation with high computational efficiency in a single-instruction multiple-data (SIMD) environment. Each participating thread initially writes an extended region of a data array to initialize the region with an identity value. For example, a value of zero is used as the identity value for addition. The initialized region of the data array includes an initialized entry for every possible out of bounds index that may be computed in the normal course of the parallel scan operation. During the parallel scan operation each thread computes data array indices according to any technically appropriate technique. When a participating thread computes an index that would conventionally be out of bounds, the thread is able to retrieve an identity value from the initialized region of the data array rather than perform a bounds check that returns the identity value."
8417838,"The present invention pertains to a configurable PCI-Express switch. The configurable PCI-Express switch includes a differential I/O interface capable of being configured in a first configuration or a second configuration. In the first configuration, the differential I/O interface implements a PCI-Express interface with a coupled device. In the second configuration, the differential I/O interface implements a differential interface other than PCI-Express with the coupled device. The configurable PCI-Express switch also includes a switching unit capable of configuring the differential I/O interface in the first configuration or the second configuration."
8417852,"A system and methods of uploading payload data to user buffers in system memory and of uploading partially processed frame data to legacy buffers allocated in Operating System memory space are described. User buffers are stored in a portion of system memory allocated to an application program, therefore data stored in user buffers does not need to be copied from another portion of system memory to the portion of system memory allocated to the application program. When partially processed frame data is uploaded by hardware to a legacy buffer in system memory, a tag, uniquely identifying the legacy buffer location is transferred by the hardware to a TCP stack, enabling the TCP stack to locate the legacy buffer."
8417980,"A power supply connected to an electrical load that supplies an output voltage to the electrical load. The power supply includes a first portion having a fast transient response topology that supplies a first part of an output current, and a second portion having a slow transient response topology that supplies a second part of the output current, such that the second part of the output current does not increase or decrease as fast as the first part of the output current. Advantageously, embodiments of the invention provide a more efficient power supply design that converts part of the total power supply output current using a fast transient response portion and part using a slow transient response portion of the power supply. Additionally, embodiments of the invention provide an alternate current path for transporting large amounts of current to a GPU, while maintaining the efficiency of the overall current path."
8423597,"A method and system for adaptive matrix trimming in an inverse discrete cosine transform (IDCT) operation. At least one row of an input matrix is accessed. At least one matrix element of the row having a value of zero is detected. During execution of an IDCT multiplication operation on the row for generating an output row, IDCT multiplication operation for a matrix element having a value of zero is skipped."
8424012,"A method for context switching on a video processor having a scalar execution unit and a vector execution unit. The method includes executing a first task and a second task on a vector execution unit. The first task in the second task can be from different respective contexts. The first task and the second task are each allocated to the vector execution unit from a scalar execution unit. The first task and the second task each comprise a plurality of work packages. In response to a switch notification, a work package boundary of the first task is designated. A context switch from the first task to the second task is then executed on the work package boundary."
8427474,"One embodiment of the present invention sets forth a method for dynamically load balancing rendering operations across an IGPU and a DGPU. For each frame, the graphics driver configures the IGPU to pre-compute Z-values for a portion of the display surface and to write feedback data to the system memory indicating the time that the IGPU used to process the frame. The graphics driver then configures the DGPU to use the pre-computed Z-values while rendering to the complete display surface and to write feedback data to the system memory indicating the time that the DGPU used to process the frame. The graphics driver uses the feedback data from the IGPU and DGPU in conjunction with the percentage of the display surface that the IGPU Z-rendered for the frame to scale the portion of the display surface that the IGPU Z-renders for one or more subsequent frames. In this fashion, overall processing within the graphics pipeline is optimized across the IGPU and DGPU."
8427487,"A method and system for interface compression in a raster stage of a graphics processor. The method includes receiving a graphics primitive for rasterization in a raster stage of a graphics processor and rasterizing the graphics primitive at a first level in a coarse raster component to generate a plurality of tiles related to the graphics primitive. The method determines whether a window ID operation is required for the plurality of tiles. If the operation is required, a respective plurality of uncompressed coverage masks for the tiles are output from the coarse raster component to a fine raster component on a one coverage mask per clock cycle basis. If the operation is not required, a compressed coverage mask for the tiles is output in a single clock cycle. The tiles are subsequently rasterized at a second-level in the fine raster component to generate pixels related to the graphics primitive."
8427490,Determining a schedule of instructions for an integrated circuit graphics pipeline. The method includes accessing a state of a host system. The state comprises operations to be performed on fragments to be processed by the graphics pipeline. The method further includes determining a vector based on the state and indexing a table based on the vector to obtain a predetermined listing and ordering of macro-operations to be executed. The method still further includes determining instructions for programming the graphics pipeline based the executing of the macro-operations in the scheduled order.
8427493,"One embodiment of the present invention sets forth a technique for reducing the overhead for transmitting explicit begin and explicit end commands that are needed in primitive draw command sequences. A draw method includes a header to specify an implicit begin command, an implicit end command, and instancing information for a primitive draw command sequence. The header is followed by a packet including one or more data words (dwords) that each specify a primitive topology, starting offset into a vertex or index buffer, and vertex or index count. Only a single clock cycle is consumed to transmit and process the header. The performance of graphics application programs that have many small batches of geometry (as is typical of many workstation applications) may be improved since the overhead of transmitting and processing the explicit begin and explicit end draw commands is reduced."
8427494,A VLC data transfer interface is presented that allows digital data to be packed and assembled according to a format selectable from a number of formats while the data is being transferred to a desired destination.
8427495,"Write operations to a unit of compressible memory, known as a compression tile, are examined to see if data blocks to be written completely cover a single compression tile. If the data blocks completely cover a single compression tile, the write operations are coalesced into a single write operation and the single compression tile is overwritten with the data blocks. Coalescing multiple write operations into a single write operation improves performance, because it avoids the read-modify-write operations that would otherwise be needed."
8427496,"A system for compressed data transfer across a graphics bus in a computer system. The system includes a bridge, a system memory coupled to the bridge, and a graphics bus coupled to the bridge. A graphics processor is coupled to the graphics bus. The graphics processor is configured to compress graphics data and transfer compressed graphics data across the graphics bus to the bridge for subsequent storage in the system memory."
8428082,A cellular communication system comprises a first communication network arranged to use a single cell identifier reuse pattern; a second communication network comprising a cluster of communication cells and arranged to use a common cell identifier reuse pattern for broadcast transmissions. The cellular communication system further comprises management logic (146) having broadcast mode logic (150) operably coupled to at least the second communication network; and a plurality of wireless serving communication units operably coupled to the management logic. The broadcast mode logic (150) applies the same common cell identifier to be used by the plurality of wireless serving communication units in transmitting broadcast communications across the cluster of communication cells in the second network.
8428083,A time division duplex (TDD) cellular communication system (100) is arranged to support both uplink and downlink communication allocated for unicast time division duplex (TDD) communication that uses a single cell identifier reuse pattern. The TDD cellular communication system (100) comprises a plurality of wireless serving communication units operably coupled to management logic. The TDD cellular communication system (100) further comprises management logic (146) arranged to partition time domain physical resources such that unicast communication using the single cell identifier reuse pattern is supported in a first portion of the time domain physical resource and a broadcast communication using a common cell identifier (215) reuse pattern for broadcast communications is supported in a second portion of the time domain physical resource.
8428084,A cellular communication system (100) is arranged to support a single cell identifier reuse pattern using a first communication. Management logic (146) comprises broadcast mode logic (150) arranged to support a common cell identifier reuse pattern for broadcast transmissions amongst a cluster of communication cells using a second communication. A plurality of wireless serving communication units are operably coupled to the management logic. At least one wireless communication unit comprises logic arranged to support a unicast communication using a first communication cell identifier and logic arranged to support broadcast communication using a common cell identifier (215) to be used by the wireless communication unit in receiving broadcast communication across the cluster of communication cells.
8428085,"A cellular communication system (100) comprises management logic (146) having broadcast mode logic (150) arranged to support a common cell identifier reuse pattern for broadcast transmissions amongst a cluster of communication cells. A plurality of wireless serving communication units is operably coupled to the management logic. At least one wireless communication unit comprises a receiver for receiving a broadcast signal from both a first serving wireless communication unit and a second serving wireless communication unit wherein both the first serving wireless communication unit and second serving wireless communication unit use a common cell identifier (215) reuse pattern for broadcast transmissions to be used by the at least one wireless communication unit in receiving broadcast communication across the cluster of communication cells. The at least one wireless communication unit further comprises logic arranged to detect the broadcast communication from both the first serving wireless communication unit and second serving wireless communication unit, where the broadcast communication is allocated to the first timeslot (350) or first sub-frame based on it being more robust to multipath delay due to temporal dispersion of the same broadcast signal from a plurality of wireless serving communication units."
8428194,"An apparatus for calibrating gain of an radio frequency receiver (“Rx”) is disclosed to provide, among other things, a structure for performing in-situ gain calibration of an RF integrated circuit over time and/or over temperature without removing the RF integrated circuit from its operational configuration, especially when the gain of the RF integrated circuit is susceptible to variations in process, such as inherent with the CMOS process. In one embodiment, an exemplary apparatus includes a thermal noise generator configured to generate thermal noise as a calibrating signal into an input of an Rx path of an RF integrated circuit. The apparatus also includes a calibrator configured to first measure an output signal from an output of the Rx path, and then adjust a gain of the Rx path based on the thermal noise. In one embodiment, the thermal noise generator further includes a termination resistance and/or impedance."
8428207,"A system and method are provided for determining a time for safely sampling a signal of a clock domain. In one embodiment, a frequency estimate of a first clock domain is calculated utilizing a frequency estimator. Additionally, a time during which a signal from the first clock domain is unchanging is determined such that the signal is capable of being safely sampled by a second clock domain, using the frequency estimate. In another embodiment, a frequency estimate of a first clock domain is calculated utilizing a frequency estimator. Further, a phase estimate of the first clock domain is calculated based on the frequency estimate, utilizing a phase estimator. Moreover, a time during which a signal from the first clock domain is unchanging is determined such that the signal is capable of being safely sampled by a second clock domain, using the phase estimate."
8429656,"Methods and apparatuses are presented for graphics operations with thread count throttling, involving operating a processor to carry out multiple threads of execution of, wherein the processor comprises at least one execution unit capable of supporting up to a maximum number of threads, obtaining a defined memory allocation size for allocating, in at least one memory device, a thread-specific memory space for the multiple threads, obtaining a per thread memory requirement corresponding to the thread-specific memory space, determining a thread count limit based on the defined memory allocation size and the per thread memory requirement, and sending a command to the processor to cause the processor to limit the number of threads carried out by the at least one execution unit to a reduced number of threads, the reduced number of threads being less than the maximum number of threads."
8429661,"Systems and methods storing data for multi-threaded processing permit multiple execution threads to store data in a single first-in first-out (FIFO) memory. Threads are assigned to classes, with each class including one or more threads. Each class may be allocated dedicated entries in the FIFO memory. A class may also be allocated shared entries in the FIFO memory. The shared entries may be used by any thread. Data for a first thread may be stored in the FIFO memory while data for a second thread is read from the FIFO memory, even when the first thread and the second thread are not in the same class. The FIFO memory is shared between the threads to conserve die area, however each thread may be executed independently, as if each thread has a dedicated FIFO memory."
8432019,"System and apparatus for capacitively coupling signals with an integrated circuit (IC) are described. Capacitive elements disposed with a transmitting IC effectively function as AC coupling capacitors for a PCIe, DisplayPort™ or other interconnect linking the transmitting IC with a receiver disposed remote there from. Integrating the coupling capacitors allows for a smaller and more economical design for the circuits that utilize the interconnect."
8432394,"A method of computing z parameters for pixels of a geometric primitive. The method includes the step of accessing the geometric primitive comprising a plurality of vertices, wherein each vertex comprises a plurality of associated parameters including a depth parameter, z. During rasterization of the geometric primitive, respective z values are interpolated for each pixel of the geometric primitive. Each z value is represented within a predefined numerical range which substantially corresponds to a depth range between a near plane and a far plane related to pixel rendering. During the interpolating, the z values are allowed to exceed the predefined numerical range and roll over within the predefined numerical range. A multi-bit indicator is used to indicate when a z value for a pixel is outside of the depth range."
8432406,"An apparatus, system, and method for clipping graphics primitives are described. In one embodiment, a graphics processing apparatus includes a clipping unit that is configured to produce and issue ni initial outputs based on execution of a set of clipping operations, wherein ni represents the number of the initial outputs that are issued by the clipping unit prior to context switching, and the initial outputs partially define a clipped graphics primitive. The graphics processing apparatus also includes a control unit connected to the clipping unit. The control unit is configured to preserve an initial execution state of the clipping unit in response to an initial command for context switching, wherein the initial execution state is preserved based on ni."
8432410,A three dimensional (3D) graphics application programming interface (API) extension provides support for specifying images in a shared exponent format. The shared exponent format is used to represent high dynamic range textures in a compact encoding to reduce the memory footprint needed to store the image data compared with other high dynamic range formats. Image data is encoded to and decoded from the shared exponent format using a pixel processing pipeline. Image data encoded into the shared exponent format can be decoded and used as texture data during rendering.
8432788,"One embodiment of the present invention sets forth a method for failing back network connections to a network interface card (NIC) within a computing device. The method includes the steps of monitoring a failed or unreliable NIC within the computing device, determining that the failed or unreliable NIC has recovered, determining that a functional NIC within the computing device is overloaded, selecting a first connection set communicating through the overloaded NIC, and transferring the first connection set to the recovered NIC. With this approach, intelligent decisions can be advantageously made regarding whether to fail back a network connection set to a recovered NIC based on the traffic loads on the overloaded NIC and the recovered NIC. Such an approach to balancing network traffic across the functional NICs within a computing device may substantially improve overall performance relative to prior art techniques."
8433331,"A method, user equipment, network equipment and a system for initiating a wireless connection and subsequent communication over a shared physical resource in a wireless communication system between user equipment and network equipment comprising: processing a UE-derived temporary identifier; determining a set of channels that the user equipment will monitor; implicitly or explicitly communicating this channel set; communicating the temporary identifier as an identifier to the network equipment; communicating a downlink message on a channel belonging to the determined channel set conveying the temporary identifier and a description of a scheduled resource on a shared channel, the scheduled resource comprising a resource allocated to the user equipment by the network equipment; and communicating data on the scheduled resource in response to the downlink message."
8436669,"One embodiment of the present invention sets forth a technique for capturing and storing a level of an input signal using a single-trigger low-energy flip-flop circuit that is fully-static and insensitive to fabrication process variations. The single-trigger low-energy flip-flop circuit presents only three transistor gate loads to the clock signal and none of the internal nodes toggle when the input signal remains constant. The output signal Q is set or reset at the rising clock edge using a single-trigger sub-circuit. A set or reset may be armed while the clock signal is low, and the set or reset is triggered at the rising edge of the clock."
8436862,"One embodiment of the present invention sets forth a method for enabling an intermediate code-based application program to access a target graphics processing unit (GPU) in a parallel processing environment. The method includes the steps of compiling a source code of the intermediate code-based application program to an intermediate code, translating the intermediate code to a PTX instruction code, and translating the PTX instruction code to a machine code executable by the target graphics processing unit before delivering the machine code to the target GPU."
8436864,"A computer-implemented method and user interface for organizing graphical operations and displaying performance data of a graphics processing pipeline. More specifically, embodiments provide a convenient and effective mechanism for enhancing graphics processing by automatically determining and grouping graphical operations with similar state attributes relating to one or more units of the graphics pipeline. As such, pipeline adjustments for reducing execution time of one graphical operation may benefit other graphical operations with similar state attributes, thereby reducing the number of pipeline adjustments and allowing more careful selection of graphical operations to increase performance and reduce image degradation. Also, the display of the grouped graphical operations also provides information for determining the troublesome operations. In one embodiment, the groups are ranked by their respective execution time. Additionally, other forms of performance data may be displayed for graphical operations with similar state attributes, thereby providing additional information to guide enhancement operations."
8436866,"Methods, apparatuses, and systems are presented for caching. A cache memory area may be used for storing data from memory locations in an original memory area. The cache memory area may be used in conjunction with a repeatedly updated record of storage associated with the cache memory area. The repeatedly updated record of storage can thus provide a history of data storage associated with the cache memory area. The cache memory area may be loaded with entries previously stored in the cache memory area, by utilizing the repeatedly updated record of storage. In this manner, the record may be used to “warm up” the cache memory area, loading it with data entries that were previously cached and may be likely to be accessed again if repetition of memory accesses exists in the span of history captured by the repeatedly updated record of storage."
8436868,"A method of organizing memory for storage of texture data, in accordance with one embodiment of the invention, includes accessing a size of a mipmap level of a texture map. A block dimension may be determined based on the size the mipmap level. A memory space (e.g., computer-readable medium) may be logically divided into a plurality of whole number of blocks of variable dimension. The dimension of the blocks is measured in units of gobs and each gob is of a fixed dimension of bytes. A mipmap level of a texture map may be stored in the memory space. A texel coordinate of said mipmap level may be converted into a byte address of the memory space by determining a gob address of a gob in which the texel coordinate resides and determining a byte address within the particular gob."
8436870,"A computer-implemented user interface and method for graphical processing analysis. More specifically, embodiments provide a convenient and effective mechanism for presenting GPU performance information such that one or more bottlenecking and/or underutilized graphics pipeline units may be identified. The presentation of the information enables quick comparison of all graphical operations within a frame for analysis with increased granularity. Additionally, the performance of graphical operations with common state attributes may be compared to more effectively and efficiently enhance GPU performance."
8437405,"The present invention includes a method and system for encoding video data by accessing a picture to be encoded, wherein the picture comprises a plurality of macro-blocks. A plurality of programmable counters are associated with each macro-block to be encoded. A counter associated with a macro-block of the plurality of macro-blocks is accessed and a value of the counter is determined. The method further includes determining whether to encode the macro-block as an Intra or non-Intra based on the value of the counter. If the macro-block is encoded as Intra, its counter is reset. If the macro-block is encoded as non-Intra, its counter value is updated. The counter value may be reset with a random number. Counters can be programmed such that a region of interest is defined for updating associated macro-blocks with greater frequency."
8438370,"Loops with internal data dependencies (e.g., in a Mersenne Twister pseudorandom number generator) are implemented by exploiting arrays of cooperating threads that can be executed concurrently using a suitably configured processor. In one implementation, each thread is assigned to update a different element of a data array where updating of later elements depends on updates to earlier elements. Thread synchronization techniques are advantageously used to control the order in which different threads update their assigned elements such that the data dependencies are correctly handled. To the extent that threads assigned to different data elements do not have data dependencies on each other, those threads can be executed in parallel."
8438554,"A system, method, and computer program product are provided for removing a synchronization statement. In use, synchronization statements are identified. Additionally, the synchronization statements are analyzed. Furthermore, the synchronization statements are removed based on the analysis."
8441487,"Embodiments of the present invention set forth systems and methods for compressing thread group data written to frame buffer memory to increase overall memory performance. A compression/decompression engine within the frame buffer memory interface includes logic configured to identify situations where the threads of a thread group are writing similar scalar values to memory. Upon recognizing such a situation, the engine is configured to compress the scalar data into a form that allows all of the scalar data to be written to or read from the frame buffer memory in fewer clock cycles than would be required to transmit the data in uncompressed form to or from memory. Consequently, the disclosed systems and methods are able to effectively increase memory performance when executing thread group STORE and LOAD operations."
8441495,Systems and methods for determining a compression tag state prior to memory client arbitration may reduce the latency for memory accesses. A compression tag is associated with each portion of a surface stored in memory and indicates whether or not the data stored in each portion is compressed or not. A client uses the compression tags to construct memory access requests and the size of each request is based on whether or not the portion of the surface to be accessed is compressed or not. When multiple clients access the same surface the compression tag reads are interlocked with the pending memory access requests to ensure that the compression tags provided to each client are accurate. This mechanism allows for memory bandwidth optimizations including reordering memory access requests for efficient access.
8441497,Vertex data can be accessed for a graphics primitive. The vertex data includes homogeneous coordinates for each vertex of the primitive. The homogeneous coordinates can be used to determine perspective-correct barycentric coordinates that are normalized by the area of the primitive. The normalized perspective-correct barycentric coordinates can be used to determine an interpolated value of an attribute for the pixel. These operations can be performed using adders and multipliers implemented in hardware.
8442111,"An encoder provided according to an aspect of the present invention uses different encoding techniques depending on an amount of power available in the corresponding durations. Due to the ability to use such different encoding techniques, power may be optimally utilized. The optimization is further enhanced by dynamically switching between encoding techniques according to power amount availability in corresponding durations. In an embodiment, each encoding technique estimates motion vectors at corresponding level of precision (thereby consuming a corresponding level of power) and the precision level is chosen to correspond to available power budget. The circuitry not required for a desired precision level may be switched off."
8442327,"A method for more efficiently detecting faces in images is disclosed. The integral image of an image may be calculated. The integral image may be sub-sampled to generate one or more sub-sampled integral images. A plurality of classifiers may be applied in one or more stages to regions of each sub-sampled integral image, where the application of the classifiers may produce classification data. The classification data may be used to determine if a face is associated with any of the regions of each sub-sampled integral image. The face determination results may be used to modify the original image such that, when rendered, the image is displayed with a graphical object identifying the face in the image. Accordingly, face detection processing efficiency may be increased by reducing the number of integral image calculations and processing localized data through application of classifiers to sub-sampled integral images."
8446417,"A DGS (discrete graphics system) unit is disclosed. The DGS unit includes a system chassis configured to house a GPU, the GPU for executing 3-D graphics instructions, and a GPU mounting unit coupled to the system chassis and configured to receive the GPU. A serial bus connector is coupled to the chassis and is coupled to the GPU mounting unit, wherein the serial bus connector is configured removably connect the GPU to a computer system to enable the GPU to access the computer system via the serial bus connector and execute the 3-D graphics instructions for the computer system. A power supply coupled to the system chassis for supplying power to the GPU independent of the computer system."
8447035,"A method of displaying an image includes generating a contract in the display engine, transferring the contract to the memory controller before the end of a sweep, generating a contract amendment in response to changes in the display engine, transferring the contract amendment to the memory controller, making a decision whether the contract amendment can be processed, fetching data from the memory controller according to the contract incorporating the contract amendment if the decision is that the contract amendment can be processed, sending the fetched data to the display engine in an isochronous stream; and processing the fetched data using the display engine."
8448002,"A clock module is coupled in parallel to a number of data processing modules that are coupled in series. The data processing modules can be individually clock-gated. Each of the data processing modules can determine whether or not it can be placed into an idle state. To reduce power consumption, any subset of the data processing modules that are eligible to be placed in an idle state can be clock-gated. The remaining data processing modules can continue to receive clock signals from the clock module and thus can continue to process data."
8451279,"A display refresh system, method and computer program product are provided. In use, at least one aspect of a display of content is identified by monitoring commands. Based on such identified aspect(s), a refresh rate of a display utilized for the display of the content may be adjusted."
8452721,"A method of simulation comprises controlling an avatar in an environment. Movement of graphical elements is simulated in a fluid coordinate frame surrounding said avatar, wherein said graphical elements in said fluid coordinate frame obey a first rule set. Said graphical elements and a first region surrounding said fluid coordinate frame are animated, wherein said graphical elements in said first region obey a second rule set. Said fluid coordinate frame moves in response to said controlling of said avatar. In an embodiment, a blending region blends the movement of graphical elements inside the fluid coordinate frame and outside the fluid coordinate frame."
8452981,"Embodiments of the present invention are directed to a computer-implemented method for author verification and authorization of object code. In one embodiment, program object code is linked with a plurality of data blocks to create linked object code and a MAP file. Thereafter, author verification is performed by executing a plurality of comparisons between the linked object code and the MAP file. In another embodiment, a digital signing procedure is performed on linked object code by creating a signature data block. The signature data block is then encrypted and written to the linked object code to create digitally-signed object code. In another embodiment, an application program embodied in linked object code generates a data packet. The data packet is then compared to a previously-generated signature data packet from the linked object code to determine if the linked object code is authorized."
8453019,"A method of receiving data. A plurality of data signals and clocking signals are received over a source synchronous communication channel. The plurality of data signals is strobed with the clocking signal at a plurality of coarse time offset delays (e.g., time offset delays spanning over a data bit period). The plurality of error rates associated with the strobing at the plurality of coarse time offset delays is determined. Strobing design of a transmitting component (e.g., edge-strobed, center-strobed, etc.) may be determined based on the plurality of error rates. The error rates of the plurality of data signals strobed with a plurality of time offset delays close to the determined strobing design of the transmitting component is calculated. A time offset delay is selected based on the error rates. The plurality of data signals can be strobed with the selected time offset delay to recover the transmitted data signals."
8456481,"A method of organizing memory for storage of texture data, in accordance with one embodiment of the invention, includes accessing a size of a mipmap level of a texture map. A block dimension may be determined based on the size of the mipmap level. A memory space (e.g., computer-readable medium) may be logically divided into a plurality of whole number of blocks of variable dimension. The dimension of the blocks is measured in units of gobs and each gob is of a fixed dimension of bytes. A mipmap level of a texture map may be stored in the memory space. A texel coordinate of said mipmap level may be converted into a byte address of the memory space by determining a gob address of a gob in which the texel coordinate resides and determining a byte address within the particular gob."
8456547,"Described is a device (e.g., a cell phone incorporating a digital camera) that incorporates a graphics processing unit (GPU) to process image data in order to increase the quality of a rendered image. The processing power provided by a GPU means that, for example, an unacceptable pixel value (e.g., a pixel value associated with a malfunctioning or dead detector element) can be identified and replaced with a new value that is determined by averaging other pixel values. Also, for example, the device can be calibrated against benchmark data to generate correction factors for each detector element. The correction factors can be applied to the image data on a per-pixel basis. If the device is also adapted to record and/or play digital audio files, the audio performance of the device can be calibrated to determine correction factors for a range of audio frequencies."
8456548,"Described is a device (e.g., a cell phone incorporating a digital camera) that incorporates a graphics processing unit (GPU) to process image data in order to increase the quality of a rendered image. The processing power provided by a GPU means that, for example, an unacceptable pixel value (e.g., a pixel value associated with a malfunctioning or dead detector element) can be identified and replaced with a new value that is determined by averaging other pixel values. Also, for example, the device can be calibrated against benchmark data to generate correction factors for each detector element. The correction factors can be applied to the image data on a per-pixel basis. If the device is also adapted to record and/or play digital audio files, the audio performance of the device can be calibrated to determine correction factors for a range of audio frequencies."
8456549,"Described is a device (e.g., a cell phone incorporating a digital camera) that incorporates a graphics processing unit (GPU) to process image data in order to increase the quality of a rendered image. The processing power provided by a GPU means that, for example, an unacceptable pixel value (e.g., a pixel value associated with a malfunctioning or dead detector element) can be identified and replaced with a new value that is determined by averaging other pixel values. Also, for example, the device can be calibrated against benchmark data to generate correction factors for each detector element. The correction factors can be applied to the image data on a per-pixel basis. If the device is also adapted to record and/or play digital audio files, the audio performance of the device can be calibrated to determine correction factors for a range of audio frequencies."
8457838,"Embodiments of the present invention include a computer-controlled method for safely operating a vehicle based electronic system. The method includes receiving a first signal from a first sensor, wherein the first sensor is for identifying the presence of a passenger located in a passenger seat of the vehicle. This may be the configuration of a seat belt associated with the passenger seat. The method further includes receiving a second signal from a second sensor, wherein the second sensor is for determining a weight of the passenger in the passenger seat. Provided the passenger is located in the passenger seat and the weight of the passenger in the passenger seat is above or equal to a threshold value, the method further includes allowing programming functionality of the electronic system while the vehicle is in motion. In one embodiment, the electronic system is a vehicle based navigation system."
8458370,"A method and system for supporting multiple display interface standards are disclosed. Specifically, one embodiment of the present invention sets forth a computing device, which includes a processing unit and a display interface. The display interface further includes a formatting logic and a set of output pins, wherein the formatting logic is configured to derive a first set of output signals conforming to a first display interface standard from a data stream, drive the first set of output signals via a set of output pins to a first display device supporting the first display interface standard, support a second display interface standard instead of the first display interface standard in response to a state change and derive the first set of output signals conforming to the second display interface standard, and drive the first set of output signals via the same set of output pins to a second display device supporting the second display interface standard."
8458440,One embodiment of the present invention sets forth a technique for computing virtual addresses for accessing thread data. Components of the complete virtual address for a thread group are used to determine whether or not a cache line corresponding to the complete virtual address is not allocated in the cache. Actual computation of the complete virtual address is deferred until after determining that a cache line corresponding to the complete virtual address is not allocated in the cache.
8461868,"A chip comprising a signal transmitting circuit, a communication system between multiple chips and a method for configuring the communication system between multiple chips are provided. The signal transmitting circuit of the chip comprises a multi-route selector, a first bias resistor and a second bias resistor, a first signal line and a second signal line, and a signal transmitting end; wherein the multi-route selector comprises a first input end, a second input end, a selection input end and an output end, wherein the first input end is grounded, the second input end is connected to a DC bias voltage and the selection input end receives a selection signal; wherein the multi-route selector selects the first input end when the selection signal is a first selection signal, and the multi-route selector selects the second input end when the selection signal is a second selection signal."
8461884,"According to an aspect of the present invention, one of multiple clock signals of different relative phases is selected based on a desired delay magnitude, and the digital values received on an input signal are then synchronized to an edge (“first edge”) of the selected clock signal to provide the digital values with the desired delay magnitude. In an embodiment, the selected clock signal can be delayed by a fine value (less than the minimum phase difference of the multiple clock signals) to provide a wide span of desired delays. An aspect of the invention provides for a synchronization circuit with reduced latency and which is substantially invariant to process, voltage and temperature (PVT) changes."
8462156,"A method and system for generating shadows for a graphics processing unit. Specifically, the method determines whether a potential blocker occludes light from reaching a point of a scene in an image space. The light is generated from a light source. A width of a corresponding penumbra is determined for the point. The width is based on a width of the light source, a depth of the potential blocker from the light source, and a depth of a receiver from the light source. The receiver includes the point. A percentage closer filtering kernel size is scaled in proportion to the width of the corresponding penumbra. Thereafter, percentage closer filtering is performed for the point using the kernel size that is scaled in order to shade a pixel corresponding to the point."
8462165,"A system, method, and computer program product are provided for controlling at least one aspect of a graphics hardware processor, in response to a command that is prompted by a vocal utterance."
8463231,A wireless access network system comprises a RADIUS (Remote Access Dial-In User System) arrangement with an associated RADIUS accounting function. The RADIUS arrangement is arranged to track access activity by a user accessing the network via wireless user equipment and via the RADIUS arrangement. The access activity is recorded in an accounting database which is associated with the RADIUS accounting function. The wireless access system also comprises a radio network controller which comprises a RADIUS client. The RADIUS arrangement is arranged to receive information from a radio network controller of the system in order to track the access activity. The Invention is applicable to cellular communication systems such as UMTS (Universal Mobile Telecommunication System).
8463951,"Embodiments of the present invention provide for initializing a device for use in a computer system. In one embodiment a BIOS routine reads a configuration register of each device in a computer system. The configuration register contains a device identifier indicating an oldest version of a device driver for controlling the device. The device identifier for each device is saved in a configuration data space. An operating system retrieves each device identifier contained in the configuration data space, and maps each device identifier to a corresponding device driver utilizing a registry. The operating system loads and causes execution of an initialization routine of each corresponding device driver mapped to each of the device identifiers."
8464001,"Systems and methods are disclosed for managing the number of affirmatively associated cache lines related to the different sets of a data cache unit. A tag look-up unit implements two thresholds, which may be configurable thresholds, to manage the number of cache lines related to a given set that store dirty data or are reserved for in-flight read requests. If the number of affirmatively associated cache lines in a given set is equal to a maximum threshold, the tag look-up unit stalls future requests that require an available cache line within that set to be affirmatively associated. To reduce the number of stalled requests, the tag look-up unit transmits a high priority clean notification to a frame buffer logic when the number of affirmatively associated cache lines in a given set approaches the maximum threshold. The frame buffer logic then processes requests associated with that set preemptively."
8466859,A digital video display response time compensation system and method are presented. A digital video display response time compensation system and method are utilized to direct adjustments in a display presentation. A test pattern response time compensation value determination process for establishing appropriate adjustment levels for a display is performed. A test pattern is displayed; user input on compensation to the test pattern display is received; pixel value calibration settings are determined based upon the user input; and the test pattern display appearance is altered based upon the pixel value calibration settings. After the appropriate pixel illumination adjustment values are establish a pixel value is received. The pixel value is adjusted in accordance with the response time compensation value and a response time compensated pixel value is output.
8471845,"A system and method for constructing a bounding volume hierarchical structure are disclosed. The method includes defining a parent node for the bounding volume hierarchical structure, the parent node including a parent node bounding volume enclosing a plurality of objects. A first cost is computed for performing an object partition of the parent node bounding volume to produce a first plurality of child node bounding volumes, and a second cost is also computed for performing a spatial partitioning of the parent node bounding volume to produce a second plurality of child node bounding volumes. The bounding volume hierarchical structure is constructed employing the second plurality of child node bounding volumes produced from the spatial partitioning of the parent node bounding volume if the second cost is lower than the first cost."
8471852,A method and system for performing adaptive tessellation of a subdivision surface. The method includes the step of accessing a model of a surface for subdivision processing. The model is converted to an intermediate form to facilitate subdivision processing. The intermediate form of the model is then tessellated.
8472372,"A system, method, and computer program product are provided for transmitting wireless signals to one or more portable devices. In use, a plurality or wireless signals is received utilizing a plurality of protocols. In addition, the plurality of protocols associated with the plurality of wireless signals are converted to a single different protocol. Further, the plurality of wireless signals is transmitted to at least one portable device utilizing the single different protocol."
8472455,"A method for performing node traversal operations of a treelet-composed hierarchical structure includes allocating a queue for each of the plurality of treelets, each queue operable to store ray-states entering a respective one of the treelets. The method additionally includes determining that a ray-state exits a first treelet of the hierarchical structure and enters a second treelet of the hierarchical structure. The method further includes forwarding the ray-state entering the second treelet to a processing element for processing therein, wherein the queue allocated to store ray-states entering the second treelet is bypassed."
8473750,A bridge is disclosed having a security engine to protect digital content at insecure interfaces of the bridge. The bridge permits cryptographic services to he offloaded from a central processing unit to the bridge. The bridge receives a clear text input from a central processing unit. The bridge encrypts the clear text input as cipher text for storage in a memory. The bridge provided the cipher text to a graphics processing unit.
8473948,"One embodiment of the present invention sets forth a technique for synchronizing the execution of multiple cooperative thread arrays (CTAs) implementing a parallel algorithm that is mapped onto a graphics processing unit. An array of semaphores provides synchronization status to each CTA, while one designated thread within each CTA provides updated status for the CTA. The designated thread within each participating CTA reports completion of a given computational phase by updating a current semaphore within the array of semaphores. The designated thread then polls the status of the current semaphore until all participating CTAs have reported completion of the current computational phase. After each CTA has completed the current computational phase, all participating CTAs may proceed to the next computational phase."
8477134,"In a raster stage of a graphics processor, a method for using low precision evaluation and high precision evaluation for conservative triage of polygon status. The method includes receiving a graphics primitive for rasterization in a raster stage of a graphics processor and rasterizing the graphics primitive to generate a plurality of tiles of pixels related to the graphics primitive. The tiles are rasterized at a first level precision to generate a plurality of sub-tiles related to the graphics primitive, wherein the sub-tiles are evaluated against the graphics primitive at each of their respective corners. Each of the sub-tiles not related to the graphics primitive are discarded. The sub-tiles related to the graphics primitive are rasterized at a second level precision."
8477852,"Described herein are embodiments for decoding and displaying video data. Several of these embodiments utilize a unified frame buffer management system, to facilitate better memory management in decoding and displaying compressed video. One approach describes a method of decoding and displaying compressed video data. The method involves receiving a compressed video frame, and allocating a frame buffer for use in decoding the compressed video frame. A frame identifier is assigned to the allocated frame buffer. The compressed video frame is decoded into the frame buffer, and the frame identifier is passed to a display module."
8478071,"A method for constructing a motion-compensated composite image of a scene includes acquiring a plurality of images of a scene over time, the plurality of images including an earlier-acquired image of the scene and a later-acquired image scene. The relative motion between the earlier and later acquired images are estimated, and an exposure parameter is computed based upon the estimated relative motion occurring between the earlier and later acquired images. A new image of the scene is acquired using the computed exposure parameter, and the earlier, later, and newly acquired images are combined to produce a motion-compensated composite image of the scene."
8478959,"A method and system for protecting content in graphics memory are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of storing a first privilege level in a privilege map with restricted access, wherein the first privilege level is associated with a memory page used to store the content; and determining whether to permit a request to access the memory page based on the first privilege level."
8482120,"A Multi-configuration Processor-Memory device for coupling to a PCB (printed circuit board) interface. The device comprises a substrate that supports multiple configurations of memory components and a processor while having a single, common interface with a PCB interface of a printed circuit board. In a first configuration, the substrate supports a processor and a first number of memory components. In a second configuration, the substrate supports a processor and an additional number of memory components. The memory components can be pre-tested, packaged memory components mounted on the substrate. The processor can be a surface mounted processor die. Additionally, the processor can be mounted in a flip chip configuration, side-opposite the memory components. In the first configuration, a heat spreader can be mounted on the memory components and the processor to dissipate heat. In the second, flip chip, configuration, the processor face can be soldered onto a non-functional area of the PCB interface of the printed circuit board to dissipate heat."
8482567,"A line rasterization technique in accordance with one embodiment includes conditioning a line by pulling in the ending vertex of the line or pushing out the starting vertex of the line. Thereafter, if the line exits a diamond test area of each pixel that it touches, the pixel may be lit."
8482574,"A system, method, and computer program product are provided for calculating statistics associated with a surface to be rendered utilizing a graphics processor. In use, w-values are identified using a graphics processor. Additionally, the graphics processor is utilized for calculating statistics associated with at least one surface to be rendered using the w-values. Furthermore, the statistics are stored."
8483687,"An arrangement and method for radio network relocation of a mobile terminal (114) from a first base station controller (122) to a second base station controller (122′) by anchoring at least some SGSN functions with respect to the first base station controller; and relocating at least some RNC functions from the first base station controller to the second base station controller. RNC (124), SGSN (132) and GGSN (134) components may be integrated together, and the RNC (124) may be parented by an SGSN. Alternatively, RANAP SGSN functionality may be split between SGSN and RNC, RANAP and user plane signals may be relayed by the first base station controller to the second base station controller, and the first base station controller may act as an anchor."
8487681,"One embodiment of the present invention sets forth a technique for technique for capturing and storing a level of an input signal using a dual-trigger low-energy flip-flop circuit that is fully-static and insensitive to fabrication process variations. The dual-trigger low-energy flip-flop circuit presents only three transistor gate loads to the clock signal and none of the internal nodes toggle when the input signal remains constant. One of the clock signals may be a low-frequency “keeper clock” that toggles less frequently than the other two clock signal that is input to two transistor gates. The output signal Q is set or reset at the rising clock edge using separate trigger sub-circuits. Either the set or reset may be armed while the clock signal is low, and the set or reset is triggered at the rising edge of the clock."
8488890,"One embodiment of the present invention sets forth a technique for compressing image data with high contrast between pixels within a tile and between samples within pixels without any data loss. Partial coverage layers are generated and written to a tile that includes multiple pixels without reading the existing image data that is stored for the tile. A partial coverage layer encodes image data, such as colors, and sub-pixel coverage information for each covered pixel in a tile. The use of partial coverage layers reduces the bandwidth used to store image data when a tile is not fully covered."
8488951,"A method of multimedia processing includes providing a multimedia processor operating at a frequency lower than that of a central processor of a multimedia processing system. A multimedia framework is implemented in the multimedia processing system. The multimedia framework is utilized to execute, on the multimedia processor, one or more of reading an input, transforming a data based on the reading of the input, and placing an output based on the transforming of the data on a rendering device. Power dissipated in the multimedia processing system is reduced by solely executing a requisite parsing on the central processor of the multimedia processing system."
8489377,A method of verifying a performance model of an integrated circuit is provided. The method comprises the following steps: obtaining statistical request numbers and corresponding latency values of memory access requests; developing functions of latency value based on the statistical request numbers and the corresponding latency values; bringing a random value to one of the functions to retrieve a latency value; and verifying the logic of the performance model using the latency value retrieved in the step above.
8489839,"The memory splitter chip couples multiple DRAM units to the PPU, thereby expanding the memory capacity available to the PPU for storing data and increasing the overall performance of the graphics processing system. The memory splitter chip includes logic for managing the transmission of data between the PPU and the DRAM units when the transmission frequencies and the burst lengths of the PPU interface and the DRAM interfaces differ. Specifically, the memory splitter chip implements an overlapping transmission mode, a pairing transmission mode or a combination of the two modes when the transmission frequencies or the burst lengths differ."
8489851,"A memory controller provided according to an aspect of the present invention includes a predictor block which predicts future read requests after converting the memory address in a prior read request received from the processor to an address space consistent with the implementation of a memory unit. According to another aspect of the present invention, the predicted requests are granted access to a memory unit only when there are no requests pending from processors and the peripherals sending access requests to the memory unit."
8489911,"One embodiment of the present invention sets forth a technique for performing high-performance clock training. One clock training sweep operation is performed to determine phase relationships for two write clocks with respect to a command clock. The phase relationships are generated to satisfy timing requirements for two different client devices, such as GDDR5 DRAM components. A second clock training sweep operation is performed to better align local clocks operating on the client devices. A voting tally is maintained during the second clock training sweep to record phase agreement at each step in the clock training sweep. The voting tally then determines whether one of the local clocks should be inverted to better align the two local clocks."
8493394,"One embodiment of the present invention sets forth a method, which includes the steps of detecting the presence of an external graphics subsystem after the external graphics subsystem is attached to the mobile computing device, transmitting a power enable signal to the external graphics subsystem, and activating PCIe signaling channels after having received a ready signal from the external graphics subsystem to enable data communications between the mobile computing device and the external graphics subsystem."
8493395,A method and system for overriding state information programmed into a processor using an application programming interface (API) avoids introducing error conditions in the processor. An override monitor unit within the processor stores the programmed state for any setting that is overridden so that the programmed state can be restored when the error condition no longer exists. The override monitor unit overrides the programmed state by forcing the setting to a legal value that does not cause an error condition. The processor is able to continue operating without notifying a device driver that an error condition has occurred since the error condition is avoided.
8493396,A multidimensional datapath processing system for a video processor for executing video processing operations. The video processor includes a scalar execution unit configured to execute scalar video processing operations and a vector execution unit configured to execute vector video processing operations. A data store memory is included for storing data for the vector execution unit. The data store memory includes a plurality of tiles having symmetrical bank data structures arranged in an array. The bank data structures are configured to support accesses to different tiles of each bank.
8493397,"A method for using a state machine to control a pipelined L2 cache to implement memory transfers for a video processor. The method includes accessing a queue of read requests from a video processor, and tracking each of a plurality of cache lines stored within the cache using a least recently used variable. For each a cache line hit out of the plurality of cache lines and corresponding to one of the read requests, the least recently used variable is adjusted for a remainder of the plurality of cache lines. A replacement cache line is determined by examining the least recently used variables for each of the plurality of cache lines. For each cache line miss, a cache line slot corresponding to the replacement cache line is allocated to store a new cache line responsive to the cache line miss."
8495327,"A memory controller includes first and second output modules for driving first and second data, respectively, to be written to a memory device. The memory controller also includes a clock module for providing an internal clock signal and a timing control module for producing a first and second timing control signals. The first and second timing control signals are supplied to the first and second output modules, respectively."
8499323,"A mobile communication device comprises receiver circuitry operable to receive broadcast real-time media data over a communication interface, and signal processing logic operable to extract real-time media content from the broadcast real-time media data, and output the extracted real-time media content via a user interface of the mobile communication device. In response to determining a partial loss of data for the broadcast real-time media data, the signal processing logic is operable to retrieve stored media content from a memory element of the mobile communication device, and output the retrieved media content via the user interface of the communication device."
8502709,"An approach to decoding variable length code (VLC) symbols is described. In one embodiment, a method of decoding VLC symbols is detailed. This method involves obtaining a bitstream sample from a bitstream, and comparing the bitstream sample against a threshold value, to obtain a VLC group number. Information associated with a VLC group is retrieved, using this VLC group number. The current VLC symbol is extracted from the bitstream, using the VLC group information, and the corresponding symbol value is obtained, using the current VLC symbol and the VLC group information."
8502818,"A method for tracking a surface representation includes providing an initial mesh representing a surface, the initial mesh comprising a plurality of mesh faces. A grid is constructed, the grid having a plurality of grid edges, whereby each grid edge is connected between two grid nodes, and each grid node has a predefined value associated therewith. The grid overlaps the initial mesh, such that at least one mesh face intersects at least one grid edge. A new value for a grid node connected to the intersected grid edge is computed based upon its intersection by the mesh face, and the initial mesh is modified based upon the new value of the grid node to produce a modified mesh, the modified mesh providing an updated representation of the surface."
8502819,"A method for performing a ray tracing node traversal operation in an image rendering process includes traversing a plurality of nodes within spatial hierarchy that represents a scene which is to be rendered, the spatial hierarchy including two or more hierarchy levels, each hierarchy level including one or more nodes. A number representing the number of nodes traversed in each one of a plurality of different hierarchy levels is stored, wherein each number is represented by at least one bit in a multi-bit binary sequence."
8502827,"A system, method, and computer program product are provided for outputting content during a boot-up period. In use, content is independently processed, utilizing a graphics processor. During a boot-up period, such content is outputted."
8502828,"A method includes performing a task in response to a request of a secondary user interface of a secondary device. The method also includes calculating a utilization of a graphics processing unit of a machine based on the task performed by the graphics processing unit. The method further includes determining the utilization, through a processor, based on a comparison of a consumption of a computing resource of the graphics processing unit and a sum of the computing resource available. The method furthermore includes performing another task in response to the request of another secondary user interface of another secondary device. The method furthermore includes calculating another utilization of another graphics processing unit based on the another task performed by the another graphics processing unit. The method furthermore includes determining the another utilization based on the comparison of a consumption of the computing resource of the another graphics processing unit."
8502844,"A system, method, and computer program product are provided for adjusting a viewing experience associated with a display device. During use, a user interface capable of being used for adjusting the viewing experience associated with the display device is automatically displayed, in response to an event that potentially affects the viewing experience associated with the display device."
8504619,"A system, method and computer program product are provided. In one embodiment, at least one parameter associated with at least one contact is received. In addition, at least one operator is received. Further, a contact set is generated based on the at least one parameter and the at least one operator. In another embodiment, an expression is received. Moreover, a contact set is generated from a plurality of contacts utilizing the expression."
8504773,"A system and method for buffering intermediate data in a processing pipeline architecture stores the intermediate data in a shared cache that is coupled between one or more pipeline processing units and an external memory. The shared cache provides storage that is used by multiple pipeline processing units. The storage capacity of the shared cache is dynamically allocated to the different pipeline processing units as needed, to avoid stalling the upstream units, thereby improving overall system throughput."
8504794,"A memory management system and method are described. In one embodiment, a memory management system includes a memory management unit for virtualizing context memory storage and independently controlling access to the context memory without interference from other engine activities. The shared resource management unit overrides a stream of access denials (e.g., NACKs) associated with an access problem. The memory management system and method facilitate access to memory while controlling translation between virtual and physical memory “spaces”. In one embodiment the memory management system includes a translation lookaside buffer and a fill component. The translation lookaside buffer tracks information associating a virtual memory space with a physical memory space. The fill component tracks the status of an access request progress from a plurality of engines independently and faults that occur in attempting to access a memory space."
8508520,"A method, apparatus, and system of luminous power control of a light source of a multimedia processing system are disclosed. In one embodiment, a method is described. The method includes capturing a digital image of a face of a user. The method also includes applying, with a processor, an algorithm capable of detecting a digital facial feature of the face of the user based on one or more markers of the digital image. In addition, the method includes determining whether the digital image includes the digital facial feature according to the marker. The method further includes causing a light source to illuminate an electronic display at an active-mode luminous power level that includes a luminous power level different than a power-saving mode luminous power level of the light source when the digital image includes the digital facial feature."
8508540,"A method, system and an apparatus of resonant induction to power a graphics processing unit (GPU) are disclosed. In one embodiment, a resonant induction system is described. The resonant induction system includes a transmitter circuit tuned to a resonant frequency. The transmitter circuit generates a non-radiative magnetic field when a control current is passed through the transmitter circuit. The resonant induction system also includes a receiver circuit, resonantly coupled to the non-radiative magnetic field generated by the transmitter circuit, and tuned to the resonant frequency of the transmitter circuit. The receiver circuit is located in a GPU. The transmitter circuit and the receiver circuit are resonantly coupled to each other at the resonant frequency. A control current source supplies the control current to the transmitter circuit. A feedback module may be communicatively coupled to the GPU to determine a power requirement of a particular computer graphics application."
8508544,A method and system for selective enablement of tile compression. The method includes receiving a graphics primitive for processing in a set-up unit of a graphics processor and determining a primitive characteristic that indicates a probability of whether a final compression of a tile related to the primitive will be retained. Compression for the tile related to the primitive is allowed when the characteristic indicates the final compression will be retained. Compression for the tile related to the primitive is disallowed in the characteristic indicates the final compression will not be retained.
8509863,"A method, system and apparatus for expandable housing of a mobile communication device are disclosed. A housing of a mobile communication device includes a base layer, at least one of a component layer coupled communicatively on either side of the base layer to enable modification of a modular peripheral component integrated into the housing by sliding the modular peripheral component through a set of grooves located on opposite sides of each of the component layer and the base layer and a holding mechanism in the component layer that enables the modular peripheral component to remain in a fixed position. The modular peripheral component includes a daisy-chainable expansion port that enables an additional modular peripheral component integratable in the mobile communication device to be communicatively coupled with the housing across a variety of physical connections of the daisy-chainable expansion port."
8510616,"A scalable scan-based architecture with reduced test time, test power and test pin-count in scan based testing of ICs. In an embodiment, a test vector is scanned serially into a functional memory element at a first frequency, which then de-multiplexes the bits in the test vector to multiple sub-chains at a lower frequency. Due to the use of lower frequency to scan-in, the power dissipation is reduced. Due to the use of the higher frequency to scan-in the test vector as well as multiple sub-chains, the test time is reduced. Due to the use of the functional memory elements for scanning in the test vector at higher frequency, any number of chains can potentially be supported."
8510643,"A method of RAID migration comprising reading first and second blocks from a first RAID array. Said first blocks are written to a second RAID array within a first write cycle. Said second blocks are read simultaneously with a portion of said first write cycle in a pipelined fashion. In a first embodiment, pipelining increases the speed of RAID migration from a one-disk stripe array to a two-disk mirror array. In a second embodiment, pipelining and the use of duplicate blocks increases the speed of RAID migration from a two-disk mirror array to a three-disk RAID 5 array. In a third embodiment, pipelining and the use of duplicate blocks increases the speed of RAID migration from a three-disk RAID 5 array to a four-disk RAID 5 array."
8514958,An Orthogonal Frequency Division Multiplex (OFDM) communication system comprises OFDM transmitters and an OFDM receiver. The system comprises a subcarrier status data controller for transmitting subcarrier status data to the OFDM receiver. The subcarrier status data indicates the active subcarriers of the OFDM transmitters. The OFDM receiver comprises a receiver which receives a signal comprising a desired signal component from a first OFDM transmitter and interference from at least one interfering OFDM transmitter. The OFDM receiver further comprises a subcarrier status processor which receives the subcarrier status data and a channel estimator which determines channel estimates for at least an air interface communication channel from the first OFDM transmitter and an air interface communication channel from the interfering OFDM transmitter. An interference mitigation processor performs interference mitigation of the interference in response to the subcarrier status data and the channel estimates.
8516165,"A computer system that employs Peripheral Component Interconnect Express (PCIe) links includes devices that generate a PCIe packet having a header portion that is smaller than the header portion for a conventional PCI packet. The devices may be an endpoint device, such as a graphics processor, and a chipset, such as a root-complex. The reduced size header improves the bus throughput efficiency of the computer system and reduces power requirements for the computer system."
8516190,"Systems and methods for using RAID with ATA mass storage devices can benefit from operating system optimizations for avoiding unaligned write accesses. When the ATA mass storage devices in the RAID array have different physical sector sizes, the largest physical sector size is reported as the physical sector size for the single disk represented by the RAID array. The operating system can optimize accesses that are aligned with all of the physical sector sizes within the RAID array. Additionally, any storage devices that have a first logical sector that does not have an offset of zero, are configured to ignore all logical sectors in the first physical sector. Accesses to the first logical sector are mapped to the second physical sector. A logical sector alignment of zero is then reported to the operating system for the RAID array, enabling the operating system to avoid unaligned writes."
8520009,"Video filtering using a programmable graphics processor is described. The programmable graphics processor may be programmed to complete a plurality of video filtering operations in a single pass through a fragment-processing pipeline within the programmable graphics processor. Video filtering functions such as deinterlacing, chroma up-sampling, scaling, and deblocking may be performed by the fragment-processing pipeline. The fragment-processing pipeline may be programmed to perform motion adaptive deinterlacing, wherein a spatially variant filter determines, on a pixel basis, whether a “bob”, a “blend”, or a “weave” operation should be used to process an interlaced image."
8521800,"An arithmetic logic stage in a graphics pipeline includes a number of arithmetic logic units (ALUs). The ALUs each include, for example, a multiplier and an adder. The ALUs are interconnected by circuitry that, for example, routes the output from the multiplier in one ALU to both the adder in that ALU and an adder in another ALU."
8522000,A trap handler architecture is incorporated into a parallel processing subsystem such as a GPU. The trap handler architecture minimizes design complexity and verification efforts for concurrently executing threads by imposing a property that all thread groups associated with a streaming multi-processor are either all executing within their respective code segments or are all executing within the trap handler code segment.
8522190,"A clock gating mechanism controls power within an integrated circuit device. One or more clock gating circuits are configured to couple a system clock to a different portion of the integrated circuit device. A logic circuit applies an enabling signal to one of the clock gating circuits to control whether the system clock passes through the clock gating circuit to a portion of the integrated circuit device associated with the clock gating circuit. A plurality of scan flip-flops is configured to provide a binary code to the logic circuit, where the binary code indicates to the logic circuit that the enabling signal should be applied to the clock gating circuit. One advantage of the disclosed technique is that power droop during at-speed testing of a device is reduced without significantly increasing the quantity of test vectors or reducing test coverage, resulting in greater test yields and lower test times."
8525842,"A semaphore system, method, and computer program product are provided for use in a graphics environment. In operation, a semaphore is operated upon utilizing a plurality of graphics processing modules for a variety of graphics processing-related purposes (e.g. for example, controlling access to graphics data by the graphics processing modules, etc.)."
8527923,"A system, method, and computer program product are provided for hierarchical formal hardware verification of floating-point division and/or square root algorithmic designs using automatic sequential equivalence checking. In use, for at least one of a floating-point division algorithm and a square root algorithm, an architectural specification for hardware, a hardware implementation on the hardware, and at least one intermediate model having a level of specificity between the architectural specification and the hardware implementation are identified. Additionally, an equivalence is automatically determined, hierarchically, between the architectural specification, and the at least one intermediate model, and between the at least one intermediate model and the hardware implementation. Furthermore, for the hardware, the at least one of the floating-point division algorithm and the square root algorithm are formally verified, based on the automatic sequential equivalence determination."
8532098,"A system and method for communicating over a single virtual channel. The method includes reserving a first group of credits of a credit pool for a first traffic class and a second group of credits of the credit pool for a second traffic class. In addition, a first and second respective groups of tags are reserved from a tag pool for the first and second traffic class. A packet may then be selected from a first buffer for transmission over the virtual channel. The packet may include a traffic indicator of the first traffic class operable to allow the packet to pass a packet of the second traffic class from a second buffer. The method further includes sending the packet over the virtual channel and adjusting the first group of credits and the first group of tags based on having sent a packet of the first traffic class."
8533425,"A shared resource management system and method are described. In one embodiment, a shared resource management system facilitates age based miss replay. In one exemplary implementation, a shared resource management system includes a plurality of engines, and a shared resource a shared resource management unit. The plurality of engines perform processing. The shared resource supports the processing. The shared resource management unit handles multiple outstanding miss requests."
8533435,"One embodiment of the present invention sets forth a technique for collecting operands specified by an instruction. As a sequence of instructions is received the operands specified by the instructions are assigned to ports, so that each one of the operands specified by a single instruction is assigned to a different port. Reading of the operands from a multi-bank register file is scheduled by selecting an operand from each one of the different ports to produce an operand read request and ensuring that two or more of the selected operands are not stored in the same bank of the multi-bank register file. The operands specified by the operand read request are read from the multi-bank register file in a single clock cycle. Each instruction is then executed as the operands specified by the instruction are read from the multi-bank register file and collected over one or more clock cycles."
8537146,"One embodiment of the invention sets forth a method for toggling between video scanouts generated by a plurality of graphics processing units. The method includes the steps of transmitting a set of programming instructions to a first graphics processing unit and to a second graphics processing unit, configuring a first state machine within the first graphics processing unit to cause a trigger signal to be included with each video frame transmitted by the first graphics processing unit for display, and configuring a second state machine within the second graphics processing unit to cause a trigger signal to be included with each video frame transmitted by the second graphics processing unit for display. The method advantageously creates a direct relationship between the transmission frequencies of the individual graphics processing units and the switching frequency of a video bridge, not relying on a driver to control the video bridge switching."
8537166,"One embodiment of the present invention sets forth a technique for displaying high-resolution images using multiple graphics processing units (GPUs). The graphics driver is configured to present one virtual display device, simulating a high-resolution mosaic display surface, to the operating system and the application programs. The graphics driver is also configured to partition the display surface amongst the GPUs and transmit commands and data to the local memory associated with the first GPU. A video bridge automatically broadcasts this information to the local memories associated with the remaining GPUs. Each GPU renders and displays only the partition of the display surface assigned to that particular GPU, and the GPUs are synchronized to ensure the continuity of the displayed images. This technique allows the system to display higher resolution images than the system hardware would otherwise support, transparently to the operating system and the application programs."
8537167,"A method and system for using bundle decoders in a processing pipeline is disclosed. In one embodiment, to perform a context switch between a first process and a second process operating in a processing pipeline, the first state information that is associated with the first process is placed on a connection separate from the processing pipeline. A number of decoders are coupled to this connection. The decoders obtain the first state information from a number of pipeline units on the processing pipeline by monitoring the data stream going into these pipeline units. Also, to restore the first state information after having switched out the second state information that is associated with the second process, the first state information is placed on the connection for the decoders to retrieve."
8537168,A method and system for deferred coverage mask generation in a raster stage of a graphics processor. The method includes receiving a graphics primitive for rasterization in a raster stage of a graphics processor and performing a bounding box test on the graphics primitive to define a bounding rectangle for the graphics primitive. A combined coverage mask is then generated after the completion of the bounding box test. The combined coverage mask indicates a plurality of pixels that are covered by the graphics primitive. The combined coverage mask is divided into a plurality of sub-portions. The sub-portions are allocated to a plurality of raster components to determine sub-pixel coverage for the sub-portions.
8537169,"One embodiment of the present invention sets forth a method for accessing, from within a graphics processing unit (GPU), data objects stored in a memory accessible by the GPU. The method comprises the steps of creating a data object in the memory based on a command received from an application program, transmitting an address associated with the data object to the application program for providing data associated with different draw commands to the GPU, receiving a first draw command and the address associated with the data object from the application program, and transmitting the first draw command and the address associated with the data object to the GPU for processing."
8537291,"A system, method, and computer program product are provided for determining an angle of polarization for a display device. Further, a polarization associated with shutter glasses is rotated the determined angle for viewing the display device utilizing the shutter glasses."
8538062,"A system, method, and computer program product are provided for validating an aspect of media data processing utilizing a signature. In use, media data is received in a system. Additionally, at least one signature of at least a portion of the media data is generated. Furthermore, at least one aspect of processing of the media data by the system is validated utilizing the at least one signature."
8538183,"A system and method are provided for approximating a diffusion profile utilizing gathered lighting information associated with an occluded portion of an object. In use, the present technique gathers information associated with an occluded portion of an object that is illuminated with a two-dimensional pattern of light including an edge which defines an illuminated portion and the occluded portion of the object. To this end, a diffusion profile of the object is approximated, utilizing such information."
8538204,"A method for estimating pixel intensity includes generating a plurality of bidirectional paths extending between a light source and a measurement point, whereby the measurement point represents a pixel within the image. Each bidirectional path includes a light subpath portion extending from the light source and an eye subpath portion extending from the view point and coupled to the light subpath. Each light subpath is characterized by a number of vertices included therein, and similarly, each eye subpath is characterized by a number of vertices included therein. The plurality of bidirectional paths are sorted into separation populations, whereby each population includes bidirectional paths constructed from eye subpaths having a common number of vertices, and light subpaths having a common number of vertices. An intensity contribution is computed for each of the individual populations, and the intensity contributions are summed over all populations to estimate the intensity of the pixel."
8539130,"The invention sets forth a crossbar unit that includes multiple virtual channels, each virtual channel being a logical flow of data within the crossbar unit. Arbitration logic coupled to source client subsystems is configured to select a virtual channel for transmitting a data request or a data packet to a destination client subsystem based on the type of the source client subsystem and/or the type of data request. Higher priority traffic is transmitted over virtual channels that are configured to transmit data without causing deadlocks and/or stalls. Lower priority traffic is transmitted over virtual channels that can be stalled."
8539204,"One embodiment of the present invention sets forth a technique for performing aggregation operations across multiple threads that execute independently. Aggregation is specified as part of a barrier synchronization or barrier arrival instruction, where in addition to performing the barrier synchronization or arrival, the instruction aggregates (using reduction or scan operations) values supplied by each thread. When a thread executes the barrier aggregation instruction the thread contributes to a scan or reduction result, and waits to execute any more instructions until after all of the threads have executed the barrier aggregation instruction. A reduction result is communicated to each thread after all of the threads have executed the barrier aggregation instruction and a scan result is communicated to each thread as the barrier aggregation instruction is executed by the thread."
8539207,"Circuits, methods, and apparatus that reduce the amount of data read from an external memory by a processor when performing calculations on data sets such as matrices or lattices. In one example, a computation algorithm is executed by threads running on a parallel processor such as a single-instruction, multiple-data processor, which stores computational data in on chip memories. Data to be processed by a group of threads is read from the external memory and stored in a first on-chip memory, while a copy of data to be processed at a later time by the group of threads is stored in a second on-chip memory. Data in the first on-chip memory is processed multiple times before being written to the external memory. Processing data multiple times and keeping a copy of data for later use reduces the amount of data to be retrieved from memory, thereby improving computational efficiency."
8539516,"One embodiment of the present invention sets forth a method for sharing graphics objects between a compute unified device architecture (CUDA) application programming interface (API) and a graphics API. The CUDA API includes calls used to alias graphics objects allocated by the graphics API and, subsequently, synchronize accesses to the graphics objects. When an application program emits a “register” call that targets a particular graphics object, the CUDA API ensures that the graphics object is in the device memory, and maps the graphics object into the CUDA address space. Subsequently, when the application program emits “map” and “unmap” calls, the CUDA API respectively enables and disables accesses to the graphics object through the CUDA API. Further, the CUDA API uses semaphores to synchronize accesses to the shared graphics object. Finally, when the application program emits an “unregister” call, the CUDA API configures the computing system to disregard interoperability constraints."
8542221,"One embodiment of the present invention sets forth a technique for continuously adjusting a variable refresh rate to reduce the power consumption of a display device. The refresh rate of the display device tracks the effective frame rate of the content being displayed. As the effective frame rate of the content decreases, the refresh rate is lowered until a minimum value is reached. When the effective frame rate of the content equals the refresh rate, the refresh rate is increased until the refresh rate exceeds the effective frame rate of the content or until a maximum value is reached."
8542247,"One embodiment of the invention sets forth a mechanism for compiling a vertex shader program into two portions, a culling portion and a shading portion. The culling portion of the compiled vertex shader program specifies vertex attributes and instructions of the vertex shader program needed to determine whether early vertex culling operations should be performed on a batch of vertices associated with one or more primitives of a graphics scene. The shading portion of the compiled vertex shader program specifies the remaining vertex attributes and instructions of the vertex shader program for performing vertex lighting and performing other operations on the vertices in the batch of vertices. When the compiled vertex shader program is executed by graphics processing hardware, the shading portion of the compiled vertex shader is executed only when early vertex culling operations are not performed on the batch of vertices."
8543792,"A memory access technique, in accordance with one embodiment of the present invention, includes coalescing mappings between virtual memory and physical memory when a contiguous plurality of virtual pages map to a contiguous plurality of physical pages. Any of the coalesced mappings are sufficient to map all pages within the coalesced region. Accordingly, a memory subsystem can cache a single coalesced mapping and not all of them. The single cached coalesced mapping may be used to translate all of the virtual addresses to physical addresses for the corresponding contiguous memory space."
8547395,"A computer-implemented graphics system has a mode of operation in which primitive coverage information is generated by a rasterizer for real sample locations and virtual sample locations for use in anti-aliasing. An individual pixel includes a single real sample location and at least one virtual sample location. If the coverage information cannot be changed by a pixel shader, then the rasterizer can write the coverage information to a framebuffer. If, however, the coverage information can be changed by the shader, then the rasterizer sends the coverage information to the shader."
8547993,"Methods, apparatuses, and systems are presented for performing asynchronous communications involving using an asynchronous interface to send signals between a source device and a plurality of client devices, the source device and the plurality of client devices being part of a processing unit capable of performing graphics operations, the source device being coupled to the plurality of client devices using the asynchronous interface, wherein the asynchronous interface includes at least one request signal, at least one address signal, at least one acknowledge signal, and at least one data signal, and wherein the asynchronous interface operates in accordance with at least one programmable timing characteristic associated with the source device."
8549170,A system and method are provided for performing the retransmission of data in a network. Included is an offload engine in communication with system memory and a network. The offload engine serves for managing the retransmission of data transmitted in the network.
8549189,"The present invention is a flexible input/output translation system and method that facilitates conservation of chip pin resources while permitting flexible and dynamic changes to processor support operations on the fly. A present invention input/output translator includes a consolidated indication port, translation logic, a plurality of translated indication ports and an initialization port. The consolidated indication port receives a consolidated indication signal (e.g., indicating a desired voltage level) from a general purpose input/output port of a processor. The translation logic translates the consolidated indication signal into a plurality of translated indication signals. The plurality of translated indication ports communicate the plurality of translated indication signals. The initialization port receives an initialization signal. In one exemplary implementation, an synchronization port receives a synchronization signal that controls the operations of the translation logic and determines the timing of an output on the plurality of translated indication ports."
8553041,"One embodiment of the present invention sets forth a technique for efficiently creating and accessing an A-Buffer that supports multi-sample compression techniques. The A-Buffer is organized in stacks of uniformly-sized tiles, wherein the tile size is selected to facilitate compression techniques. Each stack represents the samples included in a group of pixels. Each tile within a stack represents the set of sample data at a specific per-sample rendering order index that are associated with the group of pixels represented by the stack. Advantageously, each tile includes tile compression bits that enable the tile to maintain data using existing compression formats. As the A-Buffer is created, a corresponding stack compression buffer is also created. For each stack, the stack compression buffer includes a bit that indicates whether all of the tiles in the stack are similarly compressed and, consequently, whether the GPU may operate on the stack at an efficient per pixel granularity."
8555035,One embodiment of the present invention sets forth a technique for using a multi-bank register file that reduces the size of or eliminates a switch and/or staging registers that are used to gather input operands for instructions. Each function unit input may be directly connected to one bank of the multi-bank register file with neither a switch nor a staging register. A compiler or register allocation unit ensures that the register file accesses for each instruction are conflict-free (no instruction can access the same bank more than once in the same cycle). The compiler or register allocation unit may also ensure that the register file accesses for each instruction are also aligned (each input of a function unit can only come from the bank connected to that input).
8555036,"A system includes a processor having an instruction register for storing an instruction having a predefined opcode, a predicate register for storing a predicate condition to select an output register for a result of the instruction, a first output register, and a second output register. The processor further includes processor circuitry operable to execute the instruction to produce a result, and processor circuitry operable to store the result of the instruction in the first output register if the predicate condition to select the output is true, and to store the second output register if the predicate condition to select the output is false. A single instruction is used to produce the result, and to store the result of the instruction."
8558832,"A system, method, and computer program product are provided for generating a plurality of two-dimensional images and a plurality of depth maps for a scene at a point in time. In various embodiments, such two-dimensional images and depth maps may be utilized to generate a plurality of images."
8558833,"One embodiment of the present invention sets forth a technique for consistently evaluating geometric patches with shared boundaries using barycentric coordinates. A barycentric parameter is generated and represented using a fixed-point fraction. The barycentric parameter is then used to generate a fixed-point barycentric coordinate. The fixed-point barycentric coordinate is then converted to a floating-point representation for evaluating the geometric patches. Computing shared boundary splits using fixed-point fractions eliminates inconsistencies in associated barycentric coordinates due to round-off errors. Evaluating geometric patch equations using consistent barycentric coordinates facilitates precise, consistent computation of vertices along shared boundaries."
8558835,"A system, method, and computer program product are provided for focusing computing power to a region of interest that can be changed interactively and arbitrarily during the process of image synthesis. In operation, a problem domain is partitioned utilizing a first selected technique. Additionally, a number of samples to be drawn per partition are assigned utilizing a second selected technique. Furthermore, the assigned number of samples are drawn for each partition, where the samples are generated by only one deterministic sample sequence. Still yet, the partitioning, assigning, and drawing are capable of being repeated such that existing partitions and assignments are capable of remaining unchanged during sampling and a convergence speed is adapted without compromising convergence in at least one of a sequential computing environment or a parallel computing environment. In this way, the convergence of image synthesis is not compromised. In fact, the image synthesis process may converge to the same solution that would have been obtained without interaction."
8558839,"A system and method force a display device to receive the output produced by a graphics processing unit that is configured as the video graphics array (VGA) boot device for display of critical system screens. A hybrid computer system that includes multiple graphics processors configures a display multiplexor to select image data from one of the multiple graphics processing units for output to the display device. When a critical system event occurs and the graphics processing unit that is selected is not configured as the VGA boot device, system basic input/output system (BIOS) interfaces are used to configure the multiplexor to select the one graphics processing unit that is configured as the VGA boot device to output the critical system screen to the display device."
8558842,"One embodiment of the present invention sets forth a technique for detecting duplicate vertex indices in parallel and batching indices defining multiple primitives for parallel primitive processing. A lookback cache breaks the dependent loop for the miss processing. Because each index is compared to all previous indices (duplicate or not), each index is not dependent on whether the previous indices have hit or missed. This allows the comparison operation that detects the duplicate vertex indices to be fully pipelined. The duplicate vertex indices are removed to reduce the number of indices that define the primitives in the batch. Multiple, independent rasterizer units operate concurrently on the different batches of graphics primitives to render multiple primitives per system clock."
8559248,"One embodiment of the present invention sets forth a clamping circuit that is used to maintain a bit line of a storage cell in a memory array at a nearly constant clamp voltage. During read operations the bit line is pulled high or low from the clamp voltage by the storage cell and a change in current on the bit line is converted by the clamping circuit to produce an amplified voltage that may be sampled to read a value stored in the storage cell. The clamping circuit maintains the nearly constant clamp voltage on the bit line. Clamping the bit line to the nearly constant clamp voltage reduces the occurrence of read disturb faults. Additionally, the clamping circuit functions with a variety of storage cells and does not require that the bit lines be precharged prior to each read operation."
8559565,A method (500) for estimating at least one offset in a subcarrier that is subject to distortion in a multicarrier communication system. The method comprises receiving a plurality of subcarriers wherein the plurality of subcarriers contain the subcarrier that is subject to the distortion; and generating a plurality of first channel estimates for a respective plurality of received subcarriers that are not subject to the distortion. The method further comprises processing a number of the plurality of first channel estimates for the respective plurality of received subcarriers that are not subject to the distortion to generate a second channel estimate for the subcarrier that is subject to the distortion; and estimating an offset associated with the subcarrier that is subject to the distortion. Estimation of the offset comprises: receiving a known reference signal transmitted for the subcarrier that is subject to the distortion; multiplying the second channel estimate with the known reference signal to produce a first value; and subcarrier subtracting the first value from the received known reference signal to produce the estimated offset.
8564589,"A method for performing a ray-box intersection test includes forming a span extending between a first plane-ray intersection point and a second plane-ray intersection point, and increasing the span by relocating to a new position at least one of the first and second plane-ray intersection points. A box intersection span is constructed using the increased span, and the box intersection span, which corresponds to a node in a hierarchical acceleration structure, is tested for intersection with the ray."
8564598,"In a graphics pipeline of a graphics processor, a method for a unified primitive description for rasterization. The method includes receiving a group of primitives from a graphics application, wherein the group includes different types of primitives and the types of primitives include line primitives, point primitives and triangle primitives. For each of the types of primitives, the method includes generating a corresponding parallelogram, wherein the parallelogram has four sides disposed along an x-axis and a y-axis, and computing an inside y-axis mid point and an outside y-axis mid point based on the four sides. The parallelogram is controlled to represent to each of the primitive types respectively by adjusting a location of the inside y-axis mid point or the outside y-axis mid point."
8564616,"One embodiment of the invention sets forth a mechanism for compiling a vertex shader program into two portions, a culling portion and a shading portion. The culling portion of the compiled vertex shader program specifies vertex attributes and instructions of the vertex shader program needed to determine whether early vertex culling operations should be performed on a batch of vertices associated with one or more primitives of a graphics scene. The shading portion of the compiled vertex shader program specifies the remaining vertex attributes and instructions of the vertex shader program for performing vertex lighting and performing other operations on the vertices in the batch of vertices. When the compiled vertex shader program is executed by graphics processing hardware, the shading portion of the compiled vertex shader is executed only when early vertex culling operations are not performed on the batch of vertices."
8564687,"An aspect of the present invention reduces computational complexity in determining a illuminant of a scene of interest by selecting only a subset of illuminants from several more potential illuminants, and searching for a current illuminant for a present image frame in only the subset of illuminants. Computational complexity may be reduced due to the searching in fewer illuminants. The subset of illuminants are selected according to various aspects to enhance the probability that the closest matching potential illuminant is accurately determined. The features can be used in image capture devices (ICDs) such as video cameras."
8570322,"A system, method, and computer program product are provided for efficiently ray tracing micropolygon or other highly complex geometry. In operation, a first hierarchy of a plurality of objects is established. Additionally, rays are traced using the first hierarchy to efficiently identify which of the plurality of objects are potentially intersected. Furthermore, at least one of the potentially intersected objects are decomposed, on-demand, into a set of subobjects, each set of subobjects corresponding to one of the at least one of the potentially intersected objects. Still yet, a second hierarchy is established for at least one of the set of subobjects, the second hierarchy being determined by a connectivity of subobjects in an associated set of subobjects in order to accelerate ray tracing."
8570324,"One embodiment of the present invention sets forth technique for watertight evaluation of Gregory patches for Catmull-Clark subdivision surfaces. Each boundary of each patch within a subdivision surface is configured to be owned by one related patch. In general, a given patch may own specific control points for the patch, while certain other control points for the patch may need to be reconstructed because the control points are owned by an adjacent patch. For a given patch, each control point along to a shared boundary is consistently generated using reconstruction data available to the patch. The reconstruction data is generated from values associated with a patch that owns the shared boundary. Because numerically identical data is used to evaluate each patch at each boundary, the boundaries are watertight. One advantage of the present invention is that watertight evaluation may be achieved using similar computational effort versus conventional non-watertight evaluation techniques."
8570331,"A software layer is disposed between an application and a driver. In use, the software layer is adapted to receive an object from the application intended to be rendered by a first graphics processor. Such software layer, in turn, routes the object to a second graphics processor, based on a policy."
8570333,"One embodiment of the present invention sets forth a method for enabling an intermediate code-based application program to access a target graphics processing unit (GPU) in a parallel processing environment. The method includes the steps of compiling a source code of the intermediate code-based application program to an intermediate code, translating the intermediate code to a PTX instruction code, and translating the PTX instruction code to a machine code executable by the target graphics processing unit before delivering the machine code to the target GPU."
8570634,"A method, computer-usable medium and a system for varying an incoming light field are disclosed. Embodiments provide mechanisms for performing image processing on an incoming light field using a spatial light modulator which is adjusted based upon characteristics of the incoming light field. The spatial light modulator may be positioned between the viewed scene and the eye, and therefore, may be semi-transparent. The image processing may consist of tone mapping, color enhancement, beautification, edge enhancement, spectral separation of colors, spectral separation of metamers, object emphasis, other image processing, or some combination thereof. Additionally, embodiments compensate for parallax errors by adjusting the spatial light modulator based upon the position of an observer with respect to the spatial light modulator. And further, embodiments may be incorporated into optical devices, wearable optical devices, windows, windshields, and the like, where the semi-transparent spatial light modulator adjusts the image before entering the eye."
8570916,"One embodiment of the present invention sets forth a destination credit management unit (CMU) that is coupled to source clients and a destination client and manages the transmission of credits associated with the destination client to the source clients. The destination CMU receives credits from the destination client as memory spaces within the destination client free up and transmits the credits to source clients as credits are consumed by the source clients. When a data packet is received from a source client, the destination CMU returns a credit to the source client if a credit is available. If a credit is not available, then the destination CMU stalls the source client until a credit becomes available. Credits are transmitted to stalled source clients in the order in which the source clients were stalled."
8571346,"In a method of image signal processing, defective pixels are determined on-the-fly in a digital image representation based on a comparison of a pixel under evaluation with its surrounding pixels, with reference to a known resolving capability of a lens-sensor arrangement that captured the digital image representation. In response to the determination of defective pixels, the defective pixels are corrected."
8572288,"The invention sets forth an approach for aggregating a plurality of NICs in a computing device into a single logical NIC as seen by that computing device's operating system. The combination of the single logical NIC and a network resource manager provides a reliable and persistent interface to the operating system and to the network hardware, thereby improving the reliability and ease-of-configuration of the computing device. The invention also may improve communications security by supporting the 802.1X and the 802.1Q networking standards."
8572289,"A system, method and associated data structure are provided for offloading upper protocol layer operations. In use, data is communicated over a network utilizing a plurality of protocols associated with a plurality of protocol layers, where the protocol layers include a network layer. Further, processing associated with the communicating is offloaded, at least in part. Such offloaded processing involves at least one protocol associated with at least one of the protocol layers situated at or above the network layer. Still yet, such offloading is performed statelessly."
8572355,"One embodiment of the present invention sets forth a method for executing a non-local return instruction in a parallel thread processor. The method comprises the steps of receiving, within the thread group, a first long jump instruction and, in response, popping a first token from the execution stack. The method also comprises determining whether the first token is a first long jump token that was pushed onto the execution stack when a first push instruction associated with the first long jump instruction was executed, and when the first token is the first long jump token, jumping to the second instruction based on the address specified by the first long jump token, or, when the first token is not the first long jump token, disabling the active thread until the first long jump token is popped from the execution stack."
8572573,"Systems and methods are disclosed for performing interactive debugging of shader programs using a non-preemptible graphics processing unit (GPU). An iterative process is employed to repeatedly re-launch a workload for processing by the shader program on the GPU. When the GPU encounters a hardware stop event, such as by reaching a breakpoint in any thread of the shader program, encountering a hardware exception, or failing a software assertion in the shader program, the state of any executing threads is saved, graphics memory is copied to system memory, and any currently executing threads are killed to enable the GPU to process graphics data for updating a display device. Each pass of the workload may result in incrementally more data being processed. In effect, the changing state and variable data resulting from each pass of the workload has the effect that the debugger is incrementally stepping through the shader program."
8572588,One embodiment of the present invention sets forth a technique for translating application programs written using a parallel programming model for execution on multi-core graphics processing unit (GPU) for execution by general purpose central processing unit (CPU). Portions of the application program that rely on specific features of the multi-core GPU are converted by a translator for execution by a general purpose CPU. The application program is partitioned into regions of synchronization independent instructions. The instructions are classified as convergent or divergent and divergent memory references that are shared between regions are replicated. Thread loops are inserted to ensure correct sharing of memory between various threads during execution by the general purpose CPU.
8572598,"A method and system for upgrading a software component in a computing device are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of storing a first software component in a first memory segment, maintaining a second software component in a second memory segment, wherein the second software component enables the computing device to boot up, and modifying at least one of a plurality of address lines to access the second memory segment after exiting a reset condition, if the execution of the first software component fails to satisfy a predetermined test condition."
8576208,"A system, method, and computer program product are provided for controlling stereo glasses shutters. In use, a right eye shutter of stereo glasses is controlled to switch between a closed orientation and an open orientation. Further, a left eye shutter of the stereo glasses is controlled to switch between the closed orientation and the open orientation. To this end, the right eye shutter and the left eye shutter of the stereo glasses may be controlled such that the right eye shutter and the left eye shutter simultaneously remain in the closed orientation for a predetermined amount of time."
8576227,"Systems and methods for estimating light transport between respective points includes selecting a plurality of first sub-paths extending the first point A. and selecting a plurality of second sub-paths extending from a second point B. A plurality of transport paths are constructed, wherein each one of the plurality of the first sub-paths is coupled to a respective one of the plurality of second paths, and wherein each transport path comprises one first sub-path and one second sub-path. Two or more of the transport paths are sampled, and a light transport value for each of the sampled transport paths is calculated to estimate the light transported between first point A and second point B."
8578387,An embodiment of a computing system is configured to process data using a multithreaded SIMD architecture that includes heterogeneous processing engines to execute a program. The program is constructed of various program instructions. A first type of the program instructions can only be executed by a first type of processing engine and a third type of program instructions can only be executed by a second type of processing engine. A second type of program instructions can be executed by the first and the second type of processing engines. An assignment unit may be configured to dynamically determine which of the two processing engines executes any program instructions of the second type in order to balance the workload between the heterogeneous processing engines.
8581833,"A system, method, and computer program product are provided for controlling stereo glasses shutters. In use, a right eye shutter of stereo glasses is controlled to switch between a closed orientation and an open orientation. Further, a left eye shutter of the stereo glasses is controlled to switch between the closed orientation and the open orientation. To this end, the right eye shutter and the left eye shutter of the stereo glasses may be controlled such that the right eye shutter and the left eye shutter simultaneously remain in the closed orientation for a predetermined amount of time."
8581969,"A single display system and method are provided for displaying stereoscopic content. In particular, a single display mechanism capable of displaying stereoscopic content for viewing with passive glasses is provided."
8582632,"Method, receiver and computer program product for processing a signal transmitted from a plurality of spatially separated transmit antennas using a Multiple-Input Multiple-Output transmission over a wireless network. The signal is received at a plurality of spatially separated receive antennas, the signal comprising a plurality of data streams and the quality/reliability of each of the data streams in the received signal is determined. Based on the determined quality/reliability of the data streams, a decoding technique is selected to be one of (i) a successive decoding technique for successively decoding data streams in which one of the data streams is decoded and a signal corresponding to said one of the data streams is removed from the received signal prior to decoding further data streams in the received signal, and (ii) a non-successive decoding technique in which each data stream is decoded from the received signal by treating the other data streams as noise in the received signal. The received signal is then decoded using the selected decoding technique."
8583724,"A server for use in connection with a network including at least one client and a communication link interconnecting the client and server. The server comprises a user interaction control module, an image rendering module and an interface. The image rendering module is configured to render, from three-dimensional scene data representing a scene, a two-dimensional image. The interface configured to transmit the two-dimensional image over the communication link to the client. The user interaction control module is configured to regulate interactions between the server, in particular the image rendering module, and respective clients who may be using the server concurrently to control images in which customizations requested by, for example, respective clients are rendered."
8587581,"One embodiment of the present invention sets forth a technique for rendering graphics primitives in parallel while maintaining the API primitive ordering. Multiple, independent geometry units perform geometry processing concurrently on different graphics primitives. A primitive distribution scheme delivers primitives concurrently to multiple rasterizers at rates of multiple primitives per clock while maintaining the primitive ordering for each pixel. The multiple, independent rasterizer units perform rasterization concurrently on one or more graphics primitives, enabling the rendering of multiple primitives per system clock."
8587682,"A display system, method, and computer program product are provided for capturing images using multiple integrated image sensors. The display system includes a front panel for displaying an image. The display system further includes a matrix of image sensors situated behind the front panel."
8588305,The present invention provides an apparatus for interpolation which is able to process input data with multiple video standards without sacrificing chip area. The interpolation unit comprises: a first interpolation unit for interpolating input data; a second interpolation unit for interpolating input data; a filter indicator for providing information to the first interpolation unit and the second interpolation unit; and an output unit for multiplexing and averaging output from the first interpolation unit and the second interpolation unit. The present invention also provides a motion compensation unit and a decoder for processing multiple video standards.
8588542,"An image processing apparatus for processing pixels is disclosed. The image processing apparatus comprises one or more functional blocks adapted to perform a corresponding functional task on the pixels. Further, the image processing apparatus includes one or more line-delay elements for delaying a horizontal scan line of the pixels. A desired processing task, which includes at least one functional task, is performed by configuring each functional block based on an actual number of the line-delay elements used for performing the desired processing task. Each functional block used for performing the desired processing task receives a group of pixels for processing from one or more horizontal scan lines such that the group overlaps another group of pixels for processing from one or more horizontal scan lines by another functional block."
8589468,"The present invention enables efficient matrix multiplication operations on parallel processing devices. One embodiment is a method for mapping CTAs to result matrix tiles for matrix multiplication operations. Another embodiment is a second method for mapping CTAs to result tiles. Yet other embodiments are methods for mapping the individual threads of a CTA to the elements of a tile for result tile computations, source tile copy operations, and source tile copy and transpose operations. The present invention advantageously enables result matrix elements to be computed on a tile-by-tile basis using multiple CTAs executing concurrently on different streaming multiprocessors, enables source tiles to be copied to local memory to reduce the number accesses from the global memory when computing a result tile, and enables coalesced read operations from the global memory as well as write operations to the local memory without bank conflicts."
8593469,"In some embodiments, a video processing system including video processor, an external memory, and an integrated circuit that implements both a memory controller (having embedded intelligence) and an internal memory coupled to the memory controller. The memory controller is configured to pre-cache in the internal memory partial frames of reference video data in the external memory (e.g., N-line slices of M-line reference frames, where M>N), and to respond to requests (e.g., from the video processor) for blocks of reference video data including by determining whether each requested block (or each of at least two portions thereof) has been pre-cached in the internal memory, causing each requested cached block (or portion thereof) to be read from the internal memory, and causing each requested non-cached block (or portion thereof) to be read from the external memory. Preferably, the pre-caching is performed in a predetermined manner independent of which read requests for the reference data are actually asserted, and exploits known correlation between two-dimensional pixel locality of each block (“current block”) of data to undergo processing (e.g., decoding) using reference data, two-dimensional pixel locality of each block of reference data that may be requested to process the current block, and probability that each such reference data block will be needed to process the current block. Other aspects are memory controllers for use in such a system and methods performed during operation of any such system or memory controller."
8593472,"One embodiment of the invention sets forth a mechanism for retrieving and storing data from/to a frame buffer via a storage driver included in a GPU driver. The storage driver includes three separate routines, the registration engine, the page-fault routine and the write-back routine, that facilitate the transfer of data between the frame buffer and the system memory. The registration engine registers a file system, corresponding to the frame buffer, the page-fault routine and the write-back routine with the VMM. The page-fault routine causes a portion of data stored in a specific memory location in the frame buffer to be transmitted to a corresponding memory location in the application memory. The write-back routine causes data stored in a particular memory location in the application memory to be transmitted to a corresponding memory location in the frame buffer."
8594198,"The present invention provides a method of implementing an intra prediction computation applied to the H.264 digital video coding and a device. The method according to present invention of implementing the intra prediction computation applied to the H.264 video coding comprises selecting an image block to be intra-predicted and extracting the neighboring pixel values of said block; determining the prediction mode of said block, and perform first adding operation on said neighboring pixel values when the prediction mode is one of Diagonal_Down_Left, Diagonal_Down_Right, Vertical_Right, Horizontal_Down, Vertical_Left, and Horizontal_Up; performing first shifting operation and second adding operation on the result of first adding operation respectively; performing second shifting operation on the result of second adding operation; selecting a corresponding value to output from the results of first and second shifting operation according to said prediction mode and size of block. The method and circuit device according to present invention will decrease most of the repeated calculations and improve the efficiency without greatly increasing the required chip real estate area."
8594441,"Image-based data, such as a block of texel data, is accessed. The data includes sets of color component values. A luminance value is computed for each set of color components values, generating a range of luminance values. A first set and a second set of color component values that correspond to the minimum and maximum luminance values are selected from the sets of color component values. A third set of color component values can be mapped to an index that identifies how the color component values of the third set can be decoded using the color component values of the first and second sets. The index value is selected by determining where the luminance value for the third set lies in the range of luminance values."
8595394,A method for dynamic buffering of disk I/O command chains for a computer system. The method includes receiving a plurality of disk I/O command chains from at least one thread executing on a processor of the computer system. A respective plurality of pointers for the disk I/O command chains are stored in a buffer of a disk controller. The disk I/O command chains are accessed for execution by the disk controller by serially accessing the pointers in the buffer.
8595425,"One embodiment of the present invention sets forth a technique for providing a L1 cache that is a central storage resource. The L1 cache services multiple clients with diverse latency and bandwidth requirements. The L1 cache may be reconfigured to create multiple storage spaces enabling the L1 cache may replace dedicated buffers, caches, and FIFOs in previous architectures. A “direct mapped” storage region that is configured within the L1 cache may replace dedicated buffers, FIFOs, and interface paths, allowing clients of the L1 cache to exchange attribute and primitive data. The direct mapped storage region may used as a global register file. A “local and global cache” storage region configured within the L1 cache may be used to support load/store memory requests to multiple spaces. These spaces include global, local, and call-return stack (CRS) memory."
8595437,"One embodiment of the present invention sets forth a compression status bit cache with deterministic latency for isochronous memory clients of compressed memory. The compression status bit cache improves overall memory system performance by providing on-chip availability of compression status bits that are used to size and interpret a memory access request to compressed memory. To avoid non-deterministic latency when an isochronous memory client accesses the compression status bit cache, two design features are employed. The first design feature involves bypassing any intermediate cache when the compression status bit cache reads a new cache line in response to a cache read miss, thereby eliminating additional, potentially non-deterministic latencies outside the scope of the compression status bit cache. The second design feature involves maintaining a minimum pool of clean cache lines by opportunistically writing back dirty cache lines and, optionally, temporarily blocking non-critical requests that would dirty already clean cache lines. With clean cache lines available to be overwritten quickly, the compression status bit cache avoids incurring additional miss write back latencies."
8599202,"A system and method for performing tessellation of three-dimensional surface patches performs some tessellation operations using programmable processing units and other tessellation operations using fixed function units with limited precision. (u,v) parameter coordinates for each vertex are computed using fixed function units to offload programmable processing engines. The (u,v) computation is a symmetric operation and is based on integer coordinates of the vertex, tessellation level of detail values, and a spacing mode."
8599208,"An arithmetic logic stage in a graphics processor unit includes arithmetic logic units (ALUs) and global registers. The registers contain global values for a group of pixels. Global values may be read from any of the registers, regardless of which of the pixels is being operated on by the ALUs. However, when writing results of the ALU operations, only some of the global registers are candidates to be written to, depending on the pixel number. Accordingly, overwriting of data is prevented."
8599841,"Configurable bitstream engines are described that can operate to decode variable length decoding of video and audio bitstreams encoded using any of a plurality of encoding schemes. Systems and methods are described that allow functional components of a bitstream engine to be disabled, enabled and configured as necessitated by the encoding scheme used to encode a bitstream. Functional components of a bitstream engine can perform single actions and operations, repetitive actions and operations and sequences of actions and operations as desired. A bit field extraction process is described for extracting bit fields of specified length from memory, updating bit offsets, loading new data from memory when needed."
8601223,"A memory access technique, in accordance with one embodiment of the present invention, includes coalescing mappings between virtual memory and physical memory when a contiguous plurality of virtual pages map to a contiguous plurality of physical pages. Any of the coalesced page table entries are sufficient to map all pages within the coalesced region. Accordingly, a memory subsystem can redirect one or more pending page table entry fetch requests to an appropriate coalesced page table entry."
8601235,"A shared memory management system and method are described. In one embodiment, a memory management system includes a memory management unit for concurrently managing memory access requests from a plurality of engines. The shared memory management system independently controls access to the context memory without interference from other engine activities. In one exemplary implementation, the memory management unit tracks an identifier for each of the plurality of engines making a memory access request. The memory management unit associates each of the plurality of engines with particular translation information respectively. This translation information is specified by a block bind operation. In one embodiment the translation information is stored in a portion of instance memory. A memory management unit can be non-blocking and can also permit a hit under miss."
8604855,"One embodiment of the present invention sets forth a technique for technique for capturing and storing a level of an input signal using a dual-trigger low-energy flip-flop circuit that is fully-static and insensitive to fabrication process variations. The dual-trigger low-energy flip-flop circuit presents only three transistor gate loads to the clock signal and none of the internal nodes toggle when the input signal remains constant. One of the clock signals may be a low-frequency “keeper clock” that toggles less frequently than the other two clock signal that is input to two transistor gates. The output signal Q is set or reset at the rising clock edge using separate trigger sub-circuits. Either the set or reset may be armed while the clock signal is low, and the set or reset is triggered at the rising edge of the clock."
8604857,"One embodiment of the present invention sets forth a technique for reducing jitter caused by changes in a power supply for a clock generated by a ring oscillator of inverter devices. An inverter sub-circuit is coupled in parallel with a current-starved inverter sub-circuit to produce an inverter circuit that is insensitive to changes in the power supply voltage. When the ring oscillator is used as the voltage controlled oscillator of a phase locked loop, the delay of the inverters may be controlled by varying a bias current for each inverter in response to changes in the power supply voltage to reduce any jitter in a clock output produced by the changes in the power supply voltage. When the transistor devices are sized appropriately and the bias current is adjusted, the sensitivity of the inverter circuit to changes in the power supply voltage may be reduced."
8605085,One embodiment of the present invention sets forth a technique for warping uniformly generated barycentric parameters to compensate for perspective foreshortening during tessellation of a geometric object. Near and far step sizes are computed for each edge of the geometric object. A warp equation is associated with each edge. Coefficients for each warp equation are computed from near and far step size for a corresponding edge. Uniformly generated barycentric parameters for each edge comprise an input variable for each corresponding warp equation. Warp equation outputs for edges of the geometric object are blended together using a linear blend function to generate vertices comprising geometric tessellation samples from the geometric object.
8605086,A system and method for dynamically adjusting the pixel sampling rate during primitive shading can improve image quality or increase shading performance. Hybrid antialiasing is performed by selecting a number of shaded samples per pixel fragment. A combination of supersample and multisample antialiasing is used where a cluster of sub-pixel samples (multisamples) is processed for each pass through a fragment shader pipeline. The number of shader passes and multisamples in each cluster can be determined dynamically for each primitive based on rendering state.
8605087,A system and method for dynamically adjusting the pixel sampling rate during primitive shading can improve image quality or increase shading performance. Hybrid antialiasing is performed by selecting a number of shaded samples per pixel fragment. A combination of supersample and multisample antialiasing is used where a cluster of sub-pixel samples (multisamples) is processed for each pass through a fragment shader pipeline. The number of shader passes and multisamples in each cluster can be determined dynamically for each primitive based on rendering state.
8605097,"A method and system are implemented for verifying connection status information associated with a specific display attachment location. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of receiving a first signature representative of a first set of connection states tracked by a graphics subsystem associated with the display attachment location, authenticating whether the integrity of a content path including the display attachment location is maintained based on the first signature, and deciding whether to continue sending the content to the display attachment location so that requirements associated with protecting the content are satisfied."
8605102,A raster unit generates graphic data for specific regions of a display device by processing each graphics primitive in a sequence of graphics primitives. A tile coalescer within the raster unit receives graphic data based on the sequence of graphics primitives processed by the raster unit. The tile coalescer collects graphic data for each region of the display device into a different bin before shading and then outputs each bin separately.
8605104,"One embodiment of the present invention sets forth a technique for compressing color data. Color data for a tile including multiple samples is compressed based on an equality comparison and a threshold comparison based on a programmable threshold value. The equality comparison is performed on a first portion of the color data that includes at least exponent and sign fields of floating point format values or high order bits of integer format values. The threshold comparison is performed on a second portion of the color data that includes mantissa fields of floating point format values or low order bits of integer format values. The equality comparison and threshold comparison are used to select either computed averages of the pixel components or the original color data as the output color data for the tile. When the threshold is set to zero, only tiles that can be compressed without loss are compressed."
8605791,A method for executing video encoding operations. The method includes encoding an incoming video stream into a plurality of macro blocks by using a video encoder and receiving a box out slice map specification for the plurality of macro blocks. The box out slice map specification is converted to a foreground-background slice map specification. The plurality of macro blocks are then processed in accordance with the foreground-background specification and by using a common hardware encoder front end.
8607008,"A shared resource management system and method are described. In one embodiment a shared resource management system includes a plurality of engines, a shared resource, and a shared resource management unit. In one exemplary implementation the shared resource is a memory and the shared resource management unit is a memory management unit (MMU). The plurality of engines perform processing. The shared resource supports the processing. For example a memory store information and instructions for the engines. The shared resource management unit independently caches and invalidates page table entries on a per engine basis."
8607151,"A method of debugging an application operable on a graphics pipeline subunit. A plurality of draw call groups is accessed. Each draw call group comprises a respective plurality of draw calls, sharing common state attributes of a prescribed state. The plurality of selectable draw call groups is displayed. In response to a user selection, a plurality of selectable draw calls associated with the selected draw call group is displayed. A plurality of selectable graphics pipeline subunits is displayed. In response to a user selection of a selected subunit, a plurality of editable state information and graphical primitives associated with a selected draw call are displayed. The plurality of editable state information may be grouped such that a portion sharing common attributes of the prescribed state are in one group. In response to a user selection, changes may be made to the selected draw call or the selected draw call group."
8607177,"In an integrated circuit device, a power circuit for maintaining asserted values on an input output pin of the device when a functional block of the device is placed in a sleep mode. The device includes a power circuit disposed along the periphery of the device, the power circuit configured to maintain power when the device is placed in a low-power mode. A plurality of input output blocks are included in the device and are for receiving external inputs for the integrated circuit device and for providing outputs from the integrated circuit device. The power circuit is coupled to provide power to at least one of the input output blocks to maintain state when the integrated circuit device is in the low-power mode."
8610732,A system and method for facilitating access to graphics memory wherein the graphics memory can be shared between a graphics processor and general system application. The method includes detecting an idle state of a graphics processing unit (GPU). The GPU uses graphics memory operable for storing graphics data. The method further includes determining an amount of available memory of the graphics memory of the GPU and signaling an operating system regarding the available memory. Memory data transfers are then received to store data into the available memory of the graphics memory wherein the data is related to general system application. Memory accesses to the available memory of the GPU are translated into a suitable format and executed so that the graphics memory is shared between the GPU and the operating system.
8610739,A method includes querying a database to determine the color profile of the multimedia content. The method may include comparing the secondary color profile of the secondary display to the primary color profile of the primary display and then determining a secondary color profile to apply to the multimedia content on the secondary display. The method may include selecting the secondary color profile from a database and applying the secondary color profile to the multimedia content. The method includes displaying the multimedia content with the secondary color profile on secondary display to reduce a color discrepancy of the multimedia content between the primary and the secondary display.
8611437,One embodiment of the present invention sets forth a mechanism for transmitting and receiving ground-referenced single-ended signals. A transmitter combines a direct current (DC) to DC converter including a flying capacitor with a 2:1 clocked multiplexer to drive a single-ended signaling line. The transmitter drives a pair of voltages that are symmetric about the ground power supply level. Signaling currents are returned to the ground plane to minimize the generation of noise that is a source of crosstalk between different signaling lines. Noise introduced through the power supply is correlated with the switching rate of the data and may be reduced using an equalizer circuit.
8611864,"A method, apparatus, and system of using call termination to communicate a message are disclosed. In one embodiment, a system of a telecommunications network includes a mobile station associated with the telecommunications network, a switching module of the telecommunications network to establish a call between a communication device and the mobile station, a call termination module of the mobile station to determine if the mobile station is in a call termination mode and to communicate a communication protocol to the switching module to cause the switching module to terminate the call if the mobile station is in the call termination mode, and a message module of the telecommunications network to communicate a message to the communication device."
8612732,One embodiment of the present invention sets forth a technique for translating application programs written using a parallel programming model for execution on multi-core graphics processing unit (GPU) for execution by general purpose central processing unit (CPU). Portions of the application program that rely on specific features of the multi-core GPU are converted by a translator for execution by a general purpose CPU. The application program is partitioned into regions of synchronization independent instructions. The instructions are classified as convergent or divergent and divergent memory references that are shared between regions are replicated. Thread loops are inserted to ensure correct sharing of memory between various threads during execution by the general purpose CPU.
8614634,"Systems and methods for encoding/decoding a data word using an 8b/9b encoding scheme that eliminates two-aggressor crosstalk are disclosed. The 8b/9b encoding scheme enables a data word to be encoded using code words. Each of the valid code words does not include any three consecutive bits having a logic level of logic-high (i.e., ‘1’), and represent transition vectors for consecutive symbols transmitted over the high speed parallel bus. An encoder and corresponding decoder are disclosed for implementing the 8b/9b encoding scheme. In one embodiment, the encoder/decoder implements a modified Fibonacci sequence algorithm. In another embodiment, the encoder/decoder implements a look-up table."
8615541,The invention set forth herein describes a mechanism for efficiently performing extended precision operations on multi-word source operands. Corresponding data words of the source operands are processed together via each instruction of a cascading sequence of instructions. State information generated when each instruction is processed is stored in condition code flags. The state information is optionally used in the processing of subsequent instructions in the sequence and/or accumulated with previously set state information.
8615646,"One embodiment of the present invention sets forth a mechanism for managing thread divergence in a thread group executing a multithreaded processor. A unanimous branch instruction, when executed, causes all the active threads in the thread group to branch only when each thread in the thread group agrees to take the branch. In such a manner, thread divergence is eliminated. A branch-any instruction, when executed, causes all the active threads in the thread group to branch when at least one thread in the thread group agrees to take the branch."
8615770,"One embodiment of the present invention sets forth a technique for partitioning a predecessor thread program into sub-programs and dynamically spawning a thread grid of the sub-programs based on the outcome of a conditional statement in the predecessor thread program. The programming instructions for the predecessor thread program are analyzed to assess the benefit of partitioning the thread program at a conditional statement into sub-programs. If the predecessor thread program is partitioned, then each branch of the conditional statement may be used to form a separate sub-program. Predicate tables are populated at the predecessor thread program run-time to establish which possible instances of the thread sub-programs should be spawned in subsequent execution phases."
8618651,"An interposer having decaps formed in blind-vias, a packaged semiconductor structure having decaps formed in blind-vias, and methods for forming the same are provided. In one embodiment, an interposer is provided that includes an interconnect layer disposed on a substrate. A plurality of through-vias are formed through the substrate in an isolated region of the substrate. At least one of the plurality of conductive vias are electrically coupled to at least one of a plurality of top wires formed in the interconnect layer. A plurality of blind-vias are formed through the substrate in a dense region of the substrate during a common etching step with the through-vias. At least one blind-via includes (a) a dielectric material lining the blind-vias, and (b) a conductive material filling the lined blind-vias and forming a decoupling capacitor."
8619087,"One embodiment of the present invention sets forth a technique for reducing the amount of memory required to store vertex data processed within a processing pipeline that includes a plurality of shading engines. The method includes determining a first active shading engine and a second active shading engine included within the processing pipeline, wherein the second active shading engine receives vertex data output by the first active shading engine. An output map is received and indicates one or more attributes that are included in the vertex data and output by the first active shading engine. An input map is received and indicates one or more attributes that are included in the vertex data and received by the second active shading engine from the first active shading engine. Then, a buffer map is generated based on the input map, the output map, and a pre-defined set of rules that includes rule data associated with both the first shading engine and the second shading engine, wherein the buffer map indicates one or more attributes that are included in the vertex data and stored in a memory that is accessible by both the first active shading engine and the second active shading engine."
8619973,"The present invention provides a flexible encryption device, comprising N encryption units connected in series for encrypting N-bit input data, each one of the N encryption units further comprising an exclusive-OR gate for receiving an input data; and a flip-flop connected coupled to the exclusive-OR gate. Furthermore, the present invention also provides the data transferring system that can be easily modified without the needs of manual intervention."
8624906,"A method and system for graphics instruction fetching. The method includes executing a plurality of threads in a multithreaded execution environment. A respective plurality of instructions are fetched to support the execution of the threads. During runtime, at least one instruction is prefetched for one of the threads to a prefetch buffer. The at least one instruction is accessed from the prefetch buffer if required by the one thread and discarded if not required by the one thread."
8624910,One embodiment of the present invention sets forth a technique for dynamically specifying a texture header and texture sampler using an index. The index corresponds to a particular register value that may be static or computed during execution of a shader program. Any texture operation instruction may specify an index value for each of the texture header and the texture sampler.
8624916,"One embodiment of the invention sets forth a CROP configured to perform both color raster operations and atomic transactions. Upon receiving an atomic transaction, the distribution unit within the CROP transmits a read request to the L2 cache for retrieving the destination operand. The distribution unit also transmits the source operands and the operation code to the latency buffer for storage until the destination operand is retrieved from the L2 cache. The processing pipeline transmits the operation code, the source and destination operands and an atomic flag to the blend unit for processing. The blend unit performs the atomic transaction on the source and destination operands based on the operation code and returns the result of the atomic transaction to the processing pipeline for storage in the internal cache. The processing pipeline writes the result of the atomic transaction to the L2 cache for storage at the memory location associated with the atomic transaction."
8627041,"One embodiment of the present invention sets forth a technique for performing a memory access request to compressed data within a virtually mapped memory system comprising an arbitrary number of partitions. A virtual address is mapped to a linear physical address, specified by a page table entry (PTE). The PTE is configured to store compression attributes, which are used to locate compression status for a corresponding physical memory page within a compression status bit cache. The compression status bit cache operates in conjunction with a compression status bit backing store. If compression status is available from the compression status bit cache, then the memory access request proceeds using the compression status. If the compression status bit cache misses, then the miss triggers a fill operation from the backing store. After the fill completes, memory access proceeds using the newly filled compression status information."
8633927,"In an example embodiment, 3D graphics object information associated with a render of a frame may be stored in an object-indexed cache in a memory. The 3D graphics object information comprises results for one or more shading operations further comprises one or more input values for the one or more shading operations."
8634429,"An apparatus comprising a wireless modem for use at a terminal, the modem being adapted to connect to the terminal via a first connection, and to connect via a second, wireless connection to a gateway between a wireless cellular network and a further, packet-based network. The modem is operable to connect to the gateway via the second connection using a point-to-point link protocol that does not require a physical address for the gateway, and is operable to connect to the host terminal via the first connection using a point-to-multipoint link protocol that supports point-to-multipoint connection and does require a physical address for the gateway. The modem is configured to intercept a message being conveyed between the gateway and the terminal, to generate a substitute address that identifies an interface of the modem, and in response to intercepting the message to communicate the substitute address to the terminal."
8635480,"In a computer system with multiple processing units, power to one or more of the processing units is turned off while the other processing units remain powered on. The processing unit that is powered off may be a GPU on a graphics adapter card, and power to this GPU is controlled by turning on and off the power supplied through a voltage regulator. With this configuration, power to the GPU on the graphics adapter card can be turned off when it is not in use or when it is being used for graphics processing that another graphics processor can handle."
8638241,"Systems and methods for encoding a data word using an 8b/9b encoding scheme that eliminates two-aggressor crosstalk are disclosed. The 8b/9b encoding scheme enables a data word that can be subdivided into portions of eight bits or less to be encoded using code words having one extra bit than the corresponding portion of the data word. Each of the valid code words does not include any three consecutive bits having a logic level of logic-high (i.e., ‘1’), and represent transition vectors for consecutive symbols transmitted over the high speed parallel bus. An encoder and corresponding decoder are disclosed for implementing the 8b/9b encoding scheme. In one embodiment, the encoder/decoder implements a modified Fibonacci sequence algorithm. In another embodiment, the encoder/decoder implements a look-up table. In some embodiments, data words may be less than eight bits wide."
8639833,"A method and system for dynamically controlling scaling in a computing device is disclosed. Specifically, in one embodiment, the system information of the computing device is collected and is compared with a trigger condition to generate a comparison result. According to the comparison result, the distribution of a processing task to handle network traffic received by the computing device to at least one designated processing unit in this computing device is either enabled or disabled."
8639882,"Methods and apparatus for source operand collector caching. In one embodiment, a processor includes a register file that may be coupled to storage elements (i.e., an operand collector) that provide inputs to the datapath of the processor core for executing an instruction. In order to reduce bandwidth between the register file and the operand collector, operands may be cached and reused in subsequent instructions. A scheduling unit maintains a cache table for monitoring which register values are currently stored in the operand collector. The scheduling unit may also configure the operand collector to select the particular storage elements that are coupled to the inputs to the datapath for a given instruction."
8639892,"Circuits, methods, and apparatus that inhibit the collection or updating of page characteristics where such information is not useful. One example inhibits the updating of page usage information for pages that are to be kept resident in memory and not swapped to disk. The pages for which page usage or other characteristic updates are to be suppressed can be identified in a number of ways, including using a set range of addresses, bits in page directory entries, bits in page table entries, one or more address registers, or one or more segments."
8643655,"The present invention sets forth a method and system for communicating with an external device through a processing unit in a graphics system of a computing device. In one embodiment, the method comprises allocating a first set of memory buffers having a first memory buffer and a second memory buffer in the graphics system based on an identification information of the external device, and invoking a first thread processor of the processing unit of the graphics system to perform services associated with a physical layer according to the identification information of the external device by storing a first data stream received from the external device through an I/O interface of the processing unit of the graphics system in the first memory buffer and retrieving a second data stream from the second memory buffer for transmission to the external device through the I/O interface."
8643657,"One embodiment of a field changeable rendering system includes an output device interfaced to a motherboard, a fixed rendering device mounted to the motherboard for generating information to be output on said output device, a connector for attaching a field-changeable rendering card to the motherboard, said field-changeable rendering card capable of housing a discrete rendering device for generating information to be output on said output device and detection circuitry for detecting that a field-changeable rendering card housing a discrete rendering device is coupled to said connector and causing information from said field-changeable rendering card housing a discrete rendering device to be output on said output device. One advantage of the disclosed edge connector is that it is compatible with a plurality of graphics cards and systems, thereby enabling a computing device user to upgrade the existing device's graphics system. Thus, the user is not forced to purchase an entirely new computing device in order to take advantage of graphics innovations. A further advantage of the disclosed edge connector is that it enables upgrades to low voltage differential signaling (LVDS) features, without the need for additional costly devices capable of operating at LVDS data rates."
8644524,"Methods and systems for reducing noise relating to an electronic system are disclosed. The methods and systems determine a noise signature, which characterizes a targeted noise of the electronic system. A cancellation signal is then generated based on this noise signature, so that if the cancellation signal is transmitted, the targeted noise is at least partially reduced."
8644691,"A method includes initiating, through an interface of a multimedia application executing on a data processing device, seeking of a desired frame of a video sequence rendered thereon. The desired frame corresponds to a desired point in time. The method also includes causing, through a set of instructions associated with a processor of the data processing device and/or an operating system executing thereon, the processor to decode frames of the video sequence from a closest frame in a temporal past relative to the desired frame following the initiation. Further, the method includes rendering, through the processor and on the interface, frames of the video sequence after a predeterminable threshold time period at a lower frame rate than a frame rate of the video sequence otherwise at least until the desired frame is decoded and rendered when the desired frame is not decoded within the predeterminable threshold time period."
8645585,"A technique is disclosed for dynamically reconfiguring a digital video link based on previously determined link training parameters. Reusing the previously determined link training parameters enables a no link training (NLT) protocol for quickly configuring the digital video link without the need for repeating a link training process. A display device advertises NLT capabilities information to a GPU indicating it can retain link characteristics for one or more link configurations. The GPU uses the NLT capabilities information to determine whether the display device is able to quickly transition to a specific link configuration using the NLT protocol, or to switch between configurations. The NLT capability allows a link to be advantageously quiesced and restored quickly while the GPU is transitioning in and out of power-saving sleep states, or placing the link in a more power efficient configuration, or higher-bandwidth higher-performance configuration. Additionally, the NLT capability allows a source to determine if the link configuration can be changed quickly while the display device retains the image, and thus can continue to present a constant screen for uninterrupted viewing."
8645634,One embodiment of the present invention sets forth a technique for reducing the copying of data between memory allocated to a primary processor and a coprocessor is disclosed. The system memory is aliased as device memory to allow the coprocessor and the primary processor to share the same portion of memory. Either device may write and/or read the shared portion of memory to transfer data between the devices rather than copying data from a portion of memory that is only accessible by one device to a different portion of memory that is only accessible by the other device. Removal of the need for explicit primary processor memory to coprocessor memory and coprocessor memory to primary processor memory copies improves the performance of the application and reduces physical memory requirements for the application since one portion of memory is shared rather than allocating separate private portions of memory.
8645638,"A memory is used by concurrent threads in a multithreaded processor. Any addressable storage location is accessible by any of the concurrent threads, but only one location at a time is accessible. The memory is coupled to parallel processing engines that generate a group of parallel memory access requests, each specifying a target address that might be the same or different for different requests. Serialization logic selects one of the target addresses and determines which of the requests specify the selected target address. All such requests are allowed to proceed in parallel, while other requests are deferred. Deferred requests may be regenerated and processed through the serialization logic so that a group of requests can be satisfied by accessing each different target address in the group exactly once."
8645864,"Embodiments of the invention provide an interface for simultaneously inputting multiple data parameters for a software application. Generally, a single user input made using the input interface results in multiple data parameters being received by the application. In one embodiment, the input interface may be defined with a plurality of dimensional nodes, where each dimensional node corresponds to a dimension of input that may be specified for the software application using the input interface."
8648856,"An invention is provided for rendering using an omnidirectional light. A shadow cube texture map having six cube faces centered by a light source is generated. Each cube face comprises a shadow texture having depth data from a perspective of the light source. In addition, each cube face is associated with an axis of a three-dimensional coordinate system. For each object fragment rendered from the camera's perspective a light-to-surface vector is defined from the light source to the object fragment, and particular texels within particular cube faces are selected based on the light-to-surface vector. The texel values are tested against a depth value computed from the light to surface vector. The object fragment is textured as in light or shadow according to the outcome of the test."
8654132,"A display refresh system, method and computer program product are provided. In use, at least one aspect of a display of content is identified by monitoring commands. Based on such identified aspect(s), a refresh rate of a display utilized for the display of the content may be adjusted."
8654135,"One embodiment of the present invention sets forth a technique for efficiently creating and accessing an A-Buffer that supports multi-sample compression techniques. The A-Buffer is organized in stacks of uniformly-sized tiles, wherein the tile size is selected to facilitate compression techniques. Each stack represents the samples included in a group of pixels. Each tile within a stack represents the set of sample data at a specific per-sample rendering order index that are associated with the group of pixels represented by the stack. Advantageously, each tile includes tile compression bits that enable the tile to maintain data using existing compression formats. As the A-Buffer is created, a corresponding stack compression buffer is also created. For each stack, the stack compression buffer includes a bit that indicates whether all of the tiles in the stack are similarly compressed and, consequently, whether the GPU may operate on the stack at an efficient per pixel granularity."
8654530,"A heat transfer apparatus and method are provided for transferring heat between integrated circuits. In use, a heat transfer medium is provided with a first end in thermal communication with a first integrated circuit and a second end in thermal communication with a second integrated circuit. Furthermore, a single casting formed about the heat transfer medium and defining at least one heat sink is provided for thermal communication with the first integrated circuit or the second integrated circuit."
8655937,One or more embodiments of the invention set forth techniques to perform integer division using a floating point hardware unit supporting floating point variables of a certain bit size. The numerator and denominator are integers having a bit size that is greater than the bit size of the floating point variables supported by the floating point hardware unit. Error correcting techniques are utilized to account for any loss of precision caused by the floating point operations.
8656093,"One embodiment of the invention sets forth a mechanism to transmit commands received from an L2 cache to a bank page within the DRAM. An arbiter unit determines which commands from a command sorter to transmit to a command queue. An activate command associated with the bank page related to the commands is also transmitted to an activate queue. The last command in the command queue is marked as “last.” An interlock counter stores a count of “last” commands in the read/write command queue. A DRAM controller transmits activate and commands from the activate queue and the command queue to the DRAM. Each time a command marked as “last” is encountered, the DRAM controller decrements the interlock counter. If the count in the interlock counter is zero, then the command marked as “last” is marked as “auto-precharge.” The “auto-precharge” command, when processed, causes the bank page to be closed."
8656117,An input/output unit for a computer system that is interfaced with a memory unit having a plurality of partitions manages completions of read requests in the order that they were made. A read request buffer tracks the order in which the read requests were made so that read data responsive to the read requests can be completed and returned to a requesting client in the order the read requests were made.
8656394,"A method for executing an application program using streams. A device driver receives a first command within an application program and parses the first command to identify a first stream token that is associated with a first stream. The device driver checks a memory location associated with the first stream for a first semaphore, and determines whether the first semaphore has been released. Once the first semaphore has been released, a second command within the application program is executed. Advantageously, embodiments of the invention provide a technique for developers to take advantage of the parallel execution capabilities of a GPU."
8659337,One embodiment of the present invention sets forth a technique for capturing and holding a level of an input signal using a latch circuit that presents a low number of loads to the clock signal. The clock is only coupled to a bridging transistor and a pair of clock-activated pull-down or pull-up transistors. The level of the input signal is propagated to the output signal when the storage sub-circuit is not enabled. The storage sub-circuit is enabled by the bridging transistor and a propagation sub-circuit is activated and deactivated by the pair of clock-activated transistors.
8659590,"A system, method, and computer program product are provided for modifying signals of a three-dimensional graphics application program based on a tracking algorithm. In operation, a plurality of signals are received from a three-dimensional graphics application program. Additionally, the signals, or a derivative thereof, are modified based on an algorithm that tracks at least a portion of an upper body of a person. Furthermore, the modified signals are output."
8659601,A method for loading and executing an indeterminate length shader program. The method includes accessing a first portion of a shader program in graphics memory of a GPU and loading instructions from the first portion into a plurality of stages of the GPU to configure the GPU for program execution. A group of pixels is then processed in accordance with the instructions from the first portion. A second portion of the shader program is accessed in graphics memory of the GPU and instructions from the second portion are loaded into the plurality of stages of the GPU to configure the GPU for program execution. The group of pixels are then processed in accordance with the instructions from the second portion.
8659615,"Systems and methods for managing window transparency for a computer display, making windows wholly transparent or semi-transparent, on a window-by-window basis. Window transparency is triggered by monitoring messages exchanged between a program and an operating system, or by a user action. Upon detection of a first message indicating that a window of the display should be transparent, a layered display mode for the window is initiated. Upon detection of a second message indicating that the window should no longer be transparent, the layered display mode for the window is terminated. The layered mode can be controlled by the operating system or by a graphics processor."
8659616,"A system, method, and computer program product are provided for rendering pixels with multiple semi-transparent surfaces. In use, a pixel is identified. Additionally, an operation to generate a plurality of samples for the pixel is performed. Further, a subset of the samples for each of at least one semi-transparent surface associated with the pixel is selected at least in part in a random manner. Moreover, the pixel is rendered utilizing the selected subset of the samples for each of the at least one semi-transparent surface."
8660182,"A more efficient motion estimation process that utilizes a plurality of predicted start points (e.g., two predicted start points) based on blocks adjacent to the current block together with other improvements and requires minimal system resources (e.g., hardware resources and CPU processing) in its hardware implementation is provided. More particularly, the motion estimation technique in accordance with the present invention performs a plurality of coarse searches (either sequentially or in parallel) using a plurality of predicted start positions followed by a fine search."
8660380,"In some embodiments, a method for performing and a system configured to perform a 2D transform (for example, an inverse discrete cosine transform) on each block of a sequence of data blocks, where the 2D transform includes a row transform and a column transform. To perform the row or column transform on a row or column of data, these embodiments determine whether each of different subsets of the data values comprising a partition of the row (column) includes at least one zero value, whether each of different subsets of a first subset of the partition includes at least one zero value, and whether each of different subsets of at least one other subset of the partition includes at least one zero value. When performing the row (column) transform on each row or column that includes at least one zero value and at least one non-zero value, at least one transformation operation on at least one zero value is bypassed or performed in a reduced-power manner, where such transformation operation would otherwise be performed in a manner consuming full power if the zero value were a non-zero value. In some embodiments, the system is a pipelined video decoding system or other video processing system (or a video processing subsystem of a portable media player or other system) including a transform engine implemented in accordance with the invention. Other aspects are transform engines and transform engine circuitry for use in any embodiment of the system."
8660515,"Circuits, methods, and apparatus incorporate both a wireless physical interface and audio processing unit on a single integrated circuit. The wireless physical interface may include a receiver, transmitter, or a complete transceiver. The audio processing unit is typically in communication with both the wireless interface and one or more wired physical interfaces. The integrated circuit may be as simple as a wireless physical interface and audio processing unit, or it may include other circuits such as graphics processors, networking interfaces, memories, or other circuits."
8661226,"A system, method, and computer program product are provided for performing a scan operation on a sequence of single-bit values using a parallel processing architecture. In operation, a scan operation instruction is received. Additionally, in response to the scan operation instruction, a scan operation is performed on a sequence of single-bit values using a parallel processor architecture with a plurality of processing elements."
8666166,"A method and system for performing a 2D transform is disclosed. The 2D transform may include a row transform and/or a column transform. When performing the row or column transform, it may be determined whether each of different subsets of the data values including a partition of a row or column includes at least one zero value, whether each of different subsets of a first subset of the partition includes at least one zero value, and whether each of different subsets of at least one other subset of the partition includes at least one zero value. When performing the row or column transform, at least one transformation operation on at least one zero value may be bypassed or performed in a reduced-power manner, where such transformation operation would otherwise be performed in a manner consuming full power if the zero value were a non-zero value."
8666181,"The present invention facilitates efficient and effective detection of pixel alteration. In one embodiment a pixel alteration analysis system includes a difference summing multiple engine component and a control component. The difference summing multiple engine component determines the sum of differences between pixel values in a plurality of pixels. The control component determines an indication of motion based upon said relationship of said pixels in said plurality of pixels. In one exemplary implementation, the difference in values corresponds to a relationship between values of pixels in a block of pixels at different frames. The number and configuration of pixels in a block partition can be flexibly changed."
8666713,A method of stimulating a deformable object comprises modeling deformable elasticity for the object by defining an actual shape and a goal shape and pulling points in the goal shape towards corresponding points in the goal shape.
8667200,"One embodiment of the present invention sets forth a technique for arbitrating between a set of requesters that transmit data transmission requests to the weighted LRU arbiter. Each data transmission request is associated with a specific amount of data to be transmitted over the crossbar unit. Based on the priority state associated with each requester, the weighted LRU arbiter then selects the requester in the set of requesters with the highest priority. The weighted LRU arbiter then decrements the weight associated with the selected requester stored in a corresponding weight store based on the size of the data to be transmitted. If the decremented weight is equal to or less than zero, then the priority associated with the selected requester is set to a lowest priority. If, however, the decremented weight is greater than zero, then the priority associated with the selected requester is not changed."
8667256,"One embodiment of a computing system configured to manage divergent threads in a thread group includes a stack configured to store at least one token and a multithreaded processing unit. The multithreaded processing unit is configured to perform the steps of fetching a program instruction, determining that the program instruction is a branch instruction, determining that the program instruction is not a return or break instruction, determining whether the program instruction includes a set-synchronization bit, and updating an active program counter, where the manner in which the active program counter is updated depends on a branch instruction type."
8669991,"One embodiment of the present invention sets forth a method macro expander (MME) coupled to a driver and the processing pipeline of a graphics processing unit. In operation, the MME receives, from the driver, a first packet of work indicating a macro stored in an instruction memory that is to be executed. The MME then executes the commands of the macro in the instruction memory to generate a second packet of work, and the second packet of work is then transmitted to the processing pipeline for further execution."
8669999,"One embodiment of the present invention sets forth a technique for converting alpha values into pixel coverage masks. Geometric coverage is sampled at a number of “real” sample positions within each pixel. Color and depth values are computed for each of these real samples. Fragment alpha values are used to determine an alpha coverage mask for the real samples and additional “virtual” samples, in which the number of bits set in the mask bits is proportional to the alpha value. An alpha-to-coverage mode uses the virtual samples to increase the number of transparency levels for each pixel compared with using only real samples. The alpha-to-coverage mode may be used in conjunction with virtual coverage anti-aliasing to provide higher-quality transparency for rendering anti-aliased images."
8670613,"One embodiment of the present invention sets forth a technique for lossless compression of color data. Color data for a packet including multiple sub-pixel samples is compressed using a predictor map that is selected based on the sampling format specified for the graphics surface storing the color data. The predictor map defines one of the samples as an anchor that is represented exactly and a transform indicating which neighboring samples are used to compute difference samples for the other samples in the packet. The difference samples are truncated and tested to determine if the difference samples can fit into one or more compressed data formats, i.e., if the color data can be compressed without loss. When compression can be performed without loss, the transformed packet is output. Otherwise, the original packet is output."
8675091,"Pictures can be taken with multiple (e.g., two) cameras, and the statistics associated with any of those pictures can be used to correct (e.g., color balance) any of the other pictures. Generally speaking, first image data captured by a first camera is accessed (e.g., retrieved from memory). Similarly, second image data captured by a second camera is accessed. The first image data and second image data are acquired at or about the same time using the first and second cameras together (e.g., at the same location, so that each camera is subject to the same light source). The first image data can then be processed (e.g., color balanced) using information that is derived using the second image data."
8675730,"A method of video reconstruction includes providing a hardware accelerator to a video processing component of a video processing system, and a driver for the video processing component. In addition, the method includes segmenting macroblocks of a destination video frame in a raster order into groups based on reference parameters thereof using the driver, where the reference parameters define compensation needs of macroblocks of the destination frame. The method also includes constructing an indexed array of linked-lists using the driver, with each linked-list representing macroblocks of a group having the same reference parameters. The hardware accelerator may be programmed to accelerate motion compensation by reconstructing macroblocks of the destination frame group-wise in the indexed order of the array of linked-lists."
8676222,"A method, user equipment, network equipment and a system for initiating a wireless connection and subsequent communication over a shared physical resource in a wireless communication system between user equipment and network equipment comprising: processing a UE-derived temporary identifier; communicating the temporary identifier as an identifier to the network equipment; communicating a downlink message conveying the temporary identifier and a description of a scheduled resource on a shared channel, the scheduled resource comprising a resource allocated to the user equipment by the network equipment; and communicating data on the scheduled resource in response to the downlink message."
8677074,"Memory access techniques, in accordance with embodiments of the present technology, redirect memory access requests received from a baseband processor to shared memory coupled to an application processor. The techniques enable substantially real time read and write accesses by the application and baseband processors to the shared memory coupled to the application processor."
8677106,"One embodiment of the present invention sets forth a mechanism for managing thread divergence in a thread group executing a multithreaded processor. A unanimous branch instruction, when executed, causes all the active threads in the thread group to branch only when each thread in the thread group agrees to take the branch. In such a manner, thread divergence is eliminated. A branch-any instruction, when executed, causes all the active threads in the thread group to branch when at least one thread in the thread group agrees to take the branch."
8681169,"Systems and methods for texture processing are presented. In one embodiment a texture method includes creating a sparse texture residency translation map; performing a probe process utilizing the sparse texture residency translation map information to return a finest LOD that contains the texels for a texture lookup operation; and performing the texture lookup operation utilizing the finest LOD. In one exemplary implementation, the finest LOD is utilized as a minimum LOD clamp during the texture lookup operation. A finest LOD number indicates a minimum resident LOD and a sparse texture residency translation map includes one finest LOD number per tile of a sparse texture. The sparse texture residency translation can indicate a minimum resident LOD."
8681861,"Described herein are a number of approaches for implementing a multistandard video encoder. In several embodiments, a single encoder supports multiple video encoding standards via dedicated hardware datapaths, while using shared buffers to store a video data between processing stages. In one such embodiment, system for video encoding is described. The system includes a number of encoding stages, for performing tasks associated with encoded video data. The system also includes a number of encoding buffers, coupled to the encoding stages, for storing video data between encoding stages. The encoding stages are operable to encode the video data in accordance with a number of video encoding standards, and the encoding buffers are operable to store partially encoded video data, regardless of the video encoding standard selected."
8683067,"A video navigation system and method can be utilized to efficiently and adjustably navigate video content. In one embodiment, a video information control method facilitates efficient video navigation. A video stream is received and video access point selection between multiple access points in said video stream is controlled. The presentation information is forwarded for each of the multiple access points. In one exemplary implementation, the presentation information is forwarded to a display and the information is directed to presenting a main viewing area and navigation areas that present looping video clips or portions of the video stream at time intervals ahead of and behind the video portion being presented in the main viewing area."
8683089,"One or more client engines issues write transactions to system memory or peer parallel processor (PP) memory across a peripheral component interconnect express (PCIe) interface. The client engines may issue write transactions faster than the PCIe interface can transport those transactions, causing write transactions to accumulate within the PCIe interface. To prevent the accumulation of write transactions within the PCIe interface, an arbiter throttles write transactions received from the client engines based on the number of write transactions currently being transported across the PCIe interface."
8683126,"A storage controller which uses the same buffer to store data elements retrieved from different secondary storage units. In an embodiment, the controller retrieves location descriptors ahead of when data is available for storing in a target memory. Each location descriptor indicates the memory locations at which data received from a secondary storage is to be stored. Only a subset of the location descriptors may be retrieved and stored ahead when processing each request. Due to such retrieval and storing of limited number of location descriptors, the size of a buffer used by the storage controller may be reduced. Due to retrieval of the location descriptors ahead, unneeded buffering of the data elements within the storage controller is avoided, reducing the latency in writing the data into the main memory, thus improving performance."
8683132,"A memory controller for prefetching data for a processor, or CPU, of a computer system. The memory controller functions by interfacing the processor to system memory via a system memory bus. A prefetch cache is included in the memory controller. The prefetch cache includes a short-term storage portion and a long-term storage portion. The prefetch cache is configured to access system memory to retrieve and store a plurality of sequential cache lines subsequent to a processor access to system memory."
8683184,A method for implementing multi context execution on a video processor having a scalar execution unit and a vector execution unit. The method includes allocating a first task to a vector execution unit and allocating a second task to the vector execution unit. The first task is from a first context in the second task is from a second context. The method further includes interleaving a plurality of work packages comprising the first task and the second task to generate a combined work package stream. The combined work package stream is subsequently executed on the vector execution unit.
8683293,"An error locator unit for correcting two bit error. The error locator unit includes a plurality of operational units, a normalized basis transform unit, and a conversion unit. The plurality of operations units calculates coefficients of the polynomial based on the generated syndromes in a first basis of a Galois Field. Operating on the coefficients produces a root definition value vector in the first basis. The normalized basis transform unit transforms the root definition value vector to a normal basis to produce a plurality of roots. The conversion unit converts the plurality of roots to the first basis. A scaling factor calculated based on the coefficients is applied to the output of the conversion unit to produce a plurality of scaled roots for said polynomial in the first basis. The plurality of scaled roots is added to produce error locations for the polynomial."
8687008,"A latency tolerant system for executing video processing operations. The system includes a host interface for implementing communication between the video processor and a host CPU, a scalar execution unit coupled to the host interface and configured to execute scalar video processing operations, and a vector execution unit coupled to the host interface and configured to execute vector video processing operations. A command FIFO is included for enabling the vector execution unit to operate on a demand driven basis by accessing the memory command FIFO. A memory interface is included for implementing communication between the video processor and a frame buffer memory. A DMA engine is built into the memory interface for implementing DMA transfers between a plurality of different memory locations and for loading the command FIFO with data and instructions for the vector execution unit."
8687010,Arbitrary size texture palettes. A texture palette storage embodied in a computer readable medium is provided. The texture palette storage is partitioned into texture palette tables of arbitrary size. Texel data is stored for each of the texture palette tables in the texture palette storage. Another aspect is a palette memory that receives a texture index value of y-bits. The palette memory comprises subtables of different length. Each sub-table has a range with a start address and a length. The start address is a multiple of m. Each range is of a length addressable by y-bits. The palette memory also includes a sub-table index value of x-bits.
8687503,"A method for identifying a failed network interface card in a system having two NICs configured as a team includes the steps of transmitting a first data packet from the first NIC to a third NIC, wherein the third NIC is not a member of the team, and transmitting a second data packet from the first NIC to the second NIC or from the second NIC to the third NIC, depending on whether the third NIC responds to the transmission of the first data packet. One advantage of the disclosed method is that it specifically identifies which NIC within the team has failed, which is something that cannot be determined by simply exchanging packets between the two NICs."
8687639,"A system for ordering packets. The system includes a first memory, e.g., FIFO, storing transition information for posted packets, e.g., 1 when a posted packet transitions from a non-posted packet and 0 otherwise. A second memory stores transition information for non-posted packets, e.g., 1 when a non-posted packet transitions from a posted packet and 0 otherwise. A counter increments responsive to detecting a transition in the first memory and decrements responsive to detecting a transition in the second memory. A controller orders a posted packet for transmission prior to a non-posted packet if a value of the counter is negative and when a transitional value associated with the non-posted packet is 1, and wherein the controller orders either a posted packet or a non-posted packet otherwise. The first and the second memory may be within a same memory component."
8687875,"A method for comparator based quantization acceleration for an encoding process. The method includes computing coefficients for a discrete cosine transform encoding operation and determining a quantization step for use with a quantization operation for each of the coefficients. The method further includes determining each of the coefficients that are less than or equal to one half the quantization step by using a comparator configured in accordance with the quantization step. For the coefficients that are less than or equal to one half the quantization step, a quantized output value is transmitted to the encoding process. For the coefficients that are greater than one half the quantization step, the quantized output value is determined by executing multiplication logic to compute the quantized output value and transmit the computed quantized output value to the encoding process."
8689159,"One embodiment sets forth a technique for on-chip satisfying timing requirements of on-chip source-synchronous, CMOS-repeater-based interconnect. Each channel of the on-chip interconnect may include one or more redundant wires. Calibration logic is configured to apply transition patterns to wires comprising each channel and calibration patterns that are generated in response to the transition patterns are captured. Based on the calibration patterns, wires that best satisfy the timing requirements of the on-chip interconnect are selected for use to transmit data. The calibration logic also trims the delays of the clock and selected data wires based on captured calibration patterns to improve the timing margin of the on-chip interconnect. Improving the timing margin of the on-chip interconnect improves chip yields."
8692829,"One embodiment of the present invention sets forth a technique for computing plane equations for primitive shading after non-visible pixels are removed by z culling operations and pixel coverage has been determined. The z plane equations are computed before the plane equations for non-z primitive attributes are computed. The z plane equations are then used to perform screen-space z culling of primitives during and following rasterization. Culling of primitives is also performed based on pixel sample coverage. Consequently, primitives that have visible pixels after z culling operations reach the primitive shading unit. The non-z plane equations are only computed for geometry that is visible after the z culling operations. The primitive shading unit does not need to fetch vertex attributes from memory and does not need to compute non-z plane equations for the culled primitives."
8692837,"One embodiment of the invention sets forth a technique for compressing and storing display data and optionally compressing and storing cursor data in a memory that is local to a graphics processing unit to reduce the power consumed by a mobile computing device when refreshing the screen. Compressing the display data and optionally the cursor data also reduces the relative cost of the invention by reducing the size of the local memory relative to the size that would be necessary if the display data were stored locally in uncompressed form. Thus, the invention may improve mobile computing device battery life, while keeping additional costs low."
8692844,"A method and system are disclosed for antialiased rendering a plurality of pixels in a computer system. The method and system comprise providing a fixed storage area and providing a plurality of sequential format levels for the plurality of pixels within the fixed storage area. The plurality of format levels represent pixels with varying degrees of complexity in subpixel geometry visible within the pixel. A system and method in accordance with the present invention provides at least the following format levels: one-fragment format, used when one surface fully covers a pixel; two-fragment format, used when two surfaces together cover a pixel; and multisample format, used when three or more surfaces cover a pixel. The method and system further comprise storing the plurality of pixels at a lowest appropriate format level within the fixed storage area, so that a minimum amount of data is transferred to and from the fixed storage area. The method and system further comprise procedures for converting pixels from one format level to take into account newly rendered pixel fragments. All formats represent depth values in a consistent manner so that fragments rendered during later rendering passes match depth values resulting from rendering the same primitive in earlier passes. Thus, the invention enables high-quality antialiasing with minimal data transferred to and from the fixed storage area, while supporting multi-pass rendering."
8694688,"A hardware support system for implementing accelerated disk I/O for a computer system. The system includes a bus interface for interfacing with a processor and a system memory of the computer system, a disk I/O engine coupled to the bus interface, and a device interface coupled to the disk I/O engine for interfacing the disk I/O engine with a disk drive. The disk I/O engine is configured to cause a start up of the disk drive upon receiving a disk start up command from the processor. The disk I/O engine is further configured to execute a disk transaction by processing the disk transaction information from a bypass register coupled to the disk I/O engine."
8694697,"A system and method dispatches commands from multiple instruction streams to processing engines, allowing for some of the dispatched commands to be rescinded before they are executed by the processing engines. The dispatching enables several of the processing engines to execute commands concurrently. Dispatched commands may be rescinded to quickly switch processing from one instruction stream to another instruction stream."
8694750,"Embodiments of the present invention are directed to a method and system for allowing data structures to be moved between storage locations of varying performance and cost without changing the application firmware. In one embodiment, rather than application firmware directly accessing memory, the application firmware requests a data structure by parameters, to which the implementation returns a pointer. The parameters can be, for example, the logical block address of a data sector, and the data structure can be mapping and associated information of that logical block address (LBA) to a location in the flash device."
8694955,A technique for determining thermal design point (TDP) power efficiency for an integrated circuit is disclosed. A simulation executes a set of input vectors on a model of an integrated circuit to generate a first estimated power consumption data during a first number of clock cycles. A simulation executes the set of input vectors on a model of an integrated circuit to generate a second estimated power consumption data during a second number of clock cycles. TDP power efficiency for the integrated circuit is calculated based on the first estimated power consumption data and the second estimated power consumption data.
8698305,"A multi-configuration interface device for coupling different types of GPUs (graphics processor units) to a PCB (printed circuit board). The interface device comprises a GPU interface for a connection to the GPU and a PCB interface for a connection to the PCB. The GPU interface is implemented using a customizable attachment footprint for effectuating a connection to differing GPU types while maintaining the PCB interface for the connection to the PCB. The ball array for different GPUs can be configured to respectively support them. The interface device maintains a consistent PCB interface. Thus, as GPU characteristics change and evolve, or as different GPU versions are implemented, a consistent connection can be maintained for the PCB."
8698542,"A system, method, and computer program product are provided for performing level shifting. In use, level shifting is performed utilizing a native transistor, where the level shifting is performed utilizing a feedback based topology."
8698802,"One embodiment of the present invention sets forth technique for watertight tessellation in a displaced subdivision surface. A subdivision surface is represented as a novel parametric quad patch that is continuous with respect to position (C0) and partial derivatives (C1) along boundaries as well as interior regions. The novel parametric quad patch is referred to herein as a Hermite Gregory patch and comprises a Hermite patch augmented to include a pair of twist vector parameters per vertex. Each pair of twist vectors is combined into one twist vector during evaluation, according to weights based on proximity to parametric boundaries. Evaluation yields an approximation mesh comprising a position for each vertex and a corresponding normal vector for the vertex. Displacement is performed based on the approximation mesh and a displacement map to generate a displaced approximation mesh that is reflective of the displaced subdivision surface."
8698808,One embodiment of the present invention sets forth a technique for converting dashed strokes into quadratic Bèzier segment sequences. Path rendering with stroking and dashing may be accelerated when a graphics processing unit or other processor is configured to subdivide quadratic Bèzier segments based on the remaining distance for a current dash pattern element and the arc length of the current quadratic Bèzier path segment to generate “on” dash pattern segments. Each “on” dash pattern segment is then bounded by a conservative geometric hull. A point containment technique is then used to identify pixels within each conservative geometric hull that are within half of the stroke width of any point along a path to be stroked.
8698811,"A method for traversing pixels of an area is described. The method includes the steps of traversing a plurality of pixels of an image using a first boustrophedonic pattern along a predominant axis, and, during the traversal using the first boustrophedonic pattern, traversing a plurality of pixels of the image using a second boustrophedonic pattern. The second boustrophedonic pattern is nested within the first boustrophedonic pattern."
8698814,A mapping engine maps general processing clusters (GPCs) within a parallel processing subsystem to screen tiles on a display screen based on the number of enabled streaming multiprocessors (SMs) within each GPC. A given GPC then generates pixels for the screen tiles to which the GPC is mapped. One advantage of the disclosed technique is a given GPC performs a fraction of the processing tasks associated with the parallel processing subsystem that is roughly proportional to the fraction of SMs included within the GPC.
8698816,"Multiple graphics processors in a graphics processing system are interconnected in a unidirectional or bidirectional ring topology, allowing pixels to transferred from any one graphics processor to any other graphics processor. The system can automatically identify one or more “master” graphics processors to which one or more monitors are connected and configures the links of the ring such that one or more other graphics processors can deliver pixels to the master graphics processor, facilitating distributed rendering operations. The system can also automatically detect the connections or lack thereof between the graphics processors."
8698817,A video processor for executing video processing operations. The video processor includes a host interface for implementing communication between the video processor and a host CPU. A memory interface is included for implementing communication between the video processor and a frame buffer memory. A scalar execution unit is coupled to the host interface and the memory interface and is configured to execute scalar video processing operations. A vector execution unit is coupled to the host interface and the memory interface and is configured to execute vector video processing operations.
8698819,"Embodiments for programming a graphics pipeline, and modules within the graphics pipeline, are detailed herein. One embodiment described a method of implementing software assisted shader merging for a graphics pipeline. The method involves accessing a first shader program in memory, and generating a first shader instruction from that program. This first instruction is loaded into an instruction table at a first location, indicated by an offset register. A second shader program in memory is then accessed, and used to generate a second shader instruction. The second shader instruction is loaded into the instruction table at a second location indicated by the offset register."
8698823,"A system and method for facilitating increased graphics processing without deadlock. Embodiments of the present invention provide storage for execution unit pipeline results (e.g., texture pipeline results). The storage allows increased processing of multiple threads as a texture unit may be used to store information while corresponding locations of the register file are available for reallocation to other threads. Embodiments further provide for preventing deadlock by limiting the number of requests and ensuring that a set of requests is not issued unless there are resources available to complete each request of the set of requests. Embodiments of the present invention thus provide for deadlock free increased performance."
8698825,"A system, method, and computer program product are provided for optimizing use of a vertex cache. In use, information is identified, where such information is associated with vertex data stored in a vertex cache. To this end, use of the vertex cache may be optimized utilizing the information. In one embodiment, the information may include new information derived from the vertex data, and optionally index data, prior to processing of the vertex data. Further, the vertex cache may optionally utilize the information to optimize performance of the vertex cache by minimizing a number of cache misses."
8698836,"A system, method, and computer program product are provided for optimizing stratified sampling associated with stochastic transparency. In use, surface data associated with one or more surfaces to be rendered is received. Additionally, the one or more surfaces are rendered, utilizing stochastic transparency, where stratified sampling associated with the stochastic transparency is optimized."
8698837,"One embodiment of the present invention sets forth a technique for rendering clipped paths by first generating clip stencil buffer state indicating pixels that are inside of the clip path. The clip stencil buffer state may also store an opacity value for each covered pixel to generate a mask that modulates the opacity of a draw path that is clipped. Clipped draw stencil buffer state is then generated indicating pixels of the draw path that should be covered based on the clip stencil buffer state and coverage of the draw path. The clipped draw path is then filled or stroked to produce the clipped draw path. The clip and draw paths may be filled or stroked without tessellating the paths. Path rendering may be accelerated when a GPU or other processor that is configured to perform operations to generate the clip stencil buffer state and the clipped draw stencil buffer state, and to fill or stroke the clipped draw path."
8698908,"A rolling shutter digital camera. Each photographic image of a given exposure duration is captured as a multi-frame burst of frames each having a shorter exposure duration to minimize motion blur and to reduce sensor noise by averaging. Each frame is quantized into swaths, captured sequentially by the rolling shutter. Swaths of the first frames are analyzed to select a set of best motion detection reference regions. Swaths of subsequent frames are analyzed versus only those regions, to reduce required computation, and are re-registered accordingly. Corresponding swaths of each frame are accumulated. The accumulator is normalized to the desired bit depth and written as the final image. Averaging of the multiple frames is improved by re-registering swaths rather than entire frames, because of the time delta caused by the rolling shutter. Computation is further reduced by selecting candidate points only along a key line of each swath of the first frame, and still further by pre-limiting the search by using a thumbnail version of the first frame to cull most candidate points. Thresholds are used to ensure adequate motion detection regions are used for each swath."
8698917,"In an embodiment, computational complexity of estimating the actual illuminant of a scene is reduced by examining only a subset of the pixel values generated for a received image frame. In another embodiment, number of rotations of color values is minimized by selecting an area which contains the color cue values of a color in an original/unrotated coordinate space and has boundaries which parallel the axis of the original coordinate space, and rotating a color value only if the color value is within the selected area. In another embodiment, such an area is used in conjunction with a histogram-based approach to determine the actual illuminant."
8698918,"Embodiments of the claimed subject matter are directed to methods for automatic white balancing in an image-capture device. In one embodiment, given an estimated illuminant color (e.g., derived from the Gray World method), a more optimal illuminant color can be found by projecting this point to a plot of common illuminants to determine the closest point on the plot of common illuminants. Once the closest point of the plot of common illuminants is derived, the actual image (e.g., pixel) data of the scene is adjusted by the value of the closest point on the plot of common illuminants so that the light is normalized for the scene."
8699218,"A portable computer system is disclosed according to the invention. The portable computer system comprises: a multi-functional processing unit with power consumption of no more than approximately 10 watts consisting of a single chip having a plurality of processors thereon, wherein each processor is operable for at least one task selected from a group consisting of computing, graphic processing and audio processing; a mother board to which the multi-functional processing unit is connected; a memory unit connected to the motherboard and in communication with the multi-functional processing unit; and an I/O interface connected to the motherboard and in communication with the multi-functional processing unit, the portable computer system is configured to insert into a interface of a peripheral device to communicate between the portable computer system and the peripheral device."
8700387,"Methods and systems for transcoding input audio data in a first encoding format to generate audio data in a second encoding format, and filterbanks for use in such systems. Some such systems include a combined synthesis and analysis filterbank (configured to generate transformed frequency-band coefficients indicative of at least one sample of the input audio data by transforming frequency-band coefficients in a manner equivalent to upsampling the frequency-band coefficients and filtering the resulting up-sampled values to generate the transformed frequency-band coefficients, where the frequency-band coefficients are partially decoded versions of input audio data that are indicative of the at least one sample) and a processing subsystem configured to generate transcoded audio data in the second encoding format in response to the transformed frequency-band coefficients. Some such methods include the steps of: generating frequency-band coefficients indicative of at least one sample of input audio data by partially decoding frequency coefficients of the input audio data; generating transformed frequency-band coefficients indicative of the at least one sample of the input audio data by transforming the frequency-band coefficients in a manner equivalent to upsampling the frequency-band coefficients to generate up-sampled values and filtering the up-sampled values; and in response to the transformed frequency-band coefficients, generating the transcoded audio data so that the transcoded audio data are indicative of each sample of the input audio data."
8700808,"A hardware support system for implementing accelerated disk I/O for a computer system. The system includes a bus interface for interfacing with a processor and a system memory of the computer system, a disk I/O engine coupled to the bus interface, and a device interface coupled to the disk I/O engine for interfacing the disk I/O engine with a disk drive. The disk I/O engine is configured to cause a start up of the disk drive upon receiving a disk start up command from the processor. The disk I/O engine is further configured to execute a disk transaction by processing the disk transaction information from a bypass register coupled to the disk I/O engine."
8700862,A compression status bit cache provides on-chip availability of compression status bits used to determine how many bits are needed to access a potentially compressed block of memory. A backing store residing in a reserved region of attached memory provides storage for a complete set of compression status bits used to represent compression status of an arbitrarily large number of blocks residing in attached memory. Physical address remapping (“swizzling”) used to distribute memory access patterns over a plurality of physical memory devices is partially replicated by the compression status bit cache to efficiently integrate allocation and access of the backing store data with other user data.
8700865,"A shared resource management system and method are described. In one embodiment a shared resource management system includes a plurality of engines, a shared resource, and a shared resource management unit. In one exemplary implementation the shared resource is a memory and the shared resource management unit is a memory management unit (MMU). The plurality of engines perform processing. The shared resource supports the processing. For example, a memory stores information and instructions for the engines. The shared resource management unit manages memory operations and handles access requests associated with compressed data."
8700877,"A method for thread address mapping in a parallel thread processor. The method includes receiving a thread address associated with a first thread in a thread group; computing an effective address based on a location of the thread address within a local window of a thread address space; computing a thread group address in an address space associated with the thread group based on the effective address and a thread identifier associated with a first thread; and computing a virtual address associated with the first thread based on the thread group address and a thread group identifier, where the virtual address is used to access a location in a memory associated with the thread address to load or store data."
8700883,"A memory access technique that provides for overriding a translation lookaside buffer and page table data structure, in accordance with one embodiment of the present invention, includes selectively translating a virtual address directly to a physical address utilizing an adjustment in a context specifier, or translating the virtual address to the physical address utilizing a translation lookaside buffer or page table data structure."
8700925,Metrics representing a combined measure of power used by a central processing unit (CPU) and power used by a graphics processing unit (GPU) are compared to a shared supply power and thermal power budgets. Power used by the CPU and power used by the GPU are regulated in tandem using a fuzzy logic control system that can implement fuzzy rules that describe the management within thermal and supply power design constraints of the platform.
8701057,"An integrated circuit (IC) is designed that includes one variant having a plurality of a modular circuits communicatively coupled together and a second variant having a sub-set of the plurality of modular circuits. The modular circuits are then laid out on a wafer for fabricating each of the variants of the IC. The layout includes routing communicative couplings between the sub-set of the modular circuits of the second variant to the other modular circuits of the first variant in one or more metallization layers to be fabricated last. Fabricating the IC is then started, up to but not including the one or more metallization layers to be fabricated last. One or more of the plurality of variants of the IC is selected based upon a demand predicted during fabrication. Fabrication then continues with the last metallization layers of the IC according to the selected layout."
8701091,"A method and system for application development. Specifically, a generic console interface is provided that is capable of interacting with graphics applications. The console interface is capable of accessing a graphics application by detouring at least one predefined system call made by the graphics application. User input is intercepted that is related to the predefined system call that is detoured. The user input is communicated through the console interface. An operation is performed as implemented by the user input through a dynamically loadable module."
8704275,"A die micro electro-mechanical switch management system and method facilitate power conservation by selectively preventing electrical current from flowing in designated components. A present invention semiconductor die comprises a block of transistors for performing switching operations, a bus (e.g., a power bus, a signal bus, etc.) for conveying electrical current and a micro electro-mechanical switch that couples and decouples the block of transistors to and from the bus. The micro electro-mechanical switch is opened and closed depending upon operations (e.g., switching operations) being performed by the block of transistors. Electrical current is prevented from flowing to the block of transistors when the micro electro-mechanical switch is open and the block of transistors is electrically isolated. The micro electro-mechanical switch can interrupt electrical current flow in a plurality of the bus lines and/or can be included in a relay array."
8704826,"One embodiment of the present invention includes approaches for processing graphics primitives associated with cache tiles when rendering an image. A set of graphics primitives associated with a first render target configuration is received from a first portion of a graphics processing pipeline, and the set of graphics primitives is stored in a memory. A condition is detected indicating that the set of graphics primitives is ready for processing, and a cache tile is selected that intersects at least one graphics primitive in the set of graphics primitives. At least one graphics primitive in the set of graphics primitives that intersects the cache tile is transmitted to a second portion of the graphics processing pipeline for processing. One advantage of the disclosed embodiments is that graphics primitives and associated data are more likely to remain stored on-chip during cache tile rendering, thereby reducing power consumption and improving rendering performance."
8704830,"One embodiment of the present invention sets forth a technique for improving path rendering on computer systems by efficiently representing and computing sub-pixel coverage for path objects. A stencil buffer is configured to store multiple stencil samples per pixel stored in an image buffer. The stencil samples undergo stencil testing to produce a set of Boolean values per pixel, which collectively define a geometric coverage percentage for the pixel. The coverage percentage is used to modulate a color value for the pixel. The modulated color value is then blended into the image buffer as an anti-aliased pixel. This technique advantageously enables efficient anti-aliasing for path rendering."
8704834,"A method for synchronizing an input data stream with an output data stream in a video processor. The method includes receiving an input data stream and receiving an output data stream, wherein the input data stream and the output data stream each comprise a plurality of pixels. The method further includes sequentially storing pixels of the input data stream using an input buffer and sequentially storing pixels of the output data stream using an output buffer. Timing information is determined by examining the input data stream and the output data stream. A synchronization adjustment is applied to the input buffer and the output buffer in accordance with the timing information. Pixels are output from the input buffer and the output buffer to produce a synchronized mixed video output stream."
8704835,"A parallel processing subsystem includes a plurality of general processing clusters (GPCs). Each GPC includes one or more clipping, culling, viewport transformation, and perspective correction engines (VPC). Since VPCs are distributed per GPC, each VPC can process graphics primitives in parallel with the other VPCs processing graphics primitives."
8704836,"One embodiment of the present invention sets forth a technique for parallel distribution of primitives to multiple rasterizers. Multiple, independent geometry units perform geometry processing concurrently on different graphics primitives. A primitive distribution scheme delivers primitives from the multiple geometry units concurrently to multiple rasterizers at rates of multiple primitives per clock. The multiple, independent rasterizer units perform rasterization concurrently on one or more graphics primitives, enabling the rendering of multiple primitives per system clock."
8705630,Described are methods and systems for processing data. A motion estimator uses a block of an input frame of video data and a block of a reference frame of video data to generate motion vectors according to a first encoding scheme. A motion compensator produces half pel motion vectors from the motion vectors according to a second encoding scheme that is different from the first encoding scheme.
8706874,"A method includes registering one or more target computing device(s) with a request processing module of a server computing device and an application executing on a client computing device communicatively coupled to the server computing device, and initiating, through the application, a request to configure a hardware setting on the one or more target computing device(s) based on a communication mechanism. The method also includes processing, through the request processing module, the request to generate a validated message related to the hardware setting configuration and to extract information related to identifiers of the one or more target computing device(s), a hardware thereof and the hardware setting. Further, the method includes redirecting the validated message to the one or more target computing device(s) along with the extracted information, and interpreting the received validated message and the extracted information at the one or more target computing device(s)."
8706917,"The present invention permits an I/O port to be used with a variety of different I/O devices, regardless of their device type implementation. Thus, one set of pins may be used for various different I/O devices."
8706975,"A shared memory management system and method are described. In one embodiment, a memory management system includes a memory management unit for coordinating context memory storage block binds and independently controlling access to the context memory without interference from other engine activities. In one exemplary implementation the context information is included in a block and the memory management unit binds the block to instance memory. The instance memory can be protected memory. The instance memory can also support multiple channels associated with the plurality of engines. In one exemplary implementation, the instance memory includes a pointer to a page table. The instance memory can also include context save and restore data and each one of the plurality of engines initiates a unique block bind by indicating an association between their engine ID and a given block of instance memory."
8707011,"A memory access technique, in accordance with one embodiment of the present invention, includes caching page size data for use in accessing a set-associative translation lookaside buffer (TLB). The technique utilizes a translation lookaside buffer data structure that includes a page size table and a translation lookaside buffer. Upon receipt of a memory access request a page size is looked-up in the page size table utilizing the page directory index in the virtual address. A set index is calculated utilizing the page size. A given set of entries is then looked-up in the translation lookaside buffer utilizing the set index. The virtual address is compared to each TLB entry in the given set. If the comparison results in a TLB hit, the physical address is received from the matching TLB entry."
8707081,"Circuits, methods, and apparatus for slowing clock circuits on a graphics processor integrated circuit in order to reduce power dissipation. An exemplary embodiment of the present invention provides a graphics processor having two memory clocks, specifically, a switched memory clock and an unswitched memory clock. The switched memory clock frequency is reduced under specific conditions, while the unswitched memory clock frequency remains fixed. In a specific embodiment, the switched memory clock frequency is reduced when related graphics, display, scaler, and frame buffer circuits are not requesting data, or are such data requests can be delayed. Further refinements to the present invention provide circuits, methods, and apparatus for ensuring that the switched and unswitched memory clock signals remain in-phase and aligned with each other."
8711155,"A pixel processing system and method which permits rendering of complicated three dimensional images using a shallow graphics pipeline including reduced gate counts and low power operation. Pixel packet information includes pixel surface attribute values retrieved in a single unified data fetch stage. A determination is made if the pixel packet information contributes to an image display presentation (e.g., a depth comparison of Z values may be performed). The pixel packet information processing is handled in accordance with results of the determining. The pixel surface attribute values and pixel packet information are removed from further processing if the pixel surface attribute values are occluded. In one exemplary implementation, the pixel packet includes a plurality of rows and the handling is coordinated for the plurality of rows. Any of a number of downstream pipestages may remove the occluded pixel information, and in response thereto, may notify a gatekeeper pipestage of the slack increase so that more pixels can be allowed into the pipeline."
8711156,"A method and system for remapping units that are disabled to active units in a 3-D graphics pipeline. Specifically, in one embodiment, a method remaps processing elements in a pipeline of a graphics pipeline unit. Graphical input data are received. Then the number of enabled processing elements are determined from a plurality of processing elements. Each of the enabled processing elements are virtually addressed above a translator to virtually process the graphical input data. Then, the virtual addresses of each of the enabled processing elements are mapped to physical addresses of the enabled processing elements at the translator. The graphical input data are physically processed at the physical addresses of the enabled processing elements. In addition, each of the enabled processing elements are physically addressed below the translator to further process the graphical input data."
8711161,"A memory cell reconfiguration process is performed in accordance with the operational characteristic settings determined based upon the results of analysis and/or testing of memory cell operations. The memory circuit can include a plurality of memory cells and memory cell configuration controller. The memory cells store information associated with a variety of operations. The memory cell configuration controller coordinates selective enablement and disablement of each of the plurality of memory cells, which can be done on a subset or group basis (e.g., enables and/or disables memory cells on a word length or row by row basis). The address mapping can be adjusted so that the memory space appears continuous to external components. The memory cell configuration controller can also forward configuration information to upstream and/or downstream components that can adjust operations to compensate for the memory cell configuration (e.g., to prevent overflow)."
8711167,One embodiment of the present invention sets forth a technique for generating and transmitting video frame data from a graphics processing unit (GPU) to a color field sequential display device. A frame buffer image comprising per-pixel packed color channels is transformed to a frame buffer image comprising regions corresponding to the color channels with vertical blanking regions inserted between color sub-field regions. Each region of the transformed frame buffer image is sequentially transmitted to the color field sequential display device for display of the corresponding color channel. Backlight illumination for each color channel is controlled by the GPU for temporal alignment with display of each color channel during a vertical blanking interval. The GPU may compensate an individual pixel's color channel value based on a corresponding previous color channel value in order to minimize crosstalk between neighboring color fields.
8712183,"A system and method for correcting image data. Embodiments of the present invention provide image correction to overcome various lens effects, optical crosstalk, and electrical crosstalk. In one embodiment, the method includes accessing, within an electronic system, a plurality of control points for a patch of a spline surface and calculating a plurality of intermediate control points corresponding to a row of pixels of the patch. The method further includes receiving a pixel of an image and correcting the pixel based on the plurality of intermediate control points in streaming scanline column-wise or row-wise order."
8713262,One embodiment of the present invention sets forth a technique for synchronization between two or more processors. The technique implements a spinlock acquire function and a spinlock release function. A processor executing the spinlock acquire function advantageously operates in a low power state while waiting for an opportunity to acquire spinlock. The spinlock acquire function configures a memory monitor to wake up the processor when spinlock is released by a different processor. The spinlock release function releases spinlock by clearing a lock variable and may clear a wait variable.
8717370,"A method and system for automatically analyzing graphics processing unit (“GPU”) test results are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of identifying the GPU test results associated with a first register type, creating a template document associated with the same first register type, wherein the template document is pre-configured to store and operate on the GPU test results of the first register type, filling the GPU test results in the template document, aggregating the GPU test results associated with the first register type to establish a common output, and determining a suitable register value from a passing range of register values based on the common output without human intervention."
8717371,"A method for transitioning from a first operational mode, where operations are executed on a first processor while a second processor is powered off, to a second operational mode, where operations are executed on the second processor while the first processor is powered off. A driver causes detects a first system event that indicates a transition from the first to the second operational mode is likely. The driver powers on the second processor in response to the first system event and detects a second system event. The driver determines whether each of the client applications can be transferred from the first processor to the second processor without resulting in any data loss, and depending on whether each of the client applications can be transferred, either transfers the client applications from the first to the second processor or continues to cause the operations to be executed in the first operational mode."
8717372,"A method for transitioning from a first operational mode, where operations are executed on a first processor while a second processor is powered off, to a second operational mode, where operations are executed on the second processor while the first processor is powered off. A driver causes detects a first system event that indicates a transition from the first to the second operational mode is likely. The driver powers on the second processor in response to the first system event and detects a second system event. The driver determines whether each of the client applications can be transferred from the first processor to the second processor without resulting in any data loss, and depending on whether each of the client applications can be transferred, either transfers the client applications from the first to the second processor or continues to cause the operations to be executed in the first operational mode."
8718175,"A method, a receiver and computer program product for reporting at least one channel quality indicator from a receiver to a transmitter in a MIMO system are disclosed herein. In one embodiment, the receiver receives one or more data streams transmitted by the transmitter wherein the data streams are processed by the transmitter using a transmission precoding matrix W prior to transmission to the receiver. The receiver estimates a preferred precoding matrix Wp which is preferred by the receiver and processes the received data streams using the transmission precoding matrix W, such that the effective channel G at the output of the signal processing module is dependent upon the transmission precoding matrix W used by the transmitter. The receiver determines a second effective channel Gp, uses it to determine the at least one channel quality indicator and transmits the determined at least one channel quality indicator to the transmitter."
8719585,Techniques for securely updating a boot image without knowledge of a secure key used to encrypt the boot image.
8723231,"A die micro electro-mechanical switch management system and method facilitate power conservation by selectively preventing electrical current from flowing in designated components. A present invention semiconductor die comprises a block of transistors for performing switching operations, a bus (e.g., a power bus, a signal bus, etc.) for conveying electrical current and a micro electro-mechanical switch that couples and decouples the block of transistors to and from the bus. The micro electro-mechanical switch is opened and closed depending upon operations (e.g., switching operations) being performed by the block of transistors. Electrical current is prevented from flowing to the block of transistors when the micro electro-mechanical switch is open and the block of transistors is electrically isolated. The micro electro-mechanical switch can interrupt electrical current flow in a plurality of the bus lines and/or can be included in a relay array."
8723571,"Integrated circuit and method for generating a clock signal, the integrated circuit comprising (i) a frequency locked loop comprising a voltage controlled oscillator configured to receive a control input and to generate a clock signal determined by the control input; and (ii) a microprocessor configured to be powered by a supply voltage and to receive the clock signal generated by the voltage controlled oscillator. The integrated circuit is configured to use the supply voltage as the control input, such that the clock signal is determined by the supply voltage."
8723577,"Method, circuitry and device for spreading a clock signal in which the clock signal is received at an input of a variable delay line, the clock signal having been generated by a clock signal generator. In one embodiment, for each edge of the clock signal, the delay introduced by the variable delay line is set in accordance with a stored delay value. For each of a plurality of consecutive edges of the clock signal, the stored delay value is either incremented or decremented based on a randomly generated value for that edge. A spread version of the clock signal is output from the variable delay line, wherein each edge of the spread version of the clock signal is delayed by the respective delay that is set for that edge of the clock signal."
8723865,"A method for rendering a volumetric shadow includes defining a light source ray emanating from a light source, wherein the light source ray intersects a plurality of occluding primitives included within the scene. The method further includes computing an aggregate absorption function for the light source ray, whereby a per-primitive absorption function is computed for each of the plurality of occluding primitives intersecting the light source ray, and the resulting plurality of per-primitive absorption functions are summed to form an aggregate absorption function for the light source ray. A transmittance value is computed as a function of the aggregate absorption function, the transmittance value used to render the volumetric shadow within the scene."
8723969,"An image processor in an image capture device compensates for the effects of undesirable camera shakes occurring during video capture The image processor receives a pair of source frames representing images of a scene, generates a pair of subsampled frames from the source frames, and computes a coarse displacement of the captured image due to camera shakes by comparing the two subsampled frames. The image processor may then refine the determined coarse displacement by comparing the two source frames and a bound determined by an extent of subsampling, and compensate for the displacement accordingly. Display aberrations such as blank spaces caused due to shifting are also avoided by displaying only a portion of the captured image and shifting the displayed portion to compensate for camera shake. The image processor also recognizes displacements due to intentional camera movement, and does not correct for such displacements."
8724483,"An interface for implementing a loopback configuration which offers improved calibration and/or testing of an electronic system is disclosed. More specifically, embodiments provide a bi-directional interface with at least two portions or partitions capable of communicating data in opposite directions and implementing a loopback configuration between components of an electronic system, thereby enabling more flexible, efficient and effective calibration and/or testing of the electronic system using a single interface. The loopback of the partitioned bi-directional interface may be used to perform data link training and/or electronic system testing. In one embodiment, the loopback configuration of the interface may be reversible. Additionally, the looped or coupled end of the partitions may be switched from one component to another, thereby reversing the configuration of the loopback in one embodiment. As such, embodiments enable different and/or additional calibration operations and/or tests to be performed when compared with conventional loopback configurations."
8724694,"A decoder pipeline may include a decoding (prior to deblocking) stage followed by a deblocking stage. A memory can be coupled to the decoder pipeline. A decoded first macroblock can be output from the decoding stage directly into the deblocking stage, bypassing the memory, if a decoded second macroblock depended on to deblock the first macroblock is already deblocked. Otherwise, the decoded first macroblock is stored in the memory until the second macroblock is deblocked and available to deblock the first macroblock."
8724702,"A framework for efficient sum of absolute difference (SAD) computations for variable block size, sub-pixel motion estimation is presented. Simultaneous, or parallelized, SAD computations can be performed by storing and re-using previous SAD computational information, which can speed up the performance of a motion estimation module by reducing the number of cycles necessary to perform a particular motion estimation algorithm."
8724895,"A technique for reducing artifacts in a digital image, in accordance with one embodiment, includes receiving a stream of raw filter pixel data representing the image. The raw filter pixel data is interpolating to produce red, green-on-red row, green-on-blue row and blue pixel data for each pixel. An artifact in one or more given pixels is reduced as a function of a difference between the green-on-red row and green-on-blue row pixel data of each of the given pixels to generate adjusted interpolated pixel data."
8725504,"An approach to performing inverse quantization on a quantized integral value is described. This approach involves determining whether a quantized integral value lies within a first range or a second range of possible values. An interpolated inverse quantization value is calculated from the quantized integral value, using a predetermined bit shifting operation, depending on whether the quantized integral value was in the first or the second range."
8725990,"A configurable SIMD engine in a video processor for executing video processing operations. The engine includes a SIMD component having a plurality of inputs for receiving input data and a plurality of outputs for providing output data. A plurality of execution units are included in the SIMD component. Each of the execution units comprise a first and a second data path, and are configured for selectively implementing arithmetic operations on a set of low precision or high precision inputs. Each of the execution units have a first configuration and a second configuration, such that the first data path and the second data path are combined to produce a single high precision output in the first configuration, and such that the first data path and the second data path are partitioned to produce a respective first low precision output and second low precision output in the second configuration."
8726124,"Cyclic redundancy check (CRC) values are efficiently calculated using an improved linear feedback shift register (LFSR) circuit. CRC value generation is separated into two sub-calculations, which are then combined to form a final CRC value. A programmable XOR engine performs logic functions via a table lookup rather than via a random logic circuit. LCRC and ECRC calculations are performed using a single shared LFSR circuit. Multiple links share the same CRC value generator. One advantage of the present invention is that CRC values are generated using smaller and fewer LFSR circuits relative to conventional circuit designs. As a result, a CRC value generator utilizing the disclosed techniques consumes less surface area of an integrated circuit and consumes less power, resulting in cooler operation."
8726125,"An approach to reducing interpolation error is described. This approach generally involves using an offset correction table, populated with predetermined offset correction values, to reduce the error introduced by linear interpolation. This approach includes calculating an approximate inverse quantized value. The offset correction table is accessed, and a corrected inverse quantized value is then calculated."
8726205,"A method includes reading, through a processor of a computing device communicatively coupled to a memory, a design of an electronic circuit at a first level higher than a second level at which design verification and/or design simulation of the electronic circuit is to be conducted, and representing instances of elements of the electronic circuit in a data structure. The method also includes parsing, at the first level, the design to automatically generate a list of regular expressions related to text-matching strings with the elements of the electronic circuit based on removing undesired instances related to the elements from the data structure, and pruning, at the second level, connectivity descriptors of the electronic circuit based on the automatically generated list of regular expressions. Further, the method includes optimizing the design verification and/or the design simulation at the second level based on the pruned connectivity descriptors thereof."
8726279,"Methods and system for sharing a hardware resource in a computer system running at least one software process having multiple threads. A lock_indicator is provided in data structures within the computer system. A request is received to use the hardware resource by one of the threads that is defined to be a requesting tread. Based on the lock_indicator, it is determined whether the hardware resource is available for use by the requesting thread. If this indicates that the hardware resource is available, the lock_indicator is set under control of the hardware resource to instead indicate that the hardware resource is unavailable, and a go_indicator signals to indicate that use of the hardware resource for the request can now proceed."
8726283,"Under some conditions, requests transmitted between different devices in a computing system may be blocked in a way that prevents the request from being processed, resulting in a deadlock condition. A skid buffer is used to allow additional requests to be queued in order to remove the blockage and end the deadlock condition. Once the deadlock condition is removed, the requests are processed and the additional buffer entries in the skid buffer are disabled."
8730249,"A parallel array architecture for a graphics processor includes a multithreaded core array including a plurality of processing clusters, each processing cluster including at least one processing core operable to execute a pixel shader program that generates pixel data from coverage data; a rasterizer configured to generate coverage data for each of a plurality of pixels; and pixel distribution logic configured to deliver the coverage data from the rasterizer to one of the processing clusters in the multithreaded core array. A crossbar coupled to each of the processing clusters is configured to deliver pixel data from the processing clusters to a frame buffer having a plurality of partitions."
8730252,"A system, method and computer program product are provided for bump mapping in a hardware graphics processor. Initially, a first set of texture coordinates is received. The texture coordinates are then multiplied by a matrix to generate results. A second set of texture coordinates is then offset utilizing the results. The offset second set of texture coordinates is then mapped to color."
8730253,One embodiment of the present invention sets forth a technique for decomposing and filling cubic Bèzier segments of paths without tessellating the paths. Path rendering may be accelerated when a GPU or other processor is configured to perform the decomposition operations. Cubic Bèzier paths are classified and decomposed into simple cubic Bèzier path segments based on the classification. A stencil buffer is then generated that indicates pixels that are inside of the decomposed cubic Bèzier segments. The paths are then filled according to the stencil buffer to produce a filled path.
8731051,"A video processor is described, which is useful for implementing a quantization process, in compliance with the H.264 standard. The video processor includes an input, for receiving a block of image data. The image data is loaded into an internal register. In response to receiving a SIMD instruction, a quantizer, which incorporates the quantization lookup tables associated with the H.264 standard in its associated hardware, makes necessary high-level quantization decisions. In response to receiving another SIMD instruction, the quantizer uses those high-level quantization decisions to retrieve specific values from the quantization lookup tables."
8731071,"A system for performing finite input response filtering. The system includes an array of random access memories (RAMs) for storing at least one two-dimensional (2D) block of pixel data. The pixel data is stored such that one of each type of column or row from the 2D block of pixel data is stored per RAM. A control block provides address translation between the 2D block of pixel data and corresponding addresses in the array of RAMs. An input crossbar writes pixel data to the array of RAMs as directed by the control block. An output crossbar simultaneously reads pixel data from each of the array of RAMs and passes the data to an appropriate replicated data path, as directed by the control block. A single instruction multiple data path block includes a plurality of replicated data paths for simultaneously performing the FIR filtering, as directed by the control block."
8731694,"In a class of embodiments, a method and apparatus for detecting freefall of a disk device (thereby predicting that the disk device will likely suffer imminent physical impact) and typically also preventing damage that a disk drive of the device would otherwise suffer if and when a predicted impact occurs. In some embodiments, a disk device includes a freefall detection processor and a CPU. The freefall detection processor is configured to monitor acceleration data to determine whether the disk device is in freefall and to perform at least one other operation (e.g., decoding of MP3-encoded audio data to generate decoded audio data) while the CPU performs at least one other task. Other embodiments pertain to a portable device including a digital audio processing subsystem and an accelerometer. The digital audio processing subsystem is configured to monitor acceleration data to identify any rhythm associated with motion of the portable device and to modify the playback of audio data in response to any such identified rhythm."
8732350,"A system for improving direct memory access (DMA) offload. The system includes a processor, a data DMA engine and memory components. The processor selects an executable command comprising subcommands. The DDMA engine executes DMA operations related to a subcommand to perform memory transfer operations. The memory components store the plurality of subcommands and status data resulting from DMA operations. Each of the memory components has a corresponding token associated therewith. Possession of a token allocates its associated memory component to the processor or the DDMA engine possessing the token, making it inaccessible to the other. A first memory component and a second memory component of the plurality of memory components are used by the processor and the DDMA engine respectively and simultaneously. Tokens, e.g., the first and/or the second, are exchanged between the DDMA engine and the processor when the DDMA engine and/or the microcontroller complete accessing associated memory components."
8732496,"A method and apparatus for supporting a self-refreshing display device coupled to a graphics controller are disclosed. A self-refreshing display device has a capability to drive the display based on video signals generated from a local frame buffer. A graphics controller coupled to the display device may optimally be placed in one or more power saving states when the display device is operating in a panel self-refresh mode. Data objects stored in a memory associated with the graphics controller may be aliased in another memory subsystem accessible to the operating system, graphical user interface, or applications executing in the system while the graphics controller is in a deep sleep state. The disclosed technique utilizes a virtual memory pointer, that may be updated in one or more virtual memory page tables to point to either the memory associated with the graphics controller or an alternate memory alias."
8732576,"An operating system providing multi-touch support for (user) applications in a mobile device. In one embodiment, a check of whether the touch screen (in the mobile device) has multi-touch capability is performed. A first interface with multi-touch capability is provided to the (user) applications if the touch screen has multi-touch capability and a second interface with single touch capability being provided if the touch screen does not have multi-touch capability. The first and second interfaces may be provided by corresponding device drivers loaded when the mobile device is initialized with the operating system. A device driver (providing the second interface) is also designed to perform the check and execute another device driver (providing the first interface) if the touch screen has multi-touch capability."
8732644,"The present invention systems and methods enable configuration of functional components in integrated circuits. A present invention system and method utilizes micro electro-mechanical switches included in pathways of an integrated circuit to flexibly change the operational characteristics of functional components in an integrated circuit die based upon a variety of factors including power conservation, manufacturing defects, compatibility characteristics, performance requirements, and system health (e.g., the number of components operating properly). The micro electro-mechanical switches are selectively opened and closed to permit and prevent electrical current flow to and from functional components. Opening the micro electro-mechanical switches also enables power conservation by facilitating isolation of a component and minimization of impacts associated with leakage currents."
8732711,"One embodiment of the present invention sets forth a technique for scheduling thread execution in a multi-threaded processing environment. A two-level scheduler maintains a small set of active threads called strands to hide function unit pipeline latency and local memory access latency. The strands are a sub-set of a larger set of pending threads that is also maintained by the two-leveler scheduler. Pending threads are promoted to strands and strands are demoted to pending threads based on latency characteristics. The two-level scheduler selects strands for execution based on strand state. The longer latency of the pending threads is hidden by selecting strands for execution. When the latency for a pending thread is expired, the pending thread may be promoted to a strand and begin (or resume) execution. When a strand encounters a latency event, the strand may be demoted to a pending thread while the latency is incurred."
8732713,"A parallel thread processor executes thread groups belonging to multiple cooperative thread arrays (CTAs). At each cycle of the parallel thread processor, an instruction scheduler selects a thread group to be issued for execution during a subsequent cycle. The instruction scheduler selects a thread group to issue for execution by (i) identifying a pool of available thread groups, (ii) identifying a CTA that has the greatest seniority value, and (iii) selecting the thread group that has the greatest credit value from within the CTA with the greatest seniority value."
8736617,"A method of displaying graphics data is described. The method involves accessing the graphics data in a memory subsystem associated with one graphics subsystem. The graphics data is transmitted to a second graphics subsystem, where it is displayed on a monitor coupled to the second graphics subsystem."
8736620,"A present invention pixel processing system and method permit complicated three dimensional images to be rendered with shallow graphics pipelines including reduced gate counts and also facilitates power conservation. Pixel packet information includes pixel surface attribute values are retrieved in a single unified data fetch stage. At a data fetch pipestage a determination may be made if the pixel packet information contributes to an image display presentation (e.g., a depth comparison of Z values is performed determine if the pixel is occluded). A pixel packet status indicator (e.g., a kill bit) is set in the sideband portion of a pixel packet and the pixel packet is forwarded for processing in accordance with the pixel packet status indicator. The status indicator is a kill bit is set to prevent logic components from clocking information for a payload portion of the pixel packet if the status indicator indicates the pixel packet payload does not contribute to the image display presentation while continuing to clock pixel packet sideband information."
8736623,A method for using a programmable DMA engine to implement memory transfers and video processing for a video processor. A DMA control program is configured for controlling DMA memory transfers between a frame buffer memory and a video processor. The DMA control program is stored in the DMA engine. A DMA request can be received from the video processor. The DMA control program is executable to implement the DMA request for the video processor. The DMA engine is operable to execute low-level command for accessing the frame buffer memory to implement a high-level command.
8736624,"Detailed herein are approaches to enabling conditional execution of instructions in a graphics pipeline. In one embodiment, a method of conditional execution controller operation is detailed. The method involves configuring the conditional execution controller to evaluate conditional test. A pixel data packet is received into the conditional execution controller, and evaluated, with reference to the conditional test. A conditional execution flag, associated with the pixel data packet, is set, to indicate whether a conditional operation should be performed on the pixel data packet."
8736628,"A present invention pixel processing system and method permit complicated three dimensional images to be rendered with shallow graphics pipelines including reduced gate counts and facilitates power conservation by utilizing a single unified data fetch stage (e.g., unified data fetch module) that retrieves a variety of different pixel surface attribute values for different attribute types (e.g., depth, color, and/or texture values) in a single stage. Different types of pixel surface attribute data (e.g., depth, color, texture) associated with multiple graphics processing functions (e.g., color blending, texture mapping, etc.) are retrieved in the single unified data fetch graphics pipeline stage. The pixel packet rows including the pixel surface attribute values are forwarded to other graphics pipeline stages for single thread processing (e.g. to a universal arithmetic logic unit capable of performing multiple graphics functions on the pixel surface attribute values)."
8737832,A flicker band automated detection system and method are presented. In one embodiment an incidental motion mitigation exposure setting method includes receiving image input information; performing a motion mitigating flicker band automatic detection process; and implementing exposure settings based upon results of the motion mitigating flicker band automatic detection process. The auto flicker band detection process includes performing a motion mitigating process on an illumination intensity indication. Content impacts on an the motion mitigated illumination intensity indication are minimized. The motion mitigated illumination intensity indication is binarized. A correlation of the motion mitigated illumination intensity and a reference illumination intensity frequency is established.
8738382,"Audio feedback time shifted filtering systems and methods are presented. The systems and methods facilitate separation of program audio feedback from received environmental audio (e.g., audio sensed by a microphone.) The separation of the program audio feedback reduces interference from program content audio feedback on performance of voice recognition operations. In one embodiment of a personal video recorder audio filter method, environmental audio patterns are received, an audio feedback time shift filter process is executed for separating out program content from the environmental audio patterns, and voice recognition is performed on the filtered environment audio patterns (without interference from program audio content feedback). The time shift or deterministic delay provides a closer correlation between program audio content and program audio content feedback received at the microphone and permits input timing compensation to compensate for feedback loop delays."
8738580,"An aspect of the present invention stores files of a source directory in a target directory. In an embodiment, a unique identifier is generated for each of the files and a new location and a new name are generated for the file. The new location represents the specific sub-directory of the target at which the file is stored. The file is stored at the new location with the new name. Such storing in a new location with a new name can be advantageously used to address various issues in corresponding environments. In one environment, the target directory is stored in an embedded system, with limited resources and the source directory contains several files with substantial overlapping names (which can require substantial resources to search for a specific file). The unique identifiers are generated according to media transfer protocol (MTP), which generates an object identifier for each of the files/directories, etc."
8738800,"Described are data structures, and methodology for forming same, for network protocol processing. A method for creating data structures for firewalling and network address translating is described. A method for creating data structures for physical layer addressing is described. A method for security protocol support using a data structure is described. A method for creating at least one data structure sized responsive to whether a firewall is activated is described. A data structure for routing packets is described. A method of forming hashing table chains is described. Additionally, method and apparatus for tracking packet states is described. More particularly, Transmission Control Protocol (“TCP”) tracking of states for packets is described. In an embodiment, a division between software states and hardware states is made as a packet is processed by both software and hardware. Additionally, method and apparatus for network protocol processing are described. For example, a packet for network address translation having a media access control header is obtained, from which information, including the media access control header, is obtained. The information is parsed into one or more data structures. It is determined whether a network processing unit is in a first round processing mode, or a second round pass-through mode."
8738852,"A memory controller and a dynamic random access memory (DRAM) interface are disclosed. The memory controller implements signals for the DRAM interface. The DRAM interface includes a differential clock signal, an uncalibrated parallel command bus, and a high-speed, serial address bus. The command bus may be used to initiate communication with the memory device upon power-up and to initiate calibration of the address bus."
8738891,"A method for implementing command acceleration. The method includes receiving a first set of instructions from a first processor, wherein the first set of instructions are formatted in accordance with a microarchitecture of the first processor. The first set of instructions are translated into a second set of instructions, wherein the second set of instructions are formatted in accordance with a microarchitecture of a second processor. The second set instructions are then transmitted to the second processor for execution by the second processor."
8738945,"Circuits, methods, and systems that reduce or eliminate the number of data transfers between a system memory and a graphics processor under certain conditions. After inactivity by a user of an electronic device is detected, the color fidelity of pixels being displayed is reduced. Color fidelity can be reduced by compressing pixel values, and the compression may be non-lossless, for example, pixel data bits may be truncated. The degree of compression can be progressively increased for longer durations of inactivity, and this progression may be limited by a threshold. Inactivity may be detected by a lack of input from devices such as a keyboard, pen, mouse, or other input device. Once activity is resumed, uncompressed pixel data, or pixel data that is compressed in a lossless manner, is displayed."
8738990,"Cyclic redundancy check (CRC) values are efficiently calculated using an improved linear feedback shift register (LFSR) circuit. CRC value generation is separated into two sub-calculations, which are then combined to form a final CRC value. A programmable XOR engine performs logic functions via a table lookup rather than via a random logic circuit. LCRC and ECRC calculations are performed using a single shared LFSR circuit. Multiple links share the same CRC value generator. One advantage of the present invention is that CRC values are generated using smaller and fewer LFSR circuits relative to conventional circuit designs. As a result, a CRC value generator utilizing the disclosed techniques consumes less surface area of an integrated circuit and consumes less power, resulting in cooler operation."
8742796,Embodiments of the present technology are directed toward circuits for gating pre-charging sense nodes within a flip-flop when an input data signal changes and a clock signal is in a given state. Embodiments of the present technology are further directed toward circuits for maintaining a state of the sense nodes.
8743019,Embodiments of the present invention include a host computer system implemented method comprising receiving an indication of total requested display size of a remotely coupled client computer system. The method further includes automatically determining a number of display screens and a predetermined average display screen size. The method further includes an operating system of the host computer system allocating therein a display area to accommodate the total requested display size and dividing the display area into a number of separate portions equal to the number of display screens usable by the client computer system. The method further includes allocating each separate portion of the display area of the host computer system to a respective display screen of the client computer wherein each separate portion so allocated functions as a separate and independent display screen.
8743142,"A present invention pixel processing system and method permit complicated three dimensional images to be rendered with shallow graphics pipelines including reduced gate counts and facilitates power conservation by utilizing a single unified data fetch stage (e.g., unified data fetch module) that retrieves a variety of different pixel surface attribute values (e.g., depth, color, and/or texture values) in a single stage. Different types of pixel surface attribute data (e.g., depth, color, texture) associated with multiple graphics processing functions (e.g., color blending, texture mapping, etc.) are retrieved in the single unified data fetch graphics pipeline stage. The pixel surface attribute values may be placed in corresponding variable fields of a pixel packet row. The pixel packet rows including the pixel surface attribute values are forwarded to downstream graphics pipeline stages (e.g., an arithmetic logic pipestage)."
8745200,"Testing operation of processors setup to operate in different modes. In an embodiment, each tester system includes a processor setup to operate in a corresponding mode. A user sends a test request to a scheduler system indicating the mode of the processor sought to be tested, and the scheduler system forwards the test request to one of the tester systems with a processor setup to test the requested configuration. The scheduler system may maintain configuration information indicating which processors are setup to test which modes of interest, and also status information indicating which tester systems are presently available for testing. The configuration information and status information is used in determining a specific suitable tester system to which a test request is to be forwarded."
8745366,"A method and apparatus for supporting a self-refreshing display device coupled to a graphics controller are disclosed. A technique for setting the operating state of the graphics controller during initialization from a deep sleep state is described. The graphics controller may set the operating state based on a signal that controls whether the graphics controller executes a warm-boot initialization procedure or a cold-boot initialization procedure. In the warm-boot initialization procedure, instructions and values stored in a non-volatile memory connected to the graphics controller may be used to set the operating state of the graphics controller. In one embodiment, the graphics controller may determine whether any changes have been made to the physical configuration of the computer system and, if the physical configuration has changed, the graphics controller may set the operating state based on values received from a software driver."
8749561,A method and system for coordinated data execution in a computer system. The system includes a first graphics processor coupled to a first memory and a second graphics processor coupled to a second memory. A graphics bus is configured to couple the first graphics processor and the second graphics processor. The first graphics processor and the second graphics processor are configured for coordinated data execution via communication across the graphics bus.
8749562,"A system and method for sharing binding groups between shaders allows for efficient use of shader state data storage resources. In contrast with conventional graphics processors and Application Programming Interfaces that specify a set of binding points for each shader that are exclusive to that shader, two or more shaders may reference the same binding group that includes multiple binding points. As the number and variety of different shaders increases, the number of binding groups may increase at a slower rate since some binding groups may be shared between different shaders."
8749564,"One embodiment of the present invention includes a graphics subsystem. The graphics subsystem includes a first processing entity and a second processing entity. Both the first processing entity and the second processing entity are configured to receive first and second batches of primitives, and a barrier command in between the first and second batches of primitives. The barrier command may be either a tiled or a non-tiled barrier command. A tiled barrier command is transmitted through the graphics subsystem for each cache tile. A non-tiled barrier command is transmitted through the graphics subsystem only once. The barrier command causes work that is after the barrier command to stop at a barrier point until a release signal is received. The back-end unit transmits a release signal to both processing entities after the first batch of primitives has been processed by both the first processing entity and the second processing entity."
8749576,A rasterizer stage configured to implement multiple interpolators for graphics pipeline. The rasterizer stage includes a plurality of simultaneously operable low precision interpolators for computing a first set of pixel parameters for pixels of a geometric primitive and a plurality of simultaneously operable high precision interpolators for computing a second set of pixel parameters for pixels of the geometric primitive. The rasterizer stage also includes an output mechanism coupled to the interpolators for routing computed pixel parameters into a memory array. Parameters may be programmably assigned to the interpolators and the results thereof may be programmably assigned to portions of a pixel packet.
8749662,"A system and method for correcting image data. Embodiments of the present invention provide calibration and image correction to overcome various lens effects including lens shading and lens imperfections. In one embodiment, the correction of image data is performed via utilization of a spline surface (e.g., Bezier surface). The use of spline surfaces facilitates efficient hardware implementation. The image correction may be performed on a per channel and illumination type basis. In another embodiment, the present invention provides a method for determine a spline surface to be used for calibrating an image signal processor to be used in correcting image data."
8751771,"One embodiment of the present invention sets forth a technique providing an optimized way to allocate and access memory across a plurality of thread/data lanes. Specifically, the device driver receives an instruction targeted to a memory set up as an array of structures of arrays. The device driver computes an address within the memory using information about the number of thread/data lanes and parameters from the instruction itself. The result is a memory allocation and access approach where the device driver properly computes the target address in the memory. Advantageously, processing efficiency is improved where memory in a parallel processing subsystem is internally stored and accessed as an array of structures of arrays, proportional to the SIMT/SIMD group width (the number of threads or lanes per execution group)."
8751825,"A method of storing content, in accordance with one embodiment of the present invention, includes receiving an item of content in a protected format and a key corresponding to the item of content. The item of content in its protected format may be stored on a mass storage device. The key may also be stored in a safeguarded format on the mass storage device."
8752018,"One embodiment of the present invention sets forth a technique for emitting coherent output from multiple threads for the printf( ) function. Additionally, parallel (not divergent) execution of the threads for the printf( ) function is maintained when possible to improve run-time performance. Processing of the printf( ) function is separated into two tasks, gathering of the per thread data and formatting the gathered data according to the formatting codes for display. The threads emit a coherent stream of contiguous segments, where each segment includes the format string for the printf( ) function and the gathered data for a thread. The coherent stream is written by the threads and read by a display processor. The display processor executes a single thread to format the gathered data according to the format string for display."
8756482,"Encoding data by first performing a transformation of predicted data and input data, and then performing a subtraction of the resulting outputs. In an embodiment, the prediction approach is chosen such that fewer elements of different values (compared to a number of elements in the input data) are generated, and the different values are generated in a predictable position. The transformation approach is chosen such that the output expressly represents variations in the input data as well as satisfies a distributive property. The decoding may be performed based on the same concepts. As a result, the data can be encoded and/or decoded efficiently."
8760204,A method and a system are provided for variation-tolerant synchronization. A phase value representing a phase of a second clock signal relative to a first clock signal and a period value representing a relative period between the second clock signal and the first clock signal are received. An extrapolated phase value of the second clock signal relative to the first clock signal corresponding to a next transition of the first clock signal is computed based on the phase value and the period value.
8760455,"One embodiment of the present invention sets forth a technique for reducing overhead associated with transmitting primitive draw commands from memory to a graphics processing unit (GPU). Command pairs comprising an end draw command and a begin draw command associated with a conventional graphics application programming interface (API) are selectively replaced with a new construct. The new construct is a reset topology index, which implements a combined function of the end draw command and begin draw command. The new construct improves efficiency by reducing total data transmitted from memory to the GPU."
8760460,"One embodiment of the present invention sets forth a technique for using a shared memory to store hardware-managed virtual buffers. A circular buffer is allocated within a general-purpose multi-use cache for storage of primitive attribute data rather than having a dedicated buffer for the storage of the primitive attribute data. The general-purpose multi-use cache is also configured to store other graphics data sinces the space requirement for primitive attribute data storage is highly variable, depending on the number of attributes and the size of primitives. Entries in the circular buffer are allocated as needed and released and invalidated after the primitive attribute data has been consumed. An address to the circular buffer entry is transmitted along with primitive descriptors from object-space processing to the distributed processing in screen-space."
8760535,"In an embodiment, computational complexity of estimating the actual illuminant of a scene is reduced by examining only a subset of the pixel values generated for a received image frame. In another embodiment, number of rotations of color values is minimized by selecting an area which contains the color cue values of a color in an original/unrotated coordinate space and has boundaries which parallel the axis of the original coordinate space, and rotating a color value only if the color value is within the selected area. In another embodiment, such an area is used in conjunction with a histogram-based approach to determine the actual illuminant."
8761046,"A modem is disclosed that, in one embodiment, includes: first interface apparatus comprising a first wireless transceiver arranged to connect to a wireless cellular network; second interface apparatus arranged to connect to the terminal; and processing apparatus configured as a wireless cellular modem for accessing packet-based communications. The processing apparatus is arranged to receive at least one first address from the wireless cellular network via the first interface apparatus, the first address being an address of a server of a name-to-address resolution system. The processing apparatus is further configured to intercept, via the second interface apparatus, a name-to-address resolution query being conveyed from the terminal to the wireless cellular network comprising a second address as a destination address, to translate the second address into the first address, and to retransmit the query to the wireless cellular network via the first interface apparatus with the first address as the destination address."
8761253,"The following embodiments describe an approach for selecting an intra prediction mode for video encoding, such as occurs in the H.264 standard. One embodiment describes a method of selecting an optimum intra prediction mode. This method involves selecting a first intra prediction mode, which is used to determine a search order for a number of intra prediction modes. These intra prediction modes are then evaluated in order to identify the optimum intra prediction mode."
8761538,"In a deblocking operation, pixel values within a first block of pixels are compared, and pixel values in the first block are also compared to pixel values in a second block of pixels that is adjacent to the first block. Based on the results of the comparisons, a digital deblocking filter and a region of interest can be selected, where the region of interest identifies a number of pixels in the first block and a number of pixels in the second block to which the selected filter is to be applied."
8762214,"A method for hierarchical product selection and purchasing from a server. The method includes accessing a plurality of products from a plurality of component subareas, wherein the products are for an assembly of a computer system, and wherein each of the component subareas have corresponding compatibility constraints with respect to other component subareas. A hierarchical presentation of the products is generated, wherein the presentation proceeds from a parent product out of the plurality of products to a child product out of the plurality of products. The hierarchical presentation of the products are provided to a client computer system via a Web browser hosted on the client computer system, wherein the presentation is configured to show child component subareas that satisfy compatibility restraints with parent component subareas. An order for the at least one product is accepted and implemented with a corresponding e-commerce agent for the product."
8762444,"In one embodiment, a microprocessor includes fetch logic for retrieving an instruction, decode logic configured to identify an arithmetic operation specified in the instruction, and execution logic configured to receive operands specified by the instruction. The execution logic includes a primary logic path configured to perform the arithmetic operation on such operands and a secondary parallel logic path configured to output metadata associated with the result of the arithmetic operation."
8762759,"To reduce power consumption, a processor can be placed into a reduced power state. Before doing so, interrupt events can be designated as wakeup events. While the processor is in the reduced power state, if an event designated as a wakeup event occurs, then a signal is directed to a wakeup event handler instead of to an interrupt handler. In response to the signal, the wakeup event handler causes power to be restored to the processor, so that the event can be subsequently serviced."
8762761,"An integrated circuit, in accordance with embodiments of the present technology, includes a plurality of engines, a plurality of engine level power gating (ELPG) controllers, and a power gating arbiter for implementing engine level power gating arbitration techniques. The power gating arbiter may receive requests from one or more ELPG controllers to turn on their respective engines or portions therein. The power gating arbiter prioritizes the request and sends an acknowledgment to a given ELPG controller to turn on or off its corresponding engine according to the prioritized predetermined order. After receiving the acknowledgement, the given ELPG controller turns on or off its corresponding engine and returns an indication to the power gating arbiter that the corresponding engine is turned on or off. The process may be iteratively repeated for each received request after receiving the indication from the previously serviced ELPG controller that its corresponding engine is turned on or off."
8766988,One embodiment of the present invention sets forth a technique for providing state information to one or more shader engines within a processing pipeline. State information received from an application accessing the processing pipeline is stored in constant buffer memory accessible to each of the shader engines. The shader engines can then retrieve the state information during execution.
8766989,"The present invention provides a method and system for coordinating graphics processing units in a single computing system. A method is disclosed which allows for the construction of a list of shared display modes that may be employed by both of the graphics processing units to render an output in a display device. By creating the list of shared commonly supportable display modes, the output displayed in the display device may advantageously provide a consistent graphical experience persisting through the use of alternate graphics processing units in the system. One method builds a list of shared display modes by compiling a list from a GPU specific base mode list and dynamic display modes acquired from an attached display device. Another method provides the ability to generate graphical output configurations according to a user-selected display mode that persists when alternate graphics processing units in the system are used to generate graphical output."
8768160,A flicker band automated detection system and method are presented. In one embodiment an incidental motion mitigation exposure setting method includes receiving image input information; performing a motion mitigating flicker band automatic detection process; and implementing exposure settings based upon results of the motion mitigating flicker band automatic detection process. The auto flicker band detection process includes performing a motion mitigating process on an illumination intensity indication. Content impacts on an the motion mitigated illumination intensity indication are minimized. The motion mitigated illumination intensity indication is binarized. A correlation of the motion mitigated illumination intensity and a reference illumination intensity frequency is established.
8768494,"Embodiments of the invention provide a policy-based audio system. The system includes a sound application protocol interface, a configuration module and a speaker driver. The sound application protocol interface receives a set of sound samples generated by an application or event. The configuration module retrieves a first group of one or more parameters, rules and priorities applicable to the application or event. The speaker driver produces an audio output by processing the set of sound samples as a function of the group of one or more configuration parameters, rules and priorities."
8768642,"The present invention systems and methods facilitate configuration of functional components included in a remotely located integrated circuit die. In one exemplary implementation, a die functional component reconfiguration request process is engaged in wherein a system requests a reconfiguration code from a remote centralized resource. A reconfiguration code production process is executed in which a request for a reconfiguration code and a permission indicator are received, validity of permission indicator is analyzed, and a reconfiguration code is provided if the permission indicator is valid. A die functional component configuration process is performed on the die when an appropriate reconfiguration code is received by the die. The functional component configuration process includes directing alteration of a functional component configuration. Workflow is diverted from disabled functional components to enabled functional components."
8769413,"A system, method and article of manufacture provide a multifunction toolbar for a web browser. A toolbar is displayed over a web browser. The toolbar is linked to a portal of a user. The portal is for aggregating content selected by the user. A bucket is presented on the toolbar. The present invention recognizes when the user selects content on a website, which is displayed on the web browser, and drops the content in the bucket. The selected content is added to the portal."
8769463,"Embodiments of the claimed subject matter are directed to methods and a system that use a standardized grid of clock buffers to automatically route clocks according to a uniform clock grid throughout an ASIC of a non-uniform arrangement of non-uniformly sized logic partitions. According to one embodiment, clock sources and sinks are mapped to grid point locations and a novel grid routing process is performed to link them together. A clock routing macro is assigned to a corresponding partition and associated with the corresponding partition or logic unit according to a partition hierarchy. The underlying routing structure and resources of a clock routing macro are automatically renamed to correspond to the local partition in a script or schedule of programmed instructions, or a routing map. The position of blockages within a partition may also be detected and alternate routes for traversing the blockage may be preemptively determined as well."
8769569,"A system, method, and computer program product are provided for delivering video content over a wide area network (WAN). Included is at least one server for transcoding or transrating the video content for delivery over the WAN."
8773422,"A system, method, and computer program product are provided for grouping linearly ordered primitives. In operation, a plurality of primitives are linearly ordered. Additionally, the primitives are grouped. Furthermore, at least one intersection query is performed, utilizing the grouping."
8773439,"One embodiment of the present invention sets forth a technique for subdividing stroked higher-order curved segments into quadratic Bèzier curve segments. Path stroking may be accelerated when a GPU or other processor is configured to perform the subdivision operations. Cubic Bèzier path segments are subdivided into quadratic Bèzier curve segments and other lower-order segments at key features. The quadratic Bèzier curve segments approximate the cubic Bèzier path segments. A variance metric is computed for each quadratic Bèzier curve segment, and when the variance metric indicates that the quadratic Bèzier curve segment deviates by more than a threshold from the corresponding portion of the cubic Bèzier path segment, the quadratic Bèzier curve segment is further subdivided. The path composed of the quadratic Bèzier curve segments is then stroked by rendering hull geometry that encloses the path."
8773443,"The graphics co-processing technique includes rendering a frame of red, green, blue (RGB) data on a graphics processing unit on an unattached adapter. The frame of RGB data are converted on the graphics processing unit on the unattached adapter to luminance-color difference (YUV) data. The YUV data is copied from frame buffers of the graphics processing unit on the unattached adapter to buffers in system memory. The YUV data is copied from the buffers in the system memory to texture buffers of a graphics processing unit on a primary adapter. A frame of RGB data is recovered from the YUV data in the texture buffer of the graphics processing unit on the primary adapter. The recovered frame of RGB data may then be presented by the graphics processing unit on the primary adapter on the primary display."
8773445,"One embodiment of the present invention sets forth a method, which includes the steps of generating a first rendered image associated with a first application, independently generating a second rendered image associated with a second application, applying a first set of blending weights to the first rendered image to establish a first weighted image, applying a second set of blending weights to the second rendered image to establish a second weighted image, and blending the first weighted image and the second weighted image before scanning out a blended result to a first display device."
8773447,A method for tag logic score boarding in a graphics pipeline of a graphics processor. The method includes receiving a graphics primitive for rasterization in a raster stage of a graphics processor and rasterizing the graphics primitive to generate a plurality of pixels of pixels related to the graphics primitive. The method further includes accounting for an initiation of parameter evaluation for each of the plurality of pixels as the pixels are transmitted to a subsequent stage of the graphics pipeline and accounting for a completion of parameter evaluation for each of the plurality of pixels as the pixels complete processing in the subsequent stage of the graphics pipeline. Respective tag memory is allocated to track the initiation of parameter evaluation and the completion of parameter evaluation for each of the plurality of pixels.
8775112,"The present invention systems and methods facilitate increased die yields by flexibly changing the operational characteristics of functional components in an integrated circuit die. The present invention system and method enable integrated circuit chips with defective functional components to be salvaged. Defective functional components in the die are disabled in a manner that maintains the basic functionality of the chip. A chip is tested and a functional component configuration process is performed on the chip based upon results of the testing. If an indication of a defective functional component is received, the functional component is disabled. Workflow is diverted from disabled functional components to enabled functional components."
8775229,"Automated methods for correcting the remaining portion of a project schedule in order to reflect actual performance to date are provided. For some embodiments, the remaining schedule is corrected by applying factors that are extrapolated from the actual completion times of project milestones in comparison to the scheduled times for the same milestones. This approach results in a project schedule that is more accurate, and thus enables improved management of the project."
8775494,"A computer-implemented method for executing a floating-point calculation where an exact value of an associated result cannot be expressed as a floating-point value is disclosed. The method involves: generating an estimate of the associated result and storing the estimate in memory; calculating an amount of error for the estimate; determining whether the amount of error is less than or equal to a threshold of error for the associated result; and if the amount of error is less than or equal to the threshold of error, then concluding that the estimate of the associated result is a correctly rounded result of the floating-point calculation; or if the amount of error is greater than the threshold of error, then testing whether the floating-point calculation constitutes an exception case."
8775704,"A method for communication over an SMB, I2C bus, or other serial bus between an auxiliary display subsystem and a secondary processor of a notebook including the auxiliary display subsystem, and systems, circuits and notebooks configured to perform the method. Typically, communication over the serial bus between the auxiliary display subsystem and secondary processor can occur when the notebook is in a standby or other low-power state (e.g., to obtain system status data or cause the notebook to wake up) or a fully-powered normal operating state. Typically, the auxiliary display subsystem is coupled not only to the notebook's secondary processor by the serial bus but also to the notebook's central processing unit by another link (e.g., a USB)."
8775777,"Sourcing immediate values from a very long instruction word includes determining if a VLIW sub-instruction expansion condition exists. If the sub-instruction expansion condition exists, operation of a portion of a first arithmetic logic unit component is minimized. In addition, a part of a second arithmetic logic unit component is expanded by utilizing a block of a very long instruction word, which is normally utilized by the first arithmetic logic unit component, for the second arithmetic logic unit component if the sub-instruction expansion condition exists."
8775843,"A central processing unit (CPU) can specify an initial (e.g., baseline) frequency for a clock signal used by a device to perform a task. The CPU is then placed in a reduced power mode. The device performs the task after the CPU is placed in the reduced power mode until a triggering event causes the device to send an interrupt to the CPU. In response to the interrupt, the CPU awakens to dynamically adjust the clock frequency. If the clock frequency is reset to the baseline value, then the CPU is again placed in the reduced power mode."
8775997,"The present invention systems and methods enable configuration of functional components in integrated circuits. A present invention system and method can flexibly change the operational characteristics of functional components in an integrated circuit die based upon a variety of factors including manufacturing defects, compatibility characteristics, performance requirements, and system health (e.g., the number of components operating properly). Functional component operational behavior is tested and analyzed at various levels of configuration abstraction and component organization (e.g., topological inversion analysis). The testing and analysis can be performed in parallel on numerous functional components. Functional component configuration related information is presented in a graphical user interface (GUI) at various levels of granularity and in real time. The graphical user interface can facilitate user interaction in recognizing failure patterns, production test tuning and field configuration algorithm adjustment. The testing and analysis information can also be organized in a variety of convenient database formats."
8776030,One embodiment of the present invention sets forth a technique for translating application programs written using a parallel programming model for execution on multi-core graphics processing unit (GPU) for execution by general purpose central processing unit (CPU). Portions of the application program that rely on specific features of the multi-core GPU are converted by a translator for execution by a general purpose CPU. The application program is partitioned into regions of synchronization independent instructions. The instructions are classified as convergent or divergent and divergent memory references that are shared between regions are replicated. Thread loops are inserted to ensure correct sharing of memory between various threads during execution by the general purpose CPU.
8779793,"A system and method for non-isothermal temperature cycling (also called Conduction Temperature Cycling) of a semiconductor device. The method includes inserting a semiconductor device into a testing chamber and thermally coupling the semiconductor device to a heating and cooling element via a vacuum holding component. The method further includes heating and cooling a die portion of the semiconductor device with the heating and cooling element and testing the semiconductor device for component failure caused by thermo-mechanical stress induced by the non-isothermal temperature cycling. In one embodiment, the heating and cooling comprises non-isothermal temperature cycling."
8780122,"A method for transferring graphics data includes receiving graphics data in the system memory. The graphics data may be loaded into system memory by and application from a mass storage device. One or more graphics commands associated with the graphics data may also be received. The graphics commands may also be received from the application. The graphics data in system memory is compressed in response to receipt of the one or more graphics commands before the graphics data is transferred to a discrete graphics processing unit. The one or more received graphics commands are transferred to the discrete graphics processing unit. The one or more graphics commands include an operation to copy the compressed graphics data to the discrete graphics processing unit. The compressed graphics data is copied from the system memory to memory of the graphics processing. The compressed graphics data is then decompressed by the graphics processing unit. Thereafter, the discrete graphics processing unit may perform one or more graphics operations on the transferred graphics data."
8780123,"Techniques for handling an interrupt in the rasterizer, in accordance with embodiment of the present technology, start with rasterizing one or more primitives of a first context. If an interrupt is received, state information of the rasterizer is saved in a backing store after coarse rasterizing a given tile. After storing the raster state information, the one or more primitives of a second context are rasterized. After the second context is served, the raster state information of the first context is restored and rasterization of the one or more primitives of the first context is restarted."
8780128,"Data for data elements (e.g., pixels) can be stored in an addressable storage unit that can store a number of bits that is not a whole number multiple of the number of bits of data per data element. Similarly, a number of the data elements can be transferred per unit of time over a bus, where the width of the bus is not a whole number multiple of the number of bits of data per data element. Data for none of the data elements is stored in more than one of the storage units or transferred in more than one unit of time. Also, data for multiple data elements is packaged contiguously in the storage unit or across the width of the bus."
8782291,"In some embodiments, a notebook including a content source (e.g., a DVD or other display data source), mass storage device (e.g., hard disk drive), auxiliary display subsystem (including an auxiliary processor), PC chipset, a multiplexer between the content source, auxiliary processor, and PC chipset, and another multiplexer between the mass storage device, auxiliary processor and PC chipset, and methods implemented thereby. The auxiliary display subsystem can be operable (without communicating with the notebook's CPU) when the notebook is in a low-power state."
8782349,"Techniques are disclosed for maintaining cache coherency across a serial interface bus such as a Peripheral Component Interconnect Express (PCIe) bus. The techniques include generating a snoop request (SNP) to determine whether first data stored in a local memory is coherent relative to second data stored in a data cache, the snoop request including destination information that identifies the data cache on the serial interface bus and causing the snoop request to be transmitted over the serial interface bus to a second processor. The techniques further include extracting a cache line address from the snoop request, determining whether the second data is coherent, generating a complete message (CPL) indicating that the first data is coherent with the second data, and causing the complete message to be transmitted over the bus to the first processor. The snoop request and complete messages may be vendor defined messages."
8782611,"One embodiment of the invention sets forth a mechanism for debugging PPU code executing on a PPU where many thread groups simultaneously execute the same instruction on different slices of input data. A debugger engine receives breakpoint information associated with a breakpoint set on a specific instruction within PPU code. The debugger engine then injects a debugging routine into compiled PPU code. A driver notifies the debugger engine when the specific instruction within the PPU code is executed. The debugger engine then retrieves thread state information associated with each thread group in a set of thread groups being inspected from the PPU via the PPU driver. Among other things, thread state information includes the execution state of each thread in each thread group and values of variables included in the PPU code. The thread state information is then transmitted to the debugger user interface for display to a software developer."
8786345,"One embodiment of the present invention sets forth a technique for capturing and storing a level of an input signal using a single-trigger low-energy flip-flop circuit that is fully-static and insensitive to fabrication process variations, The single-trigger low-energy flip-flop circuit presents only three transistor gate loads to the clock signal and none of the internal nodes toggle when the input signal remains constant, The output signal Q is set or reset at the rising clock edge using a single- trigger sub-circuit. A set or reset may be armed while the clock signal is low, and the set or reset is triggered at the rising edge of the clock."
8786478,"A processor and a circuit implementing a continuous-time deglitching technique for a digital-to-analog converter are disclosed. The circuit includes a digital-to-analog converter having a differential current output, an operational amplifier having an inverting input coupled to a first output of the differential current output and a non-inverting input coupled to a second output of the differential current output, and a transistor coupled to the second output and the output of the operational amplifier. The operational amplifier is configured to operate the transistor to adjust the voltage potential of the second output to substantially match the voltage potential of the first output."
8786600,"A system and method for constructing a displacement-mapped surface representation are presented. An exemplary method includes defining a plurality of local vectors emanating from the displacement-mapped surface, each local vector extending at a local angle from a local position disposed on the displacement-mapped surface. The method further includes determining first and second global vectors for respective first and second subsets of the local vectors, the first global vector determined as a function of the first subset vectors' local positions and local angles, and the second global vector determined as a function of the second subset vectors' local positions and local angles. The first and second global vectors are utilized to form a representation of the displacement-mapped surface."
8786606,One embodiment of the present invention sets forth a technique for stroking rendered paths. Path rendering may be accelerated when a graphics processing unit or other processor is configured to identify pixels that are within half of the stroke width of any point along a path to be stroked. The path is represented by quadratic Bèzier segments and a cubic equation is evaluated to determine whether or not each point in a conservative hull that bounds the quadratic Bèzier segment is within the stroke width.
8786618,"One embodiment of the present invention sets forth a technique for configuring a graphics processing pipeline (GPP) to process data according to one or more shader programs. The method includes receiving a plurality of pointers, where each pointer references a different shader program header (SPH) included in a plurality of SPHs, and each SPH is associated with a different shader program that executes within the GPP. For each SPH included in the plurality of SPHs, one or more GPP configuration parameters included in the SPH are identified, and the GPP is adjusted based on the one or more GPP configuration parameters."
8787445,"A technique of encoding video frames allocates an available number of bits to different portions of the video frame. A processing unit identifies a region of interest (ROI) in a video frame, and computes a first and second complexity parameter respectively representing the change in video information in the ROI portions and non-ROI portions in the video frame relative to a reference frame. Bits are allocated to the ROI portion proportional (positive correlation) to the first complexity parameter and a ratio of the area of the ROI to the area of the frame. The remaining available bits are allocated to the non-ROI. In an embodiment, the bits are encoded according to H.264 standard."
8787464,"A video processor is described, which is useful for implementing a Hadamard transform process, in compliance with the H.264 standard. The video processor includes an input, for receiving a block of image data. The image data is loaded into an internal register. In response to receiving a SIMD instruction, a multiplier, which incorporates the H.264 Hadamard transform matrix in its associated hardware, processes the block of image data, and writes the resulting partially transformed pixel data back to the internal register, transposing the data during the process."
8787472,A method is provided for estimating at least one offset of a communication in a multicarrier communication system. The method comprises receiving a plurality of subcarriers wherein the plurality of subcarriers contain the subcarrier that is subject to the distortion; and generating a plurality of first channel estimates for a respective plurality of received subcarriers that are not subject to the distortion. The method further comprises processing a number of the plurality of first channel estimates for the respective plurality of received subcarriers that are not subject to the distortion to generate a second channel estimate for the subcarrier that is subject to the distortion; and estimating an offset associated with the subcarrier that is subject to the distortion.
8787577,"The invention discloses a method and a system for wireless transmission of content. The present invention relates generally to wireless network technology, Problems solved by the invention is that, the method for manually entering the shared key is neither convenient nor secure, while the method for transmitting the shared key over the wireless network also makes the shared key exposed to an unsafe environment. Embodiments of the invention provide the program as follows: a method and a system for wireless transmission of content, wherein, capturing shared key, using the shared key to encrypt the content, and then transmitting the encrypted content over the wireless network. Embodiments of the invention are suitable for terminals and devices wirelessly connected, and so on."
8788425,"A method and system for accessing content on demand are described. In one embodiment, upon receiving a user request to access an instance of content (e.g., information that is independent of a particular physical medium), the identity of the user is authenticated. The request conveys a unique identifier of the instance of content and a key for activating the content corresponding thereto according to an instance of ownership stored therewith. The instance of ownership corresponding to the user in that instance of content is ascertained. Upon associating the instance of ownership corresponding to the user in the instance of content, the instance of content is activated to allow the user to access the instance of content according to the corresponding instance of ownership. Where access is demanded in excess of the instance of ownership, a transaction is initiated with which the instance of ownership can be upgraded."
8788692,"Method and system for broadcasting live data over a network are described. In one embodiment, live data is accessed. Next, a first client is authenticated. The live data is then broadcast to a first client, wherein the first client is capable of buffering and re-transmitting the live data. Next, a second client is authenticated. A list of clients receiving the live data is then sent to the second client. The second client then selects the first client from the list, contacts the first client, and then receives the live data from the first client."
8788761,"One embodiment of the present invention sets forth am extension to a cache coherence protocol with two explicit control states, P (private), and R (read-only), that provide explicit program control of cache lines for which the program logic can guarantee correct behavior. In the private state, only the owner of a cache line can access the cache line for read or write operations. In the read-only state, only read operations can be performed on the cache line, thereby disallowing write operations to be performed."
8788996,"The present invention systems and methods enable configuration of functional components in integrated circuits. A present invention system and method can flexibly change the operational characteristics of functional components in an integrated circuit die based upon a variety of factors. In one embodiment, manufacturing yields, compatibility characteristics, performance requirements, and system health (e.g., the number of components operating properly) are factored into changes to the operational characteristics of functional components. In one exemplary implementation, the changes to operational characteristics of a functional component are coordinated with changes to other functional components. Workflow scheduling and distribution is also adjusted based upon the changes to the operational characteristics of the functional components. For example, a functional component configuration controller changes the operational characteristics settings and provides an indication to a workflow distribution component. The workflow distribution component changes the workflow schedule based upon the operational characteristics settings (e.g., work flow is diverted to or away from functional components)."
8789006,"A system, method, and computer program product are provided for testing a circuit representation. A command line input is received at a command line interface. The command line input is translated into one or more test conditions. Additionally, a test environment configured to simulate the circuit representation and verify the one or more test conditions is generated."
8793091,"A system and method for calibrating an integrated circuit. The method includes configuring a first impedance for a first output of the integrated circuit according to a first configuration code and measuring a first voltage at the first output which corresponds to the first configuration code. The method further includes configuring a second impedance for a second output of the integrated circuit according to a second configuration code and measuring a second voltage at the second output which corresponds to the second configuration code. A determination of which of the first voltage and the second voltage is nearest to a predetermined voltage value. Based on the voltage determination, the integrated circuit is configured according a code of said first and second codes that corresponds to the voltage nearest to the predetermined voltage."
8797340,"A system, method, and computer program product are provided for modifying a pixel value as a function of a display duration estimate. In use, a value of a pixel of an image frame to be displayed on a display screen of a display device is identified, wherein the display device is capable of handling updates at unpredictable times. Additionally, the value of the pixel is modified as a function of an estimated duration of time until a next update including the pixel is to be displayed on the display screen. Further, the modified value of the pixel is transmitted to the display screen for display thereof."
8798140,"An encoder provided according to an aspect of the present invention uses an approach which seeks to limit the number of bits in each of a sequence of video frames to a same upper limit. By providing such a restriction, additional budget (i.e., more number of bits that can be used for the encoded bits for the frame) may be available for encoding of later received frames in the sequence, thereby avoiding quality degradation with respect to reproduction of such later frames. According to another aspect of the present invention, a quantization parameter used during encoding is controlled to enforce such a limit. According to one more aspect of the present invention, a quantization parameter is generated for a video frame by examining content corresponding to the same video frame."
8798157,"A video processor is described, which is useful for implementing a forward transform process, in compliance with the H.264 standard. The video processor includes an input, for receiving a block of image data. The image data is loaded into an internal register. In response to receiving a SIMD instruction, a multiplier, which incorporates the H.264 forward transform matrix in its associated hardware, processes the block of image data, and writes the resulting partially transformed pixel data back to the internal register, transposing the data during the process."
8799425,"An administrator system provided according to an aspect of the present invention enables the configuration of display properties of display units on remote systems to desired values. In an embodiment, the user can specify the desired values for multiple systems together. The remote systems may further enable the previously configured values of the display properties to be displayed on the administrator system."
8800051,"Systems and methods for communicating private information from a browser to a driver are presented. The private information communication method can comprise: performing a private information communication process in which private information is communicated through a private information communication plug-in of a browser to a driver; and performing a driver process based upon the private communication information communicated in the private information communication process. The private information communication process can comprise determining private information content; communicating the private information to the private information communication plug-in coupled to a private communication channel; calling a graphics driver from the private information communication plug-in using the private communication channel; and forwarding the private information from the private information communication plug to the driver via the private communication channel. The driver process can comprise: determining if there is an association between normal information and the private information, and processing the normal information in accordance with associated private. The private information can be associated with stereoscopic 3D video streaming."
8803879,"An invention is provided for rendering using an omnidirectional light. A shadow cube texture map having six cube faces centered by a light source is generated. Each cube face comprises a shadow texture having depth data from a perspective of the light source. In addition, each cube face is associated with an axis of a three-dimensional coordinate system. For each object fragment rendered from the camera's perspective a light-to-surface vector is defined from the light source to the object fragment, and particular texels within particular cube faces are selected based on the light-to-surface vector. The texel values are tested against a depth value computed from the light to surface vector. The object fragment is textured as in light or shadow according to the outcome of the test."
8804437,"A column select multiplexer, a method of reading data from a random-access memory and a memory subsystem incorporating the multiplexer or the method. In one embodiment, the column select multiplexer includes: (1) a first field-effect transistor having a gate coupled via an inverter to a bitline of a static random-access memory array, (2) a second field-effect transistor coupled in series with the first field-effect transistor and having a gate coupled to a column select bus of the static random-access memory array and (3) a latch having an input coupled to the first and second field-effect transistors."
8804580,"An apparatus, such as a base station, transmitting signaling information in a cellular communication system whereby a plurality of shared uplink transmission resources is divided into sets of mutually exclusive transmission resources. The apparatus comprises means for granting uplink resources to a wireless subscriber communication unit via a grant message for uplink transmission; means for receiving an uplink transmission from a wireless subscriber communication unit; means for deriving an uplink code resource identifier from the uplink transmission or the grant message; means for assigning at least one downlink code sequence used to carry downlink signaling information associated with the uplink transmission and which is derived using the uplink code resource identifier; and means for transmitting a downlink transmission comprising the at least one downlink code sequence to the wireless subscriber communication unit."
8806100,"Circuits, methods, and apparatus that reduce the power consumed by transactions initiated by a number of USB host controllers. Peripheral devices on a number of USB networks are accessed in a coordinated manner in order to reduce power dissipated by a CPU and other circuits when reading data needed by the host controllers. The resulting memory reads are temporally clustered. This allows the CPU to process a greater number of requests each time it leaves a low-power state. As a result, the CPU may possibly remain in a sleep state for a longer period of time, thus saving power. This is accomplished at the host controller level by synchronizing the time frames used by each host controller in a system. The synchronizing signal may be one or more bits of a frame count provided by one host controller to a number of other frame controllers."
8810584,"A method includes automatically acquiring, through a resource manager module associated with a driver program executing on a node of a cluster computing system, information associated with utilization of a number of Graphics Processing Units (GPUs associated) with the node, and automatically calculating a window of time in which the node is predictably underutilized on a reoccurring and periodic basis. The method also includes automatically switching off, when one or more GPUs is in an idle state during the window of time, power to the one or more GPUs to transition the one or more GPUs into a quiescent state of zero power utilization thereof. Further, the method includes maintaining the one or more GPUs in the quiescent state until a processing requirement of the node necessitates utilization thereof at a rate higher than a predicted utilization rate of the node during the window of time."
8810592,"One embodiment of the present invention sets forth a technique for providing primitives and vertex attributes to the graphics pipeline. A primitive distribution unit constructs the batches of primitives and writes inline attributes and constants to a vertex attribute buffer (VAB) rather than passing the inline attributes directly to the graphics pipeline. A batch includes indices to attributes, where the attributes for each vertex are stored in a different VAB. The same VAB may be referenced by all of the vertices in a batch or different VABs may be referenced by different vertices in one or more batches. The batches are routed to the different processing engines in the graphics pipeline and each of the processing engines reads the VABs as needed to process the primitives. The number of parallel processing engines may be changed without changing the width or speed of the interconnect used to write the VABs."
8812892,"One embodiment of the present invention sets forth a technique for performing high-performance clock training. One clock training sweep operation is performed to determine phase relationships for two write clocks with respect to a command clock. The phase relationships are generated to satisfy timing requirements for two different client devices, such as GDDR5 DRAM components. A second clock training sweep operation is performed to better align local clocks operating on the client devices. A voting tally is maintained during the second clock training sweep to record phase agreement at each step in the clock training sweep. The voting tally then determines whether one of the local clocks should be inverted to better align the two local clocks."
8813019,"A method includes reading, through a processor of a computing device communicatively coupled to a memory, a design of an electronic circuit as part of verification thereof. The method also includes extracting, through the processor, a set of optimized instructions of a test algorithm involved in the verification such that the set of optimized instructions covers a maximum portion of logic functionalities associated with the design of the electronic circuit. Further, the method includes executing, through the processor, the test algorithm solely relevant to the optimized set of instructions to reduce a verification time of the design of the electronic circuit."
8817031,"A technique for performing stream output operations in a parallel processing system is disclosed. A stream synchronization unit is provided that enables the parallel processing unit to track batches of vertices being processed in a graphics processing pipeline. A plurality of stream output units is also provided, where each stream output unit writes vertex attribute data to one or more stream output buffers for a portion of the batches of vertices. A messaging protocol is implemented between the stream synchronization unit and the plurality of stream output units that ensures that each of the stream output units writes vertex attribute data for the particular batch of vertices distributed to that particular stream output unit in the same order in the stream output buffers as the order in which the batch of vertices was received from a device driver by the parallel processing unit."
8817035,"Circuits, methods, and apparatus that perform a context switch quickly while not wasting a significant amount of in-progress work. A texture pipeline includes a cutoff point or stage. After receipt of a context switch instruction, texture requests and state updates above the cutoff point are stored in a memory, while those below the cutoff point are processed before the context switch is completed. After this processing is complete, global states in the texture pipeline are stored in the memory. A previous context may then be restored by reading its texture requests and global states from the memory and loading them into the texture pipeline. The location of the cutoff point can be a point in the pipeline where a texture request can no longer result in a page fault in the memory."
8817894,"A method of sending a data signal and a clock signal between a radio frequency circuit of a device and a baseband circuit of the device. The method comprises: determining whether at least one of the data signal and the clock signal is disturbing in that it has a harmonic within the radio frequency band. If it is determined that at least one of the data signal and the clock signal is disturbing, the method further comprises: scrambling the at least one disturbing signal to flatten the spectrum thereof for frequencies below the clock frequency FC, setting a respective at least one indicator to indicate that the at least one disturbing signal has been scrambled, and sending the at least one scrambled signal between the radio frequency circuit and the baseband circuit. The method further comprises, subsequent to the step of sending the at least one scrambled signal, descrambling the at least one scrambled signal if the respective at least one indicator is set."
8823724,"Systems and methods for texture processing are presented. In one embodiment a texture method includes creating a sparse texture residency translation map; performing a probe process utilizing the sparse texture residency translation map information to return a finest LOD that contains the texels for a texture lookup operation; and performing the texture lookup operation utilizing the finest LOD. In one exemplary implementation, the finest LOD is utilized as a minimum LOD clamp during the texture lookup operation. A finest LOD number indicates a minimum resident LOD and a sparse texture residency translation map includes one finest LOD number per tile of a sparse texture. The sparse texture residency translation can indicate a minimum resident LOD."
8823725,"A system, method, and computer program product are provided for determining a duty cycle for a pixel (e.g. of alternating pixel values to achieve an average pixel color). In use, a first value of a sub-color component bit of a pixel is determined. Additionally, a second value for the sub-color component bit of the pixel is calculated. Further, a duty cycle for alternating between the first value and the second value is determined (e.g. which when applied at normal display frame rate may achieve an average color)."
8824530,"A modem for handling notifications received over a network is disclosed. In one embodiment, the modem includes a first interface to connect to a network, a second interface to connect to a host processor on a terminal and a modem processor to receive presence configuration information from the host processor and in response thereto transmit a request comprising the presence configuration information to a presence information store. The modem processor further arranged to receive one or more notifications with presence information from the store based on the presence configuration information in the request. The presence information supplied to the store by one or more further terminals associated with one or more users. The modem processor stores the one or more notifications in a storage means, and in response to receiving a request for presence information from said host processor, supply presence information thereto based on the one or more notifications."
8825015,"A mobile phone provided according to an aspect of the present invention generates a non-visual human perceptible signal (e.g., sound or touch/vibration) after the data representing a web page content is received. Due to such a feature, the user need not watch a display screen of the mobile phone to know that the web page is displayed. The use-friendliness is enhanced when accessing the web pages over low bandwidth communication paths."
8826048,"Metrics representing a combined measure of power used by a central processing unit (CPU) and power used by a graphics processing unit (GPU) are compared to a shared supply power and/or shared thermal power budget. A state of the CPU and a state of the GPU are regulated by the power management system to maintain the metrics within the shared supply power and/or thermal power budget for the purpose of managing the components to meet platform power supply, and cooling, constraints and design requirements."
8830110,"A window-enabled TDC and method of detecting phase of a reference signal. One embodiment of the window-enabled TDC includes: (1) a window generator configured to receive a reference signal and a clock signal, and (2) a TDC circuit coupled to the window generator and configured to be enabled based on the reference signal and disabled based on the clock signal."
8830341,"An aspect of the present invention selects one of the images captured in burst mode as an optimum image based on processing only the captured images, without requiring any external images. According to another aspect of the present invention, the camera settings are set to different combination of values and a frame is formed for each combination of values from the corresponding captured image. Image metrics representing inherent image qualities may be extracted from each of the frames and one of the frames is selected based on the extracted metrics. In an embodiment, each combination of the camera settings includes corresponding values for exposure duration and white balance."
8831005,"An embodiment of a method for processing data units is provided that includes receiving a plurality of data units, of a data stream, having respective sequence numbers and, employing a reordering window, determining whether a newly received data unit of the data stream is a new data unit or a repeated data unit at the receiver and defining a first and a second range of sequence numbers relative to the sequence number of a previously received data unit. A newly received data unit is determined to be either a new or a repeated data unit based on whether the sequence number of the newly received data unit falls within the first or second range, and processed at the receiver based on this determination. A handover condition is detected, and in response thereto the first and second ranges of the reordering window are adjusted for use during the handover condition."
8831099,Non-encoded data for a macroblock of an image frame is accessed. A cost to intra-encode the macroblock is computed using at least a portion of the non-encoded data in place of reconstructed image data from another macroblock of the image frame. The cost can be compared against the cost to inter-encode the first macroblock in order to select how the first macroblock is to be encoded.
8832346,"Systems and methods are disclosed to transfer data between a first bus internal to a system-on-chip (SOC) device and a second bus external to the SOC device, each bus having a plurality of bus segments shared among a plurality of peripheral devices communicating over one or more bus segments. When reading data from a peripheral device, the system packs data by enabling each effected first bus data segment in sequence until requested data is packed; and when writing data to a peripheral device, the system unpacks data by enabling each effected second bus data segment in sequence until requested data is unpacked."
8832671,One embodiment of the present invention sets forth a technique for using a multi-bank register file that reduces the size of or eliminates a switch and/or staging registers that are used to gather input operands for instructions. Each function unit input may be directly connected to one bank of the multi-bank register file with neither a switch nor a staging register. A compiler or register allocation unit ensures that the register file accesses for each instruction are conflict-free (no instruction can access the same bank more than once in the same cycle). The compiler or register allocation unit may also ensure that the register file accesses for each instruction are also aligned (each input of a function unit can only come from the bank connected to that input).
8836517,"A method and system are implemented for monitoring the thermal dissipation from a computer processing unit. The system comprises a temperature sensor, and a temperature controller. The temperature controller is configured to set a temperature observation window in a first temperature range, gradually narrow the observation window from the first temperature range after a monitored temperature of the processing unit has entered the observation window, and issue an alert signal when the monitored temperature exits the observation window."
8837161,"A Multi-configuration Processor-Memory device for coupling to a PCB (printed circuit board) interface. The device comprises a substrate that supports multiple configurations of memory components and a processor while having a single, common interface with a PCB interface of a printed circuit board. In a first configuration, the substrate supports a processor and a first number of memory components. In a second configuration, the substrate supports a processor and an additional number of memory components. The memory components can be pre-tested, packaged memory components mounted on the substrate. The processor can be a surface mounted processor die. Additionally, the processor can be mounted in a flip chip configuration, side-opposite the memory components. In the first configuration, a heat spreader can be mounted on the memory components and the processor to dissipate heat. In the second, flip chip, configuration, the processor face can be soldered onto a non-electrically functional area of the PCB interface of the printed circuit board to dissipate heat."
8838665,"In one embodiment, a microprocessor includes fetch logic for retrieving an instruction, decode logic configured to identify a plurality of operands and a multiply operation specified in the instruction, and execution logic configured to receive the plurality of operands and the multiply operation. The execution logic includes a first logic path configured to perform the multiply operation on the plurality of operands and output a result, and a second logic path, arranged in parallel with the first logic path, configured to output metadata associated with the result of the multiply operation."
8839006,"Power management systems and methods that facilitate efficient and effective power conservation are presented. In one embodiment a power management method comprises: performing an initiation metric determination process, and adjusting operations of a logic component based on said threshold value. In one exemplary implementation, the initiation metric determination process includes monitoring activity of a logic component, and establishing a power conservation initiation threshold value. The initiation metric determination process can include performing a system architecture characteristic analysis in which a system architecture power-consumption break-even time (BE) is determined for the system. The initiation metric determination process can also include performing a system utilization analysis process is performed in which idle period durations detected during said monitoring are sorted into a variety of different length intervals and analyzed accordingly. Histograms of idle period durations can be collected. Adjusting operations can include entering a low power state."
8839039,"An approach is disclosed for performing initialization operations for a graphics processing unit (GPU). The approach includes detecting errors while performing one or more initialization operations. Further, the approach includes releasing a holdoff on a communication link that couples the GPU to a memory bridge and causing debug output to be displayed to a user that indicates the error."
8841953,"A double-edge-triggered flip-flop circuit and a method for operating the double-edge-trigger flip-flop circuit are provided. Sub-circuits of a flip-flop circuit are coupled to a ground supply and decoupled the sub-circuits from a power supply when a clock signal is asserted. The sub-circuits generate trigger signals including a first pair of signals and a second pair of signals. The first pair of signals is evaluated, levels of the second pair of signals are maintained when the clock signal is asserted, and an output signal is transitioned to equal an input signal based on the trigger signals when the clock signal is asserted."
8842030,"A sigma-delta analog-to-digital converter includes an input transconductance stage that provides an analog input current proportional to an analog input voltage and a current summing stage that generates an analog error signal corresponding to a difference between the analog input current and a feedback current. The sigma-delta analog-to-digital converter also includes a forward signal path that processes the analog error signal to provide a digital output signal corresponding to the analog input voltage. Additionally, the sigma-delta analog-to-digital converter includes a feedback path that includes a current steering digital-to-analog converter having both sourcing and sinking current sources, wherein currents provided by the sourcing and sinking current sources are steerable and connected to directly provide the feedback current based on the digital output signal. A sigma-delta analog-to-digital converter operating method is also provided."
8842114,"A system, method, and computer program product are provided for adjusting a depth of displayed objects within a region of a display. In use, a display that displays one or more objects three-dimensionally is identified. Additionally, a region within the display is determined. Further, a depth of objects displayed within the region is adjusted."
8842526,"A method for handling error recovery at a user equipment is provided herein. In one embodiment, the method includes: maintaining first and second communication channels between the user equipment and a radio access network; storing a plurality of control messages in a buffer for transmission over the first communication channel; detecting if the first communication channel is disabled; initiating a recovery procedure using the second communication channel that includes restoring the first communication channel using the second communication channel and sending a further message to one of the one or more buffers for transmission on the restored first communication channel; and in response to detecting that the first communication channel is disabled, moderating control messages stored in the one or more buffers."
8842931,"A system, method, and computer program product are provided for reducing noise in an image using depth-based on sweeping over image samples. In use, each noisy pixel of an image having noise is identified. Additionally, for each noisy pixel, at least one sample included in each of a plurality of neighboring pixels to the noisy pixel is identified. Furthermore, the samples are swept over at least partially in a depth-based order to identify a value for the noisy pixel that reduces the noise."
8847957,"A system, method, and computer program product are provided for hierarchical photon mapping. In use, photons and query locations are generated. Additionally, a bounding volume of the query locations is determined. Further, a set of the photons inside of the bounding volume is determined. It is then determined whether the set of photons and query locations meet predetermined criteria. If it is determined that the set of photons and query locations do not meet the predetermined criteria, the query locations are partitioned, and for each set of the query locations resulting from the partitioning, the above described steps for the hierarchical photon mapping are repeated. Once it is determined that the set of photons and query locations meet the predetermined criteria, a contribution of the set of photons to the query locations is computed."
8848458,"A memory circuit in which a level of a first data input appears promptly at an output in response to a clock pulse received. The circuit includes a flip-flop triggered by the clock pulse and configured to receive the first data input and drive a second data input. The circuit also includes a first control input driven by the clock pulse, a second control input driven by the flip-flop and selection logic configured to receive the first and second data inputs and the first and second control inputs. The selection logic is configured to drive the output of the memory circuit to the level of the first data input or of the second data input depending on the first and second control inputs."
8849051,"An approach to decoding Huffman symbols in JPEG images is described. One approach involves a method of decoding Huffman codes in a JPEG image file. This method involves obtaining a bitstream sample from a bitstream associated with the JPEG image file. The bitstream sample is compared against a threshold value, to identify a Huffman group number. Information associated with a Huffman group is retrieved, and used to extract the current Huffman symbol from the bitstream. A corresponding symbol value can then be obtained, using the current Huffman symbol and the group information."
8850252,"A USB host for wakeup from a sleep state includes a hold memory, a USB host controller, and a USB driver. When going to sleep, the USB driver sends a suspend command to the USB host controller in response to receiving a sleep command. The USB driver also reads a controller context from the USB host controller and saves the controller context in the hold memory. Thereafter, the USB driver turns off one or more supply potentials and one or more clocks in the host controller, and returns a sleep acknowledgement. While in sleep, the interface pins are placed in a hold state and notification to the operating system are disabled."
8850371,"Embodiments of the invention may include receiving a design netlist representing a datapath operable to execute a function corresponding to an opcode combination. The datapath may include an input stage, a register stage, and an output stage and the register stage may include a plurality of registers. For a first function corresponding to a first opcode combination, a subset of unused registers in the plurality of registers may be automatically determined. Further, clock gating logic may be automatically inserted into the design netlist, wherein the clock gating logic is operable to dynamically clock gate the subset of unused registers contemporaneously when the datapath executes the first function corresponding to the first opcode combination."
8850436,"One embodiment of the present invention sets forth a technique for performing a method for synchronizing divergent executing threads. The method includes receiving a plurality of instructions that includes at least one set-synchronization instruction and at least one instruction that includes a synchronization command, and determining an active mask that indicates which threads in a plurality of threads are active and which threads in the plurality of threads are disabled. For each instruction included in the plurality of instructions, the instruction is transmitted to each of the active threads included in the plurality of threads. If the instruction is a set-synchronization instruction, then a synchronization token, the active mask and the synchronization point is each pushed onto a stack. Or, if the instruction is a predicated instruction that includes a synchronization command, then each active thread that executes the predicated instruction is monitored to determine when the active mask has been updated to indicate that each active thread, after executing the predicated instruction, has been disabled."
8854123,"A system of interconnected chips comprising a multi-chip module (MCM) includes a first processor chip, a second processor chip, and an MCM package configured to include the first processor chip, the second processor chip, and an interconnect circuit. The first processor chip is configured to include a first ground-referenced single-ended signaling (GRS) interface circuit. A first set of electrical traces fabricated within the MCM package and configured to couple the first GRS interface circuit to the interconnect circuit. The second processor chip is configured to include a second GRS interface circuit. A second set of electrical traces fabricated within the MCM package and configured to coupled the second GRS interface circuit to the interconnect circuit."
8854364,"The range of depth values within the overlap of a convex polygon and a square or rectangular rasterization area can be determined by identifying whether the minimum and maximum depth values occur at the corners of the rasterization area or at intersections of the polygon's edges with the area's sides. By choosing between the corner and intersection for both the minimum and maximum depth limit, solving the depth plane equation at the chosen location, and clamping against the polygon's vertex depth range, a tight depth range describing the depth values within that overlap are obtained. That tight depth range is utilized to cull pixel values early in the pipeline, improving performance and power consumption."
8854380,"One embodiment of the present invention sets forth a technique for displaying high-resolution images using multiple graphics processing units (GPUs). The graphics driver is configured to present one virtual display device, simulating a high-resolution mosaic display surface, to the operating system and the application programs. The graphics driver is also configured to partition the display surface amongst the GPUs and transmit commands and data to the local memory associated with the first GPU. A video bridge automatically broadcasts this information to the local memories associated with the remaining GPUs. Each GPU renders and displays only the partition of the display surface assigned to that particular GPU, and the GPUs are synchronized to ensure the continuity of the displayed images. This technique allows the system to display higher resolution images than the system hardware would otherwise support, transparently to the operating system and the application programs."
8856499,"An apparatus is disclosed. The apparatus comprises an instruction mapping table, which includes a plurality of instruction counts and a plurality of instruction pointers each corresponding with one of the instruction counts. Each instruction pointer identifies a next instruction for execution. Further, each instruction count specifies a number of instructions to execute beginning with the next instruction. The apparatus also has a data operation unit adapted to receive a data group and adapted to execute on the received data group the number of instructions specified by a current instruction count of the instruction mapping table beginning with the next instruction identified by a current instruction pointer of the instruction mapping table before proceeding with another data group."
8856744,The HDMI debug cable methods and apparatuses are directed toward a means for pulling up a hot plug detect line to a power line. The debug cable methods and apparatuses also include means for providing an extended display identification data (EDID) code indicating a debug cable or debug host device. The debug cable methods and apparatuses also include means for transmitting and receiving debug commands and data.
8858327,"The present invention discloses a method and a device for providing a game. The method includes: a detection step, for determining an additional display device being attached to a mobile device; and a push step, for pushing multimedia information of the game to the additional display device to be presented by the additional display device, and pushing a visual human machine interface of the game to a display of the mobile device to be displayed by the display; wherein, a controlled object displayed on the additional display device is controlled by the visual human machine interface. The above-mentioned method and device for providing a game can make a game machine have a smaller size and be more portable, display multimedia information of a game on a bigger screen for players and provide players with a visual human machine interface on the entire screen of a mobile device, and therefore it improves user experiences."
8860497,"A reduced oxide stress cascode stack circuit includes a cascade transistor stack and dynamic bias circuits that supply an output voltage having a magnitude greater than an oxide reliability voltage of their component transistors. The reduced oxide stress cascode stack circuit also includes an offset voltage generator that provides an offset voltage based on a transient extreme of the output voltage, wherein the offset voltage is applied to the cascade transistor stack and the dynamic bias circuits to reduce component transistor voltages commensurate with the oxide reliability voltage. The reduced oxide stress cascode stack circuit further includes a bias voltage supply that modifies a bias voltage value of the cascade transistor stack and dynamic bias circuits by an amount proportional to the offset voltage. A method of reducing oxide stress in a cascode stack circuit is also provided."
8860722,"Early Z scoreboard tracking systems and methods in accordance with the present invention are described. Multiple pixels are received and a pixel depth raster operation is performed on the pixels. The pixel depth raster operation comprises discarding a pixel that is occluded. In one exemplary implementation, the depth raster operation is done at a faster rate than a color raster operation. Pixels that pass the depth raster operation are checked for screen coincidence. Pixels with screen coincidence are stalled and pixels without screen coincidence are forwarded to lower stages of the pipeline. The lower stages of the pipeline are programmable and pixel flight time can vary (e.g., can include multiple passes through the lower stages). Execution through the lower stages is directed by a program sequencer which also directs notification to the pixel flight tracking when a pixel is done processing."
8860725,"A system, method, and computer program product are provided for deterministically simulating light transport. In use, all pairs of non-negative integers are enumerated (e.g. in a predetermined order). Additionally, for each of the enumerated pairs of non-negative integers, an associated pair of a query point and a photon is identified by: identifying a query point associated with a first non-negative integer of the pair of non-negative integers using a deterministic point sequence of query points and identifying a photon associated with a second non-negative integer of the pair of non-negative integers using a deterministic point sequence of photons. Further, for each of the query points in the deterministic point sequence of query points, photons in the deterministic point sequence of photons associated with the query point are identified. Still yet, an illumination value is computed for each query point of each of the photons associated with the query point using the pairs of query points and photons and at least one transport property at the query point."
8860737,"A processing unit includes multiple execution pipelines, each of which is coupled to a first input section for receiving input data for pixel processing and a second input section for receiving input data for vertex processing and to a first output section for storing processed pixel data and a second output section for storing processed vertex data. The processed vertex data is rasterized and scan converted into pixel data that is used as the input data for pixel processing. The processed pixel data is output to a raster analyzer."
8860741,"In contrast to a conventional computing system in which the graphics processor (graphics processing unit or GPU) is treated as a slave to one or several CPUs, systems and methods are provided that allow the GPU to be treated as a central processing unit (CPU) from the perspective of the operating system. The GPU can access a memory space shared by other CPUs in the computing system. Caches utilized by the GPU may be coherent with caches utilized by other CPUs in the computing system. The GPU may share execution of general-purpose computations with other CPUs in the computing system."
8860742,"A technique for caching coverage information for edges that are shared between adjacent graphics primitives may reduce the number of times a shared edge is rasterized. Consequently, power consumed during rasterization may be reduced. During rasterization of a first graphics primitive coverage information is generated that (1) indicates cells within a sampling grid that are entirely outside an edge of the first graphics primitive and (2) indicates cells within the sampling grid that are intersected by the edge and are only partially covered by the first graphics primitive. The coverage information for the edge is stored in a cache. When a second graphics primitive is rasterized that shares the edge with the first graphics primitive, the coverage information is read from the cache instead of being recomputed."
8860743,"Systems and methods for texture processing are presented. In one embodiment a texture method includes creating a sparse texture residency translation map; performing a probe process utilizing the sparse texture residency translation map information to return a finest LOD that contains the texels for a texture lookup operation; and performing the texture lookup operation utilizing the finest LOD. In one exemplary implementation, the finest LOD is utilized as a minimum LOD clamp during the texture lookup operation. A finest LOD number indicates a minimum resident LOD and a sparse texture residency translation map includes one finest LOD number per tile of a sparse texture. The sparse texture residency translation can indicate a minimum resident LOD."
8860766,"A system, method, and computer program product are provided for determining one or more contact points between a pair of objects. In operation, a first contact normal is identified between a pair of objects at a first position. Additionally, a relative velocity of the pair of objects is determined at the first position. Furthermore, one or more contact points between the pair of objects are determined at a second position through a translational analysis, utilizing the first contact normal and the relative velocity."
8861290,A method and a system are provided for performing write assist. Write assist circuitry is initialized and voltage collapse is initiated to reduce a column supply voltage provided to a storage cell. A bitline of the storage cell is boosted to a boosted voltage level that is below a low supply voltage provided to the storage cell and data encoded by the bitline is written to the storage cell.
8861586,"A decoder can include a first stage operable for decoding (prior to deblocking) an encoded frame, and second stage coupled downstream of the first stage. The second stage includes a first deblocker and a second deblocker that can be used to deblock decoded frames in parallel. Each decoded frame can be classified as a type of frame and is sent to one of the deblockers depending on its classification."
8862091,"An efficient method and apparatus to receive broadcasted emergency alerts using portable handheld devices or mobile devices that are operable to provide a user with relevant alerts based on the user's relevant position, in a low-powered, always-on manner are presented. Using the always on partitions of both the receiver and the system on chip (SOC) of a mobile device, embodiments of the present invention are capable of determining whether or not the remainder of the circuits of a mobile device need to be powered on in order to record audio data associated with an alert, when the alert is received. Furthermore, embodiments of the present invention are operable for displaying these alerts in a manner such that a user is notified that a relevant alert has been received and placing the user in a position where the user must address the alert notification and take appropriate action."
8862823,"One embodiment of the present invention sets forth a compression status cache configured to store compression information for blocks of memory stored within an external memory. A data cache unit is configured to request, in response to a cache miss, compressed data from the external memory based on compression information stored in the compression status bit cache. The compression status for active buffers is dynamically swapped into the compression status cache as needed. Different compression formats may be specified for one or more tiles within an active buffer. One advantage of the disclosed compression status cache is that a lame amount of attached memory may be allocated as compressible memory blocks, without incurring a corresponding die area cost because a portion of the compression status stored off chip in attached memory is cached in the compression status cache."
8866511,A method and a system are provided for clock phase detection. A first set of delayed versions of a first clock signal is generated and a second set of delayed versions of a second clock signal is generated. The second set of delayed versions of the second clock signal is sampled using the first set of delayed versions of the first clock signal to produce an array of clock samples in a domain corresponding to the first clock signal. At least one edge indication is located within the array of clock samples.
8866528,"A dual flip-flop circuit combines two or more flip-flip sub-circuits into a single circuit. The flip-flop circuit comprises a first flip-flop sub-circuit and a second flip-flop sub-circuit. The first flip-flop sub-circuit comprises a first storage sub-circuit configured to store a first selected input signal and transfer the first selected input signal to a first output signal when a buffered clock signal transitions between two different logic levels and a dock driver configured to receive a clock input signal, generate an inverted clock signal, and generate the buffered clock signal. The second flip-flop sub-circuit is coupled to the clock driver and configured to receive the inverted clock signal and the buffered clock signal. The second flip-flop sub-circuit comprises a second storage sub-circuit configured to store a second selected input signal and transfer the second selected input signal to a second output signal when the buffered clock signal transitions."
8866833,"A system, method, and computer program product are provided for a dynamic display refresh. In use, a state of a display device is identified in which an entirety of an image frame is currently displayed by the display device. In response to the identification of the state, it is determined whether an entirety of a next image frame to be displayed has been rendered to memory. The next image frame is transmitted to the display device for display thereof, when it is determined that the entirety of the next image frame to be displayed has been rendered to the memory. Further, a refresh of the display device is delayed, when it is determined that the entirety of the next image frame to be displayed has not been rendered to the memory."
8867605,A decoder may include a first stage that can be used to decode (prior to deblocking) an encoded frame of data. The decoder may also include a second stage that is downstream of the first stage. The second stage includes a first deblocker and a second deblocker that can be used to deblock decoded frames in parallel.
8868078,"A mobile terminal comprising: transceiver apparatus for accessing a wireless network using an earlier and a later generation radio access technology, to establish a voice channel and packet data channel; and an inter radio access technology selector configured to monitor a condition for disabling the earlier generation access, being a condition other than coverage under the earlier generation technology falling below an acceptable lower level. The selector makes inter radio access technology decisions dynamically from the mobile terminal by updating registration with the network to indicate that the earlier generation technology is no longer supported. The selector thereby prevents the mobile terminal being subject to decisions from the network that would otherwise impose transfer to the earlier generation. At least some of the decisions made from the mobile terminal thus disable the earlier generation access whilst in presence of at least the lower level of coverage under the earlier generation."
8868838,"One embodiment of the invention sets forth a mechanism for evicting data from a data cache based on the data class of that data. The data stored in the cache lines in the data cache is categorized based on data classes that reflect the reuse potential of that data. The data classes are stored in a tag store, where each tag within the tag store corresponds to a single cache line within the data cache. When reserving a cache line for the data associated with a command, a tag look-up unit examines the data classes in the tag store to determine which data to evict. Data that has a low reuse potential is evicted at a higher priority than data that has a high reuse potential. Advantageously, evicting data that belongs to a data class that has a lower reuse potential reduces the number of cache misses within the system."
8868925,"A secure virtual machine system, method, and computer program product implemented on a processor are provided for processing a third party's content for output. At least one processor is provided. Additionally, at least one secure virtual machine implemented on the processor is provided for interpreting a second party's program that processes and outputs a third party's content. The virtual machine system abstracts the underlying processor hardware allowing implementation variations across products to execute the same program identically. Furthermore, the scope of the programmable operations, the types of input & output variables, and execution of programs within the processor, is deliberately constrained within the virtual machine environment, in order to mitigate potential security leaks by programs, and to ensure confidentiality of second party's secrets, and third party's content as managed by the second party's program."
8872754,"A system, method, and computer program product are provided for controlling stereo glasses shutters. In use, a right eye shutter of stereo glasses is controlled to switch between a closed orientation and an open orientation. Further, a left eye shutter of the stereo glasses is controlled to switch between the closed orientation and the open orientation. To this end, the right eye shutter and the left eye shutter of the stereo glasses may be controlled such that the right eye shutter and the left eye shutter simultaneously remain in the closed orientation for a predetermined amount of time."
8872824,"A system, method, and computer program product are provided for performing shadowing utilizing shadow maps and ray tracing. In operation, one or more shadow maps are rendered for at least one light source. Additionally, low confidence pixels associated with the one or more shadow maps are determined. Furthermore, shadow rays associated with the low confidence pixels are traced."
8872827,"A shadow softening GPU and method. One embodiment of the GPU is configured to render a shadow cast by a surface occluding a light source and includes: (1) a fetching circuit operable to retrieve a depth value from a texture associated with the surface and a depth comparison result in a single fetch operation, and (2) a shadow softening circuit configured to respectively employ the depth comparison result and the depth value to identify the surface as a blocker and attenuate the light source for a pixel."
8872833,"The present invention systems and methods enable configuration of functional components in integrated circuits. A present invention system and method can flexibly change the operational characteristics of functional components in an integrated circuit die based upon a variety of factors, including if the die has a defective component. An indication of the defective functional component identification is received. A determination is made if the defective functional component is one of a plurality of similar functional components that can provide the same functionality. The other similar components can be examined to determine if they are parallel components to the defective functional component. The defective functional component is disabled if it is one of the plurality of similar functional components and another component can handle the workflow that would otherwise be assigned to the defective component. Workflow is diverted from the disabled component to other similar functional components."
8872896,"A system, method, and computer program product are provided for synchronizing stereo signals. In use, stereo signals are synchronized amongst a plurality of display devices utilizing hardware."
8872969,"A method includes storing data related to a video frame or an image separately from data related to a subtitle of the video frame or the image in a memory of a data processing device, and comparing, through a processor communicatively coupled to the memory, a color parameter of the data related to the video frame or the image to a color parameter of the data related to the subtitle. The method also includes dynamically adjusting a color parameter of at least a portion of the data related to the subtitle and/or a color parameter of at least a portion of the data related to the video frame or the image based on the comparison. Further, the method includes overlaying the data related to the subtitle on the data related to the video frame or the image following the dynamic adjustment prior to rendering thereof on a display unit."
8873237,"One embodiment of a system for cooling a heat-generating device includes a base adapted to be coupled to the heat-generating device, a housing coupled to the base, a liquid channel formed between the base and the housing, where a heat transfer liquid may be circulated through the liquid channel to remove heat generated by the heat-generated device, and a heat pipe disposed within the liquid channel, where the heat pipe increases the heat transfer surface area to which the heat transfer liquid is exposed. Among other things, the heat pipe advantageously increases the heat transfer surface area to which the heat transfer liquid is exposed and efficiently spreads the heat generated by the heat-generating device over that heat transfer surface area. The result is enhanced heat transfer through the liquid channel relative to prior art cooling systems."
8873625,"Using fewer bits to indicate the prediction mode used for encoding some of the non-frame-edge blocks of a frame. In an embodiment, fewer bits are used in case of boundary blocks of a slice, or slice group. In another embodiment, fewer bits are used when adjacent blocks are encoded using inter-frame coding or switchable intra-frame coding and such adjacent block cannot be used in predicting a block."
8874844,"A system and method for buffering intermediate data in a processing pipeline architecture stores the intermediate data in a shared cache that is coupled between one or more pipeline processing units and an external memory. The shared cache provides storage that is used by multiple pipeline processing units. The storage capacity of the shared cache is dynamically allocated to the different pipeline processing units as needed, to avoid stalling the upstream units, thereby improving overall system throughput."
8875121,"Disclosed are a method, system, and/or apparatus to enable multi-type and multi-location firmware updates and hardware feature updates through a single interface protocol. In one embodiment, a computer-implemented method of updating a platform system firmware and a component device firmware through a single interface protocol includes assigning a unique index number to each of a platform system and a component device, generating a platform system firmware payload, receiving a component device firmware payload, and generating a firmware update package comprising the platform system firmware payload and the component device firmware payload. The method also includes querying the platform payload header and the component payload header using a check image application programming interface and updating at least one of the platform system firmware and the component device firmware by passing at least one of the platform system firmware payload and the component device firmware payload to a set image API."
8875309,"A method of presenting content, in accordance with one embodiment of the present invention, includes receiving a request for an item of content and selectively verifying ownership of the requested content. If verification of ownership is not to be performed for the particular request, the item of content may be served. If ownership is substantiated for the particular request, the content may also be served. If ownership is not substantiated for the particular request, the content may be purged. Ownership verification may be by access to a physical copy of the content (e.g., DVD, CD or the like)."
8878849,"The method includes receiving a plurality of graphics primitives for rendering at a GPU of a computer system and rendering graphics primitives into pixel parameters of the pixels of a display, wherein the parameters include pixel depth values and pixel normal values. For each pixel of the display, an ambient occlusion process is performed. The algorithm takes as input a ND-buffer containing pixel depth values and pixel normals. Based on the pixel 3-D position and the pixel normal vector, horizon heights are computed by sampling the ND-buffer and an occlusion term is computed for each pixel based on the horizon heights. Based on the pixel 3-D position, the pixel normal vector, a normal occlusion term is computed by sampling the ND-buffer above the horizon in multiple directions. An ambient occlusion illumination value is computed by combining the horizon occlusion term and the normal occlusion term."
8878856,"A system, method, and computer program product are provided for depicting a body of water utilizing a height field and particles. In use, content depicting a body of water is identified. Additionally, a height field is generated for the content. Furthermore, at least a portion of the height field is converted to a plurality of particles based on predetermined criteria."
8878904,"A system, method, and computer program product are provided for enhancing a viewing experience when display content is viewed utilizing stereo glasses. In use, display content is received for being outputted utilizing a display. Further, a duration of a vertical blanking interval associated with the display content is increased for enhancing a viewing experience when the display content is viewed utilizing the stereo glasses."
8879350,"A processor and a system are provided for tuning a supply voltage for data retention. The contents of data storage circuitry are read and a data verification indication corresponding to the contents is computed. Then, the supply voltage provided to the data storage circuitry is reduced to a low voltage level that is intended to retain the contents of the data storage circuitry."
8879491,"A terminal comprising: a radio-frequency transmitter for transmitting packets on an uplink to a wireless cellular network; and processing apparatus comprising an upper protocol stack and a lower protocol stack, the upper stack being arranged to process data according to one or more transport protocols and form the data into packets of a plurality of different types for transmission over a packet-based network, and the lower stack being arranged to receive the packets from the upper stack and process them for transmission via the wireless cellular network. The lower stack comprises a plurality of packet queues each corresponding to a different respective priority level, and a packet decoder configured to supply each packet in dependence on its type to a packet queue of a corresponding priority level. The lower stack further comprises a dequeuing mechanism configured to dequeue packets for transmission from said queues in dependence on the priority levels."
8879681,"A system and method are provided for determining a time for safely sampling a signal of a dock domain. In one embodiment, a frequency estimate of a first clock domain is calculated utilizing a frequency estimator. Additionally, a time during which a signal from the first clock domain is unchanging is determined such that the signal is capable of being safely sampled by a second clock domain, using the frequency estimate. In another embodiment, a frequency estimate of a first dock domain is calculated utilizing a frequency estimator. Further, a phase estimate of the first clock domain is calculated based on the frequency estimate, utilizing a phase estimator. Moreover, a time during which a signal from the first clock domain is unchanging is determined such that the signal is capable of being safely sampled by a second clock domain, using the phase estimate."
8879699,"The application relates to a modem for use at a terminal. In one embodiment, the modem includes: (1) a first interface arranged for connection to a network; (2) a second interface arranged for connection to a host processor on the terminal; and (3) a processing unit arranged to, on receipt of a message from the network addressed to the host processor: determine whether or not the host processor is in a power saving mode; and if it is determined that the host processor is in a power saving mode, cause the first interface to transmit an acknowledgement to the message to the network regardless of whether a communication from the host processor is received via the second interface."
8880789,"Decoding a content of interest with optimal power usage. In an embodiment, a central processing unit (CPU) retrieves the frames of a data stream of interest from a secondary storage and stores them in a random access memory (RAM). The CPU forms an index table indicating the locations at which each of the frames is stored. The index table is provided to a decoder, which processes the frames in sequence to recover the original data from the encoded data. By using the index information, the power usage is reduced at least in an embodiment when the decoding is performed by an auxiliary processor."
8886501,A method of stimulating a deformable object comprises modeling deformable elasticity for the object by defining an actual shape and a goal shape and pulling points in the goal shape towards corresponding points in the goal shape.
8890573,"A clock gating latch, a method of gating a clock signal and an integrating circuit incorporating the clock gating latch or the method. In one embodiment, the clock gating latch includes: (1) a propagation circuit having a single, first switch configured to be driven by an input clock signal, (2) a keeper circuit coupled to the propagation circuit and having a single, first switch configured to be driven by the input clock signal and (3) an AND gate coupled to the propagation circuit and the keeper circuit and having an internal node coupled to a second switch in the propagation circuit and a second switch in the keeper circuit."
8893016,"A graphics system and a multi-user computer system are disclosed. The graphics system comprises a graphics processing unit (GPU) for processing pixels. It further includes a multi-user manager for allocating pixel processing capability for each one of a plurality of users, wherein each user uses a display and an input device. Moreover, the graphics system has a plurality of user attributes for each user. The multi-user computer system comprises a central processing unit (CPU) and a disk drive configured to support a plurality of users. Further, the multi-user computer system includes the graphics system."
8893299,"A method of authorizing access to content, in accordance with one embodiment of the present invention, includes receiving a request to access an instance of content. A key registry server may provide user accounts, which identify an authorized user of the instance of content and a parameter for accessing the instance of content. A determination is then made that accessing the instance of content is within the parameter and authorized for the user and access to the instance of content is allowed. The content may be local to the use system or accessed remotely (e.g., over a network). Also, the registry may be remote to the user system or local or both (e.g., with updates periodically made)."
8897352,A method comprises performing a first pass test over a plurality of sets of equalization coefficients to filter the plurality of sets of equalization coefficients to produce one or more filtered sets of equalization coefficients. Each filtered set of equalization coefficients meets a first predetermined threshold. The method also comprises performing a second pass test over the one or more filtered sets of equalization coefficients to determine a final set of equalization coefficients that meets a second predetermined threshold. The second pass test produces more accurate results than the first pass test.
8897365,"A system for executing video encoding operations. The system includes a video encoder for encoding an incoming video stream into a plurality of macro blocks. A motion estimation engine is coupled to the video encoder for controlling the encoding of the macro blocks. A video rate control processor is coupled to the video encoder and coupled to the motion estimation engine. The video rate control processor receives a plurality of parameters from the video encoder that indicate an encoding complexity for a macro block and a video frame of the video stream and, upon receiving an indication from the motion estimation engine, computes a quantization parameter for the macro block. The quantization parameter is dynamically adjusted for the video stream to achieve a target bit rate."
8897750,"A method, in a wireless communications device, comprising: receiving a new security mode configuration from a radio access network that is to replace an original security mode configuration as part of a security procedure; detecting, prior to completion of said security procedure, that a cell update message is to be sent to the network; transmitting a first cell update message to the network in accordance with the original security mode configuration; transmitting a second cell update message to the network in accordance with the new security mode configuration; receiving a cell update confirm message, the cell update confirm message sent by the network in accordance with a network determined security mode configuration; ascertaining if the network determined security mode configuration is either the original or new security mode configuration; and completing the cell update procedure in accordance with the ascertained security mode configuration."
8897829,"One aspect provides a method of controlling transmit power in a wireless device, wherein a desired transmit power is determined as a result of detection of a receive signal parameter. The method comprises detecting a desired maximum transmit power and generating a sequence of attenuation factors. The sequence is generated by monotonically increasing a variable at a controlled rate between a starting value and the maximum transmit power. The method further comprises using each attenuation factor in turn to: (a) reduce the measured value of the received signal power; and (b) reduce a determined desired value of the transmit power, where the transmit power is continually reduced as the variable is increased."
8904068,"One embodiment sets forth a technique for dynamically allocating memory during multi-threaded program execution for a coprocessor that does not support dynamic memory allocation, memory paging, or memory swapping. The coprocessor allocates an amount of memory to a program as a put buffer before execution of the program begins. If, during execution of the program by the coprocessor, a request presented by a thread to store data in the put buffer cannot be satisfied because the put buffer is full, the thread notifies a worker thread. The worker thread processes a notification generated by the thread by dynamically allocating a swap buffer within a memory that cannot be accessed by the coprocessor. The worker thread then pages the put buffer into the swap buffer during execution of the program to empty the put buffer, thereby enabling threads executing on the coprocessor to dynamically receive memory allocations during execution of the program."
8907975,"Digital video communication system and method facilitate conservation of communication bandwidth are presented. A present invention method forwards sampled chrominance data to other components in the system. Pixel chrominance values are sampled in accordance with the sampling scheme. The sampled chrominance values (e.g., 422, 420, 411, etc.) are forwarded to another component. For example, a graphics processing unit performs sampling operations and forwards the chrominance sampled information to another component (e.g., a board, a display, etc.). The graphics processing unit can also perform color space conversion before forwarding the chrominance sampled information to the other component. The other component performs up-sampling. For example, a display can perform the up-sampling to generate synthesized full RGB values. The sampled chrominance data can be further compressed (e.g., MPEG, WMV, etc.) before forwarding the sampled chrominance data and before performing the up-sampling."
8909746,"One embodiment of the present invention sets forth a technique for automatically provisioning a diskless computing device and an associated server system. A diskless computing device client incorporates an iSCSI initiator that is used to access resources provided by an iSCSI target that is resident on a server computing device. The iSCSI initiator is implemented in the client firmware, providing INT13 disk services entry points, thereby enabling the client to transparently access virtual storage devices at boot time. The client device conducts an apparently local installation using the virtual storage devices provided by the server computing device. A short signature value is associated with the boot image, uniquely associating the boot image with the specific client hardware configuration. When the client device boots normally, the signature value of the client device is presented to the server computing device to automatically reference the appropriate boot image."
8910191,"A codec architecture including an audio wave driver and a coded topology driver. The audio wave driver is communicatively coupled to an audio engine and an analog audio codec. The coded topology driver is communicatively coupled to the audio wave driver by a set of interfaces that enables streamlined code implementation, improved operation efficiency and power savings, while allowing vendors to supply differentiating functionality outside of the basic requirements of the operating system."
8913653,"An equalization parameter analyzer includes a parameter section configured to acquire at least one current parameter for a wireless receiver and an analyzer section configured to compare the at least one current parameter with at least one corresponding previous parameter. Additionally, the equalization parameter analyzer also includes a coefficients section configured to initiate a generation of new equalizer coefficients in the wireless receiver based on a change between the at least one current and corresponding previous parameters that exceeds a predefined threshold. A method of equalization coefficients generation is also provided."
8917271,"One embodiment of the present invention sets forth a technique for redistributing geometric primitives generated by tessellation and geometry shaders for per-vertex by multiple graphics pipelines. Geometric primitives that are generated in a first processing stage are collected and redistributed more evenly and in smaller batches to the multiple graphics pipelines for vertex processing in a second processing stage. The smaller batches do not exceed the resource limits of a graphics pipeline and the per-vertex processing workloads of the graphics pipelines in the second stage are balanced. Therefore, the performance of the tessellation and geometry shaders is improved."
8917760,"The invention provides a method of manufacturing a user equipment comprising a wireless modem, a method of activating a user equipment as a wireless modem, and a corresponding server and user equipment. A processor is produced for executing wireless modem code to operate the processor as a wireless modem, the processor having a writeable, non-volatile memory for storing the wireless modem code but being produced with at least a substantive portion of said wireless modem code not installed on said memory or otherwise, thus rendering the processor inoperative as a wireless modem. The processor is assembled into a user equipment and supplied to an end-user still without the substantive portion of wireless modem code installed. In response to an indication from the end-user requesting activation of the user equipment as a wireless modem, at least said substantive portion of wireless modem code is then distributed to the end-user for installation on the memory the user equipment's processor."
8918440,"Methods and systems for decompressing data are described. The relative magnitudes of a first value and a second value are compared. The first value and the second value represent respective endpoints of a range of values. The first value and the second value each have N bits of precision. Either the first or second value is selected, based on the result of the comparison. The selected value is scaled to produce a third value having N+1 bits of precision. A specified bit value is appended as the least significant bit of the other (non-selected) value to produce a fourth value having N+1 bits of precision."
8922550,"A system and method for constructing a bounding volume hierarchical structure are disclosed. The method includes defining a parent node for the bounding volume hierarchical structure, the parent node including a parent node bounding volume enclosing a plurality of objects. A first cost is computed for performing an object partition of the parent node bounding volume to produce a first plurality of child node bounding volumes, and a second cost is also computed for performing a spatial partitioning of the parent node bounding volume to produce a second plurality of child node bounding volumes. The bounding volume hierarchical structure is constructed employing the second plurality of child node bounding volumes produced from the spatial partitioning of the parent node bounding volume if the second cost is lower than the first cost."
8922555,"One embodiment of the present invention sets forth a technique for storing only the enabled components for each enabled vector and writing only enabled components to one or more specified render targets. A shader program header (SPH) file provides per-component mask bits for each render target. Each enabled mask bit indicates that the pixel shader generates the corresponding component as an output to the raster operations unit. In the hardware, the per-component mask bits are combined with the applications programming interface (API)-level per-component write masks to determine the components that are updated by the shader program. The combined mask is used as the write enable bits for components in one or more render targets. One advantage of the combined mask is that the components that are not updated are not forwarded from the pixel shader to the ROP, thereby saving bandwidth between those processing units."
8922566,"A graphics processing device that is portable, reconfigurable and provides graphics processing for a computer system is provided. The graphics processing device includes a Universal Serial Bus (USB) interface coupled with the graphics processor and configured to be coupled with computer system. The graphics processing device further includes the USB interface configured to transfer a graphics instruction, originated by the computer system, to the graphics processor. The graphics processing device may further include a battery coupled with the graphics processor to partially power the graphics processor. The battery may be rechargeable. The graphics processor may be configured to process graphics instruction on behalf of the computer system. A portable processing system to provide processing for a computer system is also disclosed. The portable processing system may include a processor. The portable processing system may include a USB module coupled with processor and configured to be coupled with computer system."
8923311,"A unit for use at a terminal as an external wireless modem. In one embodiment, the unit includes: a wireless transceiver for connecting to a gateway between the wireless cellular network and a further, packet-based network; second interface apparatus for connecting to the terminal. The unit further includes processing apparatus arranged to receive a first link layer identifier from the wireless cellular network, gateway or further network, intended for use by the terminal as a source identifier when accessing the further network via the wireless cellular network and gateway. The processing apparatus is configured to intercept at least one message being conveyed from the terminal to the gateway comprising a second link layer identifier generated by the terminal as a source identifier, translate the second identifier into the first link layer identifier and retransmit the message to the gateway with the first link layer identifier as the source identifier."
8923385,"Described herein are a number of approaches for implementing a video encoder with hardware-enabled rewind functionality. In several embodiments, rewind functionality can be implemented in hardware, in a manner which allows the transform engine of the encoder to reprocess video data, without requesting data from other stages in the encoder. Such rewind functionality is useful in implementing some video standards in a pipeline architecture, such as the H.264 standard. In one embodiment, a method of encoding video data is described, which involves obtaining a first portion of video data from a first location in a buffer, and performing an encoding operation on it. The second portion of video data is obtained from a second location in the buffer, and encoding operations begin on the second portion. The first portion of video data can be retrieved from the first location, in order to reprocess the first portion if necessary."
8923652,"A set of images is processed to modify and register the images to a reference image in preparation for blending the images to create a high-dynamic range image. To modify and register a source image to a reference image, a processing unit generates a correspondence map for the source image based on a non-rigid dense correspondence algorithm, generates a warped source image based on the correspondence map, estimates one or more color transfer functions for the source image, and fills the holes in the warped source image. The holes in the warped source image are filled based on either a rigid transformation of a corresponding region of the source image or a transformation of the reference image based on the color transfer functions."
8924625,"A method includes implementing, with a memory of a computing device, a memory controller of the memory of the computing device, a storage device coupled to the computing device and/or an external device coupled to the computing device, a scheme for detecting an overlap between a first address range and a second address range. The first address range includes a first starting address and a first ending address, and the second address range includes a second starting address and a second ending address. The method also includes reducing a number of comparators utilized in the address range overlap detection through solely determining whether the first starting address is within the second address range or the second starting address is within the first address range."
8928676,"In a raster stage of a graphics processor, a method for parallel fine rasterization. The method includes receiving a graphics primitive for rasterization in a raster stage of a graphics processor. The graphics primitive is rasterized at a first level to generate a plurality of tiles of pixels. The titles are subsequently rasterized at a second level by allocating the tiles to an array of parallel second-level rasterization units to generate covered pixels. The covered pixels are then output for rendering operations in a subsequent stage of the graphics processor."
8928677,"One embodiment of the present invention sets forth a technique for performing low latency computation on a parallel processing subsystem. A low latency functional node is exposed to an operating system. The low latency functional node and a generic functional node are configured to target the same underlying processor resource within the parallel processing subsystem. The operating system stores low latency tasks generated by a user application within a low latency command buffer associated with the low latency functional node. The parallel processing subsystem advantageously executes tasks from the low latency command buffer prior to completing execution of tasks in the generic command buffer, thereby reducing completion latency for the low latency tasks."
8928681,"Sequential write operations to a unit of compressed memory, known as a compression tile, are examined to see if the same compression tile is being written. If the same compression tile is being written, the sequential write operations are coalesced into a single write operation and the entire compression tile is overwritten with the new data. Coalescing multiple write operations into a single write operation improves performance, because it avoids the read-modify-write operations that would otherwise be needed."
8929683,"A set of images is processed to modify and register the images to a reference image in preparation for blending the images to create a high-dynamic range image. To modify and register a source image to a reference image, a processing unit generates correspondence information for the source image based on a global correspondence algorithm, generates a warped source image based on the correspondence information, estimates one or more color transfer functions for the source image, and fills the holes in the warped source image. The holes in the warped source image are filled based on either a rigid transformation of a corresponding region of the source image or a transformation of the reference image based on the color transfer functions."
8930636,"One embodiment sets forth a technique for ensuring relaxed coherency between different caches. Two different execution units may be configured to access different caches that may store one or more cache lines corresponding to the same memory address. During time periods between memory barrier instructions relaxed coherency is maintained between the different caches. More specifically, writes to a cache line in a first cache that corresponds to a particular memory address are not necessarily propagated to a cache line in a second cache before the second cache receives a read or write request that also corresponds to the particular memory address. Therefore, the first cache and the second are not necessarily coherent during time periods of relaxed coherency. Execution of a memory barrier instruction ensures that the different caches will be coherent before a new period of relaxed coherency begins."
8930861,"A system, method, and computer program product are provided for creating a hardware design. In use, one or more parameters are received, where at least one of the parameters corresponds to an interface protocol. Additionally, a data flow is constructed based on the one or more parameters. Further, an indication of one or more control constructs is received, where a hardware design is capable of being created, utilizing the constructed data flow and the one or more control constructs."
8930862,"A system, method, and computer program product for converting a design from edge-triggered docking to two-phase non-overlapping clocking is disclosed. The method includes the steps of replacing an edge-triggered flip-flop circuit that is coupled to a combinational logic circuit with a pair of latches including a first latch circuit and a second latch circuit and determining a midpoint of the combinational logic circuit based on timing information. The second latch circuit is propagated to a midpoint of the combinational logic circuit and two-phase non-overlapping clock signals are provided to the pair of latches."
8930969,"A method of executing a physics simulation is performed in a system comprising a computational platform, a main application stored in the computational platform, a secondary application stored in the computational platform, and a cloth application programming interface (API) implemented in the computational platform. The method defines a cloth simulation call in the cloth API, and by operation of the main application, invokes a software routine using the cloth simulation call. Additionally, by operation of the secondary application, a state of the physics simulation is updated in response to the software routine."
8933933,"One embodiment of the present invention sets forth an architecture for advancing the Z-test operation prior to pixel shading whenever possible. The current rendering state, as maintained by the setup engine, determines whether advancing the Z-test function above the shader engine for “early” Z-testing is possible or whether the Z-test function should be deferred until after shading operations for “late” Z-testing. Data is dynamically routed to each processing engine in the pipeline, so that the appropriate data flow for either early Z or late Z is dynamically constructed, as determined by the current rendering state. The same functional units are utilized in both early Z and late Z configurations."
8934458,"A method, program and user equipment for wireless communication in a cellular communication system comprising a plurality of base stations. The method comprises: synchronizing to one of said the base stations using a synchronization channel transmitted from that base station; receiving a pilot channel from said base station; after synchronizing to said base station, receiving a signal from that base station; and using the pilot channel from said base station to cancel interference on said signal caused by the synchronization channel."
8934539,"A method and system for vector processor quantization acceleration for an encoding process. The encoding process is implemented using the hardware of a video processor. The method includes computing coefficients for a DCT (discrete cosine transform) encoding operation and determining a quantization step for use with a quantization operation for each of the coefficients. A vector processor is then used for quantization acceleration. Out of a range of possible quantized output values, the vector processor computes a set of quantized output values from the coefficients. The vector processor is configured to evaluate each of the quantized output values of the set in parallel. For the range of possible quantized output values that are not computed using the vector processor, the quantized output values are computed by using a multiplication logic path."
8935559,A data connector includes two different sets of wires that transport data between components of a computer system. A first set of wires transports data from a first component to a second component. A second set of wires transports data from the second component to the first component. The first set of wires is interlaced with the second set of wires so that each wire in the data connector transports data in the opposite direction of one or more neighboring wires.
8938127,"Rendered image data is encoded by a server computing device and transmitted to a remote client device that executes an interactive application program. The client device decodes and displays the image data and, when the user interacts with the application program, the client device provides input control signals to the server computing device. When input control signals are received by the server, the latency incurred for encoding and/or decoding the image data is reduced. Therefore, the user does not experience inconsistencies in the frame rate of images displayed on the client when the user interacts with the application program. The reduction in latency is achieved by dynamically switching from a hardware implemented encoding technique to a software implemented encoding technique. Latency may also be reduced by dynamically switching from a hardware implemented decoding technique to a software implemented decoding technique."
8938485,"One embodiment of the present invention sets forth a technique for performing fast integer division using commonly available arithmetic operations. The technique may be implemented in a four-stage process using a single-precision floating point reciprocal in conjunction with integer addition and multiplication. Furthermore, the technique may be fully pipelined on many conventional processors for overall performance that is comparable to the best available high-performance alternatives."
8938598,A technique for ensuring that multiple producer threads may simultaneously write entries in a shared queue and one or more consumers may read valid data from the shared queue. Writing of the shared queue by the multiple producer threads may occur in parallel and the one or more consumer threads may read the shared queue while the producer threads write the shared queue. A “wait-free” mechanism allows any producer thread that writes a shared queue to advance an inner pointer that is used by a consumer thread to read valid data from the shared queue. The inner pointer indicates the most recent valid entry. An output pointer is advanced with an atomic operation to indicate a next entry or portion of memory in the shared queue that is available for allocation. The shared queue may be implemented as a circular buffer.
8938661,"An application programming interface (API) executed by a first processing unit combines audio data samples with error code values generated for those samples. The API then causes a data stream to be opened having sufficient bandwidth to accommodate combined samples made up of audio data samples and corresponding error code values. The combined samples are then transmitted to a decoder and validation unit within a second processing unit that receives the combined data, strips the error code values and validates the audio data based on the error code values. When the error code values indicate that the audio data has been compromised, the second processing unit terminates the output of sound derived from the audio data."
8941430,"One embodiment sets forth a timing calibration technique for on-chip source-synchronous, complementary metal-oxide-semiconductor (CMOS) repeater-based interconnect. Two transition patterns may be applied to calibrate the delay of an on-chip data or clock wire. Calibration logic is configured to apply the transition patterns and then trim the delays of the clock and data wires based on captured calibration patterns. The trimming adjusts the delay of the clock and data wires using a configurable delay circuit. Timing errors may be caused by crosstalk, power-supply-induced jitter (PSIJ), or wire delay variation due to transistor and wire metallization mismatch. Chip yields may be improved by reducing the occurrence of timing errors due to mismatched delays between different wires of an on-chip interconnect."
8941594,"An interface, apparatus, circuit and method for interfacing with an electronic device, such as a cellular telephone, are disclosed. The interface includes a key pad with a number of keys, each operable for providing a unique input to the electronic device, and a actuator for selectively actuating one or more of the keys. A controller, coupled to the key pad, scans the keys according to a mode of operation of the electronic device. A mode selector, operable with the controller, selects a first or second operating mode. In the first, useful for instance in performing telephonic functions, each key provides its unique input discretely. In the second mode, useful for instance for providing a game related function, certain of the keys are selectively chorded to function for providing their respective inputs together, effectively simultaneously, according to a manipulation of the actuator by the user."
8941653,"One embodiment of the present invention sets forth a technique for rendering graphics primitives in parallel while maintaining the API primitive ordering. Multiple, independent geometry units perform geometry processing concurrently on different graphics primitives. A primitive distribution scheme delivers primitives concurrently to multiple rasterizers at rates of multiple primitives per clock while maintaining the primitive ordering for each pixel. The multiple, independent rasterizer units perform rasterization concurrently on one or more graphics primitives, enabling the rendering of multiple primitives per system clock."
8941668,A scalable discrete graphics system (DGS) is disclosed. The DGS includes a serial bus bridge configured to couple a plurality of GPUs to a serial bus. A serial bus connector is coupled to the serial bus bridge. A system chassis coupled to the serial bus bridge and the serial bus connector and configured to house the GPUs. The serial bus connector is configured to removably connect to a computer system. The GPUs access the computer system via the serial bus bridge and the serial bus connector to cooperatively execute 3-D graphics instructions from the computer system.
8941669,"Frames are rendered by multiple graphics processors (GPUs), which may be heterogeneous. Graphics processors split the execution of the command in a push buffer of a frame. One GPU begins rendering a frame, and a second GPU takes over rendering that frame after the second GPU is done rendering a previous frame. The second GPU may then begin rendering a subsequent frame."
8941672,"Embodiments of the present disclosure provide techniques for identifying a display when a graphics processing unit (GPU) connected to the display via a display control bus is in a low power state. By providing a separate microcontroller with a parallel connection to the display control bus, the microcontroller may detect the presence of a display device even when the GPU is in the low power state. In response to detecting the display device, the microcontroller may notify a motherboard chipset (e.g., via an interrupt) prompting the motherboard chipset to initiate a sequence to bring the GPU out of the low power state."
8941676,"One embodiment of the present invention includes a graphics subsystem for processing multi-sample anti-aliasing work. The graphics subsystem includes a cache unit, a tiling unit, and a screen-space pipeline coupled to the cache unit and to the tiling unit. The tiling unit is configured to organize multi-sample anti-aliasing commands into cache tile batches. The screen-space pipeline includes a pixel shader and a raster operations unit, and receives cache tile batches from the tiling unit. The pixel shader is configured to generate sample data based on a set of primitives and to generate resolved data based on the sample data. The raster operations unit is configured to store the sample data in the cache unit and to invalidate the sample data after the pixel shader generates the resolved data."
8942474,"A method for performing indexing in an image decoder. The method includes identifying a tile in an image, wherein the image comprises a plurality of tiles, and wherein each tile includes color data associated with a plurality of pixels. The method includes asymmetrically providing a plurality of indices throughout the tile. The method includes identifying a pixel in the tile. The method also includes determining a corresponding rectangular grid that includes the pixel, wherein the corresponding rectangular grid comprises at least one indices in a group of indices. The method includes determining an index for the pixel by bilinearly filtering the group of indices that is associated with the corresponding rectangular grid, wherein the filtering is performed in relation to the pixel."
8942536,"A video navigation system and method can be utilized to efficiently and adjustably navigate video content. In one embodiment, a video information control method facilitates efficient video navigation. A video stream is received and video access point selection between multiple access points in said video stream is controlled. The presentation information is forwarded for each of the multiple access points. In one exemplary implementation, the presentation information is forwarded to a display and the information is directed to presenting a main viewing area and navigation areas that present looping video clips or portions of the video stream at time intervals ahead of and behind the video portion being presented in the main viewing area."
8943091,"A system, method, and computer program product are provided for performing a string search. In use, a first string and a second string are identified. Additionally, a string search is performed, utilizing the first string and the second string."
8943448,"A hardware model database is identified which stores a graph-based common representation of a hardware design that includes hardware module nodes each representative of a unique module of the hardware design and associated with one or more instances of the unique module. Additionally, a signal dump resulting from a simulation of a logic code model of the hardware design is identified. Each instance of each unique module is identified using the hardware model database, and for each assertion condition included therein, a corresponding value for the assertion condition is determined from the signal dump. Further, a construct of the hardware design corresponding to each instance of each unique module is conditionally displayed by a debugger application, based on the determined values of the corresponding assertion conditions included in the instance of the unique module."
8943457,"An aspect of the present invention replaces memory elements in a scan chain with corresponding new (memory) elements, with each new element having two paths to provide the corresponding data output. One of the two paths is operable to connect the data value to the combinational logic only during a capture phase of said test mode, and the second path is operable to connect the data value to the next element in the chain during a shift phase of said test mode. As a result, unneeded transitions/evaluations in the combinational logic are avoided during shift time, thereby reducing the resource requirements in the corresponding duration. However, the further processes (including various design phases and fabrication) are continued based on the original data (i.e., without the new elements) such that unneeded delays are avoided during the eventual operation in functional mode of the various fabricated IC units."
8943559,"A method of authenticating access to an electrical device. The method comprises comparing, at an electronic processor, one or more patterns of temporal or physical properties, associated with an access entry string, to a non-transitory electronic profile data base of ranges of the corresponding patterns, from previously approved access entry strings. The method also comprises approving or denying at the electronic processor, the access entry string. The access entry string is approved if the one or more patterns falls within the respective range of the corresponding patterns in the profile data base. The access entry string is denied if the one or more patterns falls outside the respective range of the corresponding patterns in the profile data base."
8943584,"A method for providing an operating system access to devices, including enumerating hardware devices and virtualized devices, where resources associated with a first hardware device are divided into guest physical resources creating a software virtualized device, and multiple instances of resources associated with a second hardware device are advertised thereby creating a hardware virtualized device. First and second permission lists are generated that specify which operating systems are permitted to access the software virtualized device and the hardware virtualized device, respectively. First and second sets of virtual address maps are generated, where each set maps an address space associated with either the software virtualized device or the hardware virtualized device into an address space associated with each operating system included in the corresponding permission list. The method further includes arbitrating access requests from each of the plurality of operating systems based on the permission lists and the virtual address maps."
8947137,"Presented systems and methods facilitate efficient reset operation. In one embodiment, a system comprises a core domain portion an I/O domain portion and a core reset I/O by-pass component. The core domain portion is configured to operate at a nominal core domain voltage level. The I/O domain portion configured to operate at a nominal I/O domain voltage level. The core reset I/O by-pass component configured to forward a reset indication to the core domain independent of the I/O domain. In one exemplary implementation the core reset I/O by-pass component is operable to receive an input reset indication at a high domain voltage level and to convert the input reset indication to a core reset signal that is less than or substantially equal to the nominal core domain voltage, wherein the high domain is voltage higher than the core domain voltage level."
8947430,"A method for rendering a particle-based fluid surface includes generating a depth image of a plurality of particles which form a fluid surface, and smoothing the depth image to generate a smoothed depth image. From the smoothed depth image, a smoothed surface position and a smoothed surface normal for each of a plurality of pixels included within the smoothed depth image is determined, and a shaded surface of the fluid is rendered as a function of the smoothed surface positions and the smoothed surface normals."
8947432,"One embodiment of the invention sets forth a mechanism for interleaving consecutive display frames rendered at complementary reduced resolutions. The GPU driver configures a command stream associated with a frame received from a graphics application for reduced frame rendering. The command stream specifies a nominal resolution at which the frame should be rendered. The reduced resolution associated with the frame is determined based on the reduced resolution of an immediately preceding frame (i.e., the complementary reduced resolution), if one exists, or on GPU configuration information. The GPU driver then modifies the command stream to specify the reduced resolution. The GPU driver also inserts an upscale command sequence specifying the nominal resolution into the command stream. Once the command stream is configured in such a manner, the GPU driver transmits the command stream to the GPU for reduced rendering."
8947444,A data structure that includes pointers to vertex attributes and primitive descriptions is generated and then processed within a general processing cluster. The general processing cluster includes a vertex attribute fetch unit that fetches from memory vertex attributes corresponding to the vertices defined by the primitive descriptions.
8948167,"One embodiment of the present invention is a control unit for distributing packets of work to one or more consumer of works. The control unit is configured to assign at least one processing domain from a set of processing domains to each consumer included in the one or more consumers, receive a plurality of packets of work from at least one producer of work, wherein each packet of work is associated with a processing domain from the set of processing domains, and a first packet of work associated with a first processing domain can be processed by the one or more consumers independently of a second packet of work associated with a second processing domain, identify a first consumer that has been assigned the first processing domain, and transmit the first packet of work to the first consumer for processing."
8948817,"A wireless serving communication unit comprises a signal processor, for receiving and processing a signal to be broadcast, and a number of transmitters operably coupled to the signal processor, for transmitting the broadcast signal in a plurality of sectorised cells to a wireless subscriber communication unit. The wireless serving communication unit comprises logic to replicate the processed signal into a plurality of replicated signals and logic introduce one or more delay(s) to one or more of the replicated processed signals, such that replicated broadcast signals having different delays are transmitted from a plurality of sectorised cells to one or more wireless subscriber communication unit."
8949497,"In an apparatus according to one embodiment of the present disclosure, a communications link comprises a first device and a second device communicating with each other via the communications link at a plurality of different speeds. However, prior to communicating via the communications link for the first time at a second speed, the first device and second device complete a first training cycle at the second speed. Further, during this first training cycle for the second speed, the first training cycle for the second speed will pause before the first training cycle at the second speed completes, and the first device and second device communicate at a first speed for a period of time before returning to the paused first training cycle at the second speed. When the paused first training cycle for the second speed continues, the first training cycle for the second speed will continue where it had paused."
8949541,"A method for cleaning dirty data in an intermediate cache is disclosed. A dirty data notification, including a memory address and a data class, is transmitted by a level 2 (L2) cache to frame buffer logic when dirty data is stored in the L2 cache. The data classes may include evict first, evict normal and evict last. In one embodiment, data belonging to the evict first data class is raster operations data with little reuse potential. The frame buffer logic uses a notification sorter to organize dirty data notifications, where an entry in the notification sorter stores the DRAM bank page number, a first count of cache lines that have resident dirty data and a second count of cache lines that have resident evict_first dirty data associated with that DRAM bank. The frame buffer logic transmits dirty data associated with an entry when the first count reaches a threshold."
8949576,An apparatus for processing operations in an adaptive computing environment is provided. The adaptive computing environment including at least one processing node. A node includes a memory configured to receive and store data. The data is received from a programmable interconnection network and stored. The node also includes an execution unit configured to perform a signal processing operation. The operation is performed using data retrieved from the memory and an output result is generated. The output result may be used for further computations or sent directly to the programmable interconnection network for transfer to another processing node in the adaptive computing environment.
8949645,"Embodiments related to controlling power distribution within a microprocessor are provided. In one example, a microprocessor comprising a power supply is provided. The example microprocessor also includes a plurality of power gate zones configured to receive power from the power supply, each power gate zone including a plurality of power gates, where the power gates within any given one of the power gate zones are controlled by the microprocessor independently of its control of power gates within any other of the power gate zones. The example microprocessor is operative to cause power initially to be supplied to a first power gate in a first one of the power gate zones, power then to be supplied to a second power gate in a second one of the power gate zones, and power then to be supplied to a third power gate in the first one of the power gate zones."
8949652,"In one embodiment, a microprocessor includes one or more processing cores. At least one processing core includes a clock shaping circuit that is configured to receive a clock input signal. The clock shaping circuit includes rising edge skew logic that is configured to selectively delay a rising edge of the clock input signal and falling edge skew logic that is configured to selectively delay a falling edge of the clock input signal independent of adjustment of the rising edge."
8949841,"A streaming multiprocessor (SM) in a parallel processing subsystem schedules priority among a plurality of threads. The SM retrieves a priority descriptor associated with a thread group, and determines whether the thread group and a second thread group are both operating in the same phase. If so, then the method determines whether the priority descriptor of the thread group indicates a higher priority than the priority descriptor of the second thread group. If so, the SM skews the thread group relative to the second thread group such that the thread groups operate in different phases, otherwise the SM increases the priority of the thread group. f the thread groups are not operating in the same phase, then the SM increases the priority of the thread group. One advantage of the disclosed techniques is that thread groups execute with increased efficiency, resulting in improved processor performance."
8951814,"A device and method for providing access to a signal of a flip chip semiconductor die. A hole is bored into a semiconductor die to a test probe point. The hole is backfilled with a conductive material, electrically coupling the test probe point to a signal redistribution layer. A conductive bump of the signal redistribution layer is electrically coupled to a conductive contact of a package substrate. An external access point of the package substrate is electrically coupled to the conductive contact, such that signals of the flip chip semiconductor die are accessible for measurement at the external access point."
8952705,"Systems and methods for transition delay measuring are presented. A transition delay measuring method can include oscillating a signal between states and tracking an indication associated with an isolated attribute of the transitions between the states. Oscillations can include asymmetric transitions between the states and the tracked isolated attribute can be a delay in completing transitions between the states in one direction or vice versa. The asymmetric transitions can include transitions between the first state and the second state that are faster than slower transitions between the second state and the first state or vice versa. The tracked indication can be utilized in analysis of the isolated transition delay characteristics. The results can be utilized in analysis of various further features and characteristics (e.g., examination of leakage current related power consumption, timing of asymmetric operation, etc.). The analysis can include examination of fabrication process and operating parameters."
8952736,"A phased lock loop (PLL) including a retimer unit, rotator unit, and clock selection unit. The retimer unit is configured for sampling a divided clock generated by a divide-by-N unit with a plurality of phases of an oscillator clock generated by a ring oscillator to generate a plurality of phase shifted divide-by-N clocks. The rotator unit is configured for selectively rotating through the plurality of phase shifted divide-by-N clocks based on a constant phase shift interval, wherein the rotator unit controls a clock selection unit to produce a single output phase selected from a plurality of generated divide-by-N clock phases."
8958390,"An apparatus comprising: a first transceiver arranged to communicate over a wireless network, the first transceiver comprising a first clock; and a second transceiver arranged to communicate other than by said wireless network, the second transceiver comprising a second clock. The second sends a request signal to the first transceiver. In response, the first transceiver transitions from a first mode to a second mode and provides to the second transceiver a response signal for calibrating the second clock relative to the first clock. In the first mode the first transceiver performs zero or more calibrations of the first clock relative to the wireless network, and in the second mode the first transceiver performs at least one additional calibration of the first clock relative to the wireless network, the response signal being based on the at least one additional calibration."
8958688,"Aspects of performing smooth backwards playback in a DVD system are described. The aspects include reconstructing frame data for every frame in a set of frames of an original playback, the set of frames preceding a currently displayed frame. Further included is the utilization of at least seven frame buffers to store frame data during the reconstructing step. The reconstructed frame data is then displayed in reverse order of the original playback for the set of frames."
8959497,"One embodiment of the present invention sets forth a technique for partitioning a predecessor thread program into sub-programs and dynamically spawning a thread grid of the sub-programs based on the outcome of a conditional statement in the predecessor thread program. The programming instructions for the predecessor thread program are analyzed to assess the benefit of partitioning the thread program at a conditional statement into sub-programs. If the predecessor thread program is partitioned, then each branch of the conditional statement may be used to form a separate sub-program. Predicate tables are populated at the predecessor thread program run-time to establish which possible instances of the thread sub-programs should be spawned in subsequent execution phases."
8963932,"A method of calculating performance parameters for a type of data being executed by a unified processing subunit. In one embodiment, a task (e.g., a draw call) is executed by a processing pipeline (e.g., a GPU). An ALU within a unified processing subunit (e.g., a unified shader processing unit) is queried to determine a type of data (e.g., vertex processing, pixel shading) being processed by the ALU. Performance parameters (e.g., bottleneck and utilization) for the type of data being processed by the ALU is calculated and displayed (e.g., stacked graph). Accordingly, software developers can visualize component workloads of a unified processing subunit architecture. As a result, utilization of the unified processing subunit processing a particular data may be maximized while bottleneck is reduced. Therefore, the efficiency of the unified processing subunit and the processing pipeline is improved."
8963935,"One embodiment of the present invention sets forth a method for accessing display configuration information of a display device in a multi-graphics-processing-unit (multi-GPU) system based on a hot-plug detection signal associated with the same display device. The method includes the steps of changing the power state of a discrete GPU (dGPU) in the multi-GPU coupled to the display device after having detected an assertion of the hot-plug detection signal, retrieving the display configuration information of the display device with the dGPU, and powering down the dGPU after having retrieved the display configuration information."
8963940,"One embodiment of the invention sets forth a method for transmitting display data to a display device. The method includes the steps of receiving a contract for a frame of display data, preparing the frame of display data to ensure the timing requirements of the display device can be satisfied based on the contract, and transmitting the frame of display data to the display device while the contract is pending."
8964580,"Techniques for the discovery of a topology of varying complexity and discovery of the capability of the devices of the topology include querying a plurality of node devices for node data. At least an initial portion of node data of one or more node devices is received in response to the query. In addition, previously determined node data is retrieved from a cache. The initial portion of node data is correlated to the previously determined node data to deduce node data for one or more node devices within a predetermined period of time. It is to be appreciated that the deduced node data may include node data beyond the initial portion of node data and/or node data for other node devices beyond the initially responding node devices. The deduced node data may then be reported to an operating system."
8964822,"A modem is disclosed. An embodiment thereof includes: a first interface arranged to connect to a network, a second interface arranged to connect to a host processor on the terminal, an audio interface arranged to connect to an audio processing means and a processing unit arranged to receive a plurality of parameters from the terminal via the second interface. The plurality of parameters are associated with a call established by the host processor to at least one further terminal connected to the network; wherein the processing unit is further arranged to receive input voice data from the audio processing means, process the input voice data in dependence on at least one of said parameters; and transmit the processed input voice data via the first interface to the at least one further terminal over said network during the call in dependence on a further at least one of said parameters."
8964919,"A system and method are provided for determining a time for safely sampling a signal of a clock domain. In one embodiment, a phase estimate of a first clock domain is calculated based on a relative frequency estimate between a second clock domain and the first clock domain and, based on the phase estimate, a first time during which a signal from the first clock domain is unchanging such that the signal is capable of being safely sampled by the second clock domain is determined to generate a first sampled signal in the second clock domain. Additionally, an updated phase estimate is calculated, and, based on the updated phase estimate, a second time during which the signal from the first clock domain is changing such that the signal is not capable of being safely sampled by the second clock domain is determined. During the second time the first sampled signal in the second clock domain is maintained."
8966272,"Embodiments of the present invention are directed to a computer-implemented method for author verification and authorization of object code. In one embodiment, program object code is linked with a plurality of data blocks to create linked object code and a MAP file. Thereafter, author verification is performed by executing a plurality of comparisons between the linked object code and the MAP file. In another embodiment, a digital signing procedure is performed on linked object code by creating a signature data block. The signature data block is then encrypted and written to the linked object code to create digitally-signed object code. In another embodiment, an application program embodied in linked object code generates a data packet. The data packet is then compared to a previously-generated signature data packet from the linked object code to determine if the linked object code is authorized."
8970584,"A bounding box-based method for reducing the number of samples tested for rendering a screen space region of an image includes determining a trajectory of a primitive in screen space for an image which is to be rendered and constructing an axis-aligned bounding box for the screen space region. The axis-aligned bounding box includes a bound in a non-screen dimension that is defined as a function of the screen space trajectory of the primitive, and overlaps a portion of the screen space region. One or more sample points which are located within the screen space region, and which are not overlapped by the axis-aligned bounding box are excluded from testing."
8970608,"One embodiment of the present invention sets forth a technique for transmitting state information associated with at least one graphics command to a graphics processor. The method includes the steps of generating a state object that specifies a set of properties that is needed to execute a first graphics command within the graphics processor, storing in the state object a value associated with a first property included in the set of properties, marking a second property included in the set of properties as a dynamic property, where a value associated with the second property is not stored in the state object and can be updated without having to modify the state object, and transmitting the state object to the graphics processor in order to execute the first graphics command."
8970626,"A system, method, and computer program product are provided for performing path tracing. In use, one or more matte objects are identified in a scene. Additionally, one or more synthetic objects are identified in the scene. Further, path tracing is performed within the scene, where the path tracing accounts for interactions between one or more of the matte objects and one or more of the synthetic objects."
8976185,"One embodiment of the present invention sets forth a technique for executing an operation once work associated with a version of a state object has been completed. The method includes receiving the version of the state object at a first stage in a processing pipeline, where the version of the state object is associated with a reference count object, determining that the version of the state object is relevant to the first stage, incrementing a counter included in the reference count object, transmitting the version of the state object to a second stage in the processing pipeline, processing work associated with the version of the state object, decrementing the counter, determining that the counter is equal to zero, and in response, executing an operation specified by the reference count object."
8976195,"One embodiment of the present invention sets forth a technique for generating a batch clip state stored in clip state machine (CSM) associated with a batch of vertices. Per-vertex clip state is generated for each vertex in the batch of vertices based on the position of each vertex relative to each clip plane. For a given vertex, per-vertex clip state indicates whether the vertex is inside or outside each of the one or more clip planes. The per-vertex clip states of all the vertices in the batch of vertices are coalesced into a batch clip state by determining whether each vertex in the batch of vertices is inside every clip plane, each vertex is outside at least one clip plane or neither. The batch clip state is stored in the CSM associated with the thread group that processes the batch of vertices that can be accessed by further stages of the graphics pipeline."
8976883,"Method, receiver and computer program product for processing a signal, wherein the signal is received over a wireless network from a transmitter, the signal comprising a plurality of data streams. A selected one of the data streams is preferentially treated by reporting an adjusted value of a characteristic of the selected data stream to the transmitter and the received signal is decoded using a technique of successively decoding data streams in which the selected data stream is the first data stream to be decoded, a signal corresponding to the selected data stream being removed from the received signal prior to decoding at least one of the unselected data streams in the received signal."
8977049,"A method for estimating signal-dependent noise includes defining a plurality of pixel groups from among the image pixels. The method further includes computing, for one or more signal levels of the image, a difference value between two pixel groups, whereby a respective one or more difference values are computed collectively. The method determines an estimated noise response of the image as a function of the one or more computed difference values."
8978027,"Disclosed herein are methods and systems that provide compatible device drivers to mobile computing devices. In one embodiment, a method of determining compatibility between different versions of device drivers and operating systems of a mobile computing device is disclosed that includes: (1) establishing a test environment employing a current operating system of a mobile computing device, (2) applying an updated driver to the test environment and (3) determining system compatibility of the updated driver with the current operating system employing the test environment, wherein the determining is based on both direct and implied compatibility of the updated driver with the current operating system."
8982140,One embodiment of the present invention sets forth a technique for addressing data in a hierarchical graphics processing unit cluster. A hierarchical address is constructed based on the location of a storage circuit where a target unit of data resides. The hierarchical address comprises a level field indicating a hierarchical level for the unit of data and a node identifier that indicates which GPU within the GPU cluster currently stores the unit of data. The hierarchical address may further comprise one or more identifiers that indicate which storage circuit in a particular hierarchical level currently stores the unit of data. The hierarchical address is constructed and interpreted based on the level field. The technique advantageously enables programs executing within the GPU cluster to efficiently access data residing in other GPUs using the hierarchical address.
8982660,"The invention discloses a semiconductor memory device and a method for word line decoding and routing. The present invention relates generally to semiconductor memory field, Problems solved by the invention is that, to improve the quality of word line signals results in routing congestion. Embodiments of the invention provide the program as follows: a semiconductor memory device and a method for word line decoding and routing, dividing memory array of the semiconductor memory device into a plurality of smaller memory arrays, on a first metal layer routing first decoded row address, on a second metal layer below the first metal layer routing second decoded row address, and the output word line after decoding drives the plurality of smaller memory arrays. Embodiments of the invention are suitable for various semiconductor memory designs, including: on-chip cache, translation look-aside buffer, content addressable memory, ROM, EEPROM, and SRAM and so on."
8983223,"A method includes implementing, through a processor communicatively coupled to a memory and/or a hardware block, a Bilateral Filter (BF) including a spatial filter component and a range filter component, and implementing the spatial filter component with a low-complexity function to allow for focus on the range filter component. The method also includes determining, through the processor, filter tap value(s) related to the range filter component as a function of radiometric distance between a pixel of a video frame and/or an image and other pixels thereof based on a pre-computed corpus of data related to execution of an application in accordance with a filtering requirement of the pixel by the application. Further, the method includes constraining, through the processor, the filter tap value(s) to a form i×base based on the BF implementation. i is an integer and base is a floating point base."
8984167,"A client computing device transmits commands and/or data to a software application executing on a server computing device. The server computing device includes one or more graphics processing units (GPUs) that render frames of graphic data associated with the software application. For each frame, the one or more GPUs copy the frame to memory. A server engine also executing on the server computing device divides the frame into subframes, compresses each subframe, and transmits compressed subframes to the client computing device. The client computing device decompresses and reassembles the frame for display to an end-user of the client computing device."
8984183,"One embodiment of the present invention sets forth a technique for enabling the insertion of generated tasks into a scheduling pipeline of a multiple processor system allows a compute task that is being executed to dynamically generate a dynamic task and notify a scheduling unit of the multiple processor system without intervention by a CPU. A reflected notification signal is generated in response to a write request when data for the dynamic task is written to a queue. Additional reflected notification signals are generated for other events that occur during execution of a compute task, e.g., to invalidate cache entries storing data for the compute task and to enable scheduling of another compute task."
8984372,"A partition unit that includes a cache for storing both data and error-correcting code (ECC) checkbits associated with the data is disclosed. When a read command corresponding to particular data stored in a memory unit results in a cache miss, the partition unit transmits a read request to the memory unit to fetch the data and store the data in the cache. The partition unit checks the cache to determine if ECC checkbits associated with the data are stored in the cache and, if the ECC checkbits are not in the cache, the partition unit transmits a read request to the memory unit to fetch the ECC checkbits and store the ECC checkbits in the cache. The ECC checkbits and the data may then be compared to determine the reliability of the data using an error-correcting scheme such as SEC-DED (i.e., single error-correcting, double error-detecting)."
8984484,"A method includes continuously capturing, through an application executing on a data processing device, images of a desktop of the data processing device as a background process as part of a testing session on the data processing device in an active mode thereof. The method also includes encoding, through a processor of the data processing device, the captured images of the desktop as a video sequence, and providing a capability to a user of the data processing device and/or another data processing device to detect a fault event related to the testing session based on access to the encoded video sequence."
8984486,"A method, system, and computer-program product are provided for automatically performing stability testing on device firmware. The method includes the steps of copying a binary file corresponding to a version of a firmware to one or more nodes that each include a testbench, causing the one or more nodes to perform tests utilizing the version of the firmware, and determining whether a new build of the firmware is available. If the new build is available, then the steps include copying a second binary file corresponding to the new build to the one or more nodes and causing the one or more nodes to perform the tests utilizing the new build. However, if the new build is not available, then the steps include then causing the one or more nodes to perform one or more further iterations of the tests utilizing the version of the firmware."
8984498,One embodiment of the present invention sets forth a technique for translating application programs written using a parallel programming model for execution on multi-core graphics processing unit (GPU) for execution by general purpose central processing unit (CPU). Portions of the application program that rely on specific features of the multi-core GPU are converted by a translator for execution by a general purpose CPU. The application program is partitioned into regions of synchronization independent instructions. The instructions are classified as convergent or divergent and divergent memory references that are shared between regions are replicated. Thread loops are inserted to ensure correct sharing of memory between various threads during execution by the general purpose CPU.
8988123,"Small area low power data retention flop. In accordance with a first embodiment of the present invention, a circuit includes a master latch coupled to a data retention latch. The data retention latch is configured to operate as a slave latch to the master latch to implement a master-slave flip flop during normal operation. The data retention latch is configured to retain an output value of the master-slave flip flop during a low power data retention mode when the master latch is powered down. A single control input is configured to select between the normal operation and the low power data retention mode. The circuit may be independent of a third latch."
8988960,"A static random-access memory (SRAM) module includes a column select (RSEL) driver coupled to an input/output (I/O) circuit by an RSEL line. The I/O circuit is configured to read bit line signals from a bit cell within the SRAM module. During a read operation, the RSEL driver pulls the RSEL line to zero in order to cause p-type metal-oxide-semiconductors (PMOSs) within the I/O circuit to sample the bit line signals output by the bit cell. In response, an aggressor driver drives the RSEL line to a negative voltage, thereby reducing the resistance of the PMOSs within the I/O circuit."
8990280,"In some embodiments, a data processing system including an operation unit including circuitry configurable to perform any selected one of a number of operations on data (e.g., audio data) and a configuration unit configured to assert configuration information to configure the operation unit to perform the selected operation. When the operation includes matrix multiplication of a data vector and a matrix whose coefficients exhibit symmetry, the configuration information preferably includes bits that determine signs of all but magnitudes of only a subset of the coefficients. When the operation includes successive addition and subtraction operations on operand pairs, the configuration information preferably includes bits that configure the operation unit to operate in an alternating addition/subtraction mode to perform successive addition and subtraction operations on each pair of data values of a sequence of data value pairs."
8990437,A software or hardware agent running on a personal computing (PC) device provides allows a consumer electronic device connected to the PC device over a high definition multimedia interface (HDMI) network to control the PC device using standardized commands. This enables a user to control the PC device and other consumer electronic devices that are connected to the HDMI network using a single interface. The agent responds as a consumer electronic device and translates the standardized commands as universal serial bus (USB) human interface device (HID) input reports to the PC device operating system. The agent represents the specific capabilities of the PC device as standard consumer electronic device controls.
8994640,One embodiment of the present invention sets forth a technique for reducing motion blur in a liquid crystal display (LCD) by pulsing each frame with a relatively short pulse of backlight illumination while driving pixels within the LCD with compensated intensity values to account for LCD settling time and vertical position. An LCD drive compensation unit implements the disclosed technique to generate an intensity value for each pixel that is scanned into the LCD. The technique advantageously reduces motion blur while preserving uniform vertical display accuracy.
8996152,"Hardware resource sharing for a computerized system running software tasks. A mutex controller is associated with the hardware resource. Lock and unlock indicators are settable by a software task and readable by the controller, and locked and waiters flags are settable and readable by the controller. The controller monitors whether the lock indicator has been set and determines whether the locked flag is set. If not, it sets the locked flag and, if so, it sets the waiters flag and asserts a mutex interrupt signaling the computer system to divert the software task to run a lock request routine. The controller also monitors whether the unlock indicator has been set and then determines whether the waiters flag is set. If not, it clears the locked flag and, if so, it asserts a mutex interrupt signaling the computer system to divert the software task to run an unlock request routine."
8996337,A physics simulation engine simulates the motion of one or more particles that represent virtual objects in a virtual graphics scene. Each particle is assigned to a level in a particle hierarchy that has at least two levels. The physics simulation engine collapses constraints associated with particles assigned to a first level of the particle hierarchy to generate hierarchical constraints associated with particles assigned to the second level of the particle hierarchy. The physics simulation engine updates the position of each particle assigned to the second level of the particle hierarchy by enforcing constraints associated with the particle. The physics simulation engine then updates the position of each particle assigned to the first level of the particle hierarchy based on the positions of the particles assigned to the second level of the particle hierarchy.
8996846,"A system, method, and computer program product are provided for efficiently performing a scan operation. In use, an array of elements is traversed by utilizing a parallel processor architecture. Such parallel processor architecture includes a plurality of processors each capable of physically executing a predetermined number of threads in parallel. For efficiency purposes, the predetermined number of threads of at least one of the processors may be executed to perform a scan operation involving a number of the elements that is a function (e.g. multiple, etc.) of the predetermined number of threads."
8996896,"An Optimized Personal Computer (OPC) system may be a multi-functional processing unit with ultra-low power consumption and may consist of a single chip having a plurality of processors thereon. Each processor may be specialized for tasks including computing, graphic processing and audio processing. The OPC may be connected to a mother board, a memory unit and an I/O interface. The OPC may be connected to a primary PC (either in an expansion slot or in a drive bay) via a USB connection, for example, and be configured to run continuously and take over certain tasks from the primary PC as needed while the primary PC hibernates. The OPC may also be embedded in a monitor or other peripheral devices."
8996897,"A method includes monitoring, through a battery driver component of a embedded operating system executing on a data processing system deriving power from a battery, a state of the battery. The method also includes modifying, through a backlight driver component of the embedded operating system, an intensity level of a backlight of one or more Input/Output (I/O) devices of the data processing system from a current level associated with a normal operation thereof to an intensity level lower than the current level when the battery is detected to be in a critical state to prolong a lifetime thereof. The critical state is associated with a remaining charge on the battery being below a threshold required to maintain the data processing system in a powered on state."
8997103,"One embodiment sets forth a technique for N-way memory barrier operation coalescing. When a first memory barrier is received for a first thread group execution of subsequent memory operations for the first thread group are suspended until the first memory barrier is executed. Subsequent memory barriers for different thread groups may be coalesced with the first memory barrier to produce a coalesced memory barrier that represents memory barrier operations for multiple thread groups. When the coalesced memory barrier is being processed, execution of subsequent memory operations for the different thread groups is also suspended. However, memory operations for other thread groups that are not affected by the coalesced memory barrier may be executed."
9001016,"A method and system for restoring output to a display device. The method includes receiving a request to restore the output, modifying output timing so output is visible on a display device, and invoking an output configuration application. The method and system allow a user to restore the output on a display device after the output has been configured to settings which exceed the capabilities of the display device."
9001134,"Method, apparatuses, and systems are presented for processing a sequence of images for display using a display device involving operating a plurality of graphics devices, including at least one first graphics device that processes certain ones of the sequence of images, including a first image, and at least one second graphics device that processes certain other ones of the sequence of images, including a second image, delaying processing of the second image by the at least one second graphics device, by a specified duration, relative to processing of the first image by the at least one first graphics device, to stagger pixel data output for the first image and pixel data output for the second image, and selectively providing output from the at least one first graphics device and the at least one second graphics device to the display device."
9001157,"A technique for stereographic display of a selection marquee in a scene includes receiving the selection marquee in a two-dimensional viewpoint at a near plane of the scene. A selection volume is generated from which the fragments of a scene associated with the selection marquee are determined. A two-dimensional stereoscopic representation of the three-dimensional scene, including the selection marquee at the associated fragments, may then be rendered."
9002125,A method for compressing graphics data comprises selecting z-planes from a plurality of z-planes. The selected z-planes are predictor z-planes. A residual is determined for each sample not covered by one of the predictor z-planes. A sample is covered by one of the predictor z-planes when the predictor z-plane correctly defines a z-value of the sample. A residual comprises a value that is a difference between a predicted z-value provided by one of the predictor z-planes and an actual z-value for the sample. The predictor z-planes and the residuals are stored in a z-buffer.
9003000,"One embodiment of the present invention sets forth a technique for automatically provisioning a diskless computing device and an associated server system. A diskless computing device client incorporates an iSCSI initiator that is used to access resources provided by an iSCSI target that is resident on a server computing device. The iSCSI initiator is implemented in the client firmware, providing INT13 disk services entry points, thereby enabling the client to transparently access virtual storage devices at boot time. The client device conducts an apparently local installation using the virtual storage devices provided by the server computing device. A short signature value is associated with the boot image, uniquely associating the boot image with the specific client hardware configuration. When the client device boots normally, the signature value of the client device is presented to the server computing device to automatically reference the appropriate boot image."
9003369,"The muxed HDMI debug port methods and apparatuses are directed toward means for detecting an extended display identification data (EDID) code indicating a debug cable or debug host device coupled to the high-definition multimedia interface (HDMI) port of a computing device. In addition, the methods and apparatuses include means for disabling a display data channel (DDC) bus of the high-definition multimedia interface (HDMI) port in response to the extended display identification data (EDID) code indicating the debug cable or debug host device. Furthermore, the method and apparatuses include means for transmitting and receiving debug commands and data on a serial input (RXD) and serial output (TXD) of the high-definition multimedia interface (HDMI) port in response to the extended display identification data (EDID) code indicating the debug cable or debug host device."
9007079,"An IDDQ test system and method that, in one embodiment, includes 1) an empirical extraction subsystem operable to generate an IDDQ versus temperature model for a given semiconductor device design, 2) an automatic test equipment (ATE) test subsystem operable to obtain a measured IDDQ value (IDDQm) at a measured temperature (Tm) for a specific semiconductor device embodying the given semiconductor device design, the measured temperature (Tm) obtained within 5 seconds of obtaining the measured IDDQ value (IDDQm), and 3) a scaling subsystem operable to scale the measured IDDQ value (IDDQm) at the measured temperature (Tm) to a compensated IDDQ value (IDDQc) at a desired temperature (Td) using the IDDQ versus temperature model."
9007109,"A phase-locked loop digital bandwidth calibrator includes a digital loop filter having a gain multiplier memory and a perturbation unit configured to generate a calibration offset signal to initiate a calibration. Additionally, the phase-locked loop digital bandwidth calibrator also includes a digital bandwidth calibration unit configured to provide a corrected nominal gain for storage in the gain multiplier memory, wherein a digital gain correction for the corrected nominal gain is determined by a digital integration stage and a correction database. A phase-locked loop digital bandwidth calibration method is also provided."
9007113,"According to one aspect of the present disclosure, there is provided a flip flop circuit, comprising a first input circuit configured to receive a clock input signal and input data and comprising a first node. The flip-clop circuit further comprises a second input circuit configured to receive the input data and an inverse of the clock signal and comprising a second node. The first and second input circuits are configured such that the first node and the second node are pre-charged to respective complementary states when the clock signal is at a first level and, dependent on a value of the input data, one of said first and second nodes changes state to a state complementary to its pre-charged state when the clock signal transitions from the first level to a second level."
9007389,"Embodiments of the present invention are directed towards increasing texture filtering performance for texel components represented by more than 8 bits. As the number of bits per component increases, the number of texels that are processed each clock cycle decreases since more bits need to be processed to produce each filtered result. A filtered result may be accumulated over two or more iterations, with each iteration producing a portion of the filtered result. When only a portion of the components for each texel are used, the unused texel components are not processed. Elimination of unnecessary texel processing for unused texel components may improve texture filtering performance."
9009179,"A system, method, and computer program product are provided for performing graph aggregation. In use, a graph with a plurality of vertices and a plurality of edges is identified. Additionally, graph matching is performed on the vertices and edges of the graph by computing a graph matching, wherein the performance of the graph matching is optimized."
9009561,"An application programming interface (API) executed by a first processing unit combines audio data samples with error code values generated for those samples. The API then causes a data stream to be opened having sufficient bandwidth to accommodate combined samples made up of audio data samples and corresponding error code values. The combined samples are then transmitted to a decoder and validation unit within a second processing unit that receives the combined data, strips the error code values and validates the audio data based on the error code values. When the error code values indicate that the audio data has been compromised, the second processing unit terminates the output of sound derived from the audio data."
9009686,"One embodiment of the present invention sets forth a technique for extracting a memory address offset from a 64-bit type-conversion expression included in high-level source code of a computer program. The technique involves receiving the 64-bit type-conversion expression, where the 64-bit type-conversion expression includes one or more 32-bit expressions, determining a range for each of the one or more 32-bit expressions, calculating a total range by summing the ranges of the 32-bit expressions, determining that the total range is a subset of a range for a 32-bit unsigned integer, calculating the memory address offset based on the ranges for the one or more 32-bit expressions, and generating at least one assembly-level instruction that references the memory address offset."
9013498,A system and method for tracking and reporting texture map levels of detail that are computed during graphics processing allows for efficient management of texture map storage. Minimum and/or maximum pre-clamped texture map levels of detail values are tracked by a graphics processor and an array stored in memory is updated to report the minimum and/or maximum values for use by an application program. The minimum and/or maximum values may be used to determine the active set of texture map levels of detail that is loaded into graphics memory.
9014342,"A mobile communication device, a method of establishing a mobile telephone voice call and an apparatus are provided herein. In one embodiment, the mobile communication device includes: 1) a processor configured to indicate a voice call employing the mobile communication device is a hearing impaired call and (3) a modem configured to initiate establishment of the hearing impaired call with a mobile cellular network, wherein the establishment includes providing a hearing impaired codec list to the mobile cellular network."
9015446,"A method for providing a first processor access to a memory associated with a second processor. The method includes receiving a first address map from the first processor that includes an MMIO aperture for a NUMA device, receiving a second address map from a second processor that includes MMIO apertures for hardware devices that the second processor is configured to access, and generating a global address map by combining the first and second address maps. The method further includes receiving an access request transmitted from the first processor to the NUMA device, generating a memory access request based on the first access request and a translation table that maps a first address associated with the first access request into a second address associated with the memory associated with the second processor, and routing the memory access request to the memory based on the global address map."
9015643,"A system, method, and computer program product are provided for applying a callback function to data values. In use, a plurality of data values and a callback function are identified. Additionally, the callback function is recursively applied to the plurality of data values in order to determine a result. Further, the result is returned."
9015646,"A system, method, and computer program product are provided for translating a hardware design. In use, a hardware design is received that is encoded as one or more data flows and one or more control constructs. A node is generated for each data flow of the one or more data flows and for each control construct of the one or more control constructs. Additionally, connectivity of the nodes is determined to generate a graph-based intermediate representation of the hardware design and the graph-based intermediate representation of the hardware design is stored in a source database."
9019284,"An input output connector for a graphics processing unit having a graphics pipeline including fixed function units and programmable function units is disclosed. Additionally, a graphics processing unit and a method of operating a graphics pipeline are disclosed. In one embodiment, the input output connector includes: (1) a request arbiter configured to connect to each of the programmable function units, receive fixed function requests therefrom and arbitrate the requests and (2) fixed unit converters, wherein each of the fixed unit converters is dedicated to a single one of the fixed function units and is configured to convert the requests directed to the single one to an input format for the single one."
9021408,"A system, method, and computer program product are provided for translating a hardware design. In use, a hardware design is received that is a graph-based intermediate representation of a hardware design stored in a source database. An instance of each unique module in the source database is determined and a hardware module node is generated for each unique module. Additionally, a list of one or more instances is associated with each hardware module node and a graph-based common representation of the hardware design that includes one or more of the generated hardware module nodes is stored."
9024946,One embodiment of the present invention sets forth a technique for performing a computer-implemented method for tessellating patches. An input block is received that defines a plurality of input patch attributes for each patch as well as instructions for processing each input patch. A plurality of threads is launched to execute the instructions to generate each vertex of a corresponding output patch based on the input patch. Reads of values written during instruction execution are synchronized so threads can read and further process the values of other threads. An output patch is then assembled from the outputs of each of the threads; and emitting the output patch for further processing.
9024957,A method for loading a shader program from system memory into GPU memory. The method includes accessing the shader program in system memory of a computer system. A DMA transfer of the shader program from system memory into GPU memory is performed such that the shader program is loaded into GPU memory in an address independent manner.
9026069,"A method, device and computer program product is provided for sending a data signal and a clock signal between a radio frequency circuit of a device and a baseband circuit of the device, the radio frequency circuit being configured for at least one of transmission and reception of radio signals in a radio frequency band, where the clock signal has a clock frequency Fc. The method comprises selecting the clock frequency Fc to be a rational multiple of the 0.270833 MHz symbol rate of the Global System for Mobile Communications (GSM) standard and a rational multiple of the 3.84 MHz chipping rate of the Wideband Code Division Multiple Access (WCDMA) interface. The clock frequency Fc is selected such that the clock signal can be generated using a 38.4 MHz or 19.2 MHz reference clock signal, a non-fractional Phase Locked Loop clock multiplier and an output divider, without first having to divide down the reference clock signal. The data signal and the clock signal can then be sent between the radio frequency circuit and the baseband circuit using the selected clock frequency Fc."
9026745,A method for efficiently managing memory resources in a computer system having a graphics processing unit that runs several processes simultaneously on the same computer system includes using threads to communicate that additional memory is needed. If the request indicates that termination will occur then the other processes will reduce their memory usage to a minimum to avoid termination but if the request indicates that the process will not run optimally then the other processes will reduce their memory usage to 1/N where N is the count of the total number of running processes. The apparatus includes a computer system using a graphics processing unit and processes with threads that can communicate directly with other threads and with a shared memory which is part of the operating system memory.
9030480,"One embodiment of the present invention sets forth a method for analyzing the performance of a graphics processing pipeline. A first workload and a second workload are combined together in a pipeline to generate a combined workload. The first workload is associated with a first instance and the second workload is associated with a second instance. A first and second initial event are generated for the combined workload, indicating that the first and second workloads have begun processing at a first position in the graphics processing pipeline. A first and second final event are generated, indicating that the first and second workloads have finished processing at a second position in the graphics processing pipeline."
9031393,"An electronic system for enhancing camera focusing on a portable electronic device is disclosed. The system comprises a body, a bus, and a camera module coupled to the bus and comprising a photosensitive substrate and a lens assembly wherein the lens assembly comprises a lens capable of being selectively moved to a distance from the photosensitive substrate for light focus thereon. Further, it comprises an accelerometer coupled to the bus and configured to generate orientation information, said orientation information indicating contemporaneous orientation of the body with respect to a predetermined reference. It also comprises a memory and a processor coupled to the bus. The memory comprises instructions that when executed implement an autofocus program configured to automatically determine the distance based on: 1) image data captured by said camera module; and 2) the orientation information generated by the accelerometer."
9032101,"A method for providing access to hardware devices by a processor without causing conflicts with other processors included in a computer system. The method includes receiving a first address map from a first processor and a second address map from a second processor, where each address map includes memory-mapped input/output (I/O) apertures for a set of hardware devices that the processor is configured to access. The method further includes generating a global address map by combining the first address map and the second address map, receiving a first access request from the first processor and routing the first access request to a hardware device based on an address mapping included in the global address map. Advantageously, heterogeneous processors included in multi-processor system can access any hardware device included in the computer system, without modifying the processors, one or more operating systems executed by each processor, or the hardware devices."
9035957,"An efficient pipeline debug statistics system and method are described. In one embodiment, an efficient pipeline debug is utilized in a graphics processing pipeline of a handheld device. In one embodiment, a pipeline debug statistics system includes a plurality of pipeline stages with probe points, a central statistic component, and a debug control component. The plurality of pipeline stages with probe points perform pipeline operations. The central statistic block gathers information from the probe points. The debug control component directs the gathering of information from the probe points. In one exemplary implementation, debug control component can direct gathering of information at a variety of levels and abstraction."
9036686,"A modem and a method of placing a modem in an online data state. In one embodiment, the modem includes: (1) a digital interface configured to receive, via an AT channel thereof, a standard AT command directing an AT channel of the modem to exit a command state and enter an online data state and (2) a command processor coupled to the digital interface and configured to: extract channel designation data received as a standard parameter of the standard AT command, cause a channel designated by the channel designation data and separate from the AT channel to enter the online data state, and allow the AT channel to remain in the command state."
9038080,"A system and method for detecting, filtering, prioritizing and reporting shared memory hazards are disclosed. The method includes, for a unit of hardware operating on a block of threads, mapping a plurality of shared memory locations assigned to the unit to a tracking table. The tracking table comprises initialization information for each shared memory location. The method also includes, for an instruction of a program within a barrier region, identifying a potential conflict by identifying a second access to a location in shared memory within a block of threads executed by the hardware unit. First information associated with a first access and second information associated with the second access to the location is determined. Filter criteria is applied to the first and second information to determine whether the instruction causes a reportable hazard. The instruction is reported when it causes the reportable hazard."
9041719,A method for transparently directing data in a multi-GPU system. A driver application receives a first plurality of graphics commands from a first graphics application and selects a first GPU from the multi-GPU system to exclusively process the first plurality of graphics commands. The first plurality of graphics commands is transmitted to the first GPU for processing and producing a first plurality of renderable data. The first plurality of renderable data is stored in a first frame buffer associated with the first GPU. A second plurality of graphics commands is received from a second graphics application and a second GPU is selected to exclusively process the second plurality of graphics commands. The second GPU processing the second plurality of graphics commands produces a second plurality of renderable data. The second plurality of renderable data is stored in a second frame buffer associated with the second GPU.
9041721,"A system, method, and computer program product are provided for evaluating an integral utilizing a low discrepancy sequence and a block size. In use, a low discrepancy sequence and a block size are determined. Additionally, an integral is evaluated, utilizing the low discrepancy sequence and the block size."
9047085,"A method and apparatus for controlling sparse refresh of a self-refreshing display device coupled to a graphics controller are disclosed. The display device includes capabilities to drive the display based on video signals generated from a local frame buffer. The graphics controller may optimally be placed in one or more power-saving states when the display device is operating in a panel self-refresh mode. When exiting the power-saving state to update the image displayed by the display device, a fast-resume initialization routine may be run to reconfigure the GPU when operating in a sparse refresh mode, i.e., where the image being displayed on the display device is updated infrequently. In such cases, the graphics controller may be configured to receive instructions and data from a central processing unit via an alternative low-bandwidth communications path instead of the high-bandwidth communications path used in normal operation."
9052897,"Method and computing system for controlling a supply voltage in the computing system. A voltage related indication for use in setting the supply voltage of the computing system is stored, and a supply voltage is set for the computing system based on the stored voltage related indication. A crash of the computing system is detected, and in dependence thereon, an adjusted indication is determined for use in the computing system. An adjusted supply voltage is set based on the adjusted indication, and the adjusted indication is stored for further use of the computing system."
9053041,"A system, method, and computer program product are provided for categorizing a plurality of vertices of a graph into independent sets. A random number is assigned to each vertex in the graph and the assigned number of each vertex is compared to the assigned numbers each of the neighbors of the vertex, where all vertices in the graph that have an assigned number greater than the assigned numbers of each of their neighbors are added to a first independent set, and all vertices in the graph that have an assigned number less than the assigned numbers of each of their neighbors are added to a second independent set separate from the first independent set."
9053209,"A system, method, and computer program product are provided for categorizing a plurality of vertices of a graph. A predetermined plurality of random numbers is assigned to each vertex of the plurality of vertices, a determination is made whether each of the assigned predetermined plurality of random numbers of a single vertex is greater than a corresponding random number of the assigned predetermined plurality of random numbers of each of the neighbors of the single vertex, and in response to the determination, one of the assigned random numbers is selected from a group of assigned random numbers of the single vertex."
9053559,"A method and system for presenting image data to a video output device is disclosed. One embodiment of the present invention sets forth a method, which includes the steps of queuing the buffer of image data for display, attaching an object to a command associated with presenting the buffer of image data, wherein the object is capable of storing timing information relating to executing the command, and enabling an application program to access the timing information."
9058453,"A system and method are provided for configuring a plurality of pin resources. The method includes identifying a plurality of pin resources of a primary application specific integrated circuit (ASIC) device and configuring the plurality of pin resources based on a pin distribution between a first interface and a second interface, where the first interface provides a first communication path between the primary ASIC device and a first device, and the second interface provides a second communication path between the primary ASIC device and a second device."
9058672,"One embodiment of the present invention sets forth a technique controlling the pixel location at which the plane equation is evaluated. Multiple pixel offsets (dx, dy) may be specified that each define to a sub-pixel sample position. Attributes are then calculated for each sub-pixel sample position that is covered by a geometric primitive. One advantage of the technique is that anti-aliasing quality may be improved since high frequency color components may be selectively supersampled for particular geometric primitives."
9058677,"One embodiment of the present invention sets forth a technique for efficiently performing broad phase collision detection using parallel spatial subdivision. The technique involves organizing candidate objects according to a hashed representation of each object centroid, constructing a cell identification (ID) array, sorting the cell ID array, creating a collision cell list, and traversing the collision cell list. The result is a candidate list of object groups that may collide, based on an initial assessment of spatial proximity. Whether a given pair of objects actually collides is determined by a precise narrow phase collision analysis."
9058678,"One embodiment of the present invention sets forth a technique for efficiently performing broad phase collision detection using parallel spatial subdivision. The technique involves organizing candidate objects according to a hashed representation of each object centroid, constructing a cell identification (ID) array, sorting the cell ID array, creating a collision cell list, and traversing the collision cell list. The result is a candidate list of object groups that may collide, based on an initial assessment of spatial proximity. Whether a given pair of objects actually collides is determined by a precise narrow phase collision analysis."
9058792,"Sequential write operations to a unit of compressed memory, known as a compression tile, are examined to see if the same compression tile is being written. If the same compression tile is being written, the sequential write operations are coalesced into a single write operation and the entire compression tile is overwritten with the new data. Coalescing multiple write operations into a single write operation improves performance, because it avoids the read-modify-write operations that would otherwise be needed."
9059054,"One aspect of the present disclosure provides an IC substrate, comprising a first material layer located on a first side of the IC substrate, and a second material layer located on a second, opposing side of the IC substrate, wherein the second material layer has a higher coefficient of thermal expansion CTE value than the first material layer."
9060355,"A method of handling messages at a user equipment received from a communications network during a procedure, the method implemented at the user equipment comprising: receiving a first message from the network while the user equipment is in a first operating state; processing the first message and entering a second operating state in response to receiving the first message; receiving a second message from the network while the user equipment is in the second operating state; detecting that the second message is a duplicate of the first message; and checking for an indication that the second message is a potential duplicate of the first message. If the indication is not present, the method further comprises transmitting a failure notification to the network. If the indication is present, the method further comprises discarding the second message and not transmitting a failure notification to the network to prevent failure of the procedure."
9064061,"A method and system are implemented to instantaneously detect a hot plugging of a video connector in a computer device by detecting a change in the electrical state of one ground pin of the video connector. The computer device comprises a video connector having at least two ground pins, a processing unit, and a hot-plugging detection circuit coupled between the processing unit and one of the ground pins of the video connector, wherein the hot-plugging detection circuit is configured to detect a hot plugging of the video connector based on a change in voltage potential of the ground pin."
9064314,"A MacBeth color checker chart automatic detection system includes an imaging unit that provides an image and a processing unit that applies an edge detection operation to the image and performs a flood-fill operation on the image to provide a flood-filled image. Additionally, the MacBeth color checker chart automatic detection system includes a testing unit that tests the flood-filled image to provide a modified flood-fill image, wherein a set of heuristic tests are employed to automatically determine quantity and location of MacBeth color checker charts. Generally, the set of heuristic tests are employed to automatically reject regions that are unlikely to belong to a MacBeth color checker chart and to cluster the remaining regions that are likely to belong to a Macbeth color checker chart. A MacBeth color checker chart automatic detection method is also provided."
9064322,"One embodiment of the present invention sets forth a method for accessing display configuration information in a multi-graphics-processing-unit (multi-GPU) system, which includes the steps of asserting a select signal to steer the display configuration information of a display device, which is coupled to a discrete GPU (dGPU), to a motherboard GPU (mGPU) in the multi-GPU system if dGPU is unavailable, and validating the display configuration information prior to availing the dGPU or the display device as an option to be selected."
9064333,"Techniques for handling an interrupt in the rasterizer, in accordance with embodiment of the present technology, start with rasterizing one or more primitives of a first context. If an interrupt is received, the tile count of tiles of a current primitive that have been coarse rasterized is saved in a backing store. After storing the tile count, the one or more primitives of a second context are rasterized. After the second context is served, the coarse rasterization of the current primitive of the previous context is rerun without output until the tile corresponding to the stored tile count is coarse rasterized. Thereafter, rasterization of the current primitive of the first context from the next tile beyond the stored tile count is continued until rasterization is completed or another interrupt is received and the above described process is repeated."
9066285,"A modem comprising: a wireless transceiver for connecting to a wireless cellular network; second interface apparatus for connecting to a terminal; and processing apparatus which performs operations of a wireless cellular modem to enable the terminal to access a further, packet-based network via access points of the wireless cellular network. The processing apparatus receives a modem command from the terminal, the modem command comprising a field for specifying the name of one of the access points in the form of a text string. The field comprises the names a plurality of the access points and one or more separator characters between them. The processing apparatus is configured to extract each of the names from the field based on the one or more separator characters, and to establish a different respective channel with each of the plurality of access points based on the extracted names."
9066337,"A wireless subscriber communication unit is provided for operation in a cellular communication system having a plurality of shared uplink and downlink transmission resources, each divided into sets of mutually exclusive resources. The shared uplink transmission resources are defined in terms of codes and timeslots. The communication unit comprises a receiver, control, and transmitter unit. The receiver unit receives scheduling information including an assignment of a scheduled uplink transmission resource from the shared uplink transmission resources from a network infrastructure apparatus. The control unit derives an uplink resource identifier related to the scheduled uplink transmission resource from the received scheduling information. The transmitter unit transmits an uplink transmission, which includes the uplink resource identifier, using the scheduled uplink transmission resource. The control unit receives a downlink transmission associated with the uplink transmission on a downlink transmission resource determined from at least one of the received scheduled uplink resource or identifier."
9069609,"One embodiment of the present invention sets forth a technique for assigning a compute task to a first processor included in a plurality of processors. The technique involves analyzing each compute task in a plurality of compute tasks to identify one or more compute tasks that are eligible for assignment to the first processor, where each compute task is listed in a first table and is associated with a priority value and an allocation order that indicates relative time at which the compute task was added to the first table. The technique further involves selecting a first task compute from the identified one or more compute tasks based on at least one of the priority value and the allocation order, and assigning the first compute task to the first processor for execution."
9069664,"One embodiment of the present invention sets forth a technique for providing a unified memory for access by execution threads in a processing system. Several logically separate memories are combined into a single unified memory that includes a single set of shared memory banks, an allocation of space in each bank across the logical memories, a mapping rule that maps the address space of each logical memory to its partition of the shared physical memory, a circuitry including switches and multiplexers that supports the mapping, and an arbitration scheme that allocates access to the banks."
9069684,"A system, method, and computer program product are provided for invalidating cache lines. In use, one or more cache lines that hold data from within a region of a memory address space are invalidated."
9069706,"Efficient and effective permission confidential information protection systems and methods are described. The secure information protection systems and methods facilitate storage of confidential information in a manner safe from rogue software access. In one embodiment, a confidential information protection method is implemented in hardware and facilitates protection against software and/or Operating System hacks. In one exemplary implementation, a confidential information protection method includes setting a permission sticky bit flag to a default state upon system set up. The permission sticky bit flag access permission indication is adjusted at system reset in accordance with an initial application instruction. Access to the confidential information is restricted in accordance with the permission sticky bit and the permission sticky bit is protected from adjustments attempting to violate the permission indication. For example, another software application can not access or alter confidential information (e.g., an encryption key, initialization vector, etc.) if a permission sticky bit is designated as the highest security rating (e.g., disabling read permission and write permission until system reset)."
9069990,"The present invention systems and methods facilitate secure communication of information between devices. A present invention system and method can enable secure communication of proprietary content in a HDCP compliant configuration. In one embodiment, a high definition content protection key secure management method is utilized to enable efficient and secure storage of a HDCP key. A high definition content protection key value is received. The high definition content protection key is encrypted utilizing a secure key value, wherein the secure key value is not accessible via an external port. In one exemplary implementation, the secure key is stored in fuses included in a processing unit. The results of said encrypting in a memory (e.g., a BIOS memory, flash memory, etc.)."
9070213,"In a raster stage of a graphics processor, a method for tile based precision rasterization. The method includes receiving a graphics primitive for rasterization in a raster stage of a graphics processor and rasterizing the graphics primitive at a first level precision to generate a plurality of tiles of pixels. The tiles are then rasterized at a second level precision to generate covered pixels. The covered pixels are then output for rendering operations in a subsequent stage of the graphics processor."
9070220,"A method is provided for depicting on a display, an object within a simulated environment having clothing. In this method, the clothing is represented as a series of vertices that include vertices that are attached to the object and vertices that are not attached to the object. The method improves upon position based dynamics algorithm by constraining unattached vertices to be a predefined distance away from attached vertices that are connected thereto to compensate for overstretching in the simulated clothing."
9071233,"A flip-flop circuit may include a master latch and a slave latch. Each latch may have a transparent mode and a storage mode. The slave latch may be in storage mode when the master latch is in transparent mode; and vice-versa. A clock signal may control the mode of each latch through a pair of clock-gated pull-up transistors and a pair clock-gated of pull-down transistors, for a total of four clock-gated transistors. The clock-gated transistors may be shared by the master latch and the slave latch. Fewer clock-gated transistors may be required when they are shared, as opposed to not being shared. Clock-gated transistors may have parasitic capacitance and consume power when subjected to a varying clock signal, due to the charging and discharging of the parasitic capacitance. Having fewer clock-gated transistors thus may reduce the power consumed by the flip-flop circuit."
9071240,"Provided herein is a voltage level shifter, an apparatus including a voltage level shifter and a method of converting voltages between input and output power domains. In one embodiment, the voltage level shifter includes: (1) an input circuit configured to receive a data signal from an input power domain and a power down signal from a output power domain and (2) a transition circuit coupled to the input circuit and configured to receive the data signal and an inverted signal of the power down signal, wherein the input circuit and the transition circuit are both configured to connect to a supply voltage of the output power domain as a power source."
9071244,One embodiment of the present invention sets forth a mechanism for transmitting and receiving ground-referenced single-ended signals. A transmitter combines a direct current (DC) to DC converter including a flying capacitor with a 2:1 clocked multiplexer to drive a single-ended signaling line. The transmitter drives a pair of voltages that are symmetric about the ground power supply level. Signaling currents are returned to the ground plane to minimize the generation of noise that is a source of crosstalk between different signaling lines. Noise introduced through the power supply is correlated with the switching rate of the data and may be reduced using an equalizer circuit.
9071319,"A circuit and method for filtering adjacent channel interferers. One embodiment of an adjacent channel filtering circuit for reducing adjacent channel interference with an in-band signal, includes: (1) a radio frequency (RF) circuit configured to receive and down-convert an RF signal to a baseband signal containing an in-band signal and adjacent channel components, (2) a controlled single pole filter electrically coupled to the RF circuit and configured to reject the adjacent channel components and cause a predetermined attenuation in the in-band signal, (3) a baseband circuit coupled to the controlled single pole filter and configured to condition the baseband signal for conversion to a digital signal, and (4) a digital circuit coupled to the baseband circuit and configured to receive the digital signal and compensate for the predetermined attenuation."
9071581,A security command protocol provides secure authenticated access to an auxiliary security memory within a SCSI storage device. The auxiliary security memory acts as an authenticated separate secure storage area that stores sensitive data separately from the user data area of the SCSI storage device. The security command protocol is used to access the auxiliary security memory. The security command protocol allows a trusted execution environment to transport sensitive data to and from storage in the auxiliary security memory. The regular execution environment does not have access to the security command protocol or the auxiliary security memory. The security command protocol and auxiliary security memory eliminate the need for additional secure storage components in devices that provide the security features of firmware TPM.
9071765,"A system, method, and computer program product for generating high-dynamic range image data is disclosed. The method includes the steps of receiving image sensor data from an interleaved image sensor. The interleaved the image sensor includes a first portion of pixels exposed for a first exposure time and a second portion of pixels exposed for a second exposure time that is shorter than the first exposure time. The method further includes the steps of identifying a first subset of pixels in the second portion having an intensity value above a first threshold value, identifying a second subset of pixels in the first portion having an intensity value below a second threshold value, and generating high-dynamic range (HDR) data based on the first subset and the second subset."
9075559,"Systems and methods for utilizing multiple graphics processing units for controlling presentations on a display are presented. In one embodiment, a dual graphics processing system includes a first graphics processing unit for processing graphics information; a second graphics processing unit for processing graphics information; and a component for controlling switching between said first graphics processing unit and said second graphics processing unit. In one embodiment, the component for controlling complies with appropriate panel power sequencing operations when coordinating the switching between the first graphics processing unit and the second graphics processing unit."
9076551,"A system includes a control circuit and first, second, and third ground-referenced single-ended signaling (GRS) driver circuits that are each coupled to an output signal. The control circuit is configured to generate a first, second, and third set of control signals that are each based on a respective phase of a clock signal. Each GRS driver circuit is configured to pre-charge a capacitor to store a charge based on the respective set of control signals during at least one phase of the clock signal and drive the output signal relative to a ground network by discharging the charge during a respective phase of the clock signal."
9077329,One embodiment of the present invention sets forth a technique for capturing and holding a level of an input signal using a latch circuit that presents a low number of loads to the clock signal. The clock is only coupled to a bridging transistor and a pair of clock-activated pull-down or pull-up transistors. The level of the input signal is propagated to the output signal when the storage sub-circuit is not enabled. The storage sub-circuit is enabled by the bridging transistor and a propagation sub-circuit is activated and deactivated by the pair of clock-activated transistors.
9078380,"Embodiments of the invention provide methods and configuration for packaging multiple semiconductor ships in a semiconductor package. In one embodiment, an integrated circuit system includes a printed circuit board, a first MOSFET device disposed on a first surface of the printed circuit board, and a second MOSFET device disposed on a second surface of the printed circuit board, wherein the first MOSFET device overlaps an edge of the second MOSFET device in a direction extending through the printed circuit board."
9081535,"Disclosed are methods, an apparatus and a system of automatic topology configuration through automatic profiles across multiple display units. A method of a display driver involves automatically identifying a hardware profile data associated with a plurality of display units, applying a logic function to the hardware profile data to create a set of automatic topology display settings when a match of the hardware profile data with a set of settings in a hardware profile lookup table is not found, and automatically applying the set of automatic topology display settings to simultaneously display a sequence of graphics signals across the plurality of display units. The method may also include automatically designating one display unit from the plurality of display units as a sample display unit and setting a scaling factor based on an automatic designation of the one display unit from the plurality of display units as the sample display unit."
9081681,A method for compressing normal maps in a computer system. The method includes accessing a map of input normals. A memory block having a first portion and a second portion is defined. A table of indices is stored in the first portion of the memory block and a table of normals is stored in the second portion of the memory block. The indices of the first portion of the memory block reference the normals of the second portion. The normals in the second portion of the memory block are unit normals of a sphere defined to represent the map of input normals.
9082180,"A system, method, and computer program product for applying a spatially varying unsharp mask noise reduction filter is disclosed. The spatially varying unsharp mask noise reduction filter generates a low-pass filtered image by applying a low-pass filter to a digital image, generates a high-pass filtered image of the digital image, and generates an unsharp masked image based on the low-pass filtered image and the high-pass filtered image. The filter also blends the low-pass filtered image with the unsharp masked image based on a shaping function."
9082212,"Techniques are disclosed for dispatching pixel information in a graphics processing pipeline. A fragment processing unit in the graphics processing pipeline generates a pixel that includes multiple samples based on a portion of a graphics primitive received by a thread. The fragment processing unit calculates a set of source values, where each source value corresponds to a different sample of the pixel. The fragment processing unit retrieves a set of destination values from a render target, where each destination value corresponds to a different source value. The fragment processing unit blends each source value with a corresponding destination value to create a set of final values, and creates one or more dispatch messages to store the set of final values in a set of output registers. One advantage of the disclosed techniques is that pixel shader programs perform per-sample operations with increased efficiency."
9082674,A microelectronic package includes larger diameter solder bumps and smaller diameter solder bumps for coupling an interposer to a packaging substrate. The larger diameter solder bumps are positioned on a peripheral surface of the interposer and the smaller diameter solder bumps are positioned on a center surface of the interposer. The solder bumps positioned in the peripheral region can more reliably withstand the higher mechanical stresses that occur in this peripheral region during operation of the microelectronic package.
9083577,"A sampler circuit for a decision feedback equalizer and a method of use thereof. One embodiment of the sampler circuit includes: (1) a first sampler portion including a series-coupled first master regeneration latch and first slave latch, (2) a second sampler portion including a series-coupled second master regeneration latch and second slave latch, and (3) a first feedback circuit coupled to a first node between the first master regeneration latch and the first slave latch and operable to provide a feedback signal to the second master regeneration latch to cause a bias charge to be built up therefor."
9084269,"Method and apparatus for processing a signal using a recursive method for determining a plurality of frequency components of the signal, the signal being a chirp-like polyphase sequence, wherein a first frequency component of the plurality of frequency components is determined; a component factor is determined by accessing a factor table for use in determining a second frequency component of the plurality of frequency components; and the second frequency component is determined using the determined first frequency component and the determined component factor."
9084362,"Disclosed are a method and system to reduce impedance of printed circuit boards through an interconnecting of printed circuit boards using a square wave pattern of plated-through holes. A method of connecting a first printed circuit board to a second printed circuit board comprises forming a square wave pattern of the first printed circuit board and the second printed circuit board and adjoining the first printed circuit board and the second printed circuit board. The method also involves producing plated-through holes along the square wave pattern, a top section, and/or a bottom section of the adjoined first printed circuit board and second printed circuit board. The method further involves securing the top section and the bottom section using a first metal clip and a second metal clip, respectively, and connecting the first printed circuit board to the second printed circuit board by a wave soldering process."
9086707,"Disclosed are methods, devices, and systems to digitally control a duty cycle of a switching mode power supply. In one embodiment, a method comprises calculating a base duty cycle using a power management unit of a high-speed processing unit, calculating a dynamic offset duty cycle using the power management unit to apply a transfer function to a sampled feedback voltage signal, and adding the base duty cycle to the dynamic offset duty cycle to obtain a duty cycle of the switching mode power supply. A system comprises a switching mode power supply, a power management unit, a voltage sensor, and an analog to digital converter all embedded within a high-speed processing unit, and a pulse-width modulator coupled between the switching mode power supply and the high-speed processing unit to modulate the duty cycle of the switching mode power supply."
9086838,"Disclosed are methods, an apparatus and a system of synchronous media display through automatic profiles across multiple display units. A method of a display driver involves automatically identifying a hardware profile data associated with a plurality of display units, applying a logic function to the hardware profile data to create a set of synchronization display settings when a match of the hardware profile data with a set of synchronization display settings in a hardware profile lookup table is not found, and automatically applying the set of synchronization display settings to simultaneously display a sequence of graphics signals across the plurality of display units. The method may also include automatically designating one display unit from the plurality of display units as a master display unit and setting a synchronization timing based on an automatic designation of the one display unit from the plurality of display units as the master display unit."
9086933,"A system and method are provided for launching a callable function. A processing system includes a host processor, a graphics processing unit, and a driver for launching a callable function. The driver is adapted to recognize at load time of a program that a first function within the program is a callable function. The driver is further adapted to generate a second function. The second function is adapted to receive arguments and translate the arguments from a calling convention for launching a function into a calling convention for calling a callable function. The second function is further adapted to call the first function using the translated arguments. The driver is also adapted to receive from the host processor or the GPU a procedure call representing a launch of the first function and, in response, launch the second function."
9087161,"An asymmetrically scaling multiple GPU graphics system wherein the multiple GPUs are asymmetric, meaning that their rendering capabilities and/or rendering power is not equal. The asymmetric scaling multiple GPU graphics system includes a plurality of GPUs configured to execute graphics instructions from a computer system. A GPU output multiplexer and a controller unit are coupled to the GPUs. The controller unit is configured to control the GPUs and the output multiplexer such that the GPUs cooperatively execute the graphics instructions from the computer system."
9087398,"Methods of compressing (and decompressing) bounding box data and a processor incorporating one or more of the methods. In one embodiment, a method of compressing such data includes: (1) generating dimension-specific multiplicands and a floating-point shared scale multiplier from floating-point numbers representing extents of the bounding box and (2) substituting portions of floating-point numbers representing a reference point of the bounding box with the dimension-specific multiplicands to yield floating-point packed boundary box descriptors, the floating-point shared scale multiplier and the floating-point packed boundary box descriptors together constituting compressed bounding box data."
9087411,"One embodiment of the present invention sets forth multigrid generation technique which enables accurate simulations of large scale three dimensional (3D) fluid volumes. A model of the fluid to be simulated is represented using a cell grid. The generated multigrid provides a hierarchy of increasingly coarser representations of the model that are used by a pressure solver. Eulerian simulation techniques require solving a linear system to determine pressure values for each cell within the cell grid. Different levels of the multigrid are then used to compute the pressure values for different regions of the model, maintaining accuracy near the surface of the fluid while simplifying the computations. The accurate pressure values ensure that the simulation produces detailed features of the water movement. Additionally, the multigrid pressure solver may be optimized for execution by a graphics processor."
9087469,Systems and methods for automatically switching scene modes of a monitor may comprise processes and corresponding modules for sending a request to a driver to activate hardware modules of a graphics processing unit (GPU) based on a requirement of a launched application program and then recording identifiers of the activated hardware modules on a list. A record of a scene mode associated with one or more activated hardware modules on the list is located within a scene mode profile table and then the corresponding monitor parameters previously associated with the scene mode are read. The monitor is then automatically adjusted according to the monitor parameters read.
9087473,"A system, method, and computer program product are provided for changing a display refresh rate in an active period. In operation, a request is received to change a display refresh rate. Further, in response to the request, the display refresh rate is changed in an active period during which pixels are being written to a display device."
9087830,"A system, method, and computer program product are provided for affixing a post to a substrate pad. In use, a post is affixed to each of one or more pads of a substrate, where each post receives a ball of a package during an assembly process."
9088176,"A power management unit for improving power efficiency of an electronic device. The power management unit includes a first and a second stage power regulator and a control circuitry. The first stage power regulator includes a switching regulator to efficiently adjust an input voltage based on a feedback signal. The adjusted input voltage provides the second stage power regulator that includes low dropout voltage regulators with an input voltage close to its output. Thus, power dissipation in the second stage is reduced by reducing the voltage differential between the input and desired output voltages. The second stage turns on/off power to units of the electronic device. The control circuitry generates the feedback signal based on dropout voltages of the low dropout voltages, the desired output voltage and the adjusted input voltage. The largest dropout voltage is selected and adds it to the desired output voltage to generate the feedback signal."
9088289,"A system and method are provided for increasing a voltage range associated with a voltage controlled oscillator. A voltage-to-current converter is provided. Additionally, a current controlled oscillator is provided that is in communication with the voltage-to-current converter. Further, at least one circuit component is provided that is in communication with the voltage-to-current converter for increasing a voltage range with which the apparatus operates as a voltage controlled oscillator."
9092170,A method and system for a cooperative graphics processing across a graphics bus in a computer system. The system includes a bridge coupled to a system memory via a system memory bus and coupled to a graphics processor via the graphics bus. The bridge includes a fragment processor for implementing cooperative graphics processing with the graphics processor coupled to the graphics bus. The fragment processor is configured to implement a plurality of raster operations on graphics data stored in the system memory.
9092220,"A computer system comprising a graphics processor, a frame buffer, a display device, a system agent operable to detect an absence of active software applications and system configurations capable of rendering a disruptive user experience during system suspend, and a memory for storing instructions, that when executed perform a method of entering a power conservation state. The method comprises detecting a system idle event, activating the frame buffer, and storing display information in the frame buffer from the graphics processor. The method further comprises initiating a power reduction state for the graphics processor, self-refreshing the display device during the power reduction state with the display information stored in the frame buffer, and initiating a system suspend comprising a power reduction state for the computer system provided the system agent detects the absence of disruptive software and system configurations."
9092573,"A system, method, and computer program product are provided for testing device parameters. In use, a plurality of device parameters is determined, utilizing a directed acyclic graph (DAG). Further, the determined plurality of device parameters is tested."
9092658,"A method includes calculating, through a processor of a computing device communicatively coupled to a memory, correlation between two portions of an image and/or a video frame on either side of a reference portion thereof. The method also includes determining, through the processor, whether content of the image and/or the video frame is stereoscopic or non-stereoscopic based on the determined correlation."
9093135,"A system, method, and computer program product are provided for implementing a storage array. In use, a storage array is implemented utilizing static random-access memory (SRAM). Additionally, the storage array is utilized in a multithreaded architecture."
9094095,"In a CDMA system (100), two chip rates in a TDD cell are supported by: transmitting signals in the system in a frame (400) having a plurality of timeslots; operating at least a first one (0-8) of the plurality of timeslots in the frame at a lower chip rate; and operating at least a second one (9-14) of the plurality of timeslots in the frame at a higher chip rate. This provides the following advantages: provides backwards compatibility of a network including higher chip rate functionality with existing lower chip rate user equipment; allows greater network capacity during the transition phase from a low chip rate network to a high chip rate network; and allows a network operator with a high chip rate network to provide service to roaming users from low chip rate networks."
9094676,"A system, method, and computer program product are provided for determining that a display device is operating in a three-dimensional mode. Further, in response to the determination that the display device is operating in the three-dimensional mode, determining a phase of a current frame. Additionally, a setting from a first table or a setting from a second table is applied based on the determined phase of the current frame."
9094678,"A system, method, and computer program product are provided for determining that a display device is operating in a three-dimensional mode. Further, in response to the determination that the display device is operating in the three-dimensional mode, inverting a polarity of each cell of the display device every N number of frames. Additionally, the N number of frames is even and includes at least two frames."
9098272,"An automatic load detection system. A first reference signal that may be known apriori can be used for load detection. For example, the first reference signal may be used for invisible portion of a frame. The DAC receives the first reference signal and outputs a signal that is based on the first reference signal. The output of the DAC may have two known values depending on whether the load is coupled to the DAC, e.g., by having a different impedance. Thus, the output signal may be used for detecting whether the load is uncoupled from the DAC. If it is determined that the load is uncoupled from the DAC, the clocking signal to the DAC may be turned off. Thus, DAC no longer consumes power when the load is uncoupled, thereby saving power."
9098297,An apparatus and method are provided including a hardware accelerator capable of being interfaced with a processor for accelerating the execution of an application written utilizing an object-oriented programming language. Such object-oriented programming language may include Java and/or C++.
9098323,"A method includes executing a driver component on a hypervisor of a computing platform including a first graphics processing unit (GPU) and a second GPU, and executing an instance of the driver component in the VM. The method also includes providing support for hardware virtualization of the second GPU in the hypervisor and the instance of the driver component executing in the VM, defining a data path between the VM and the first GPU in a configuration register, and defining a data path between the VM and the second GPU in another configuration register. Further, the method includes providing a capability to the VM to utilize the first GPU in a shared mode with one or more other VM(s) and to simultaneously dedicatedly utilize the second GPU based on reading exposed emulated versions of the configuration register and the another configuration register and the support for the hardware virtualization."
9098383,"One embodiment of the present invention sets forth a crossbar unit that is coupled to a plurality of client subsystems. The crossbar unit is configured to transmit data packets between the client subsystems and includes a high-bandwidth channel and a narrow-bandwidth channel. The high-bandwidth channel is used for transmitting large data packets, while the narrow-bandwidth is used for transmitting smaller data packets. The transmission of data packets may be prioritized based on the source and destination clients as well as the type of data being transmitted. Further, the crossbar unit includes a buffer mechanism for buffering data packets received from source clients until those data packets can be received by the destination clients."
9098924,"One embodiment sets forth a method for associating each stencil value included in a stencil buffer with multiple fragments. Components within a graphics processing pipeline use a set of stencil masks to partition the bits of each stencil value. Each stencil mask selects a different subset of bits, and each fragment is strategically associated with both a stencil value and a stencil mask. Before performing stencil actions associated with a fragment, the raster operations unit performs stencil mask operations on the operands. No fragments are associated with both the same stencil mask and the same stencil value. Consequently, no fragments are associated with the same stencil bits included in the stencil buffer. Advantageously, by reducing the number of stencil bits associated with each fragment, certain classes of software applications may reduce the wasted memory associated with stencil buffers in which each stencil value is associated with a single fragment."
9098925,"One embodiment sets forth a method for associating each stencil value included in a stencil buffer with multiple fragments. Components within a graphics processing pipeline use a set of stencil masks to partition the bits of each stencil value. Each stencil mask selects a different subset of bits, and each fragment is strategically associated with both a stencil value and a stencil mask. Before performing stencil actions associated with a fragment, the raster operations unit performs stencil mask operations on the operands. No fragments are associated with both the same stencil mask and the same stencil value. Consequently, no fragments are associated with the same stencil bits included in the stencil buffer. Advantageously, by reducing the number of stencil bits associated with each fragment, certain classes of software applications may reduce the wasted memory associated with stencil buffers in which each stencil value is associated with a single fragment."
9099050,"A method and system for dynamically modifying the graphics capabilities of a mobile device is disclosed. One embodiment of the present invention sets forth a method, which includes the steps of abstracting the handling of a first graphics subsystem and a second graphics subsystem associated with the mobile device, so that the first graphics subsystem and the second graphics subsystem appear as a third graphics subsystem to an operating system for the mobile device, detecting a configuration change event corresponding to the first graphics subsystem, masking the configuration change event to induce the generation of a reset event, and modifying the graphics capabilities of the mobile device to match the highest graphics capabilities between the first graphics subsystem and the second graphics subsystem that are accessible to the mobile device."
9100094,"A system and method are provided for tuning a serial link. The method includes receiving, by a receiver circuit, an offset correction pattern transmitted over a serial link and sampling the received offset correction pattern based on an offset correction parameter to generate a sampled signal. A distribution of the sampled signal is computed and the offset correction parameter is set based on the distribution. The system includes a receiver circuit that is coupled to the serial link and an offset correction unit that is coupled to the receiver circuit. The receiver circuit is configured to receive the offset correction pattern and sample the received offset correction pattern based on the offset correction parameter to generate the sampled signal. The offset correction unit is configured to compute the distribution of the sampled signal and set the offset correction parameter based on the distribution."
9100504,"A method includes determining, through a processor of a data processing device in conjunction with one or more sensor(s) associated therewith, an intent of a user of the data processing device to respond to an alert of an incoming communication thereto expressed through a sound volume level and/or a vibrational level of the alert. The method also includes automatically reducing, through the processor, the sound volume level and/or the vibrational level of the alert following the determination of the intent of the user to respond to the alert."
9104421,"A method for managing a memory controller comprising selecting a low-power state from a plurality of low-power states. The method further comprises transitioning to the low-power and entering the low-power state when the transition is complete, provided a wake-event has not been received. An apparatus comprises a controller configured to select a power state for transition, a state-machine configured to execute steps for transitions between power states of a memory controller connected by a bus to a memory, a storage configured to store at least one context, and a context engine configured to stream, at the direction of the state-machine engine, the at least one context to the memory controller. Streaming comprises communicating N portions of context data as a stream to N registers in the memory controller. A context comprises a plurality of calibrations corresponding to a state selected for transition."
9104423,A system and method for power management by providing advance notice of events. The method includes snooping a register of an operating system timer to determine a timer period associated with a scheduled event. A unit of a computer system is identified that is in a low power state. A wake up latency of the unit is determined that is based on the low power state. An advance period is determined based on the wake up latency. An advance notice of the operating system timer is triggered based on the timer period and the advance period to wake up the unit.
9105113,"A graphics processor method and system for rendering a circle. The method includes the step of accessing an instruction to render a circle. A square is defined using at least one graphics primitive, and a circle is defined within the square, wherein a center of the circle corresponds to a center of the square and wherein a radius of the circle is defined by a width of the square. The circle is rasterized into at least one pixel and a coverage value is determined for each pixel of the circle by comparing a distance from the pixel to the center of the circle with the radius of the circle. Each pixel is then shaded in accordance with the coverage value."
9105250,"A method for compressing graphics data, the method comprising sorting a plurality of coverage masks into an order of descending number of samples covered by the plurality of coverage masks. A first coverage mask is identified. The first coverage mask comprises a greatest number of covered samples. Additional coverage masks of the plurality of coverage masks are compacted in the order of descending number of samples covered. Compacting additional coverage masks comprises removing samples from the coverage mask that are covered by any other compacted coverage mask."
9106013,"An external latching mechanism for an Input/Output (I/O) connection between devices is provided. In one embodiment, an external latching mechanism for an Input/Output (I/O) cable is provided. The external latching mechanism includes a housing coupled to an I/O cable at a first end and having an I/O connector extending a second end. An external latch is coupled by a mounting portion to the housing. The external latch has a first end and a second end. The second end of the arm extends beyond the second end of the housing to a barb. In another embodiment, an external latching Input/Output (I/O) connection is provided that includes a I/O card latching bracket configured to mate with an I/O cable assembly."
9106235,"A method and a system are provided for synchronizing a signal. A keep out window is defined relative to a second clock signal and an edge detection signal is generated that indicates if an edge of a first clock signal is within the keep out window. The edge detection signal may be filtered. An input signal is received in a domain corresponding to the first clock signal and a delayed input signal is generated. Based on the edge detection signal or the filtered edge detection signal, either the input signal or the delayed input signal is selected, to produce an output signal in a domain corresponding to the second clock signal."
9106401,"One embodiment sets forth a technique for deterministic synchronization of signals that are transmitted between different clock domains. The relative phase difference between a source clock domain and a destination clock domain is characterized and the source clock and/or the destination clock are delayed as needed to generate phase-shifted versions of the source and destination clocks for use during a deterministic operating mode. The phase-shifted versions of the source and destination clocks are non-overlapping, meaning that the rising edge of the destination clock does not occur when the source clock is asserted. The non-overlapping source and destination clocks are used by a deterministic synchronization unit to ensure that signals being transmitting from the source clock domain to the destination clock domain are not sampled within a metastability window."
9110141,"A scan flip-flop circuit comprises a scan input sub-circuit and a selection sub-circuit. The scan input sub-circuit is configured to receive a scan input signal and a scan enable signal and, when the scan enable signal is activated, generate complementary scan input signals representing the scan input signal that are delayed relative to a transition of a clock input signal between two different logic levels. The selection sub-circuit is coupled to the scan input sub-circuit and configured to receive the complementary scan input signals and, based on the scan enable signal, output an inverted version of either the scan input signal or a data signal as a first selected input signal."
9110809,"A method for managing memory traffic includes causing first data to be written to a data cache memory, where a first write request comprises a partial write and writes the first data to a first portion of the data cache memory, and further includes tracking the number of partial writes in the data cache memory. The method further includes issuing a fill request for one or more partial writes in the data cache memory if the number of partial writes in the data cache memory is greater than a predetermined first threshold."
9110810,"One embodiment of the present invention sets forth an improved way to prefetch instructions in a multi-level cache. Fetch unit initiates a prefetch operation to transfer one of a set of multiple cache lines, based on a function of a pseudorandom number generator and the sector corresponding to the current instruction L1 cache line. The fetch unit selects a prefetch target from the set of multiple cache lines according to some probability function. If the current instruction L1 cache 370 is located within the first sector of the corresponding L1.5 cache line, then the selected prefetch target is located at a sector within the next L1.5 cache line. The result is that the instruction L1 cache hit rate is improved and instruction fetch latency is reduced, even where the processor consumes instructions in the instruction L1 cache at a fast rate."
9111325,"The graphics processing technique includes detecting a transition from rendering graphics on a first graphics processing unit to a second graphics processing, by a hybrid driver. The hybrid driver, in response to detecting the transition, configures the first graphics processing unit to create a frame buffer. Thereafter, an image rendered on the second graphics processing unit may be copied to the frame buffer of the first graphics processing unit. The rendered image in the frame buffer may then be scanned out on the display."
9111360,"A tessellation pipeline includes an alpha phase and a beta phase. The alpha phase includes pre-tessellation processing stages, while the beta phase includes post-tessellation processing stages. A processing unit configured to implement a processing stage in the alpha phase stores input graphics data within a buffer and then copies over that buffer with output graphics data, thereby conserving memory resources. The processing unit may also copy output graphics data directly to a level 2 (L2) cache for beta phase processing by other tessellation pipelines, thereby avoiding the need for fixed function copy-out hardware."
9111368,"A method for using a pipelined L2 cache to implement memory transfers for a video processor. The method includes accessing a queue of read requests from a video processor. For each of the read requests, a determination is made as to whether there is a cache line hit corresponding to the request. For each cache line miss, a cache line slot is allocated to store a new cache line responsive to the cache line miss. An in-order set of cache lines is output to the video processor responsive to the queue of read requests."
9111393,"A system, process, and computer program product are provided for sampling a hierarchical depth map. An approach for sampling the hierarchical depth map includes the steps of generating a hierarchical depth map and reading a value associated with a sample pixel from a target level of the hierarchical depth map based on a difference between the sample pixel and a target pixel. The hierarchical depth map includes at least two levels."
9112588,"A transceiver, a method of providing multiple-band virtual concurrent wireless communication and a wireless device incorporating the transceiver or the method. In one embodiment, the transceiver includes: (1) first transmit and receive intermediate frequency (IF) strips, (2) second transmit and receive IF strips, (3) first and second local oscillators (LOs) and (4) switches operable to multiplex clock signals from the first and second local oscillators to cause the transceiver to operate in a selectable one of: (4a) a unified, multiple-input, multiple-output (MIMO) mode in which the first and second transmit and receive IF strips are driven to transmit and receive in a first band and (4b) a concurrent multiple-band connection mode in which the first transmit and receive IF strips are driven in the first band and the second transmit and receive IF strips are concurrently driven in a second band."
9113162,"A dynamic AC prediction technique is implemented in a data partition mode which automatically disables AC prediction for encoding the current macroblock in the next packet when packet overflow occurs. Otherwise, when there is no overflow, AC prediction remains enabled to maintain compression efficiency. More particularly, in the preferred embodiment, a determination is first made whether a macroblock causes a packet overflow if it is encoded in the current packet. If so, a new packet is initiated into which the macroblock is encoded without AC prediction as the first macroblock. Otherwise, the macroblock with AC prediction remains in the current packet and a new macroblock is encoded."
9115721,"The present invention provides a turbofan and a graphics card with the turbofan. The turbofan comprises: a turbofan assembly which admits air in an axial direction and dispenses air in a radial direction; an inlet fan assembly disposed at an inlet of the turbofan assembly and disposed coaxially with the turbofan assembly; and a driving means for driving the turbofan assembly and the inlet fan assembly to rotate. The turbofan provided by the invention gathers the ambient air to the inlet through the inlet fan assembly disposed at the inlet of the turbofan assembly, so as to change a negative pressure state at the inlet. Consequently, the cooling efficiency of the turbofan is improved effectively and the noise of the turbofan is reduced."
9116668,"The present invention provides a panel protecting device of a flat panel electronic device and a flat panel electronic device. The panel protecting device comprises: a sensor for detecting one or more of a falling speed, a falling time and a falling distance of the flat panel electronic device in a vertical direction when the flat panel electronic device is only under gravity; and a protecting means for being mounted around a panel of the flat panel electronic device. The protecting means has a rest position and a protruding position. The protecting means is accommodated in a recess of the flat panel electronic device when the protecting means is in the rest position and protrudes from the panel when the protecting means is in the protruding position. The protecting means moves to the protruding position from the rest position automatically when the one or more of the falling speed, the falling time and the falling distance is greater than or equal to a predetermined value. The panel protecting device of the flat panel electronic device provided by the present invention is able to protrude the protecting means automatically when the movement of the panel protecting device is determined to be the accidental falling, so as to prevent the panel from contacting with the ground and further avoid the damage of the panel."
9117254,"A system, method, and computer program product are provided for performing ray tracing. In use, ray tracing is performed utilizing a divide and conquer method, where the divide and conquer method is associated with a cache."
9117284,"An asynchronous computing and rendering system includes a data storage unit that provides storage for processing a large-scale data set organized in accordance to data subregions and a computing cluster containing a parallel plurality of asynchronous computing machines that provide compute results based on the data subregions. The asynchronous computing and rendering system also includes a rendering cluster containing a parallel multiplicity of asynchronous rendering machines coupled to the asynchronous computing machines, wherein each rendering machine renders a subset of the data subregions. Additionally, the asynchronous computing and rendering system includes a data interpretation platform coupled to the asynchronous rendering machines that provides user interaction and rendered viewing capabilities for the large-scale data set. An asynchronous computing and rendering method is also provided."
9117309,"A method for rendering polygons with a bounding box and a graphics processor unit. The method includes generating a bounding rectangle, wherein each edge of the bounding rectangle is defined to a sub-pixel precision. At least one polygon within the bounding rectangle is cropped to the sub-pixel precision. The polygon is blended with a background color outside the bounding rectangle to anti-alias the polygon with the background color, wherein the blending is performed with the sub-pixel precision of the bounding rectangle."
9117392,"A method includes providing an Input/Output (I/O) interface at a periphery of a motherboard of a data processing device, and providing traces between a processor of the data processing device and the I/O interface across a surface of the motherboard. The traces provide conductive pathways between circuits of the processor and the I/O interface. The method also includes exposing the I/O interface through an external cosmetic surface of the data processing device in an assembled state thereof by way of a port complementary to that of a port of an external graphics card to enable direct coupling of the external graphics card to the data processing device through the exposed I/O interface by way of the complementary ports to provide boosting of processing through the data processing device."
9118927,"Reducing computational complexity when generating sub-pixel values for sub-pixel motion estimation from integer pixels. In an embodiment, half pixels in vertical and horizontal directions are computed by a applying a filter of first complexity on integer pixels, and a half pixel in diagonal direction is computed using a filter of lower complexity as compared to the filter of first complexity. Quarter (and other lower resolution pixels) pixels may also be generated using the half pixel in the diagonal direction. Thus, overall computational complexity is reduced in generating sub-pixels for sub-pixel motion estimation."
9118932,"A method includes determining, through a processor and/or a hardware engine, edge pixels and flat pixels of a video frame of a video sequence during decoding thereof or post-processing associated with the decoding based on a predetermined threshold, and quantifying spatial correlation of pixels of the video frame around edges thereof to estimate strength of ringing artifacts and spatial and temporal persistence thereof across the video frame and across video frames of the video sequence. The method also includes adaptively and spatially filtering the pixels around the edges of the video frame, adaptively and temporally filtering the video frame, and blending an output of the adaptive spatial filtering and the adaptive temporal filtering to generate an output with suppressed ringing artifacts, spatial and temporal persistence thereof and artifacts resulting from the cumulative effect of compression therein."
9118992,"One embodiment of the present invention sets forth a system that includes a detection device and a processor. The detection device is configured to sense that a handheld device has not been placed on or near a surface. In response to sensing that the handheld device has not been placed on or near a surface, the detection device is configured to transmit an indicator to the processor. The processor is configured to receive a first audio signal, and determine that the handheld device has not been placed on or near a surface by receiving the indicator from the detection device. In response to determining that the handheld device has not been placed on or near a surface, the processor is further configured to apply a compensating function to the first audio signal to generate a second audio signal, and transmit the second audio signal to a speaker."
9122643,"Methods and systems of initiating a backup process of data stored on a computer are described. One method calls for the data to be backed up to be identified. A backup event trigger is defined, and the computer is monitored for the occurrence of the backup event trigger. If the trigger occurs, a balancing heuristic is applied, to determine whether to initiate the backup process."
9123128,"Employing a general processing unit as a programmable function unit of a graphics pipeline and a method of manufacturing a graphics processing unit are disclosed. In one embodiment, the graphics pipeline includes: (1) accelerators, (2) an input output interface coupled to each of the accelerators and (3) a general processing unit coupled to the input output interface and configured as a programmable function unit of the graphics pipeline, the general processing unit configured to issue vector instructions via the input output interface to vector data paths for the programmable function unit."
9123173,"In a raster stage of a graphics pipeline, a method for rasterizing non-rectangular tile groups. The method includes receiving a graphics primitive for rasterization in a raster stage of a graphics processor. The graphics primitive is rasterized at a first level by generating a non-rectangular footprint comprising a set of pixels related to the graphics primitive. The graphics primitive is then rasterized at a second level by accessing the set of pixels and determining covered pixels out of the set of pixels. The raster stage subsequently outputs the covered pixels for rendering operations in a subsequent stage of the graphics processor."
9123438,"A configurable delay circuit and a method of clock buffering. One embodiment of the configurable delay circuit includes: (1) a first delay stage electrically couplable in series to a second delay stage, the first delay stage and the second delay stage each having an input port electrically coupled to a signal source, and (2) a delay path select circuit electrically coupled between the first delay stage and the second delay stage, and operable to select between a delay path including the first delay stage and another delay path including the first delay stage and the second delay stage."
9129443,"A cache-efficient processor and method for rendering indirect illumination using interleaving and sub-image blur. One embodiment of the processor is configured to render an indirect illumination image and includes: (1) a buffer restructurer configured to organize a reflective shadow map (RSM), rendered with respect to a reference point, into a plurality of unique sub-RSMs, each having sub-RSM pixels, (2) an indirect illumination computer configured to employ interleaved sampling on the plurality of unique sub-RSMs to generate a plurality of indirect illumination sub-images, and (3) a filter operable to smooth accumulated light values of the indirect illumination sub-images for subsequent interleaving into the indirect illumination image."
9131445,"In an aspect there is provided a method of moving a processor of a mobile device from a low-power state for conserving power to an active mode for processing signals. The mobile device is configured to receive regularly scheduled signals. The method comprises, for each of multiple operating states of the mobile device determining a restore time associated with the operating state of the mobile device and storing each determined restore time in association with its operating state. The method further comprises detecting a current operating state of the mobile device and using the determined restore time for that state to set a trigger time to control movement of the processor of the mobile device to enter the active mode from the low-power mode in time to process the scheduled signals."
9134782,"Power supply voltage to an integrated circuit (IC) or a portion of an IC is maintained at an optimum level matching the IC performance. Voltage ranges and delay measures for corresponding operating frequencies are stored in tables in a voltage control block. When a new frequency of operation is desired, the voltage control block measures delay performance of the IC, and sets the supply voltage to a value specified in a corresponding entry in a table. The voltage control block then continues to measure delay performance, and dynamically adjusts the power supply voltage to an optimum value thereby minimizing power consumption."
9134787,"To preserve power and increase the overall efficiency of the CPU, the platform idle driver causes the power gate controller to cut power to the idle core. Such power gating is autonomous, i.e., the operating system and the other cores are not involved. In operation, the platform idle driver first prepares the core and the power gate controller for power gating the core. The platform idle driver then triggers the power gating. The power gate controller monitors interrupts released by the interrupt controller, and if any on the released interrupts are associated with the power gated core, the power gate controller resumes dispersing power to the core."
9134979,"A basic block within a thread program is characterized for convergence based on mapping the basic block to an indicator subnet within a corresponding Petri net generated to model the thread program. Each block within the thread program may be similarly characterized. Each corresponding Petri net is enumerated to generate a corresponding state space graph. If the state space graph includes an exit node with an odd execution count attribute, such as by Petri net coloring, then the corresponding basic block is divergent. The corresponding basic block is convergent otherwise. Using this characterization technique, a thread program compiler may advantageously identify all convergent blocks within a thread program and apply appropriate optimizations to the convergent blocks."
9135081,"One embodiment of the present invention enables threads executing on a processor to locally generate and execute work within that processor by way of work queues and command blocks. A device driver, as an initialization procedure for establishing memory objects that enable the threads to locally generate and execute work, generates a work queue, and sets a GP_GET pointer of the work queue to the first entry in the work queue. The device driver also, during the initialization procedure, sets a GP_PUT pointer of the work queue to the last free entry included in the work queue, thereby establishing a range of entries in the work queue into which new work generated by the threads can be loaded and subsequently executed by the processor. The threads then populate command blocks with generated work and point entries in the work queue to the command blocks to effect processor execution of the work stored in the command blocks."
9135214,"A system, method, and computer program product are provided for assigning elements of a matrix to processing threads. In use, a matrix is received to be processed by a parallel processing architecture. Such parallel processing architecture includes a plurality of processors each capable of processing a plurality of threads. Elements of the matrix are assigned to each of the threads for processing, utilizing an algorithm that increases a contiguousness of the elements being processed by each thread."
9135369,"A system, method, and computer program product are provided for performing graph aggregation. In use, a graph with a plurality of vertices and a plurality of edges is identified. Additionally, aggregation is performed on the vertices and edges of the graph by computing a graph matching, where such graph matching is performed in a data-parallel manner."
9135675,"Systems and methods for utilizing multiple graphics processing units for controlling presentations on a display are presented. In one embodiment, a dual graphics processing system includes a first graphics processing unit for processing graphics information; a second graphics processing unit for processing graphics information; a component for synchronizing transmission of display component information from the first graphics processing unit and the second graphics processing unit and a component for controlling switching between said first graphics processing unit and said second graphics processing unit. In one embodiment, the component for synchronizing transmission of display component information adjusts (e.g., delays, speeds up, etc.) the occurrence or duration of a corresponding graphics presentation characteristic (e.g., end of frame, end of line, vertical blanking period, horizontal blanking period, etc.) in signals from multiple graphics processing units."
9142005,"One embodiment of the present invention sets forth a technique for placing texture barrier instructions within a thread program to advantageously enable efficient and correct operation of the thread program. A thread program compiler statically determines a pending request count needed to progress beyond a particular texture barrier instruction, which blocks execution of subsequent instructions that depend on previously requested data. Each instance of the thread program blocks execution at the barrier instruction until a pending request count condition is satisfied. This technique may advantageously reduce power consumption in a graphics processing unit by eliminating power consumption associated with conventional, generalized scoreboard resources."
9142040,"A system, method, and computer program product are provided for processing graphics data associated with shading. In operation, a first fragment is received. Further, the first fragment is shaded. While the first fragment is being shaded, a second fragment is received and it is determined whether at least one aspect of the second fragment conflicts with the first fragment. If it is determined that the at least one aspect of the second fragment does not conflict with the first fragment, the second fragment is shaded. If it is determined that the at least one aspect of the second fragment conflicts with the first fragment, information associated with the second fragment is stored, a third fragment is received, and the third fragment is shaded, if it is determined that at least one aspect of the third fragment does not conflict with the first fragment."
9142043,"A method for reducing the number of samples tested for rendering a screen space region of an image includes constructing a trajectory of a primitive extending within an image which is to be rendered. A bounding volume is constructed for a screen space region of the image, the bounding volume characterized as having a bound in a non-screen space dimension which is defined as a function of the primitive's trajectory. The bounding volume is further characterized as overlapping a portion of the screen space region which is to be rendered. One or more sample points which are located within the screen space region, and which are not overlapped by the bounding volume are excluded from testing."
9143244,"A method of mitigating interference between carrier frequency bands of a carrier aggregation scheme. The method comprises: at a wireless device, receiving a first signal on a first carrier frequency band of the carrier aggregation scheme; mixing a second signal onto a second carrier frequency band of the carrier aggregation scheme and transmitting the second signal from the wireless device; executing code on a processing apparatus of the device to generate a reconstructed interference signal, by mixing an instance of the signal with a frequency location of an interfering harmonic from the second carrier frequency band falling in the first carrier frequency band; and removing the reconstructed interference signal from the first signal."
9146949,"Described are data structures and methodology for forming same, for network protocol processing. A method for creating data structures for firewalling and network address translating is described. A method for creating data structures for physical layer addressing is described. A method for security protocol support using a data structure is described. A method for creating at least one data structure sized responsive to whether a firewall is activated is described. A data structure for routing packets is described. A method of forming hashing table chains is described. A method and apparatus for tracking packet states is described. More particularly, Transmission Control Protocol (“TCP”) tracking of states for packets is described. In an embodiment, a division between software states and hardware states is made as a packet is processed by both software and hardware. A method and apparatus for network protocol processing are also described."
9147224,"One embodiment of the present invention sets forth a technique for receiving versions of state objects at one or more stages in a processing pipeline. The method includes receiving a first version of a state object at a first stage in the processing pipeline, determining that the first version of the state object is relevant to the first stage, incrementing a first reference counter associated with the first version of the state object, assigning the first version of the state object to work requests that arrive at the first stage subsequent to the receipt of the first version of the state object, and transmitting the first version of the state object to a second stage in the processing pipeline."
9147264,"A method for performing image rendering. The method includes identifying a tile in an image, wherein the image comprises a plurality of tiles including color data that is displayed by a plurality of pixels. A quantized first base value and a quantized second base value are accessed from a block of memory, wherein the block is associated with the tile. Reverse quantization is performed on the quantized first and second base values to obtain a reproduced first base value, and a reproduced second base value corresponding to the tile for purposes of determining color values for corresponding pixels."
9147270,"A method for reducing the number of samples tested for rendering a screen space region of an image includes constructing a trajectory of a primitive in a three dimensional coordinate system, the coordinate system including a screen space dimension, a lens dimension and a time dimension. A bounding volume is constructed for a screen space region which is to be rendered, the bounding volume overlapping a portion of the screen space region. The bounding volume is defined according to a plurality of bounding planes which extend in the three dimensional coordinate system, whereby the bounding planes are determined as a function of the trajectory of the primitive. One or more sample points which are located within the screen space region, and which are not overlapped by the bounding volume are excluded from testing."
9147447,"A system is provided for transmitting signals. The system comprises a first processing unit, a memory subsystem, and a package. The first processing unit is configured to include a first ground-referenced single-ended signaling (GRS) interface circuit. The memory subsystem is configured to include a second GRS interface circuit. The package is configured to include one or more electrical traces that couple the first GRS interface to the second GRS interface, where the first GRS interface circuit and the second GRS interface circuit are each configured to transmit a pulse along one trace of the one or more electrical traces by discharging a capacitor between the one trace and a ground network."
9148544,"A system, process, and computer program product are provided for scanning a document with a hand-held device. An approach for scanning the document includes the steps of sampling one or more values from an array of sensors integrated into a hand-held device, determining whether the device has moved at least a threshold distance, and sampling one or more additional values from the array of sensors."
9152372,"A method and system for enabling multiple video graphics array (VGA) cards to process image data are disclosed. Specifically, one embodiment of a graphics system includes a first video graphics array (VGA) card having a first and a second connection ports, a second VGA card having a first and a second connection ports, a third VGA card having a first and a second connection ports, and a connecting device for electronically connecting the first, the second, and the third VGA cards via connections that transfer data. The connecting device is further configured to connect the first connection port of the first VGA card to either the first or the second connection port of the second VGA card and connect the second connection port of the first VGA card to either the first or the second connection port of the third VGA card."
9152374,"A method includes implementing an audio framework to be executed on a data processing device with a virtual audio driver component and a User Mode Component (UMC) communicatively coupled to each other. The virtual audio driver component enables modifying an original default audio endpoint device of an application executing on the data processing device to an emulated audio device associated with a new audio endpoint in response to an initiation through the application in conjunction with the UMC. The virtual audio driver component also enables registering the new audio endpoint as the modified default audio endpoint with an operating system executing on the data processing device. Further, the virtual audio driver component enables capturing audio data intended for the original default audio endpoint device at the new audio endpoint following the registration thereof to enable control of the audio data."
9153027,"A system, method, and computer program product are provided for performing fast, non-rigid registration for at least two images of a high-dynamic range image stack. The method includes the steps of generating a warped image based on a set of corresponding pixels, analyzing the warped image to detect unreliable pixels in the warped image, and generating a corrected pixel value for each unreliable pixel in the warped image. The set of corresponding pixels includes a plurality of pixels in a source image, each pixel in the plurality of pixels associated with a potential feature in the source image and paired with a corresponding pixel in a reference image that substantially matches the pixel in the source image."
9153068,"A method for reducing the number of samples tested for rendering a screen space region of an image includes constructing a trajectory of a primitive extending in an image which is to be rendered. A bounding volume is constructed for a screen space region of the image, the bounding volume characterized as having a bound in a non-screen space dimension which is defined as a function of the primitive's trajectory. The bounding volume is further characterized as overlapping a portion of the screen space region which is to be rendered. One or more sample points which are located within the screen space region, and which are not overlapped by the bounding volume are excluded from testing."
9153209,"One embodiment of the present invention sets forth a technique for generating a displacement map. The technique involves receiving a normal map which includes one or more normal vectors associated with a texture map, processing the one or more normal vectors to a calculate one or more depth difference vectors associated with the texture map, and generating one or more rays associated with a first texel of the texture map. The technique further involves calculating, for each of the one or more rays, relative depths of each of the one or more other texels traversed by the ray based on each of the depth difference vectors that correspond with the one or more other texels traversed by the ray, determining a displacement value associated with the first texel based on the relative depths calculated for the one or more rays, and storing the displacement value in a displacement map."
9153211,"A method and system for tracking accesses to virtual addresses are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of receiving a virtual address from a client requesting to access memory in a graphics context, updating access state information corresponding to a virtual page associated with the graphics context in which the virtual address resides, after the virtual address successfully maps to a physical memory location, and determining whether to evict a physical page associated with the graphics context based on the access state information."
9153314,"A system is provided for transmitting signals. The system includes a ground-referenced single-ended signaling (GRS) driver circuit that is configured to pre-charge a first capacitor to store a first charge between a first output node and a first reference node based on a first input data signal during a first pre-charge phase and drive an output signal relative to a ground network based on the first charge during a first drive phase. A control circuit is configured to generate a first set of control signals based on the first input data signal and a first clock signal, where the first set of control signals causes the first GRS driver circuit to operate in either the first pre-charge phase or in the first drive phase."
9153539,"A system of interconnected chips comprising a multi-chip module (MCM) includes a first processor chip, a graphics processing cluster (GPC) chip, and an MCM package configured to include the first processor chip, the GPC chip, and an interconnect circuit. The first processor chip is configured to include a first ground-referenced single-ended signaling interface circuit. A first set of electrical traces fabricated within the MCM package and configured to couple the first single-ended signaling interface circuit to the interconnect circuit. The GPC chip is configured to include a second single-ended signaling interface circuit and to execute shader programs. A second set of electrical traces fabricated within the MCM package and configured to couple the second single-ended signaling interface circuit to the interconnect circuit. In one embodiment, each single-ended signaling interface advantageously implements ground-referenced single-ended signaling."
9155120,"A modem for use at a terminal, the modem comprising: a first interface arranged to connect to a communications network; a second interface arranged to connect to a host processor on the terminal; and a processing unit, the processing unit configured to: detect that a call is to be established over the communications network; in response to said detection, perform a call setup procedure; determine if the call setup procedure has been successful or has failed due to failure of a security procedure; and in response to determining that the call setup procedure has failed due to failure of a security procedure, repeat said call setup procedure without indicating failure of the call setup procedure to a user of said terminal."
9158335,"A notebook computer is disclosed in the present invention which comprises: a screen, which is a touch screen configured to be operable via touching; a host, which is integrated in the screen; and a keyboard, which is detachably connected with the screen so that the keyboard and the screen can be in a state of being connected to each other or in a state of being separated from each other in use. When the notebook computer is used, the keyboard and the screen can be in the state of being separated from each other in use, so that the screen and the keyboard of the notebook computer are used separately. And the keyboard and the screen can be separated when needed and the notebook computer can be use by touching operation on the screen."
9158452,A touch screen system includes a touch screen that provides touch information in response to a touch event. The touch screen system also includes a rapid response display controller having a reactive interpretation unit that provides an initial display representation of the touch information and a reactive feedback unit that provides the initial display representation to the touch screen for an initial display. The touch screen system further includes a routine response display controller that additionally receives the touch information and provides a final display representation of the touch information to the touch screen for a final display. A method of touch screen display management is also included.
9158569,"A method includes loading a driver component on a hypervisor of a computing system including a Graphics Processing Unit (GPU) without hardware support for virtual interrupt delivery, and loading an instance of the driver component on each of a number of VMs consolidated on a computing platform of the computing system. The method also includes allocating a memory page associated with work completion by the each of the number of VMs thereto through a driver stack executing on the hypervisor, and sharing the memory page with the driver component executing on the hypervisor. Further, the method includes delivering, through the hypervisor, an interrupt from the GPU to an appropriate VM based on inspecting the memory page associated with the work completion by the each of the number of VMs."
9158595,"One embodiment sets forth a technique for scheduling the execution of ordered critical code sections by multiple threads. A multithreaded processor includes an instruction scheduling unit that is configured to schedule threads to process ordered critical code sections. A ordered critical code section is preceded by a barrier instruction and when all of the threads have reached the barrier instruction, the instruction scheduling unit controls the thread execution order by selecting each thread for execution based on logical identifiers associated with the threads. The logical identifiers are mapped to physical identifiers that are referenced by the multithreaded processor during execution of the threads. The logical identifiers are used by the instruction scheduling unit to control the order in which the threads execute the ordered critical code section."
9158896,"A method, system on a chip, and computer system for generating more robust keys which utilize data occupying relatively small die areas is disclosed. Embodiments provide a convenient and effective mechanism for generating a key for use in securing data on a portable electronic device, where the key is generated from repurposed data and a relatively small amount. A multi-stage encryption algorithm may be performed to generate the key, where the first stage may include encrypting the secure data, and the second stage may include encrypting the result of a logical operation on the encrypted secure data with a unique identifier of the portable electronic device. A secret key may be used as the encryption key for each stage. The result of the second encryption stage may include the generated key which may be used to perform subsequent operations on the portable electronic device."
9159156,"One embodiment of the present invention sets forth a technique to perform fine-grained rendering predication using an IGPU. A graphics driver divides a 3D object into batches of triangles. The IGPU processes each batch of triangles through a modified rendering pipeline to determine if the batch is culled. The IGPU writes bits into a bitstream corresponding to the visibility of the batches. Advantageously, this approach to rendering predication provides fine-grained culling without adding unnecessary overhead, thereby optimizing both hardware resources and performance."
9159158,"A method including casting a ray from a point toward a point-based three dimensional scene. The scene includes memory resident objects with object surfaces and a first splat and a second splat associated with the object surfaces. The first splat and the second splat have a position and a normal vector. The method also includes forming an event line through the first splat and the second splat. The event line intersects the first splat and the second splat. The method further includes determining whether a visibility conflict exists between the first splat and the second splat. The method also includes separating the first splat and the second splat to different object surfaces if the visibility conflict exists, otherwise merging the first splat and the second splat to a single object surface."
9159367,"A method includes initiating, through an interface of a data processing device, generation of one or more excerpt(s) of a video sequence associated with a video file stored in a memory of the data processing device. The method also includes automatically reading, through a processor of the data processing device communicatively coupled to the memory, video frames of the video file corresponding to the one or more excerpt(s) and reference video frames thereof in accordance with the initiation through the interface. Further, the method includes decoding, through the processor, the video frames of the video file corresponding to the one or more excerpt(s) and the reference video frames thereof following the automatic reading for rendering thereof on the data processing device."
9164134,"A method and a system are provided for clock phase detection. A set of delayed versions of a first clock signal is generated. The set of delayed versions of the first clock is used to sample a second clock signal, producing a sequence of samples in a domain corresponding to the first clock signal. At least one edge indication is located within the sequence of samples."
9164288,"The presentation of stereoscopic display content for viewing with passive glasses and full resolution is provided. In use, (a) a frame of stereoscopic display content intended for viewing by one eye of a user is scanned, using a display layer of a display device; (b) the scanned frame is polarized utilizing a polarizing layer of the display device, according to a polarization associated with a lens of stereoscopic glasses worn over the same one eye of the user; (c) a backlight is activated to illuminate the polarized frame, in response to an entirety of the polarized frame being scanned; (d) the display device is held for a predetermined period of time in response to activation of the backlight, and then the backlight is de-activated; and (a)-(d) are then repeated for the other eye of the user, with another frame of stereoscopic display content intended for viewing by the other eye."
9164690,"A system, method, and computer program product are provided for copying data between memory locations. In use, a memory copy instruction is implemented. Additionally, data is copied from a first memory location to a second memory location, utilizing the memory copy instruction."
9164766,"Methods and apparatus for providing additional storage, in the form of a hardware assisted stack, usable by software running an environment with limited resources. As an example, the hardware assisted stack may provide additional stack space to VBIOS code that is accessible within its limited allocated address space."
9165394,"The present invention sets forth a method for supporting enhanced audio on a graphics processing unit (GPU) in a computing device having a graphics subsystem. In one embodiment, the method includes the steps of determining whether an option of a GPU audio output is enabled and the graphics subsystem and a first external output device is connected, and routing a first audio stream to the GPU of the graphics subsystem for processing when the option of the GPU audio output is enabled and the graphics subsystem and the first external output device is in connection and causing the processed first audio stream to be transferred along a first transmission path to the first external output device, or otherwise causing a second audio stream to be transferred along a second transmission path to a second external output device."
9165396,A processor and a system are provided for performing texturing operations. The processor includes a texture return buffer having a plurality of slots for storing texture values and one or more texture units coupled to the texture return buffer. Each of the slots of the texture return buffer are addressable by a thread. Each texture unit is configured to allocate a slot of the texture return buffer when the texture unit generates a texture value.
9165399,"A system, method, and computer program product are provided for inputting modified coverage data into a pixel shader. In use, coverage data modified by a depth/stencil test is input into a pixel shader. Additionally, one or more actions are performed at the pixel shader, utilizing the modified coverage data."
9165537,"A method and apparatus for performing display image refresh in bursts to a display device. A buffered refresh controller includes capabilities to drive the display based on video signals generated from a local frame buffer at a first rate. The graphics controller may optimally be configured to burst a new frame of pixel data to the buffered refresh controller at a second rate to replace the previous frame of pixel data in the local frame buffer. The second rate is different than the first rate. Additionally, the graphics controller may send frames only when they contain new pixel data. By enabling the graphics controller to selectively transmit the new frame of pixel data at the second rate, higher than the first rate, the graphics controller may be placed in a power-saving state during at least a portion of each frame update."
9166337,"Embodiments of the invention generally include apparatus for providing a positive locked connection for I/O devices to computing devices. In one embodiment, an external latching apparatus for an Input/Output (I/O) connection is provided. The external latching apparatus includes a main body and at least one latch. The main body includes a first surface configured to abut to an I/O card bracket and a second surface, parallel and spaced apart from the first surface. The at least one latch extends from the main body beyond the first surface. A plurality of parallel slots are formed in the second surface. Each slot is open on a bottom side of the body and is configured to receive a cable of an I/O cable assembly."
9170836,"A system and method for re-factorizing a square input matrix on a parallel processor. In one embodiment, the system includes: (1) a matrix generator operable to generate an intermediate matrix by embedding a permuted form of the input matrix in a zeroed-out sparsity pattern of a combination of lower and upper triangular matrices resulting from a prior LU factorization of a previous matrix having a same sparsity pattern, reordering to minimize fill-in and pivoting strategy as the input matrix and (2) a re-factorizer associated with the matrix generator and operable to use parallel threads to apply an incomplete-LU factorization with zero fill-in on the intermediate matrix."
9170980,"A system of interconnected chips comprising a multi-chip module (MCM) includes a processor chip, a system functions chip, and an MCM package configured to include the processor chip, the system functions chip, and an interconnect circuit. The processor chip is configured to include a first ground-referenced single-ended signaling interface circuit. A first set of electrical traces manufactured within the MCM package and configured to couple the first single-ended signaling interface circuit to the interconnect circuit. The system functions chip is configured to include a second single-ended signaling interface circuit and a host interface. A second set of electrical traces manufactured within the MCM package and configured to couple the host interface to at least one external pin of the MCM package. In one embodiment, each single-ended signaling interface advantageously implements ground-referenced single-ended signaling."
9171115,"A system, method, and computer program product are provided for translating a hardware design. In use, a hardware design is received that is a graph-based common representation of a hardware design stored in a hardware model database. Logic code is generated for each hardware module node of the graph-based common representation of the hardware design. Additionally, flow control code is generated for each hardware module node of the graph-based common representation of the hardware design. A logic code model of the hardware design that includes the generated logic code and the generated flow control code is stored."
9171350,Embodiments of the present invention are directed to provide novel methods and a system for adaptive resolution rendering via scaling in a multiple graphics processor system. A method is described herein that maintains a constant framerate by reducing the resolution of the graphical output rendered in one graphics processor and using another graphics processor in the same computing system to scale the already-rendered output to its original intended resolution when the framerate drops below a desired threshold.
9171394,"Method including casting a first plurality of rays towards an original 3-D scene comprising objects with object surfaces. Method also includes constructing a simplified representation of the original 3-D scene and adjusting the simplified representation to be consistent with the original 3-D scene. Simplified representation is adjusted by using known rays and object surface intersections obtained from the casting, to produce an adjusted simplified representation. Method further includes steps for rendering a high quality image: casting a second plurality of rays toward the adjusted simplified representation and testing the second plurality of rays for points of intersection with the object surfaces within the adjusted simplified representation, estimating incoming light within the adjusted simplified representation at the points of intersection with the object surfaces, examining material properties of the object surfaces, and calculating a color and light intensity for a plurality of pixels associated with the second plurality of rays."
9171525,"A processor and a system are provided for performing texturing operations loaded from a texture queue that provides temporary storage of texture coordinates and texture values. The processor includes a texture queue implemented in a memory of the processor, a crossbar coupled to the texture queue, and one or more texture units coupled to the texture queue via the crossbar. The crossbar is configured to reorder texture coordinates for consumption by the one or more texture units and to reorder texture values received from the one or more texture units."
9171607,"A system of interconnected chips comprising a multi-chip module (MCM) includes a first processor chip, a system function chip, and an MCM package configured to include the first processor chip and the system function chip. The first processor chip is configured to include a first ground-referenced single-ended signaling (GRS) interface circuit. The system function chip is configured to include a second GRS interface circuit. A first set of electrical traces are fabricated within the MCM package and coupled to the first GRS interface circuit and to the second GRS interface circuit. The first GRS interface circuit and second GRS interface circuit together provide a communication channel between the first processor chip and the system function chip."
9172136,"Provided is a multi-band antenna. The multi-band antenna, as provided in one embodiment, includes a first resonant portion having a first length defined by an outer perimeter of a conductive segment and operable to effect an antenna for communication in a first band of frequencies. The multi-band antenna, in this aspect, further includes a second resonant portion having a second length defined by an inner perimeter of the conductive segment and operable to resonate capacitively for communication in a second different band of frequencies."
9172241,"A technique for providing electrostatic discharge (ESD) protection in complementary metal-oxide semiconductor (CMOS) technologies is disclosed. A power supply RC-based ESD protection circuit having an RC value in the nanosecond range increases the allowable power-up slew rate so that fast power-up events (e.g., hot-plug and power switching operations) are not erroneously interpreted as ESD events. Because the RC value is small, the layout area needed for the RC-based ESD protection circuit is also reduced."
9176736,"A system includes a processor having an instruction register for storing an instruction having a predefined opcode, a predicate register for storing a predicate condition to select an output register for a result of the instruction, a first output register, and a second output register. The processor further includes processor circuitry operable to execute the instruction to produce a result, and processor circuitry operable to store the result of the instruction in the first output register if the predicate condition to select the output is true, and to store the second output register if the predicate condition to select the output is false. A single instruction is used to produce the result, and to store the result of the instruction."
9176909,"Embodiments of the claimed subject matter are directed to systems and a method that allows the aggregation of multiple interfaces of a single data communication bus to provide greater bandwidth for communication between a peripheral device and system memory within a computing system. In one embodiment, a system is provided wherein the unoccupied interfaces of the data communication bus is aggregated with an occupied interface coupled to a peripheral device to increase the bandwidth of data transfer requests between the peripheral device and the system memory."
9177121,"Methods for code protection are disclosed. A method includes using a security processing component to access an encrypted portion of an application program that is encrypted by an on-line server, after a license for use of the application program is authenticated by the on-line server. The security processing component is used to decrypt the encrypted portion of the application program using an encryption key that is stored in the security processing component. The decrypted portion of the application program is executed based on stored state data. Results are provided to the application program that is executing on a second processing component."
9177368,"Methods and systems for reducing or eliminating distortion in an image are described. The approach generally involves determining the distortion introduced by a lens, and modifying a captured image to reduce that distortion. In one embodiment, the distortion information associated with a lens is determined. The distortion information is stored. A captured image taken by that lens is processed, with reference to the distortion information."
9177413,"A system, method, and computer program product are provided for generating unique primitive identifiers. A specified scope and geometry for a scene is received. A primitive identifier is generated for each primitive of a particular type, where each of the primitive identifiers is unique within the specified scope, and where the primitives are generated as the geometry for the 3D graphics scene is processed by a graphics processing unit. Different types may include patches, triangles, and vertices. The specified scope may be one of a frame, region, pixel, or draw call."
9178421,"Embodiments are disclosed relating to an electric power conversion device and methods for controlling the operation thereof. One disclosed embodiment provides a multi-stage electric power conversion device including a first regulator stage including a first stage energy storage device and a second regulator stage including a second stage energy storage device, the second stage energy storage device being operatively coupled between the first stage energy storage device and the load. The device further includes a control mechanism operative to control (i) a first stage output voltage on a node between the first stage energy storage device and the second stage energy storage device and (ii) a second stage output voltage on a node between the second stage energy storage device and the load."
9178747,"A technique for enhancing the efficiency and speed of data transmission within and across multiple, separate computer systems includes the use of an MPI library/engine. The MPI library/engine is configured to facilitate the transfer of data directly from one location to another location within the same computer system and/or on separate computer systems via a network connection. Data stored in one GPU buffer may be transferred directly to another GPU buffer without having to move the data into and out of system memory or other intermediate send and receive buffers."
9179166,"The present invention facilitates efficient and effective detection of pixel alteration. The number and configuration of pixels in a block partition can be flexibly changed. The filter inputs in the multi-protocol filter can be flexibly changed to meet the deblocking requirement in the target video compression standard. In one embodiment, the deblock engine includes an input interface, a neighbor buffer, a current data buffer; and a multi-protocol filter. The input interface receives reconstructed data. The neighbor buffer temporarily stores neighbor information. The current data buffer receives the reconstructed data and the neighbor information. The multi-protocol filter filters information selected from the reconstructed data and neighbor information."
9179309,"A method of detecting an error in a security mode configuration procedure conducted at a radio access network is provided. A cell update message is transmitted which causes the radio access network to abort a security mode configuration procedure. After the transmission of an update message, a new security mode configuration is received and the original security mode configuration is replaced with a new security mode configuration. A security mode configuration check is performed on a received downlink message using the new security mode configuration. If the security mode configuration check fails, a further security mode configuration check is performed on the downlink message to detect an error in the security mode configuration procedure. If it is determined there has been an error in the security mode configuration procedure, security mode configuration checks are performed on further downlink messages received from the network using the original security mode configuration."
9182768,"A voltage margin controller, an IC included the same and a method of controlling voltage margin for a voltage domain of an IC are disclosed herein. In one embodiment, the voltage margin controller includes: (1) monitoring branches including circuit function indicators configured to indicate whether circuitry in the voltage domain could operate at corresponding candidate reduced voltage levels and (2) a voltage margin adjuster coupled to the monitoring branches and configured to develop a voltage margin adjustment for a voltage regulator of the voltage domain based upon an operating number of the circuit function indicators."
9182939,"One embodiment of the present invention sets forth a method for managing a power state of an audio device resident in a graphics processing unit. The method includes the steps of directing audio data originated from a client application via an audio path in an audio driver stack to the audio device, determining whether an active stream of audio data along the audio path is present in response to a notification of an attempt to shut down the graphics processing unit, and requesting a plug and play manager to disable the audio device, if no active stream of audio data is present along the audio path."
9183607,A method in system for latency buffered scoreboarding in a graphics pipeline of a graphics processor. The method includes receiving a graphics primitive for rasterization in a raster stage of a graphics processor and rasterizing the graphics primitive to generate a plurality pixels related to the graphics primitive. An ID stored to account for an initiation of parameter evaluation for each of the plurality of pixels as the pixels are transmitted to a subsequent stage of the graphics processor. A buffer is used to store the fragment data resulting from the parameter evaluation for each of the plurality of pixels by the subsequent stage. The ID and the fragment data from the buffering are compared to determine whether they correspond to one another. The completion of parameter evaluation for each of the plurality of pixels is accounted for when the ID and the fragment data match and as the fragment data is written to a memory.
9183609,A technique for efficiently rendering content reduces each complex blend mode to a series of basic blend operations. The series of basic blend operations are executed within a recirculating pipeline until a final blended value is computed. The recirculating pipeline is positioned within a color raster operations unit of a graphics processing unit for efficient access to image buffer data.
9183610,"The invention provides a method for driving a graphic processing unit (GPU), where a driver applies two threads to drive one ore more GPUs. The method includes the steps of: (a) activating a rendering thread and a displaying thread in response to invoking by an application thread of a graphics application; (b) sending according to the rendering thread a plurality of rendering instructions for enabling generation of at least a first rendered frame and a second rendered frame; and (c) sending according to the displaying thread one or more interpolating instructions and one or more displaying instructions, the one or more interpolating instructions enabling execution of interpolation according to the at least a first rendered frame and the second rendered frame to create one or more interpolated frames, and the one or more displaying instructions enabling display of the one or more interpolated frames."
9183662,"One embodiment of the present invention sets forth a technique for specifying scene programs, where the effect of executing a particular scene program is to generate a sequence of graphics commands. The application programming interface is extended to include calls used to specify a high-level scene program. Upon receiving a high-level scene program, the graphics driver generates a machine code scene program. When an application program emits a call to execute one or more machine code scene programs, the graphics driver transmits corresponding scene programs execution commands to the graphics pre-processing unit. For each scene program execution command, the graphics pre-processing unit processes instructions, programmatically reconfigures the graphics pipeline based on the execution of the machine code scene program, and launches one or more parallel threads that execute commands within the graphics pipeline. Advantageously, using scene programs, application developers may tailor application programs to more effectively dispatch tasks to the GPU."
9183813,"A method includes triggering, through an interface of a data processing device, cropping of a display screen area of a display unit of the data processing device. The method also includes initiating, through a driver component associated a processor of the data processing device, an operating system executing on the data processing device and/or an application executing on the data processing device, the processor to process pixel data to be displayed on the display screen area based on the triggering. Further, the method includes rendering, through the processor, the processed pixel data on a cropped portion of the display screen area of the display unit."
9183922,"Disclosed are devices, systems and/or methods relating to an eight transistor (8T) static random access memory (SRAM) cell, according to one or more embodiments. In one embodiment, an SRAM storage cell is disclosed comprising a word line, a write column select line, a cross-coupled data latch, and a first NMOS switch device serially coupled to a second NMOS switch device. In this embodiment, the gate node of the first NMOS switch device is coupled to the word line, a source node of the first NMOS switch device is coupled to the cross-coupled data latch, a gate node of the second NMOS switch device is coupled to the write column select line, and a source node of the second NMOS switch device is coupled to the cross-coupled data latch."
9184907,"One embodiment provides a data-receiving device component comprising a phase shifter, timer logic, and control logic. The phase shifter is configured to release a train of clock pulses with a controlled phase shift. The timer logic is configured to receive data from a data-sending device, and for each transition of the data received, to determine whether a clock pulse from the train is early or late with respect to the transition, and to tally the late clock pulses relative to the early clock pulses. The control logic, operatively coupled to the phase shifter and to the timer logic, is configured to incrementally advance the phase shift when the late clock pulses outnumber the early clock pulses by a non-integer power of two."
9185381,"A backward-compatible stereo image processing system and a method of generating a backward-compatible stereo image. One embodiment of the backward-compatible stereo image processing system includes: (1) first and second viewpoints for an image, (2) an intermediate viewpoint for the image, and (3) first and second output channels configured to provide respective images composed of high spatial frequency content of the intermediate viewpoint and respective low spatial frequency content of the first and second viewpoints."
9189199,"Synthesizable code representing first-in-first out (FIFO) memories may be used to produce FIFO memories in a hardware element or system. To more efficiently use a memory element that stores the data in a FIFO, a code generator may generate a wrapper that enables the FIFO to use a memory element with different dimension (i.e., depth and width) than the FIFO's dimensions. For example, the wrapper enables a 128 deep, 1 bit wide FIFO to store data in a memory element with 16 rows that store 8 bits each. To any system communicating with the FIFO, the FIFO behaves like a 128×1 FIFO even though the FIFO is implemented using a 16×8 memory element. To do so, the code generator may generate a wrapper which enables the folded memory element to behave like a memory element that was not folded."
9189242,One embodiment of the present invention sets forth a technique for ensuring cache access instructions are scheduled for execution in a multi-threaded system to improve cache locality and system performance. A credit-based technique may be used to control instruction by instruction scheduling for each warp in a group so that the group of warps is processed uniformly. A credit is computed for each warp and the credit contributes to a weight for each warp. The weight is used to select instructions for the warps that are issued for execution.
9190396,"A system includes a semiconductor die mounted on a packaging substrate, a signal redistribution layer that is formed within the packaging substrate, a power plane that is formed on a surface of the packaging substrate, and a ground plane that is formed within the packaging substrate. The power plane couples the semiconductor die to a capacitor disposed on the packaging substrate and the ground plane is disposed between the power plane and the signal redistribution layer. An advantage of the disclosed system is that loop inductance between power and ground paths to a packaged semiconductor die is reduced, thereby lowering the impedance of the packaged semiconductor die system and signal noise associated with the packaged semiconductor system."
9195269,"A roll compensation system for an electronic device, a method of mitigating impact of an electronic device and an impact-resistant mobile device incorporating the system or the method. In one embodiment, the system includes: (1) a plurality of sensors operable to detect orientation and motion of the electronic device, (2) a controller configured to detect a fall based on the motion and determine a mitigating roll based on the orientation and the motion and (3) a compensator operable to carry out the mitigating roll thereby reducing the probability of a catastrophic impact."
9195428,"In some embodiments, a notebook including a main display, a main graphics subsystem, and an auxiliary display subsystem, but typically not an auxiliary display, wherein the notebook is configured to display on the main display one or both of data from the auxiliary display subsystem (or a scaled or otherwise processed version of such data), and data from the main graphics subsystem. Preferably, the notebook is configured to display a scaled version of data from the auxiliary display subsystem on part of the main display's screen. Other embodiments are timing controllers and other circuitry for use in such a notebook and methods for displaying data from such a notebook's auxiliary display subsystem on all or part of the main display's screen. The notebook can include a timing control subsystem for asserting to the main display one or both of display data from the auxiliary display subsystem (or a processed version thereof) and display data from the main graphics subsystem. The timing control subsystem can include a scaler for receiving raw auxiliary display data and a multiplexer having inputs for receiving the output of the scaler and display data from the main graphics subsystem."
9195434,"A true random number generator, a method of generating a true random number and a system incorporating the generator or the method. In one embodiment, the generator includes: (1) a ring oscillator including inverting gates having power inputs and (2) a time-varying power supply coupled to the power inputs to provide power thereto and including power perturbation circuitry operable to perturb the power provided to at least one of the power inputs."
9195460,"Systems and methods for compiling programs using condition codes and executing those programs when non-numeric values are present allow for explicit handling of non-numeric values. In addition to the conventional condition code values of positive, negative, and zero, a fourth value may be encoded, not a number (NaN) representing a non-numeric value. New condition tests are defined that explicitly account for condition code values of NaN. A compiler may produce code using the new condition tests to represent if and if-else statements. The code including the new condition tests generates deterministic results during execution when non-numeric values are present."
9195618,A system for selecting memory requests. The system includes arbiters and a time ordered list scheduler. Each arbiter selects a memory request for transmission from at least one client. The scheduler is operable to receive and store memory requests from the arbiters and selects a selected memory request for forwarding to a memory system. The scheduler includes a list structure operable to store memory requests received from the arbiters in a fashion to preserve relative time of arrival of the memory requests. The scheduler includes scanners that are prioritized with respect to one another. Scanners are operable to simultaneously scan contents of the list structure from the oldest to newest requests and determine whether a memory request match is found based on associated programmable rules to locate a memory request candidate. A memory request candidate of a highest priority scanner is selected by the scheduler as the selected memory request.
9197365,"Method, receiver and computer program product for decoding a coded data block received at the receiver are disclosed. A first plurality of coded data bits representing the coded data block are received. First soft information values are determined corresponding to respective ones of the received first plurality of coded data bits, wherein each of the soft information values indicates a likelihood of a corresponding coded data bit having a particular value. An attempt is made to decode the coded data block using the first soft information values. The first soft information values are compressed. The compressed first soft information values are stored in a data store. A second plurality of coded data bits representing the coded data block is received and second soft information values corresponding to respective ones of the received second plurality of coded data bits are determined. The compressed first soft information values are retrieved from the data store and decompressed. The decompressed first soft information values are combined with the second soft information values, and an attempt is made to decode the coded data block using the combined soft information values."
9198123,"A modem is disclosed, one embodiment including: first and second interface apparatuses; and a processing apparatus arranged to transmit a request message to part of a wireless cellular network to request establishment of a channel to access a packet-based network, wherein the request message requests the channel as being of a type that supports both a first and second version of a packet protocol; receive a response message indicating rejection of the request, and upon detecting that a field in the response message defines a reason other than the part of the wireless cellular network does not support first and second versions of the packet protocol on a single channel, to default to transmit a default request message to request establishment of a channel to access the packet-based network, the default request message requests the channel as being of a type that supports the first version of the packet protocol."
9201283,"A display panel is provided that includes a plurality of pixel units, each having a first surface and a second surface opposite to the first surface, and comprising an electrophoretic gel part with a shape tapered in a direction from the first surface to the second surface, wherein a top surface of the electrophoretic gel part forms the first surface and electrophoretic particles are provided in the electrophoretic gel part; a light guiding part with a shape tapered in a direction from the second surface to the first surface, wherein the light guiding part and the electrophoretic glue part match in shape and abut with each other, and a bottom surface of the light guiding part forms at least a portion of the second surface; and a light-emitting device provided on the bottom surface of the light guiding part and operable to emit light toward the first surface."
9201434,"A system and method are provided for regulating a voltage at a load. A target current is obtained and a number of regulator phases needed to provide the target current to a load is computed based on an efficiency characteristic of the regulator phases. The regulator phases are configured to provide the target current to the load. A multi-phase electric power conversion device comprises at least two regulator phases and a multi-phase control unit. The multi-phase control unit is configured to obtain the target current, compute the number of the regulator phases needed to provide the target current to the load based on the efficiency characteristic of the regulator phases, and configure the regulator phases to provide the target current to the load."
9201670,"A system, method, and computer program product are provided for determining whether parameter configurations meet predetermined criteria. In use, predetermined criteria associated with a software element are identified. Additionally, it is determined whether each of a plurality of different parameter configurations meets the criteria, utilizing a directed acyclic graph (DAG)."
9202139,"A system, method, and computer program product are provided for generating a subset of a low discrepancy sequence. In use, a low discrepancy sequence is identified. Additionally, a threshold value is determined. Further, a single dimension of the low discrepancy sequence is selected. Further still, for each element included within the low discrepancy sequence, the selected single dimension is compared to the determined threshold value. Also, a subset of the low discrepancy sequence is generated, based on the comparing."
9202303,"One embodiment of the present invention sets forth a technique for compositing a rendered path object into an image buffer. A shader program executing within a graphics processing unit (GPU) performs a stenciling operation for the path object and subsequently performs a texture barrier operation, which invalidates caches configured to store texture and frame buffer data within the GPU. The shader program then performs covering operation for the path object in which the shader renders color samples for the path object and composites the color samples into an image buffer. The shader program binds to the image buffer for access as both a texture map and a writeable image. Stencil values are reset when corresponding pixels are written once per path object, and texture caches are invalidated via the texture barrier operation, which is performed after each covering operation per path object."
9204158,"A hardware multi-standard video decoder device. A command parser accesses a video stream and identifies a video encoding standard used for encoding the video stream. A plurality of hardware decoding blocks perform operations associated with decoding the video stream, wherein different subsets of the plurality of hardware decoding blocks are for decoding video streams encoded using different video encoding standards."
9204422,"One aspect provides a modem for use at a terminal. The modem comprises a first interface and a processing unit. The first interface is arranged to connect to a communications network. The processing unit is arranged to receive a message from the communications network via the first interface while in an operating mode. The processing unit is also arranged to assess the message on receipt to determine that one or more public warning message is to be broadcast to the modem from the communication network in a second later time period. The processing unit is also arranged to, based on the determination, modify operation of the modem in the second later time period to ensure the one or more public warning message is received and acted on by the modem."
9207277,"A wafer acceptance test (WAT) system and method that, in one embodiment, includes: (1) a saturation current WAT subsystem operable to generate a weighted standard deviation based on target NMOS and PMOS saturation currents and saturation current WAT results, (2) a wafer IC speed WAT subsystem operable to generate a speed performance probability distribution of wafer ICs based on the weighted standard deviation and speed WAT results, (3) a wafer IC power WAT subsystem operable to employ the speed WAT results and power WAT results to generate a power performance model of wafer ICs, and (4) a yield calculator operable to generate a power performance variance probability distribution of wafer ICs based on the power performance model and the power WAT results, and to employ the speed performance probability distribution and the power performance variance probability distribution to generate the yield forecast with respect to a target performance profile."
9207919,"A system, method, and computer program product are provided for. The method includes the steps of executing a block of translated binary instructions by multiple threads and gathering profiling data during execution of the block of translated binary instructions. The multiple threads are then synchronized at a barrier instruction associated with the block of translated binary instructions and the block of translated binary instructions is replaced with optimized binary instructions, where the optimized binary instructions are produced based on the profiling data."
9208108,"A system for selecting a subset of issued flash storage commands to improve processing time for command execution. A plurality of ports stores a first plurality of command identifiers and are associated with the plurality of ports. Each of the first plurality of arbiters selects an oldest command identifier among command identifiers within each corresponding port resulting in a second plurality of command identifiers. A second arbiter makes a plurality of selections from the second plurality of command identifiers based on command identifier age and the priority of the port. A session identifier queue stores commands associated with the plurality of selections among other commands forming a third plurality of commands. A microcontroller selects an executable command from the third plurality of commands for execution based on an execution optimization heuristic. After execution of the command, the command identifier in the port is cleared."
9208605,"Multisampling techniques provide temporal as well as spatial antialiasing. Coverage for a primitive is determined at multiple sample locations for a pixel. In one embodiment, coverage is determined using boundary equations representing a boundary surface of the primitive in a three-dimensional space-time. A shading value for the primitive is computed for the pixel and stored for each coverage sample location of the pixel that is covered by the primitive. The sample locations are distributed in both space and time, and multiple sample locations share a single shading computation. The multisampling techniques are extendable to other dimensions that correspond to other image attributes."
9208606,"A system, method, and computer program product are provided for extruding an object through a two-dimensional scene. In use, a two-dimensional object is identified within a two-dimensional scene. Additionally, a three-dimensional model is determined that corresponds to the two-dimensional object. Further, the three-dimensional model is extruded through the two-dimensional scene to create a three-dimensional object."
9208755,"A method includes determining, through test instructions executing on a processor of a data processing device, utilization of a graphics engine of the processor by an application executing thereon based on initiation thereof through a driver associated with the processor and/or an operating system executing on the data processing device, and detecting, through the test instructions, an idle state of one or more non-graphics engine(s) of the processor. The method also includes transitioning, through the processor, a frame buffer associated therewith into a self-refresh mode of low power utilization thereof, and copying data related to the execution of the application to a memory of the data processing device. Further, the method includes clock-gating the one or more non-graphics engine(s) to reduce a power consumption of the data processing device, and enabling the graphics engine to utilize the copied data in the memory for continued execution of the application."
9208900,"A method and a system are provided for performing address-based memory access assist. An address is received for a memory access and a determination is made, based on the address, that access assist is enabled for at least one storage cell corresponding to the address. The access assist is applied to the at least one storage cell to perform the memory access."
9209792,"The present invention systems and methods enable configuration of functional components in integrated circuits. In one embodiment clock signal selection system includes an arbitration component, a control component, and a selection component The arbitration component coordinates arbitration eligibility between a plurality of clock signals. The control component controls the coordination utilizing a clock signal from the plurality of clock signals. The selection component selects between the plurality of signals."
9210437,"A hardware multi-stream multi-standard video decoder device. A command parser accesses a plurality of video streams, identifies a video encoding standard used for encoding video streams of the plurality of video streams, and interleaves portions of the plurality of video streams. A plurality of hardware decoding blocks perform operations associated with decoding the plurality of video streams, wherein different subsets of the plurality of hardware decoding blocks are for decoding video streams encoded using different video encoding standards, such that interleaved video streams are decoded by activating subsets of the plurality of hardware decoding blocks for use in decoding the plurality of video streams. A plurality of register sets store parameters associated with the plurality of video streams."
9213379,A device for processing graphics data may include a plurality of graphics processing units. The device may include a fan to dissipate thermal energy generated during the operation of the plurality of graphics processing units. Each of the plurality of graphics processing units may generate a pulse width modulated signal to control the speed of the fan. The device may include one or more monitoring units configured to monitor a signal controlling the speed of the fan. One or more of the plurality of pulse width modulated signals may be adjusted based on the monitored signal. One or more of the plurality of pulse width modulated signals may be adjusted such that a signal controlling the fan maintains a desired duty cycle.
9213613,"A system and method are provided for test program generation using key enumeration and string replacement. A system includes a test program generator and a tester. The tester receives a test program from the test program generator and tests one or more products according to the test program. The test program generator receives a seed file from a seed file database and a configuration file from a configuration file database. The test program generator iterates over enumeration keys in the configuration file and, for each key, apply to the seed file one or more rules in the configuration file keyed to the enumeration key. Applying a rule includes replacing in the seed file one or more occurrences of a predicate value of the rule with a transformation value of the rule. The test program generator also outputs to the tester the modified first seed file as the test program."
9213794,"A system and method for routing a buffered interconnect in an IC from a source cell to a target cell thereof. In one embodiment, the system includes: (1) a path tracer operable to designate the source cell as a current node and construct a path toward the target node by: (1a) defining a boundary about the current node based on a buffer driving length, (1b) trimming the boundary by any blockage therein to yield a candidate area for placing a buffer, (1c) dividing the boundary into line segments, (1d) selecting a closest, valid one of the line segments to the target cell as the current node and (1e) repeating the defining, trimming, dividing and selecting the closest, valid one until the current node lies within the buffer driving length and (2) a buffer placer associated with the path tracer and operable to select a location along the path to place the buffer."
9214008,"A system, method, and computer program product are provided for determining a size of an attribute storage buffer. Input attributes read by a shader program to generate output attributes are identified. A portion of the output attributes to be consumed by a destination shader program is identified. The size of the attribute storage buffer that is allocated for execution of the shader program is computed based on the input attributes and the portion of the output attributes."
9215528,"A flat panel electronic device and an audio playing apparatus thereof are provided. The audio playing apparatus comprises an audio generator, a plurality of speakers, a sensor and a controller. The audio generator is operable to generate a left channel audio and a right channel audio. The plurality of speakers are configured such that at least one pair of speakers is symmetrically disposed at a left side and a right side of the flat panel electronic device no matter how the flat panel electronic device is placed. The sensor is operable to detect a placed state of the flat panel electronic device in the installed state. The controller is operable to receive a detecting signal from the sensor so as to control the at least one pair of speakers to play the left channel audio and the right channel audio correspondingly according to the placed state of the flat panel electronic device."
9218691,"One embodiment of the present invention sets forth a technique for specifying scene programs, where the effect of executing a particular scene program is to generate a sequence of graphics commands. The application programming interface is extended to include calls used to specify a high-level scene program. Upon receiving a high-level scene program, the graphics driver generates a machine code scene program. When an application program emits a call to execute one or more machine code scene programs, the graphics driver transmits corresponding scene programs execution commands to the graphics pre-processing unit. For each scene program execution command, the graphics pre-processing unit processes instructions, programmatically reconfigures the graphics pipeline based on the execution of the machine code scene program, and launches one or more parallel threads that execute commands within the graphics pipeline. Advantageously, using scene programs, application developers may tailor application programs to more effectively dispatch tasks to the GPU."
9218792,"A mechanism for enabling a user to vary the scale or zoom of image data for aspect ratio conversion using a graphical user interface is disclosed. A user may move a selector of the graphical user interface to one end for selecting a linear scaling, to the other end for selecting a parabolic scaling or in between for selecting a scaling associated with another function, thereby enabling a user to vary the magnitude of the scaling across the image data. A parametric function with a single parameter may be used to scale the image data, where the movement of the selector may change the parameter and consequently vary the scaling of the image data. In this manner, a user may efficiently vary or select the scaling of the image data using a graphical user interface to reduce objectionable distortion associated with changing the aspect ratio of the image data."
9219480,"A flip-flop and a method of receiving a digital signal from an asynchronous domain. In one embodiment, the flip-flop includes: (1) a first loop coupled to a flip-flop input and having first and second stable states and (2) a second loop coupled to the first loop and having the first and second stable states, properties of cross-coupled inverters in the first and second loops creating a metastable state skewed toward the first stable state in the first loop and skewed toward the second stable state in the second loop. Certain embodiments of the flip-flop have lower time constant and thus a higher Mean Time Between Failure (MTBF)."
9222981,"A method for testing an integrated circuit to reduce peak power problems during scan capture mode is presented. The method comprises programming a respective duration of a first time window for each of a plurality of cores and a cache on the integrated circuit. It further comprises counting the number of pulses of a first clock signal during the first time window for each of the plurality of cores and the cache. Subsequently, the method comprises staggering capture pulses to the plurality of cores and the cache by generating pulses of a second clock signal for each of the plurality of cores and the cache during a respective second time window, wherein the number of pulses generated is based on the respective number of first clock signal pulses counted for each of the plurality of cores and the cache."
9223409,"A portable function-expanding device for an electronic device is provided which comprises: a housing with a plurality of accommodating slots provided on an upper surface thereof for accommodating electronic devices respectively, wherein a function-expanding interface is provided in each of the accommodating slots for being connected with a function interface of the electronic device accommodated therein; and a function means located in the housing and connected with the function-expanding interface to fulfill the function-expanding of the corresponding electronic device. The portable function-expanding device for an electronic device fulfills the function-expanding of the corresponding electronic device conveniently. That is, the function-expanding is fulfilled conveniently as required by just inserting the electronic device into the corresponding accommodating slot and connecting the corresponding function-expanding interface in the accommodating with the function interface of the electronic device."
9223578,"One embodiment of the present invention sets forth a technique for coalescing memory barrier operations across multiple parallel threads. Memory barrier requests from a given parallel thread processing unit are coalesced to reduce the impact to the rest of the system. Additionally, memory barrier requests may specify a level of a set of threads with respect to which the memory transactions are committed. For example, a first type of memory barrier instruction may commit the memory transactions to a level of a set of cooperating threads that share an L1 (level one) cache. A second type of memory barrier instruction may commit the memory transactions to a level of a set of threads sharing a global memory. Finally, a third type of memory barrier instruction may commit the memory transactions to a system level of all threads sharing all system memories. The latency required to execute the memory barrier instruction varies based on the type of memory barrier instruction."
9223708,"A system, method, and computer program product are provided for utilizing a data pointer table pre-fetcher. In use, an assembly of a data pointer table within a main memory is identified. Additionally, the data pointer table is pre-fetched from the main memory. Further, data is sampled from the pre-fetched data pointer table. Further still, the sampled data is stored within a data pointer table cache."
9224227,"A tile shader for screen space of a graphics pipeline, a method of rendering graphics and a graphics processing unit are disclosed. In one embodiment, the tile shader includes: (1) an input interface configured to receive a tile of pixels for processing and (2) a tile processor configured to perform tile-level processing of the pixels."
9224235,"A system, method, and computer program product for compressing a bounding volume hierarchy is disclosed. The method includes the steps of receiving a bounding volume hierarchy and encoding the bounding volume hierarchy to generate an encoded bounding volume hierarchy, wherein each node in the encoded bounding volume hierarchy indicates whether the node inherits zero or more values from a parent node. The bounding volume hierarchy includes a plurality of nodes, each node in the plurality of nodes is associated with a bounding volume."
9224449,A system and method are provided for refreshing a dynamic memory. A first region of a memory is refreshed at a first refresh rate and a second region of the memory is refreshed at a second refresh rate that is different than the first refresh rate. A memory controller is configured to refresh the first region of a memory at the first refresh rate and refresh the second region of the memory at the second refresh rate.
9226404,"The present invention provides a printed circuit board (PCB) board, a core for manufacturing the PCB board and a method for manufacturing the PCB board. The PCB board is in a shape of a rectangle and comprises a fiber layer formed of interlacedly weaved fiberglasses, a metal layer affixed onto a surface of the fiber layer, and a pair of differential signal traces formed on the metal layer, wherein extending directions of the fiberglasses lie at acute angles with respect to a length direction of the rectangle, and the pair of differential signal traces extends along a width direction or the length direction of the rectangle. The PCB board can effectively reduce the possibility of the skew distortion during the transmitting process of the differential signal through adjusting the angle between the fiberglasses and the edge of the core without adjusting or redesigning the original circuit layout."
9229053,"Methods and apparatus for debugging finite state machine are disclosed. The method includes implementing a debug logic circuit and connecting the debug logic circuit to a system on chip (SoC) voltage source. The method includes operating a finite state machine that sequences the SoC from a low power state to a next low power state and generating respective output signals corresponding to the low power states and wherein the finite state machine is connected to Always On voltage source. The method includes masking the output signals to generate respective masked output signals, and applying the masked output signals to SoC circuit elements to prevent from transitioning into low power states and hence keeping the debug logic circuitry alive. The method includes debugging the finite state machine in the lowest power state by the debug logic circuit."
9229242,"3D display device, 3D display system and method for displaying 3D images are disclosed in the present invention. The 3D display device comprises: a display screen; a backlight means including a pulse light source; and a drive means used to receive video signals which are based on a standard video transmission protocol, so as to control the display screen to display 3D images according to the video signals, and control the pulse light source to emit a backlight pulse in the form of pulse during a vertical blank of each frame period of the video signals, wherein the duration of the backlight pulse is shorter than that of the vertical blank. The degrading of light is avoided in the 3D display device and the efficiency of the backlight can achieve almost 100%."
9229698,"A method for processing a function with a plurality of execution spaces is disclosed. The method comprises creating an internal compiler representation for the function. Creating the internal compiler representation comprises copying substantially all lexical tokens corresponding to a body of the function. Further, the creating comprises inserting the lexical tokens into a plurality of conditional if-statements, wherein a conditional if-statement is generated for each corresponding execution space of said plurality of execution spaces, and wherein each conditional if-statement determines which execution space the function is executing in. During compilation, the method finally comprises performing overload resolution at a call site of an overloaded function by checking for compatibility with a first execution space specified by one of the plurality of conditional if-statements, wherein the overloaded function is called within the body of the function."
9229717,A method for allocating registers within a processing unit. A compiler assigns a plurality of instructions to a plurality of processing clusters. Each instruction is configured to access a first virtual register within a live range. The compiler determines which processing cluster in the plurality of processing clusters is an owner cluster for the first virtual register within the live range. The compiler configures a first instruction included in the plurality of instructions to access a first global virtual register.
9229907,"A system, method, and computer program product are provided for evaluating an integral utilizing a low discrepancy sequence. In use, a low discrepancy sequence that includes at least one component that is a (0,1)-sequence in base b is determined. Additionally, an integral is evaluated, utilizing the low discrepancy sequence."
9230305,"Methods are provided to perform area summation of various subsections of data values in a regular input array of one or several dimensions and varying sizes. The summation is achieved by adding up values from a ripmap of partial sums, where the partial sums are computed from the input array using a binary reduction method. According to such embodiments, the generation of the ripmap of partial sums will employ several binary reduction stages. Within each stage, a reduction operator is used that adds two elements along the respective direction. This is repeated until the output is only one element wide in the respective direction. The addresses of partial sums in the ripmap may subsequently be computed using a binary analysis of the target subsections in order to choose those partial sum values for a desired area that results in the desired area sum using an optimal number of data fetches."
9230362,"A system, method, and computer program product enable compression with programmable sample locations, where the compression is a function of the programmable sample locations. The method includes the steps of storing a first value specifying a programmed sample location within a pixel in a sample pattern table and storing, in a memory, geometric surface parameters corresponding to a first attribute at the programmed sample location within a first pixel of a display surface. An instruction to store a second value specifying the programmed sample location within the pixel in the sample pattern table is received. The attribute is reconstructed based on the geometric surface parameters and the first value."
9230363,"A system, method, and computer program product enable compression with programmable sample locations, where the compression is a function of the programmable sample locations. The method includes the steps of storing a first value specifying a programmed sample location within a pixel in a first sample pattern table that is associated with a first display surface and storing, in a memory, geometric surface parameters corresponding to a first attribute at the programmed sample location within a first pixel of the first display surface. A second value specifying the programmed sample location within the pixel in a second sample pattern table that is associated with a second display surface is also stored and the first attribute is reconstructed based on the geometric surface parameters and the first value."
9230678,"An enhanced fuseless fuse structure is provided herein. Additionally, an IC with an enhanced fuseless fuse structure, a data structure that can be used with this structure and a method of manufacturing an IC are disclosed herein. In one embodiment, the IC includes: (1) a fuse wrapper configured to decode fuseless fuse data for controlling the fuses, (2) JTAG registers configured to store fuse register values in designated blocks, wherein the fuse register values and the designated blocks are determined from the fuseless fuse data and (3) options registers configurable by software to store fuse override data for modifying the fuse register values."
9231304,"Provided is an antenna. In one aspect, the antenna includes a feed element having a first feed element end and a second feed element end, the first feed element end configured to electrically connect to a positive terminal of a transmission line. The antenna, in this aspect, further includes a loop antenna element having a first loop antenna element end and a second loop antenna element end, wherein the first loop antenna element end is coupled to the second feed element end and the second loop antenna element end is configured to electrically connect to a negative terminal of the transmission line. The antenna, of this aspect, further includes a monopole antenna element having a first monopole antenna element end and a second monopole antenna element end, wherein the first monopole antenna element end is coupled to the second feed element end."
9231477,"A system and method are provided for controlling a soft-switched modified buck regulator circuit. A voltage (Vx) across or a current through a pull-down switching mechanism within the modified buck regulator circuit is sensed when the pull-down switching mechanism is enabled, where the pull-down switching mechanism is coupled to an upstream end of an inductor and is coupled in parallel with a capacitor. A target time when the pull-down switching mechanism will be disabled (tlf) is computed and the pull-down transistor is disabled at the computed target time."
9231802,"An apparatus including a receiver coupled to receive an input signal from a communication link and operable to employ decision feedback equalization to the input signal of the communication link and generate an edge sample signal. The apparatus also includes a timing recovery module coupled to the receiver and operable to receive the edge sample signal and use the edge sample signal to generate a data sampling phase signal, wherein the edge sample signal influences a settling point of the data sampling phase signal."
9232129,"Embodiments of the present invention utilize an attachable lens board that can be secured to the back of a mobile device and placed in a position that is proximate to the built-in camera lens associated with the camera system of the mobile device. As such, the lens board can be positioned to accurately align several different auxiliary camera lenses, each installed within various camera lens receivers formed within the lens board, with the built-in camera lens for focusing and/or image capture. Additionally, embodiments of present invention can include circuitry within the lens board that can be used to identify the types of lenses currently installed within each camera lens receiver. In this manner, embodiments of the present invention can correct possible optical imperfections of resultant images produced by the combination of the built-in camera lens and auxiliary lens selected for focusing and/or image capture by the user."
9232206,"A multimedia framework includes a monolithic multimedia component to include a specific interface provided by the multimedia framework, and a component control unit layer to serve as a point of control of an application, and to control a data flow through the monolithic multimedia component. When the application queries the component control unit layer for the specific interface, the specific interface passes a pointer thereof that signifies a role required by the application matching a role identified by the multimedia framework for the monolithic multimedia component to the application. A command from the application is transmitted to a tunnel of a multimedia stack interfaced with the monolithic multimedia component to ensure that the same monolithic multimedia component serves as a source component, one or more transform component(s) and/or a renderer. The application is unaware of the multi-tasking associated with the monolithic multimedia component."
9232210,"A method includes receiving, through a processor of a data processing device communicatively coupled to a memory, data related to a dimensional parameter of a display unit and/or a distance between a user and the display unit, and determining, through the processor, a comfortable range of perception of a sub-portion of three -dimensional (3D) video data on the display unit based on the dimensional parameter of the display unit and/or the distance between the user and the display unit. The method also includes adjusting, through the processor, a disparity between one or more sub -portion(s) of the 3D video data corresponding to perception of the sub-portion by a left eye of the user and one or more sub-portion(s) of the 3D video data corresponding to perception of the sub-portion by a right eye of the user such that the sub-portion is mapped within the determined comfortable range of perception."
9232238,"A system for, and method of, pixel data compression and a smartphone incorporating the system or the method. In one embodiment, the system includes: (1) a differential pulse code modulation encoder operable differentially to compress the two pixel values losslessly to yield two losslessly compressed pixel values and (2) an entropy encoder coupled to the differential pulse code modulation encoder and configured to receive and entropy-encode the losslessly compressed pixel values using a tiered technique to yield entropy-encoded, losslessly compressed pixel values. values using a tiered technique to yield Huffman-encoded, losslessly compressed pixel values."
9235392,"A system, method, and computer program product are provided for compiling a computer program comprising arithmetic operations having different requirements with respect to numeric dynamic range, numeric resolution, or any combination thereof. The method comprises generating a transformed graph representation of the computer program by applying propagation rules that provide for relaxed numeric requirements, where applicable, and generating output code based on the transformed graph representation. Relaxing numeric requirements, such as dynamic range and resolution requirements, may advantageously lower power consumption during execution of the computer program."
9235512,"A system, method, and computer program product are provided for GPU demand paging. In operation, input data is addressed in terms of a virtual address space. Additionally, the input data is organized into one or more pages of data. Further, the input data organized as the one or more pages of data is at least temporarily stored in a physical cache. In addition, access to the input data in the physical cache is facilitated."
9239697,"A system, method, and computer program product are provided for a display multiplier. First image data is received for a first display device and second image data is received for a second display device, where the second display device has fewer scan lines than the first display device. A scan line of the second image data is duplicated and a display multiplier output stream is generated that includes a first scan line of the first image data, the scan line of the second image data, a second scan line of the first image data, and the duplicated scan line of the second image data."
9239699,"A method includes providing a memory unit in a computing device already including a number of processors communicatively coupled to a memory through a system bus, and providing a non-system bus based dedicated channel between the number of processors and the memory unit. The method also includes rendering a different video frame and/or a surface on each processor of the number of processors, and leveraging the memory unit to store a video frame and/or a surface rendered on a processor therein through the non-system bus based dedicated channel. Further, the method includes copying, to other processors, the stored video frame and/or the surface rendered on the processor from the memory unit through the non-system bus based dedicated channel, and scanning out, through the number of processors, the video frame and/or the surface rendered on the processor following the copying to enable display thereof on a corresponding number of displays."
9239795,"A surface cache stores pixel data on behalf of a pixel processing pipeline that is configured to generate screen tiles. The surface cache assigns hint levels to cache lines storing pixel data according to whether that pixel data is likely to be needed again. When the pixel data is needed to process a subsequent tile, the corresponding cache line is assigned a higher hint value. When the pixel data is not needed again, the corresponding cache line is assigned a lower hint value. The surface cache is configured to preferentially evict cache lines having a lower hint value, thereby preserving cache lines that store pixel data needed for future processing. In addition, a fetch controller is configured to throttle the rate at which fetch requests are issued to the surface cache to prevent situations where pixel data needed for future operations becomes prematurely evicted."
9239925,"A device comprises a processor arranged to automatically execute boot code upon start-up or reset. The boot code comprises a code authentication procedure to verify whether additional code is authenticated for execution on the processor. A separate security unit comprises a private unlock key and cryptography logic configured to use the private unlock key to sign a portion of data, thereby generating a signed unlock file for supply to a storage location. The processor is arranged to access the unlock file from the storage location, making it available without requiring connection to the security unit. The boot code further comprises an unlocking authentication procedure configured to check for the unlock file in the storage location, and if available to verify whether the unlock file is authenticated for use on the processor based on its signature, so as to de-restrict the boot authentication procedure on condition of verifying the unlock file."
9240232,"A subsystem configured to write data to a static random access memory cell employs a single N-channel MOS device connected to ground in each leg of the bi-stable memory cell to overdrive the stored data. The subsystem implements the dual control required to effect matrix operation of the SRAM cell in the gate circuit of the single N-channel MOS device in the drive path. Specifically, the column select signal controls a semiconductor junction that interrupts the data connection to the gate. In this manner, the column select control is removed from the drive path, thus increasing drive strength. Further, a second semiconductor junction connects the gate of the single NMOS device in the drive path when the gate signal is interrupted."
9240691,"A system, method, and computer program product are provided for remedying a charging error. In use, a battery and a battery charger are identified. Additionally, an error associated with the charging of the battery by the battery charger is detected. Further, the error is remedied."
9241146,"Techniques are disclosed for generating stereoscopic images. The techniques include receiving a first image frame associated with a first eye, and receiving a first depth frame associated with the first eye. The techniques further include reprojecting the first image frame based on the first depth frame to create a second image frame associated with a second eye. The techniques further include identifying a first pixel in the second image frame that remains unwritten as a result of reprojecting the first image frame, and determining a value for the first pixel based on a corresponding pixel in a prior image frame associated with the second eye. One advantage of the disclosed techniques is that DIBR reprojected image frames have a more realistic appearance where gaps are filled using pixels from a prior image for the same eye."
9244683,"A system, method, and computer program product for generating executable code for performing large integer operations on a parallel processing unit is disclosed. The method includes the steps of compiling a source code linked to a large integer library to generate an executable file and executing the executable file to perform a large integer operation using a parallel processing unit. The large integer library includes functions for processing large integers that are optimized for the parallel processing unit."
9244810,"A debugger graphical user interface (GUI) system, method, and computer program product are provided. In use, a list of constructs is displayed a first portion of the GUI of the debugger. Further, waveforms corresponding to the constructs or source code corresponding to the constructs is displayed in a second portion of the GUI of the debugger."
9245129,"A system and method are provided for protecting data. In operation, a request to read data from memory is received. Additionally, it is determined whether the data is stored in a predetermined portion of the memory. If it is determined that the data is stored in the predetermined portion of the memory, the data and a protect signal are returned for use in protecting the data. In certain embodiments of the invention, data stored in the predetermined portion of the memory may be further processed and written hack to the predetermined portion of the memory. In other embodiments of the invention, such processing may involve unprotected data stored outside the predetermined portion of the memory."
9245363,"A system, method, and computer program product for implementing an algorithm for performing thin voxelization is disclosed. The thin voxelization algorithm receives a surface, maps the surface onto a plurality of volumetric picture elements (voxels), and generates a value for each voxel in the plurality of voxels that intersects with the surface. A voxel intersects with the surface when the surface intersects a crosshair shape associated with the voxel."
9245371,"One embodiment of the present invention sets forth a method for storing processed data within buffer objects stored in buffer object memory from within shader engines executing on a GPU. The method comprises the steps of receiving a stream of one or more shading program commands via a graphics driver, executing, within a shader engine, at least one of the one or more shading program commands to generate processed data, determining from the stream of one or more shading program commands an address associated with a first data object stored within the buffer memory, and storing, from within the shader engine, the processed data in the first data object stored within the buffer memory."
9245595,"A method and a system are provided for performing memory access assist using voltage boost. A memory access request is received at a storage cell array that comprises two or more subarrays, each subarray including at least one row of storage cells. The voltage boost is applied, during the memory access, to a first negative supply voltage of a first storage cell subarray of the two or more storage cell subarrays. The first negative supply voltage of the first storage cell subarray is lower than a second negative supply voltage of a second storage cell subarray of the two or more storage cell subarrays."
9245601,"A system and device are provided for implementing memory arrays using high-density latch cells. The device includes an array of cells arranged into columns and rows. Each cell comprises a latch cell that includes a transmission gate, a pair of inverters, and an output buffer. Each row of latch cells is connected to at least one common node for addressing the row of latch cells, and each column of latch cells is connected to a particular bit of an input signal and a particular bit of an output signal. A register file may be implemented using one or more arrays of the high-density latch cells to replace any or all of the banks of SRAM cells typically used to implement the register file."
9246481,"A system and method are provided for generating an adaptive clock signal, configured to track prevailing operating conditions within an integrated circuit. The method comprises transmitting a first signal edge to a row of cells within a memory instance, waiting for two or more selected cells within the row of cells to propagate corresponding responses based on the first signal edge, and generating a memory delay signature signal edge based on the corresponding responses. The adaptive clock signal is generated based on the delay signature signal edge."
9247179,"A method includes initiating, through an interface of a data processing device, reverse playback of a video file stored in a memory of the data processing device. The method also includes causing, through a set of instructions associated with a processor of the data processing device communicatively coupled to the memory and/or an operating system executing on the data processing device, the processor to read frames corresponding to the video file in a reverse chronological order within a desired timeframe following the initiation of the reverse playback. Further, the method includes decoding, through the processor, each frame corresponding to the reverse chronological order for rendering thereof on the data processing device."
9250449,"A three-dimensional stereo display, and a system and method are provided for controlling the three-dimensional stereo display. The three-dimensional stereo display includes backlight, a first polarizer, a first liquid crystal panel, a second polarizer and a second liquid crystal panel which are sequentially arranged on the backlight source. The second liquid crystal panel switches the polarizing angle of the light travelling through and exiting from said second liquid crystal panel between a horizontal and vertical polarization. Due to the polarization direction of light could be changed by the liquid crystal panel, and makes the light for the left-eye image and the right-eye image are mutual perpendicular. The polarization direction of the light for the left-eye image is the same as that of the left lens, and the polarization direction of the light for the right-eye image is the same as that of the right lens. So the light belongs to the left-eye image or the right-eye image can pass through the left lens or the right lens respectively, then a stereo image will emerge in people's brain due to the effect of “fusion activity”. Further, there is no need to close the polarized spectacles, the displaying efficiency is improved compared with the “Active Stereo”."
9250683,"A system, method, and computer program product are provided for allowing a head to enter a reduced power mode. A first processor having a first head is provided. Additionally, a second processor having a second head is provided. Furthermore, a link is provided, coupled between the first head of the first processor and the second head of the second processor for communicating first data therebetween. In operation, at least the second head of the second processor is capable of entering a reduced power mode."
9250692,"A method includes providing, in a data processing device including a Central Processing Unit (CPU) and a Graphics Processing Unit (GPU), a capability to interface a microprocessor with the GPU, and communicatively interfacing a sensor with the microprocessor. The method also includes obtaining data related to an operating environment external to the data processing device through the sensor, and determining, through the microprocessor, personalization required of a computing environment of the data processing device with respect to a user thereof based on the data related to the operating environment external to the data processing device. Further, the method includes utilizing the GPU solely to effect the personalization required of the computing environment of the data processing device with respect to the user determined through the microprocessor to reduce power consumption through the data processing device."
9250931,"A system, method, and computer program product are provided for calculating settings for a device, utilizing one or more constraints. In use, a plurality of parameters associated with a device is identified. Additionally, one or more constraints are determined, utilizing the plurality of parameters. Further, one or more settings are calculated for the device, utilizing the one or more constraints and the plurality of parameters."
9251551,"One embodiment of the present invention sets for a method for accessing data objects stored in a memory that is accessible by a graphics processing unit (GPU). The method comprises the steps of creating a data object in the memory based on a command received from an application program, transmitting a first handle associated with the data object to the application program such that data associated with different graphics commands can be accessed by the GPU, wherein the first handle includes a memory address that provides access to only a particular portion of the data object, receiving a first graphics command as well as the first handle from the application program, wherein the first graphics command includes a draw command or a compute grid launch, and transmitting the first graphics command and the first handle to the GPU for processing."
9251557,"A system, method, and computer program product for recovering from a memory underflow condition associated with generating video signals are disclosed. The method includes the steps of determining that a first counter is greater than a second counter, incrementing an address corresponding to a memory fetch request by an offset, and issuing the memory fetch request to a memory. The first counter represents a number of pixels that have been read by a display pipeline for a current frame and the second counter represents a number of pixels requested from a memory for the current frame."
9251870,"A system is provided for transmitting signals. The system comprises a first processing unit, a cache memory, and a package. The first processing unit comprises a first ground-referenced single-ended signaling (GRS) interface circuit and the second processing unit comprises a second GRS interface circuit. The cache memory comprises a third and a fourth GRS interface circuit. The package comprises one or more electrical traces that couple the first GRS interface to the third GRS interface and couple the second GRS interface to the fourth GRS interface, where the first GRS interface circuit, the second GRS interface, the third GRS interface, and the fourth GRS interface circuit are each configured to transmit a pulse along one trace of the one or more electrical traces by discharging a capacitor between the one trace and a ground network."
9255967,"A system and method are provided for measuring an integrated circuit age. A first clock generator is provided for generating a first clock signal and a second clock generator is provided for generating a second clock signal. Further, a phase detector in communication with the first clock generator and the second clock generator is provided for receiving the first clock signal from the first clock generator and the second clock signal from the second clock generator, and outputting a phase difference signal that is capable of being used as a measure of an integrated circuit age. Still yet, a circuit in communication with the phase detector and the first clock generator is provided for receiving the first clock signal from the first clock generator and the phase difference signal from the phase detector and for synchronizing the phase difference signal from the phase detector with the first clock signal from the first clock generator."
9256265,"Embodiments of the present invention are directed to provide a method and system for applying automatic power conservation techniques in a computing system. Embodiments are described herein that automatically limits the frame rate of an application executing in a discrete graphics processing unit operating off battery or other such exhaustible power source. By automatically limiting the frame rate in certain detected circumstances, the rate of power consumption, and thus, the life of the current charge stored in a battery may be dramatically extended. Another embodiment is also provided which allows for the more effective application of automatic power conservation techniques during detected periods of inactivity by applying a low power state immediately after a last packet of a frame is rendered and displayed."
9256316,"A method includes detecting, through a processor communicatively coupled to a memory, coupling of an external display to a data processing device including an internal display, and cloning, through the processor, display data of the internal display on the external display following the detection of the coupling. The method also includes triggering, through a driver component, the processor to turn off a backlight of the internal display of the data processing device, power gate circuitry associated with rendering the display data on the internal display and/or power gate a processing pipeline associated with the rendering of the display data following the cloning. Further, the method includes maintaining, through the driver component, a touchscreen capability of the internal display even when the backlight is turned off, the circuitry associated with the rendering of the display data is power gated and/or the processing pipeline associated therewith is power gated."
9256514,"While an application is still running and using a resource that the application has already allocated, real-time capture is used to allow for a minimal overhead, quick turnaround solution for debugging and performance analysis. Application programming interface interception can be used to construct a database of resource usage that can then be mined for dependencies."
9256623,"A system, method, and computer program product for scheduling tasks associated with continuation thread blocks. The method includes the steps of generating a first task metadata data structure in a memory, generating a second task metadata data structure in the memory, executing a first task corresponding to the first task metadata data structure in a processor, generating state information representing a continuation task related to the first task and storing the state information in the second task metadata data structure, executing the continuation task in the processor after the one or more child tasks have finished execution, and indicating that the first task has logically finished execution once the continuation task has finished execution. The second task metadata data structure is related to the first task metadata data structure, and at least one instruction in the first task causes one or more child tasks to be executed by the processor."
9256914,"A graphics card is provided. The graphics card comprises: a Graphics Processing Units (GPU) for data computing; and a wireless controller for wirelessly receiving data from other graphic cards or sending data to the other graphics cards, and communicating with the GPU by bus. The graphic card able provided by the present invention can provide a low-cost solution with more powerful computing capabilities to meet the demands for computing complex problems in the fields of commerce, industry, and science."
9258633,"The present invention provides a rear cover of a flat panel electronic device and a flat panel electronic device having the rear cover. A outer surface of the rear cover is provided with a recess and a supporting leg, the supporting leg is pivotably connected in the recess through a pivot means so as to enable the supporting leg to pivot between a retracting position and an unfolding position, the supporting leg is configured to be contained in the recess when being in the retracting position, and to make an angle with the rear cover when being in the unfolding position, a speaker is disposed in the supporting leg, sound holes are disposed at a position on a side wall of the supporting leg which is corresponding to the speaker, a through-hole is formed at a position of the rear cover which is corresponding to the pivot means, and an electric wire of the speaker passes through the through-hole to extend into the rear cover. The angle of the screen of the flat panel electronic device relative to the user can be adjusted through the supporting leg of the rear cover to improve the user's comfort level in watching, and the surface to be placed (such as the table surface) has no influence on the sound effect."
9262174,"One embodiment sets forth a technique for dynamically mapping addresses to banks of a multi-bank memory based on a bank mode. Application programs may be configured to perform read and write a memory accessing different numbers of bits per bank, e.g., 32-bits per bank, 64-bits per bank, or 128-bits per bank. On each clock cycle an access request may be received from one of the application programs and per processing thread addresses of the access request are dynamically mapped based on the bank mode to produce a set of bank addresses. The bank addresses are then used to access the multi-bank memory. Allowing different bank mappings enables each application program to avoid bank conflicts when the memory is accesses compared with using a single bank mapping for all accesses."
9262328,"Cache hit information is used to manage (e.g., cap) the prefetch distance for a cache. In an embodiment in which there is a first cache and a second cache, where the second cache (e.g., a level two cache) has greater latency than the first cache (e.g., a level one cache), a prefetcher prefetches cache lines to the second cache and is configured to receive feedback from that cache. The feedback indicates whether an access request issued in response to a cache miss in the first cache results in a cache hit in the second cache. The prefetch distance for the second cache is determined according to the feedback."
9262348,"The MMU services data requests associated with isochronous (ISO) data (referred to herein as “ISO requests”) with a high priority to meet a fixed latency requirement. Such data includes display data for transmission to the display device or other display devices. Conversely data requests associated with non-isochronous (NISO) data are serviced with a relatively lower priority. Such data requests include requests received from the CPU, video requests and copy requests. The MMU utilizes a buffering mechanism to buffer ISO and NISO requests. The size of the buffer that stores ISO requests controls the amount of memory bandwidth that is allocated to the ISO requests and the amount of memory bandwidth available for NISO requests."
9262797,"A system, method, and computer program product are provided for multi-sample processing. The multi-sample pixel data is received and an encoding state associated with the multi-sample pixel data is determined. Data for one sample of a multi-sample pixel and the encoding state are provided to a processing unit. The one sample of the multi-sample pixel is processed by the processing unit to generate processed data for the one sample that represents processed multi-sample pixel data for all samples of the multi-sample pixel or two or more samples of the multi-sample pixel."
9262837,"Circuits, methods, and apparatus for modifying the data rate of a data bus. In a circuit having two processors coupled by a data bus, the processors each learn that the other is capable of operating at a modified data rate. The data rate is then changed to the modified rate. Each processor may learn of the other's capability by reading a vendor identification, for example from a vendor defined message stored on the other processor. Alternately, each processor may provide an instruction to the other to operate at the modified rate, for example by writing to the other processor's extended capability registers. In another circuit having two processors communicating over a bus, it is determined that both are capable of transmitting and receiving data at a modified data rate. An instruction is provided to one or both of the processors to transmit at the modified rate."
9263000,A graphics system includes an integrated graphics processor and a discrete graphics processing unit. An intra-system bus coupled data from the discrete graphics processing unit to the integrated graphics processor. In a high performance mode the discrete graphics processing unit is used to render frames. Compression techniques are used to aid in the data transfer over an intra-system bus interface.
9263106,"An exemplary system of the present disclosure comprises a memory controller, a command bus, a data bus, a memory device and a memory. The memory device is coupled to the memory controller by the command bus and the data bus. The memory stores instructions that when executed by the computer system perform a method of requesting data from the memory device. This method comprises receiving a plurality of commands for the memory device from the command bus, the memory device clocked by a clock. At least one command of the plurality of commands includes a first command and a second command within a single clock cycle of said clock. At least one of the first command and second command is a data access command. The first command is executed during a first clock cycle and the second command is executed during a second subsequent clock cycle."
9264265,"A method of generating white noise for use in graphic and image processing, in accordance with one embodiment of the present invention, includes receiving one or more hash inputs. The hash inputs may be one or more primitive coordinates, one or more texel addresses, a base image, a device identifier, or a user password. The one or more hash inputs are evaluated utilizing a cryptographic hash function. The output of the cryptographic hash function generates one or more white noise samples. The white noise samples may be utilized as texel data. The white noise samples may also be utilized for encrypting images."
9268528,A system and method are provided for dynamically reducing power consumption of floating-point logic. A disable control signal that is based on a characteristic of a floating-point format input operand is received and a portion of a logic circuit is disabled based on the disable control signal. The logic circuit processes the floating-point format input operand to generate an output.
9268601,"One embodiment of the present invention sets forth a technique for launching work on a processor. The method includes the steps of initializing a first state object within a memory region accessible to a program executing on the processor, populating the first state object with data associated with a first workload that is generated by the program, and triggering the processing of the first workload on the processor according to the data within the first state object."
9269179,"A system, method, and computer program product are provided for generating primitive-specific attributes. In operation, it is determined whether a portion of a graphics processor is operating in a predetermined mode. If it is determined that the portion of the graphics processor is operating in the predetermined mode, only one or more primitive-specific attributes are generated in association with a primitive."
9269182,"A method for identifying entry points of a hierarchical structure having a plurality of nodes includes the operations selecting a node of a hierarchical structure and testing it for identification as an entry point. The node is identified as an entry point, and the selection, testing, and identification operations are repeated for at least one additional node of the hierarchical structure to identify at least a second node as a respective second entry point for the hierarchical structure."
9269183,"A method for reducing the number of samples tested for rendering a screen space region of an image includes constructing a bilinear approximation per primitive for a screen space region which is to be rendered, wherein the screen space region includes a plurality of sample points. The bilinear approximation is used to estimate coverage of a predefined primitive against one or more sample points within the screen space region. At least one sample point in the screen space region which is not covered by the predefined primitive is excluded from testing in the rendering of the screen space region."
9272664,"The present invention discloses a naked eye 3D video system for backing a vehicle and vehicles including the system. The naked eye 3D video system includes: two cameras for being installed on the rear of the vehicle and configured to capture images of the scene behind the vehicle respectively; a processor configured to divide the images captured by the two cameras into image strips in equidistance respectively, and integrate alternatively the divided image strips together into a integrated image in the manner of interleave; and a display device for being installed on the instrument panel of the vehicle, and configured to display the integrated image in the form of three dimensions for a driver to watch with the naked eye. The above naked eye 3D video system for backing a vehicle provided by the present invention can make the driver see clearly any obstacle in the scene behind the vehicle and understand spatial distribution information between the vehicle and the obstacle."
9274701,"In a touchscreen viewing device, a method for implementing a crease effect. The method includes receiving a swipe input related to an image displayed on a touch screen of a viewing device, upon determination that the swipe input will generate an item end effect, causing a crease effect to appear on the image in response to the swipe input, and subsequent to the end of the swipe input, undoing the crease effect on the image to return the image to an original effect."
9274743,"A method includes providing an input port and/or an output port directly interfaced with a Graphics Processing Unit (GPU) of a data processing device further including a Central Processing Unit (CPU) to enable a corresponding reception of input data and/or rendering of output data therethrough. The method also includes implementing a voice/audio processing engine in the data processing device. Further, the method includes performing voice/audio related processing of the input data received through the input port and/or voice/audio related processing of data in the data processing device to realize the output data based on executing the voice/audio processing engine solely through the GPU."
9274792,"A compiler-controlled technique for scheduling threads to execute different regions of a program. A compiler analyzes program code to determine a control flow graph for the program code. The control flow graph contains regions and directed edges between regions. The regions have associated execution priorities. The directed edges indicate the direction of program control flow. Each region has a thread frontier which contains one or more regions. The compiler inserts one or more update predicate mask variable instructions at the end of a region. The compiler also inserts one or more conditional branch instructions at the end of the region. The conditional branch instructions are arranged in order of execution priority of the regions in the thread frontier of the region, to enforce execution priority of the regions at runtime."
9274859,"A message exchange system for software components on different processors. A first component's attempt to load a write register with a message pointer (or a message itself) triggers a determination whether space exists in a shared memory queue. If so, the queue is updated by incrementing a message counter, writing the message/pointer into the queue where designated by a write pointer, and changing the write pointer to a next queue location. A second component's attempt to load the message/pointer from a read register triggers a determination whether there is at least one new message in the queue. If so, the queue is updated by decrementing the message counter, reading the message/pointer from the queue where designated by a read pointer, and changing the read pointer to point to a next queue location. The determinations and queue updates are performed atomically with respect to the software components."
9274979,"A system, method, and computer program product are provided for implementing asymmetric AES-CBC (Advanced Encryption Standard-Cipher Block Chaining) channels usage between encryption and decryption of data. In operation, data to be written to memory is identified. In addition, the data is encrypted utilizing a first AES-CBC channel. Additionally, at least one of a plurality of AES-CBC channels is utilized to decrypt the data to achieve a determined performance target."
9274985,"Banks within a dynamic random access memory (DRAM) are managed with virtual bank managers. A DRAM controller receives a new memory access request to DRAM including a plurality of banks. If the request accesses a location in DRAM where no virtual bank manager includes parameters for the corresponding DRAM page, then a virtual bank manager is allocated to the physical bank associated with the DRAM page. The bank manager is initialized to include parameters needed by the DRAM controller to access the DRAM page. The memory access request is then processed using the parameters associated with the virtual bank manager. One advantage of the disclosed technique is that the banks of a DRAM module are controlled with fewer bank managers than in previous DRAM controller designs. As a result, less surface area on the DRAM controller circuit is dedicated to bank managers."
9275377,"A system, method, and computer program product are provided for determining a monotonic set of presets. In use, a plurality of parameters associated with a product or service is identified. Additionally, a monotonic set of presets associated with the product or service are determined, based on the plurality of parameters."
9275491,"One embodiment of the present invention sets forth a method for generating work to be processed by a graphics pipeline residing within a graphics processor. The method includes the steps of receiving an indication that a first graphics workload is to be submitted to a command queue associated with the graphics processor, allocating a first portion of shader accessible memory for one or more units of state information that are necessary for processing the first graphics workload, populating the first portion of shader accessible memory with the one or more units of state information, and transmitting to the command queue of the graphics processor the one or more units of state information stored within the first portion of shader accessible memory, wherein the first graphics workload is processed within the graphics pipeline based on the one or more units of state information."
9281054,"A static read-only memory (SRAM) includes one or more bit cell rows that each includes a collection of bit cells. Each bit cell row is coupled to two or more different wordlines, where each wordline associated with a given bit cell row provides memory access to a different subset of bit cells within that bit cell row."
9281817,A multiplexer tree operable to control an output a sequence of data stored in a plurality of storage units in accordance with a non-linear address sequence that has less bit transition counts than a linear address sequence. The non-linear address sequence is provided to the selection inputs of the multiplexer tree and causes the levels having greater numbers of multiplexers to toggle less frequently than the levels having smaller numbers of multiplexers. The non-linear address sequence may comprise a Gray code sequence where every two adjacent addresses differ by a single bit. The non-linear address sequence may be optimized to minimize transistor switching in the multiplexer tree.
9286114,"A system and method for launching data parallel and task parallel application threads. In one embodiment, the system includes: (1) a global thread launcher operable to retrieve a launch request from a queue and track buffer resources associated with the launch request and allocate output buffers therefor and (2) a local thread launcher associated with a streaming multiprocessor and operable to receive the launch request from the global thread launcher, set a program counter and resource pointers of pipelines of the streaming multiprocessor and receive reports from pipelines thereof as threads complete execution."
9286119,"A system, method, and computer program product for management of dynamic task-dependency graphs. The method includes the steps of generating a first task data structure in a memory for a first task, generating a second task data structure in the memory, storing a pointer to the second task data structure in a first output dependence field of the first task data structure, setting a reference counter field of the second task data structure to a threshold value that indicates a number of dependent events associated with the second task, and launching the second task when the reference counter field stores a particular value. The second task data structure is a placeholder for a second task that is dependent on the first task."
9286247,"A system, method, and computer program product are provided for determining settings for a device. In use, a plurality of parameters associated with a device is identified. Additionally, one or more settings associated with the device are determined, based on the plurality of parameters."
9286256,"The invention sets forth an L1 cache architecture that includes a crossbar unit configured to transmit data associated with both read data requests and write data requests. Data associated with read data requests is retrieved from a cache memory and transmitted to the client subsystems. Similarly, data associated with write data requests is transmitted from the client subsystems to the cache memory. To allow for the transmission of both read and write data on the crossbar unit, an arbiter is configured to schedule the crossbar unit transmissions as well and arbitrate between data requests received from the client subsystems."
9286647,A computer-implemented method for drawing graphical objects within a graphics processing pipeline is disclosed. The method includes determining that a bypass mode for a first primitive is a no-bypass mode. The method further includes rasterizing the first primitive to generate a first set of rasterization results. The method further includes generating a first set of colors for the first set of rasterization results via a pixel shader unit. The method further includes rasterizing a second primitive to generate a second set of rasterization results. The method further includes generating a second set of colors for the second set of rasterization results without the pixel shader unit performing any processing operations on the second set of rasterization results. The method further includes transmitting the first set of pixel colors and the second set of pixel colors to a raster operations (ROP) unit for further processing.
9286659,"A system, method, and computer program product are provided for multi-sample processing. The multi-sample pixel data is received and is analyzed to identify subsets of samples of a multi-sample pixel that have equal data, such that data for one sample in a subset represents multi-sample pixel data for all samples in the subset. An encoding state is generated that indicates which samples of the multi-sample pixel are included in each one of the subsets."
9287778,"Embodiments are disclosed relating to an electric power conversion device and methods for controlling the operation thereof. One disclosed embodiment provides an electric power conversion device comprising a first current control mechanism coupled to an electric power source and an upstream end of an inductor, where the first current control mechanism is operable to control inductor current. The electric power conversion device further comprises a second current control mechanism coupled between the downstream end of the inductor and a load, where the second current control mechanism is operable to control how much of the inductor current is delivered to the load."
9292065,"A system and method are provided for regulating a supply voltage of a device. The method includes the steps of determining whether a supply voltage for an analog multiplexor is below a threshold voltage. If the supply voltage for the analog multiplexor is below the threshold voltage, then the method includes the step of shorting the supply voltage to an output of the analog multiplexor. However, if the supply voltage for the analog multiplexor is above or equal to the threshold voltage, then the method includes the step of transmitting at least one input signal coupled to the analog multiplexor to the output of the analog multiplexor. A system configured to implement the method may include a power management integrated circuit configured to generate a supply voltage for a device and a device that includes a self-powered analog multiplexor with voltage sensing bypass switch."
9292069,"One embodiment of the present invention sets forth a technique for controlling mode switches in hardware. The resource manager includes an “is mode possible” function that evaluates a given mode in conjunction with the limitations of the hardware to determine if the given mode is feasible. The display driver is configured to call this function to validate a proposed mode before generating commands specifying the state changes for the display heads. The display software interface hardware module within the GPU processes these commands and follows a standard sequence of steps to implement the mode switch. The steps may include interrupts to the resource manager to re-validate the proposed mode, again calling the “is mode possible” function, or perform operations that are not yet supported in the hardware. Advantageously, controlling mode switches in hardware enables less error-prone, more efficient, and more discerning mode switches relative to controlling mode switches in software."
9292265,Basic blocks within a thread program are characterized for convergence based on variance analysis or corresponding instructions. Each basic block is marked as divergent based on transitive control dependence on a block that is either divergent or comprising a variant branch condition. Convergent basic blocks that are defined by invariant instructions are advantageously identified as candidates for scalarization by a thread program compiler.
9292269,"A method includes identifying a divergent region of interest (DRI) not including a post dominator node thereof within a control flow graph, and introducing a decision node in the control flow graph such that the decision node post-dominates an entry point of the DRI and is dominated by the entry point. The method also includes redirecting a regular control flow path within the control flow graph from another node previously coupled to the DRI to the decision node, and redirecting a runaway path from the another node to the decision node. Further, the method includes marking the runaway path to differentiate the runaway path from the regular control flow path, and directing control flow from the decision node to an originally intended destination of each of the regular control flow path and the runaway path based on the marking to provide for program thread synchronization and optimization within the DRI."
9292295,"A system, method, and computer program product for generating flow-control signals for a processing pipeline is disclosed. The method includes the steps of generating, by a first pipeline stage, a delayed ready signal based on a downstream ready signal received from a second pipeline stage and a throttle disable signal. A downstream valid signal is generated by the first pipeline stage based on an upstream valid signal and the delayed ready signal. An upstream ready signal is generated by the first pipeline stage based on the delayed ready signal and the downstream valid signal."
9292414,"A system, method, and computer program product are provided for debugging graphics programs via a system with a single graphics processing unit. The method includes the steps of storing an initial state of an application programming interface context in a memory, intercepting a stream of API commands associated with the frame, transmitting the stream of API commands to a software layer that implements the API to render the frame, and in response to a breakpoint, storing a graphics processing unit context in the memory. The initial state of the API context corresponds to the start of a frame, and the stream of API commands are generated by a graphics application."
9292904,"This document discusses systems and methods that track overall time for processing operations such that the processing time can be shared among the resources efficiently. Processing time can be shifted to image processing to provide the most benefit to image quality. Moreover, access time from one process is banked to be used by a subsequent process or on a subsequent group of pixels. This document discusses systems and methods that provide additional processing power on an as needed basis. For example, a processing stage and its controller are outside the normal pixel processing flow path. When it is determined that additional processing is required, the processing stage and its controller are activated to perform the additional processing. This document discusses systems and methods that provide parallel processing in a processing stage such that the data can flow internal to the controller linked to the processing stage and globally."
9292908,"A system, method, and computer program product are provided for enhancing an image utilizing a hyper-clarity transform. In use, an image is identified. Additionally, the identified image is enhanced, utilizing a hyper-clarity transform. Further, the enhanced image is returned."
9293109,"A graphics processing unit includes a set of geometry processing units each configured to process graphics primitives in parallel with one another. A given geometry processing unit generates one or more graphics primitives or geometry objects and buffers the associated vertex data locally. The geometry processing unit also buffers different sets of indices to those vertices, where each such set represents a different graphics primitive or geometry object. The geometry processing units may then stream the buffered vertices and indices to global buffers in parallel with one another. A stream output synchronization unit coordinates the parallel streaming of vertices and indices by providing each geometry processing unit with a different base address within a global vertex buffer where vertices may be written. The stream output synchronization unit also provides each geometry processing unit with a different base address within a global index buffer where indices may be written."
9293119,"A solution is proposed to perform display updates in a lower power user interface. According to one embodiment, the display panel is placed in the lower possible refresh rate that can be supported. Rendered updates are presented to the displays at the fasted possible pixel rates the communication interface between the rendering component to the display panel can support, and a buffer on the receiving end of the display receives and stores updated frames as they are rendered and transmitted. Subsequent display updates (generated in response to subsequent sensor input, for example) may be created and transmitted as soon as the preceding display frames are buffered. In the meantime, as soon as the update frame is transmitted, the timing controller of the display panel is instructed to interrupt the current refresh period and to immediately rescan the frame."
9293380,"A test system and method for selecting a derating factor to be applied to a ratio of transistors having disparate electrical characteristics in a wafer fabrication process. In one embodiment, the test system includes: (1) structural at-speed automated test equipment (ATE) operable to iterate structural at-speed tests at multiple clock frequencies over integrated circuit (IC) samples fabricated under different process conditions and (2) derating factor selection circuitry coupled to the structural at-speed ATE and configured to employ results of the structural at-speed tests to identify performance deterioration in the samples, the performance deterioration indicating the derating factor to be employed in a subsequent wafer fabrication process."
9298413,"A system, method, and computer program product are provided for changing a state of operation of a display system with respect to at least a portion of an image occluded by a non-display surface. In use, a display system is operated in a first state associated with an occlusion of at least a portion of an image resulting from a non-display surface associated with the display system. Additionally, independent of a control panel user interface, a command is received to operate the display system in a second state associated with the occlusion of the at least a portion of the image resulting from the non-display surface associated with the display system. Furthermore, in response to the command, the display system is operated in the second state associated with the occlusion of the at least a portion of the image resulting from the non-display surface associated with the display system."
9298868,"A technique for generating pushdown data comprises performing logical pushdown of circuit elements and nets and detecting physical pushdown based on partition boundary crossings. Geometry associated with one logical level may be used as a keep-out region for the same physical layer when generating physical design of a different logical level. The technique may advantageously enable concurrent design in both top-level and low-level physical design phases, thereby reducing overall design cycle time in developing an integrated circuit."
9299312,One embodiment of the present invention sets forth a technique for generating and transmitting video frame data from a graphics processing unit (GPU) to a color field sequential display device capable of displaying an auto-stereoscopic image. A frame buffer image comprising per-pixel packed color channels is transformed to a frame buffer image comprising regions corresponding to the color channels with vertical blanking regions inserted between color sub-field regions. Each region of the transformed frame buffer image is sequentially transmitted to the color field sequential display device for display of the corresponding color channel. Backlight illumination for each color channel is controlled by the GPU for temporal alignment with display of each color channel during the vertical blanking interval. The technique is compatible with lenticular and parallax barrier displays.
9300261,"A system for driving a plurality of loads each connected to respective signal terminals and to a shared common load terminal. Multiple conventional signal amplifiers each provide a content signal at one of the signal terminals. The signal amplifiers each have a primary-power upper terminal, to receive a first voltage (V1) from a first power supply, and a primary-power lower terminal, to receive a second voltage (V2) from the first power supply. A bias amplifier biases the common load terminal, and has a secondary-power upper terminal to receive a third voltage (V3) from a second power supply and a secondary-power lower terminal to receive a fourth voltage (V4) from the second power supply, wherein V2≦V4<V3≦V1."
9300933,"A method includes predicting, through a processor of a data processing device communicatively coupled to a memory, a portion of a video frame on which a user of the data processing device is likely to focus on during rendering thereof on a display unit associated with the data processing device. The video frame is part of decoded video data. The method also includes rendering, through the processor, the portion of the video frame on the display unit at an enhanced level compared to other portions thereof following the prediction of the portion of the video frame."
9301395,"Disclosed are methods and systems to reduce voltage noise on a printed circuit board (PCB) through a co-layout of multilayer ceramic capacitors. In one or more embodiments, this surface mounted layout comprises a first co-layout of multilayer ceramic capacitors mounted on a first corner of a rectangular footprint of a bottom side of the PCB; a second co-layout of multilayer ceramic capacitors mounted on a second corner of the rectangular footprint diagonal to the first corner; and a first solid electrolytic polymer capacitor and a second solid electrolytic polymer capacitor mounted on the remaining corners, respectively, of the rectangular footprint. The rectangular footprint of the PCB is a footprint of a high-speed processing unit mounted on the PCB. The high-speed processing unit is mounted on a top side of the PCB opposite the bottom side comprising the first co-layout of multilayer ceramic capacitors and the second co-layout of multilayer ceramic capacitors."
9304739,"Embodiments of the present invention set forth a technique for optimizing the performance and efficiency of complex, software-based computations, such as lighting computations. Data entering a graphics application programming interface (API) in a conventional arithmetic representation, such as floating-point or fixed-point, is converted to an internal logarithmic representation for greater computational efficiency. Lighting computations are then performed using logarithmic space arithmetic routines that, on average, execute more efficiently than similar routines performed in a native floating-point format. The lighting computation results, represented as logarithmic space numbers, are converted back to floating-point numbers before being transmitted to a graphics processing unit (GPU) for further processing. Because of efficiencies of logarithmic space arithmetic, performance improvements may be realized relative to prior art approaches to performing software-based floating-point operations."
9304775,An embodiment of a computing system is configured to process data using a multithreaded SIMD architecture that includes heterogeneous processing engines to execute a program. The program is constructed of various program instructions. A first type of the program instructions can only be executed by a first type of processing engine and a second type of program instructions can only be executed by a second type of processing engine. A third type of program instructions can be executed by the first and the second type of processing engines. An instruction dispatcher is configured to identify and remove program instruction execution conflicts for the heterogeneous processing engines to improve instruction execution throughput.
9305128,"In an integrated circuit device, a power circuit for maintaining asserted values on an input output pin of the device when a functional block of the device is placed in a sleep mode. The device includes a power circuit disposed along the periphery of the device, the power circuit configured to maintain power when the device is placed in a low-power mode. A plurality of input output blocks are included in the device and are for receiving external inputs for the integrated circuit device and for providing outputs from the integrated circuit device. The power circuit is coupled to provide power to at least one of the input output blocks to maintain state when the integrated circuit device is in the low-power mode."
9305324,"A system, method, and computer program product are provided for tiled deferred shading. In operation, a plurality of photons associated with at least one scene are identified. Further, a plurality of screen-space tiles associated with the at least one scene are identified. Additionally, each of the plurality of screen-space tiles capable of being affected by a projection of an effect sphere for each of the plurality of photons are identified. Furthermore, at least a subset of photons associated with each of the screen-space tiles from which to compute shading are selected. Moreover, shading for the at least one scene is computed utilizing the selected at least a subset of photons."
9305388,"A system, method, and computer program product are provided for using a bit-count texture format. A rasterized coverage bit mask is received by a texture processing unit from a bit-count format texture map, the rasterized coverage bit mask is converted to a scalar value, and the scalar value is processed while the rasterized coverage bit mask is retained in the bit-count format texture map. The coverage bit mask may be converted by computing a count of samples that are covered by at least one graphics primitive according to the rasterized coverage bit mask."
9305392,"Techniques are disclosed for tracing a ray within a parallel processing unit. A first thread receives a ray or a ray segment for tracing and identifies a first node within an acceleration structure associated with the ray, where the first node is associated with a volume of space traversed by the ray. The thread identifies the child nodes of the first node, where each child node is associated with a different sub-volume of space, and each sub-volume is associated with a corresponding ray segment. The thread determines that two or more nodes are associated with sub-volumes of space that intersect the ray segment. The thread selects one of these nodes for processing by the first thread and another for processing by a second thread. One advantage of the disclosed technique is that the threads in a thread group perform ray tracing more efficiently in that idle time is reduced."
9305394,"Embodiments of the present invention are directed to methods and a system that allow for deterministic parallel low discrepancy sampling, which can be efficiently processed, and are effective in removing transitionary artifacts that occur in low-dimensional projections generated in low discrepancy sequences. Embodiments of the claimed subject matter further provide improvements upon the low-dimensional projections and thus the visual quality when using the Sobol' sequence for image synthesis."
9306776,"A method for filtering a data signal includes transmitting the data signal from a transmitter to a receiver across a conductor disposed in an interposer, which interconnects the receiver and the transmitter. The data signal is low-passed with a filter, which includes a passive resistive element disposed within the interposer and coupled in series electrically with a passive inductive element. In relation thereto, the interposer is disposed in a position within the interposer, or upon a surface thereof. The filter is coupled to the conductor in a shunt configuration with respect to ground."
9307179,"A method and system for protecting content in graphics memory are disclosed. Specifically, one embodiment of the present invention sets forth a method, which includes the steps of storing a first privilege level in a privilege map with restricted access, wherein the first privilege level is associated with a memory page used to store the content; and determining whether to permit a request to access the memory page based on the first privilege level."
9307213,"Embodiments of the present invention are directed to methods and systems for robust weighting of gray patches in automatic white balancing in an image-capture device by utilizing kernel density estimation techniques with dynamically variable bandwidth to determine the probability density of samples to create an initial estimate, then verifying the initial gray point estimate to account for outliers. In one embodiment, given a set of image data, an initial gray point estimate in a color space is determined for the set of image data. The initial estimate is then refined by weighting the sub-population with the greatest probability of being gray. A final evaluation that includes a further comparison to pre-programmed constraints determines a final estimate, which can still be further tuned according to user preferences by adjusting color biases. The resulting final gray point estimate provides greater stability, and greatly improved accuracy over traditional techniques and solutions."
9307267,"Scalable techniques for dynamic data encoding and decoding are directed toward a system including a plurality of frame processing units. A main frame processing unit manages frame processing unit resource, dispatches frames to appropriate frame processing units. One or more auxiliary frame processing units encode or decode the non-reference frames dispatched by the main frame processing unit. The main frame processing unit encodes or decodes the reference frames and encodes or decodes non-reference frames if none of the auxiliary frame processing units are available."
9310872,"A clock frequency controller for a processor and a method of operation thereof. The clock frequency controller may be embodied in a processor, including: (1) a processing core operable at a clock frequency to undertake a processing of a graphics application, and (2) a clock frequency controller coupled to the processing core and operable to adjust the clock frequency based on a current frame rate of the processing and a target frame rate for the processing."
9311097,"A graphics processing system configured to track per-tile event counts in a tile-based architecture. A tiling unit in the graphics processing system is configured to cause a screen-space pipeline to load a count value associated with a first cache tile into a count memory and to cause the screen-space pipeline to process a first set of primitives that intersect the first cache tile. The tiling unit is further configured to cause the screen-space pipeline to store a second count value in a report memory location. The tiling unit is also configured to cause the screen-space pipeline to process a second set of primitives that intersect the first cache tile and to cause the screen-space pipeline to store a third count value in the first accumulating memory. Conditional rendering operations may be performed on a per-cache tile basis, based on the per-tile event count."
9311169,"The server based graphics processing techniques, describer herein, include passing graphics commands from a shim layer to a guest display device interface, wherein the shim layer and the guest display device interface (DDI) are executing in a given instance of a guest virtual machine (VM). The guest DDI calls back to the shim layer with corresponding function calls. The function calls are passed from the shim layer to a host DDI through a communication channel of a host-guest communication manager (HGCM), wherein the host display device interface and host-guest communication manager are executing in a host virtual machine manager (VMM)."
9311733,One embodiment of the present invention sets forth a technique for improved rasterization of round points mapped into a tile space within a graphics processing pipeline. A set of candidate tiles are selected based on proximity to a round point. A tile within the set of candidate tiles may be rejected based on a rejection boundary. A tile may be rejected if no vertex associated with the tile is within the coverage area. Performance is improved by rejecting certain unneeded tiles that would otherwise be included in conventional rasterization. One embodiment advantageously enlists line drawing circuitry to determine whether a given tile intersects the coverage area.
9311738,One embodiment of the present invention sets forth a technique for rendering paths by first generating a stencil buffer indicating pixels of the path that should be covered and then covering the path. The paths may be filled or stroked without tessellating the paths. Path rendering may be accelerated when a graphics processing unit or other processor that is configured to perform operations to generate the stencil buffer and cover the path to fill or stroke the path.
9312866,"A clock signal generation circuit provides an output clock signal to a digital system. The digital system is powered by a power supply voltage, VDD, that may include transients associated with the impedance of the packaged digital system. The clock signal generation circuit dynamically scales an output clock frequency based on monitored changed to VDD. The output clock frequency may be selected to approximate a maximum (margin-less) system Fmax for the monitored VDD. The average clock frequency may be improved compared with operating at a fixed output clock frequency."
9317094,"Technology is provided for distributed power delivery to a processing unit on a printed circuit board. In one example, a printed circuit board includes a processing unit coupled to multiple power channels, including first channels on a first side of the processing unit, and second channels on a second side of the processing unit. The printed circuit board further includes a first power supply coupled to the processing unit via the first channels, and a second power supply coupled to the processing unit via the second channels. The processing unit is configured to receive a total current, including currents drawn substantially simultaneously from the first power supply and the second power supply. The total current is about equivalent to a current the processing unit would draw from a single power supply."
9317251,"A method for correcting a shift error in a fused multiply add operation. The method comprises adjusting a normalized floating-point number before performing a shift error correction to produce an adjusted normalized floating-point number, and correcting a shift error in the adjusted normalized floating-point number. The correcting the shift error comprises shifting a mantissa of the adjusted normalized floating-point number in one direction. A fused multiply add module comprising a normalizer module, a compensation logic, and a round. The normalizer module is operable to normalize a floating-point number to produce a normalized floating-point number. The floating-point number is normalized based upon an estimated quantity of leading zeros. The compensation logic is operable to manage a correction of a shift error in the normalized floating-point number. The rounder is operable to correct the shift error with a mantissa shift in only one direction."
9317290,"Circuits, methods, and apparatus that provide parallel execution relationships to be included in a function call or other appropriate portion of a command or instruction in a sequential programming language. One example provides a token-based method of expressing parallel execution relationships. Each process that can be executed in parallel is given a separate token. Later processes that depend on earlier processes wait to receive the appropriate token before being executed. In another example, counters are used in place to tokens to determine when a process is completed. Each function is a number of individual functions or threads, where each thread performs the same operation on a different piece of data. A counter is used to track the number of threads that have been executed. When each thread in the function has been executed, a later function that relies on data generated by the earlier function may be executed."
9317960,"One embodiment of the present invention sets forth a technique for rendering paths by first generating a stencil buffer indicating pixels of the path that should be covered and then covering the path. The paths may be filled or stroked without tessellating the paths. Path rendering may be accelerated when a graphics processing unit or other processor that is configured to perform operations to generate the stencil buffer and cover the path to fill or stroke the path. When the paths are rendered in a top-to-bottom (front-to-back) order, an opacity stencil may be generated and used to avoid determining path coverage and shading for pixels that are opaque."
9318073,"A method includes querying, through a processor, a database of color profiles to determine a secondary color profile therefrom, and comparing, through the processor, the determined secondary color profile to a primary color profile of a primary display communicatively coupled to the processor. The method also includes selecting, through the processor, the determined secondary color profile to be applied to a secondary display also communicatively coupled to the processor upon determining that multimedia content displayed on the primary display with the primary color profile matches with the same multimedia content displayed on the secondary display with the determined secondary color profile. Further, the method includes reducing a color discrepancy between the same multimedia content on the primary display and the secondary display based on rendering the same multimedia content on the primary display with the primary color profile and the secondary display with the selected secondary color profile."
9319248,"A decision feedback equalizer system is disclosed. The decision feedback equalizer system includes a current summer core that in current mode, removes inter-symbol interference from a signal, and, a CMOS latch component, that is coupled to the current summer core, that receives a current mode signal and outputs a CMOS compatible signal. The components of the decision feedback equalizer system are controlled by a single clock."
9323315,A system and method for power management by performing clock-gating at a clock source. In the method a critical stall condition is detected within a clocked component of a core of a processing unit. The core includes one or more clocked components synchronized in operation by a clock signal distributed by a clock grid. The clock grid is clock-gated to suspend distribution of the clock signal to the core during the critical stall condition.
9323502,"A system, method, and computer program product are provided for altering a line of code. In use, a line of code is identified, where the line of code is written utilizing both a programming language and one or more syntax extensions to the programming language. Additionally, the line of code is altered so that the altered line of code is written using only the programming language. Further, the altered line of code is returned."
9323679,"A system, method, and computer program product are provided for managing miss requests. In use, a miss request is received at a unified miss handler from one of a plurality of distributed local caches. Additionally, the miss request is managed, utilizing the unified miss handler."
9323774,"A system and method are provided for representing pointers. An encoding type for a pointer structure referenced by a first cell of a data structure is determined. A first field of the pointer structure is encoded to indicate the encoding type. Further, a second field of the pointer structure is encoded according to the encoding type to indicate a location in memory where a cell structure corresponding to a second cell of the data structure is stored."
9324174,"Circuits, methods, and apparatus that provide multiple graphics processor systems where specific graphics processors can be instructed to not perform certain rendering operations while continuing to receive state updates, where the state updates are included in the rendering commands for these rendering operations. One embodiment provides commands instructing a graphics processor to start or stop rendering geometries. These commands can be directed to one or more specific processors by use of a set-subsystem device mask."
9324175,One embodiment of the present invention sets forth a technique for performing a computer-implemented method that controls memory access operations. A stream of graphics commands includes at least one memory barrier command. Each memory barrier command in the stream of graphics command delays memory access operations scheduled for any command specified after the memory barrier command until all memory access operations scheduled for commands specified prior to the memory barrier command have completely executed.
9324294,"The present invention sets forth an apparatus for supporting multiple digital display interface standards. In one embodiment, the apparatus includes a graphics processing unit (GPU) configured to determine a display device type of a display device that is in connection with a digital display interconnect, receive a display device information associated with the display device, and output a first data signal to the display device. The display device is of display port (DP) digital display interface standard and the digital display interconnect is of digital visual interface (DVI) digital display interface standard. The apparatus further includes a removable adaptor circuitry between the display device and the digital display interconnect."
9329227,"An apparatus for determining an electrical reliability of a ball grid array (BGA) assembly of an integrated circuit is presented. The assembly comprises a testing printed circuit board (PCB) having an integrated circuit (IC) test region located thereon. Vias extend through the testing PCB from a surface to an underside thereof within the IC test region. Each via has an IO pad or ground pad electrically connectable thereto. An IC package having an IC die connected thereto by solder bumps is connected to the IC test region by solder balls, such that each of the IO pads is electrically connectable to a respective pair of the solder balls and solder bumps by the vias. A method of testing interconnection reliability of the BGA using the apparatus is also presented."
9329671,"Computer system, method and computer program product for scheduling IPC activities are disclosed. In one embodiment, the computer system includes first processor and second processors that communicate with each other via IPC activities. The second processor may operate in a first mode in which the second processor is able to process IPC activities, or a second mode in which the second processor does not process IPC activities. Processing apparatus associated with the first processor identifies which of the pending IPC activities for communicating from the first processor to the second processor are not real-time sensitive, and schedules the identified IPC activities for communicating from the first processor to the second processor by delaying some of the identified IPC activities to thereby group them together. The grouped IPC activities are scheduled for communicating to the second processor during a period in which the second processor is continuously in the first mode."
9329984,"Methods and systems monitor and log software and hardware failures (i.e. errors) over a communication network. In one embodiment, the method includes detecting an event caused by an error, and generating a log of the event in response to the detection. The method further includes generating a first message prompting if a user consents to allowing a third party provider track the error and transmitting the log to the third party provider over the communication network if the user consents to allowing the third party provider track the error. The method yet further includes generating a second message prompting if the user wants to provide additional information relating to the error. The method still further includes providing a user interface including an error reporting portal to the user if the user wants to provide additional information and transmitting the portal to the third party provider."
9329988,"One embodiment of the present invention sets forth a technique for dynamically allocating memory using a nested hierarchical heap. A lock-free mechanism is used to access to a hierarchical heap data structure for allocating and deallocating memory from the heap. The heap is organized as a series of levels of fixed-size blocks, where all blocks at given level are the same size. At each lower level of the hierarchy, a collection of N blocks in the lower level equals the size of a single block at the level above. When a thread requests an allocation, one or more blocks at only one level are allocated to the thread. When threads are finished using an allocation, each thread deallocates the respective allocated blocks. When all of the blocks for a level have been deallocated, defragmentation is performed at that level."
9330031,A system and method for calibration of serial links using serial-to-parallel loopback. Embodiments of the present invention are operable for calibrating serial links using parallel links thereby reducing the number of links that need calibration. The method includes sending serialized data over a serial interface and receiving parallel data via a parallel interface. The serialized data is looped back via the parallel interface. The method further includes comparing the parallel data and the serialized data for a match thereof and calibrating the serial interface by adjusting the sending of the serialized data until the comparing detects the match. The adjusting of the sending is operable to calibrate the sending of the serialized data over the serial interface.
9330060,"A method and device for encoding and decoding video image data. An MPEG decoding and encoding process using data flow pipeline architecture implemented using complete dedicated logic is provided. A plurality of fixed-function data processors are interconnected with at least one pipelined data transmission line. At least one of the fixed-function processors performs a predefined encoding/decoding function upon receiving a set of predefined data from said transmission line. Stages of pipeline are synchronized on data without requiring a central traffic controller. This architecture provides better performance in smaller size, lower power consumption and better usage of memory bandwidth."
9331869,"The input/output request packet (IRP) handling technique includes determining if a received input/output request packet should receive a given handling. If the input/output request packet should receive the given handling, the input/output request packet is dispatched to a device specific dispatch input/output request packet handler. Otherwise, the input/output request packet is redirected to an operating system dispatch input/output request packet handler."
9332094,"A modem is disclosed. An embodiment thereof includes: a first interface arranged to connect to a network, a second interface arranged to connect to a host processor on the terminal, an audio interface arranged to connect to an audio processing means and a processing unit arranged to receive a plurality of parameters from the terminal via the second interface. The plurality of parameters are associated with a call established by the host processor to at least one further terminal connected to the network; wherein the processing unit is further arranged to receive input voice data from the audio processing means, process the input voice data in dependence on at least one of said parameters; and transmit the processed input voice data via the first interface to the at least one further terminal over said network during the call in dependence on a further at least one of said parameters."
9332437,"A wireless communications device is disclosed herein. In one embodiment, the wireless communication device includes: a transceiver configured to facilitate communications with a radio access network; and a processing unit configured to: determine that a cell update message is to be transmitted to the network; determine if a security mode configuration procedure is in progress at the device; and if a security mode configuration procedure is not in progress, transmit a second type of cell update message to the network entity, the second type of cell update message not including an indicator indicating that the device has not had to abort an on-going security procedure and in place of said indicator including information not pertaining to a security procedure."
9335964,A graphics server for remotely rendering a composite image and a method of use thereof. One embodiment of the graphics server includes: (1) a graphics renderer configured to render updates for a plurality of graphics windows within the composite image and (2) a display processing unit (DPU) configured to identify changed portions of the composite image and provide the changed portions to an encoder for encoding and subsequent transmission.
9336002,"One embodiment of the present invention includes a method for performing a multi-pass tiling test. The method includes combining a plurality of bounding boxes to generate a coarse bounding box. The method further includes identifying a first cache tile associated with a render surface and determining that the coarse bounding box intersects the first cache tile. The method further includes comparing each bounding box included in the plurality of bounding boxes against the first cache tile to determine that a first set of one or more bounding boxes included in the plurality of bounding boxes intersects the first cache tile. Finally, the method includes, for each bounding box included in the first set of one or more bounding boxes, processing one or more graphics primitives associated with the bounding box. One advantage of the disclosed technique is that the number of intersection calculations performed for each cache tile is reduced."
9338036,One embodiment of the present invention sets forth a mechanism for transmitting and receiving differential signals. A transmitter combines a direct current (DC) to DC converter including a capacitor with a 2:1 multiplexer to drive a pair of differential signaling lines. The transmitter drives a pair of voltages that are symmetric about the ground power supply level. Signaling currents are returned to the ground plane to minimize the generation of noise that is a source of crosstalk between different differential signaling pairs. Noise introduced through the power supply is correlated with the switching rate of the data and may be reduced using an equalizer circuit.
9342181,"A touch-screen input/output device including a touch sensor, a display, a display control module, a touch sensor control module and a synchronizer module. The touch sensor is overlaid on a display. The display control module is communicatively coupled to the display and converts video data into a serial bit stream video display signal including one or more blanking intervals. The touch sensor control module is communicatively coupled to the touch sensor and determines touch events and location of the touch event on the touch sensor during one or more touch sensor scan cycles. The synchronizer module is communicatively coupled between the display control module and the touch sensor control module, and interleaves the one or more touch sensor scan cycles with the one or more blanking intervals of the video display signal."
9342311,"One embodiment of the present invention includes a method for generating accumulated bounding boxes for graphics primitives. The method includes generating a first bounding box associated with a first graphics primitive. The method further includes, for each graphics primitive included in a first set of one or more additional graphics primitives, determining that the graphics primitive is within a threshold distance of the first bounding box, and adding the graphics primitive to the first bounding box. The method further includes determining not to add a second graphics primitive to the first bounding box. The method further includes generating a second bounding box associated with the second graphics primitive. Finally, the method includes transmitting the first bounding box to a tiling unit via a crossbar. One advantage of the disclosed embodiments is that multiple bounding boxes are combined to generate an accumulated bounding box that is then transferred across the crossbar."
9342362,"A computer system and a method of operating a service-processor-centric computer system. In one embodiment, the computer system includes: (1) a CPU configured to issue control signals and (2) a service processor configured for intercepting and handling the control signals, the handling including delaying, modifying or ignoring the control signals, the service processor further configuring for issuing highest-priority control signals."
9342857,"One embodiment sets forth a method for modifying draw calls using a draw-call shader program included in a processing subsystem configured to process draw calls. The draw call shader receives a draw call from a software application, evaluates graphics state information included in the draw call, generates modified graphics state information, and generates a modified draw call that includes the modified graphics state information. Subsequently, the draw-call shader causes the modified draw call to be executed within a graphics processing pipeline. By performing the computations associated with generating the modified draw call on-the-fly within the processing subsystem, the draw-call shader decreases the amount of system memory required to render graphics while increasing the overall processing efficiency of the graphics processing pipeline."
9342891,"One embodiment of the present invention includes techniques for rasterizing primitives that include edges shared between paths. For each edge, a rasterizer unit selects and applies a sample rule from multiple sample rules. If the edge is shared, then the selected sample rule causes each group of coverage samples associated with a single color sample to be considered as either fully inside or fully outside the edge. Consequently, conflation artifacts caused when the number of coverage samples per pixel exceeds the number of color samples per pixel may be reduced. In prior-art techniques, reducing such conflation artifacts typically involves increasing the number of color samples per pixel to equal the number of coverage samples per pixel. Advantageously, the disclosed techniques enable rendering using algorithms that reduce the ratio of color to coverage samples, thereby decreasing memory consumption and memory bandwidth use, without causing conflation artifacts associated with shared edges."
9343449,"Embodiments of the invention provide an integrated circuit system, which includes a first supporting substrate and a second supporting substrate, a logic chip disposed between the first supporting substrate and the second supporting substrate, and a plurality of memory stacks disposed adjacent to one another on a surface of the logic chip. The logic chip is separated from the first supporting substrate and the second supporting substrate by a distance such that at least a portion of a first memory stack in the plurality of memory stacks extending outwards past a first side edge of the logic chip is supported by the first supporting substrate, and at least a portion of a second memory stack in the plurality of memory stacks extending outwards past a second side edge of the logic chip that is opposite to the first side edge is supported by the second supporting substrate."
9348751,"One embodiment of the present invention sets forth a technique for computing dynamic random access memory (DRAM) addresses from linear physical addresses for memory subsystems implementing integral power of two virtual page sizes, and an arbitrary number of available partitions. Each DRAM address comprises a row address, column address, bank address, and partition address. The linear physical address is used to generate to the DRAM address in units of a DRAM bank size. Address scrambling may be implemented to overcome transient access contention to specific DRAM pages by multiple client modules."
9348762,"A tag unit configured to manage a cache unit includes a coalescer that implements a set hashing function. The set hashing function maps a virtual address to a particular content-addressable memory unit (CAM). The coalescer implements the set hashing function by splitting the virtual address into upper, middle, and lower portions. The upper portion is further divided into even-indexed bits and odd-indexed bits. The even-indexed bits are reduced to a single bit using a XOR tree, and the odd-indexed are reduced in like fashion. Those single bits are combined with the middle portion of the virtual address to provide a CAM number that identifies a particular CAM. The identified CAM is queried to determine the presence of a tag portion of the virtual address, indicating a cache hit or cache miss."
9349154,"One embodiment of the present invention sets for a method for accessing data objects stored in a memory that is accessible by a graphics processing unit (GPU). The method comprises the steps of creating a data object in the memory based on a command received from an application program, wherein the data object is organized non-linearly in the memory, transmitting a first handle associated with the data object to the application program such that data associated with different draw commands can be accessed by the GPU, wherein the first handle includes an address related to the location of the data object in the memory, receiving a first draw command as well as the first handle from the application program, and transmitting the first draw command and the first handle to the GPU for processing."
9355041,"One embodiment of the present invention is a memory subsystem that includes a sliding window tracker that tracks memory accesses associated with a sliding window of memory page groups. When the sliding window tracker detects an access operation associated with a memory page group within the sliding window, the sliding window tracker sets a reference bit that is associated with the memory page group and is included in a reference vector that represents accesses to the memory page groups within the sliding window. Based on the values of the reference bits, the sliding window tracker causes the selection a memory page in a memory page group that has fallen into disuse from a first memory to a second memory. Because the sliding window tracker tunes the memory pages that are resident in the first memory to reflect memory access patterns, the overall performance of the memory subsystem is improved."
9355430,"One embodiment sets forth a method for allocating memory to surfaces. A software application specifies surface data, including interleaving state data. Based on the interleaving state data, a surface access unit bloats addressees derived from discrete coordinates associated with the surface, creating a bloated virtual address space with a predictable pattern of addresses that do not correspond to data. Advantageously, by creating predictable regions of addresses that do not correspond to data, the software application program may configure the surface to share physical memory space with one or more other surfaces. In particular, the software application may map the virtual address space together with one or more virtual address spaces corresponding to complementary data patterns to the same physical base address. And, by overlapping the virtual address spaces onto the same pages in physical address space, the physical memory may be more densely packed than by using prior-art allocation techniques."
9355468,"A system and method are provided for performing joint color and depth encoding. Color data and depth data for an image is received. Based on the color data, confidence values are computed for the depth data and the depth data is encoded based on the confidence values to represent a correlated portion of the depth data and a decorrelated portion of the depth data. In one embodiment, the depth data comprises per-pixel vergence angles."
9355483,"A system, method, and computer program product are provided for shading primitive fragments. A target buffer may be recast when shaded samples that are covered by a primitive fragment are generated at a first shading rate using a first sampling mode, the shaded samples are stored in the target buffer that is associated with the first sampling mode and the first shading rate, a second sampling mode is determined, and the target buffer is associated with the second sampling mode. A sampling mode and/or shading rate may be changed for a primitive. A primitive fragment that is associated with a first sampling mode and a first shading rate is received and a second sampling mode is determined for the primitive fragment. Shaded samples corresponding to the primitive fragment are generated, at a second shading rate, using the second sampling mode and the shaded samples are stored in a target buffer."
9355492,"A system, method, and computer program product are provided for utilizing a wavefront path tracer. In use, a set of light transport paths associated with a scene is identified. Additionally, parallel path tracing is performed, utilizing a wavefront path tracer."
9355710,"A hybrid write-assist memory system includes an array voltage supply and a static random access memory (SRAM) cell that is controlled by bit lines and a word line and employs a separable cell supply voltage coupled to the array voltage supply. Additionally, the hybrid write-assist memory system includes a supply voltage droop unit that is coupled to the SRAM cell and provides a voltage reduction of the separable cell supply voltage during a write operation. Also, the hybrid write-assist memory system includes a negative bit line unit that is coupled to the supply voltage droop unit and provides a negative bit line voltage concurrently with the voltage reduction of the separable cell supply voltage during the write operation. A method of operating a hybrid write-assist memory system is also provided."
9357162,"A method of processing digital video signals, comprising: receiving input pixels to be processed; performing multiple processing operations on the input pixels, where the multiple processing operations are performed during a time interval determined in part by a desired video output rate; and performing a classification analysis at an intermediate time during the time interval, the classification analysis yielding tag data that is used to dynamically vary one or more of the multiple processing operations, and where the tag data is generated on a per-pixel basis to enable pixel by pixel variation of the multiple processing operations."
9361079,"A technique is disclosed for executing a compiled parallel application on a general purpose processor. The compiled parallel application comprises parallel thread execution code, which includes single-instruction multiple-data (SIMD) constructs, as well as references to intrinsic functions conventionally available in a graphics processing unit. The parallel thread execution code is transformed into an intermediate representation, which includes vector instruction constructs. The SIMD constructs are mapped to vector instructions available within the intermediate representation. Intrinsic functions are mapped to corresponding emulated runtime implementations. The technique advantageously enables parallel applications compiled for execution on a graphics processing unit to be executed on a general purpose central processing unit configured to support vector instructions."
9361105,"A parallel counter accesses data generated by an application and stored within a register. The register includes different segments that include different portions of the application data. The parallel counter is configured to count the number of values within each segment that have a particular characteristic in a parallel fashion. The parallel counter may then return the individual segment counts to the application, or combine those segment counts and return a register count to the application. Advantageously, applications that rely on population count operations may be accelerated. Further, increasing the number of segments in a given register may reduce the time needed to count the values in that register, thereby providing a scalable solution to population counting. Additionally, the architecture of the parallel counter is sufficiently flexible to allow both register counting and segment counting, thereby combining two separate functionalities into just one hardware unit."
9361254,"A packaged memory device includes a semiconductor interposer, a first memory stack, a second memory stack, and a buffer chip that are all coupled to the semiconductor interposer. The first memory stack and the second memory stack each include multiple memory chips that are configured as a single stack. The buffer chip is electrically coupled to the first memory stack via a first data bus, electrically coupled to the second memory stack via a second data bus, and electrically coupled to a processor data bus that is configured for transmitting signals between the buffer chip and a processor chip. Such a memory device can have high data capacity and still operate at a high data transfer rate in an energy efficient manner."
9363187,"A jitter buffering system and a method of jitter buffering. The jitter buffering system may be embodied in a quality of service (QoS) management server, including: (1) a network interface controller (NIC) configured to receive one-way-delay statistics regarding a video stream transmitted to a client, and (2) a processer configured to employ the one-way-delay statistics to calculate and recognize jitter and subsequently generate a command for the client to enable jitter buffering."
9363715,"A modem and a method for handing over Internet protocol (IP) multimedia subsystem (IMS) sessions from a packet-switched network to a circuit-switched network. One embodiment of the modem includes: (1) a physical layer through which IMS packets for a plurality of IMS sessions are transmittable and receivable, and (2) a control layer configured to gain access to respective IMS session data for the plurality of IMS sessions, the respective IMS session data originating from a host IMS application."
9367306,A technique is disclosed for executing a program designed for multi-threaded operation on a general purpose processor. Original source code for the program is transformed from a multi-threaded structure into a computationally equivalent single-threaded structure. A transform operation modifies the original source code to insert code constructs for serial thread execution. The transform operation also replaces synchronization barrier constructs in the original source code with synchronization barrier code that is configured to facilitate serialization. The transformed source code may then be conventionally compiled and advantageously executed on the general purpose processor.
9367399,"A graphics processing subsystem and a method for recovering a video basic input/output system (VBIOS). One embodiment of the graphics processing subsystem includes: (1) a memory configured to store a VBIOS, and (2) a processor coupled to the memory and configured to employ a bridge to gain access to the VBIOS and cause the VBIOS to be written to the memory."
9367467,"A system and method for managing cache replacements and a memory subsystem incorporating the system or the method. In one embodiment, the system includes: (1) a cache controller operable to control a cache and, in order: (1a) issue a pre-fetch command when the cache has a cache miss, (1b) perform at least one housekeeping task to ensure that the cache can store a replacement line and (1c) issue a fetch command and (2) a memory controller associated with a memory of a lower level than the cache and operable to respond to the pre-fetch command by performing at least one housekeeping task to ensure that the memory can provide the replacement line and respond to the fetch command by providing the replacement line."
9367487,"One embodiment of the invention sets forth a control crossbar unit that is designed to transmit control information from control information generators to destination components within the computer system. The control information may belong to various traffic paradigms, such as short-latency data traffic, narrow-width data traffic or broadcast data traffic. The physical connections within the control crossbar unit are categorized based on the different types of control information being transmitted through the control crossbar unit. The physical connections belong to the following categories: one-to-one (OTO) connections, one-to-many (OTM) connections, valid-to-one (VTO) connections, valid-to-many (VTM) connections wire-to-one (WTO) connections and wire-to-many (WTM) connections."
9367889,"A system and method for propagating scene information to a renderer. In one embodiment, the system includes: (1) an update request receiver operable to receive an update request from the renderer and determine a point from which the renderer is to be updated and (2) an update propagator associated with the update request receiver and operable to employ a graph containing scene information to construct a change list corresponding to the update request and transmit the change list toward the renderer."
9367946,"A computing system and method for representing volumetric data for a scene. One embodiment of the computing system includes: (1) a memory configured to store a three-dimensional (3D) clipmap data structure having at least one clip level and at least one mip level, and (2) a processor configured to generate voxelized data for a scene and cause the voxelized data to be stored in the 3D clipmap data structure."
9367955,"A system, method, and computer program product are provided for computing values for pixels in an image plane. In use, a low discrepancy sequence associated with an image plane is identified. Additionally, a function with the set of pixels of the image plane as a domain is determined. Further, a value is computed for each pixel in the image plane, utilizing the low discrepancy sequence and the function with the set of pixels of the image plane as a domain."
9368169,A method of training chip select for a memory module. The method includes programming a memory controller into a mode wherein a command signal is active for a programmable time period. The method then programs a programmable delay line of the chip select with a delay value and performs initialization of the memory module. The memory module is then placed in a write leveling mode wherein placing the memory module in the write leveling mode toggles a state of the chip select. A write leveling procedure is then performed and a response thereto is determined from the memory module. A determination is made whether the memory module is in a pass state or an error state based on the response.
9368183,"An integrated circuit package includes a packaging substrate with an electrical connection pad formed thereon and an integrated circuit die coupled to the electrical connection pad. The electrical connection pad includes an electroplated surface finish layer, but does not include an electrical trace configured as a plating tail. Because the electrical connection pad is free of a plating tail, signal degradation caused by the presence of plating tails in the integrated circuit package is avoided."
9368422,"One embodiment sets forth an integrated circuit package that includes a substrate, one or more devices mounted on the substrate, a layer of under-fill configured to secure the one or more devices on the substrate, and a solder trench formed in the substrate, where the aggregate volume of the solder trench is large enough to capture a flow of excess under-fill during fabrication. One advantage of the disclosed integrated circuit package is that the solder trench is used in lieu of solder dam structures, thereby allowing a stencil to be lowered closer to the substrate surface during fabrication, which facilitates depositing solder paste during fabrication."
9368439,"Embodiments of the invention generally relate to package substrates for integrated circuits. The package substrates each include a core having electrically conductive vias therethrough. Build-up layers formed from dielectric materials having different compositions are disposed around the core and include interconnects formed therein for facilitating electrical connections between integrated circuits coupled to the package substrate. The dielectric materials are selected to allow finer interconnect geometries where desired, and to increase the rigidity, and thus planarity, of the package substrate. Exemplary dielectric materials include pre-impregnated composite fibers for increasing the rigidity of a package substrate, and Ajinomoto Build-up Film for allowing the formation finer interconnect geometries."
9368862,"Provided is an antenna. The antenna, in one embodiment, includes a feed element having a first feed element end and a second feed element end, the first feed element end configured to electrically connect to a positive terminal of a transmission line. The antenna, in this embodiment, further includes a ground element having a first ground element end and a second ground element end, the first ground element end configured to electrically connect to a negative terminal of the transmission line. In this particular embodiment, the first ground element end is located proximate and inside the first feed element end, and the second ground element end is located proximate and outside the second feed element end."
9373416,"A method and system for testing a memory is provided in the present invention. The method includes the following steps. Each of at least one address bit to be tested of the memory is set to a fixed value. Current test data is written into memory unit(s) of the memory which the set address bit(s) correspond(s) to. Current read back data is read from the memory unit(s) which the set address bit(s) correspond(s) to. The current test data is compared with the current read back data. It is judged whether there is any signal integrity problem in unset address bit(s) of the memory according to the comparison result of the current test data and the current read back data, in order to determine fault address bit(s). The method and system for testing a memory provided by the present invention may determine fault address bit(s) of the memory simply and quickly."
9377510,"A method for reducing peak power during a scan shift cycle is presented. The method comprises multiplexing a test clock with a functional clock on a integrated circuit at the root of a clock tree. The method also comprises adding a plurality of delay elements on a clock path, wherein the clock path is a signal resulting from the multiplexing. Further, the method comprises routing the clock path to a plurality of cores and a cache, e.g., an L2C cache, on the integrated circuit. Finally the method comprises staggering the test clock received by each of the plurality of cores and the cache by employing the delay elements during a scan shift cycle."
9378139,"A system, method, and computer program product for low-latency scheduling and launch of memory defined tasks. The method includes the steps of receiving a task metadata data structure to be stored in a memory associated with a processor, transmitting the task metadata data structure to a scheduling unit of the processor, storing the task metadata data structure in a cache unit included in the scheduling unit, and copying the task metadata data structure from the cache unit to the memory."
9378169,A method including sorting read/write commands initiated by a memory controller based upon a destination page within a memory device. The read/write commands having a highest priority level are determined. The commands are then categorized as either page movement commands or data movement commands. The page movement commands or data movement commands are sent to the memory device based upon a signal indicating a current direction of a data bus providing communication between the memory controller and the memory device and further based upon a priority level.
9379156,Techniques for per-channel image intensity correction includes linear interpolation of each channel of spectral data to generate corrected spectral data.
9379202,"Embodiments of the invention generally relate to interposers for packaging integrated circuits. The interposers include capacitive devices for reducing signal noise and leakage between adjacent integrated circuits coupled to the interposers. The capacitive devices are formed from doped semiconductor layers. In one embodiment, an interposer includes a substrate having doped regions of opposing conductivities. First and second oxide layers are disposed over the doped regions. A first interconnect disposed in the second oxide layer is electrically coupled to a doped region of a first conductivity, and a second interconnect disposed in the second oxide is electrically coupled to a doped region of a second conductivity. Additional capacitive devices utilizing doped semiconductor layers are also disclosed."
9383851,"A solution is proposed for processing input in a lower power user interface of touch-sensitive display panels. According to an embodiment, a mobile computing device is placed in the low power mode. During this mode, the sensor controller produces a raw event/interrupts on a detected touch. Upon detecting a touch, the sensor controller also automatically increases the scan rate of the touch sensor, while the triggered event or interrupt proceeds to wake the system into a higher power state. Subsequent touch data received while the system is booting into the higher power state is buffered by the timing controller, or by a bridge chipset, while the processor(s) in the power up. When awake, the processor(s) collect the touch samples from the buffer, and processes the touch samples, generating updated displays where necessary."
9383968,"One embodiment of the present invention includes a method for simplifying arithmetic operations by detecting operands with elementary values such as zero or 1.0. Computer and graphics processing systems perform a great number of multiply-add operations. In a significant portion of these operations, the values of one or more of the operands are zero or 1.0. By detecting the occurrence of these elementary values, math operations can be greatly simplified, for example by eliminating multiply operations when one multiplicand is zero or 1.0 or eliminating add operations when one addend is zero. The simplified math operations resulting from detecting elementary valued operands provide significant savings in overhead power, dynamic processing power, and cycle time."
9384001,"A processing system includes a microprocessor, a hardware decoder arranged within the microprocessor, and a translator operatively coupled to the microprocessor. The hardware decoder is configured to decode instruction code non-native to the microprocessor for execution in the microprocessor. The translator is configured to form a translation of the instruction code in an instruction set native to the microprocessor and to connect a branch instruction in the translation to a chaining stub. The chaining stub is configured to selectively cause additional instruction code at a target address of the branch instruction to be received in the hardware decoder without causing the processing system to search for a translation of additional instruction code at the target address."
9384410,"A method for encoding at least one extra bit in an image compression and decompression system. The method includes accessing an input image, and compressing the input image into a compressed image using an encoder system, wherein said encoding system implements an algorithm for encoding at least one extra bit. The method further includes communicatively transferring the compressed image to a decoding system, and decompressing the compressed image into a resulting uncompressed image that is unaltered from said input image, wherein the algorithm for encoding enables the recovery of the at least one extra bit."
9384570,"A graphics processing system includes a central processing unit that processes a cubic Bezier curve corresponding to a filled cubic Bezier path. Additionally, the graphics processing system includes a cubic preprocessor coupled to the central processing unit that formats the cubic Bezier curve to provide a formatted cubic Bezier curve having quadrilateral control points corresponding to a mathematically simple cubic curve. The graphics processing system further includes a graphics processing unit coupled to the cubic preprocessor that employs the formatted cubic Bezier curve in rendering the filled cubic Bezier path. A rendering unit and a display cubic Bezier path filling method are also provided."
9384583,"An application executing on a rendering computer invokes a physics function request, e.g., to model the movement and interaction of objects to be rendered. The physics function request specifies a physics function to be performed on input data. Physics function request data is formatted for transmission over a network. The physics computer receives the physics function request data and performs an associated physics function using a physics GPU to generate physics computation result data. The physics computation result data is transmitted to the rendering computer over the network. A rendering GPU renders an image using the physics computation result data."
9384703,"A method for driving a display panel having a variable refresh rate is disclosed. The method comprises receiving a current input frame from an image source. It also comprises determining a first number of re-scanned frames to insert between the current input frame and a subsequent input frame, wherein the re-scanned frames repeat the current input frame, and wherein the determining depends on a minimum refresh interval (MRI) of the display panel. Further, it comprises calculating intervals to insert the first number of re-scanned frames between the current input frame and the subsequent input frame. Further, it comprises scanning the current input frame for display on the display panel. Finally it comprises inserting the first number of re-scanned frames at the respective intervals between the current input frame and the subsequent input frame from the image source, wherein the inserting is operable to reduce charge accumulation in the display panel."
9384713,"Typical hybrid graphics systems operate in either a “high-performance mode” or in an “energy saver mode.” While operating in the high-performance mode, a discrete graphics processing unit (dGPU) performs high-performance graphics processing operations and also receives and satisfies access requests targeting a configuration space within the dGPU. While operating in the energy saver mode, an integrated graphics processing unit (iGPU) performs graphics processing operations and the dGPU is powered down. In this scenario, a system management unit (SMU) intercepts and satisfies access requests targeting the dGPU. Since access requests targeting the dGPU are satisfied while the dGPU is powered down, the dGPU continues to be enumerated in the system using the same system resources as originally granted, and can therefore be switched to for implementing high-performance mode more quickly than if it was removed, and required a complete plug-and-play re-enumeration and re-allocation of system resources."
9385098,"An integrated circuit package is described including a substrate, an integrated circuit die, a first plurality of solder bump structures, and a first plurality of variable-size solder bump structures. The first plurality of solder bump structures electrically couple the integrated circuit die to the substrate. The first plurality of variable-size solder bump structures are disposed on a bottom surface of the substrate. The first plurality of variable-size solder bump structures are sized to be substantially coplanar with a seating plane of the integrated circuit package."
9386326,Techniques for synchronizing error concealment during video decoding include determining a decoding error. A recovery point within a current frame is determined for each decoding error. The determined recovery point may be the start of the next good slice of a frame after the current frame containing the error. The number of macroblock to be concealed is also determined. The determined number of macroblocks from the recovery point may then be concealed in hardware or software. The techniques for concealing errors may also include determining available macroblocks for use in concealing the error. The techniques for concealing errors may further include selecting a given concealment mode.
9389617,"A system and method are provided for sensing current. A current source is configured to generate a current and a pulsed sense enable signal is generated. A sense voltage across a resistive sense mechanism is sampled according to the sense enable signal, where the sense voltage represents a measurement of the current. A system includes the current source and a current sensing unit. The current source is configured to generate a current. The current sensing unit is coupled the current source and is configured to generate a pulsed sense enable signal and sample the sense voltage across a resistive sense mechanism according to the pulsed sense enable signal."
9389622,"A voltage margin controller, an IC included the same and a method of controlling voltage margin for a voltage domain of an IC are disclosed herein. In one embodiment, the voltage margin controller includes: (1) monitoring branches including circuit function indicators configured to indicate whether circuitry in the voltage domain could operate at corresponding candidate reduced voltage levels and (2) a voltage margin adjuster coupled to the monitoring branches and configured to develop a voltage margin adjustment for a voltage regulator of the voltage domain based upon an operating number of the circuit function indicators."
9389678,"The disclosure provides a digital camera. The digital camera includes an image sensor configured to produce image sensor data. The digital camera further includes (i) an image signal processor configured to receive and perform a plurality of on-camera processing operations on the image sensor data, where such processing operations yield a plurality of intermediate processed versions of the image sensor data, and (ii) a communication module configured to wirelessly transmit, to an off-camera image signal processor, image source data which includes at least one of: (a) the image sensor data and (b) one of the intermediate processed versions of the image sensor data, where such transmission is performed automatically in response to the producing the image sensor data."
9390042,"A processing unit exchanges data with another processing unit across a data connector that supports a particular communication protocol. When the communication protocol is updated to support a new packet type, a specification of that new packet type may be stored within software registers included within the processing unit. Under circumstances that require the use of the new packet type, packet generation logic may read the packet specification of the new packet type, then generate and transmit a packet of the new type."
9390464,"A raster operations (ROP) unit is configured to compress stencil values included in a stencil buffer. The ROP unit divides the stencil values into groups, subdivides each group into two halves, and selects an anchor value for each half. If the difference between each of the stencil values and the corresponding anchor lies within an offset range, and the difference between the two anchors lies within a delta range, then the group is compressible. For a compressible group, the ROP unit encodes the anchor value, offsets from anchors, and an anchor delta. This encoding enables the ROP unit to operate on the compressed group instead of the uncompressed stencil values, reducing the number of memory and computational operations associated with the stencil values. Consequently, the ROP unit reduces memory bandwidth use, reduces power consumption, and increases rendering rate compared to conventional ROP units that implement less flexible compression techniques."
9390540,"A deferred shading GPU, geometry data structure and method. One embodiment of the geometry data structure is found in a graphics processing subsystem operable to render a scene having a pixel represented by samples. The graphics processing subsystem includes: (1) a memory configured to store a geometry data structure associated with the pixel containing surface fragment coverage masks associated with the samples, and (2) a GPU configured to employ the surface fragment coverage masks to carry out deferred shading on the pixel."
9390543,"A graphics processing subsystem and method for computing a 3D clipmap. One embodiment of the subsystem includes: (1) a renderer operable to render a primitive surface representable by a 3D clipmap, (2) a geometry shader (GS) configured to select respective major-plane viewports for a plurality of clipmap levels, the major-plane viewports being sized to represent full spatial extents of the 3D clipmap relative to a render target (RT) for the plurality of clipmap levels, (3) a rasterizer configured to employ the respective major-plane viewports and the RT to rasterize a projection of the primitive surface onto a major plane corresponding to the respective major-plane viewports into pixels representing fragments of the primitive surface for each of the plurality of clipmap levels, and (4) a plurality of pixel shader (PS) instances configured to transform the fragments into respective voxels in the plurality of clipmap levels, thereby voxelizing the primitive surface."
9390663,"A liquid crystal display (LCD) overdrive interpolation circuit and method, and an LCD drive system incorporating the circuit or method. In one embodiment, the circuit includes: (1) a diagonal interpolator operable to perform a diagonal interpolation along a diagonal direction in a lookup table based on TO and FROM gray levels and (2) a further interpolator coupled to the diagonal interpolator and operable to perform a further interpolation based on a result of the diagonal interpolation and the FROM gray level."
9390788,"An SRAM clock circuit and an SRAM. In one embodiment, the SRAM clock circuit includes: (1) a plurality of transistor stacks optionally serially electrically couplable to form a configurable delay path through which a clock signal is buffered, and (2) a delay path select circuit respectively electrically coupled between pairs of the plurality of transistor stacks and operable to selectively electrically couple the plurality of transistor stacks to a base delay path, thereby activating the configurable delay path based on a desired delay."
9392082,"A communication interface and method for efficient robust header compression (RoHC). One embodiment of the communication interface includes: (1) a data flow associated with a context ID (CID) and a data flow status indicator, and having packets, and (2) a robust header compression (RoHC) compressor configured to employ the CID to compress headers of the packets and to mark the CID as reusable by another data flow if the data flow status indicator indicates the data flow is terminated."
9392158,"Embodiments of the present invention initially calculate a confidence score for the image environment surrounding the subject matter in order to determine the initial number of lens positions. Once the initial lens positions are determined, a sharpness score is calculated for each determined initial lens position. Using these sharpness scores, embodiments of the present invention generate a projection used to locate an estimated optimum focus position as well as to determine an estimated sharpness score at this lens position. Embodiments of the present invention then position the lens of the camera to calculate the actual sharpness score at the estimated optimum focus position, which is then compared to the estimated optimum sharpness score previously calculated. Based on this comparison, embodiments of the present invention dynamically determine whether it has a sufficient number of lens positions to determine the optimum focus position or if additional sample lens positions are needed."
9395414,"A method for performing scan based tests is presented. The method comprises routing scan data serially from a plurality of I/O ports to a plurality of partitions of an integrated circuit using a first clock signal operating at a first frequency, where each partition comprises a plurality of internal scan chains. The method also comprises deserializing the scan data to feed internal scan chains. Further, the method comprises generating a plurality of second clock signals operating at a second frequency using the first clock signal, where each partition receives a respective one of the plurality of second clock signals and where the plurality of second clock signals are staggered where each pulses at a different time. Finally, the method comprises shifting in the scan data into the internal scan chains at the rate of the second frequency."
9395738,A system and method are provided for regulating a voltage level at a load. The method configures a current control mechanism to generate a current through a first inductor and a second inductor that are coupled in series and configures a voltage control mechanism to provide a portion of the current to regulate the voltage level. The second inductor isolates the load from a parasitic capacitance of the current control mechanism. An electric power conversion device for regulating the voltage level at the load comprises the current control mechanism that is coupled to an electric power source and configured to generate a current through the first inductor and the second inductor that are coupled in series and the voltage control mechanism that is coupled to the second inductor and configured to provide a portion of the current to regulate the voltage level.
9395799,"Power management techniques for a Universal Serial Bus (USB) include determining an idle period on one or more USB ports by a main controller circuit of a USB host controller. The main controller circuit signals a suspend to a Power Management Controller (PMC) sub-circuit of the USB host controller, in response to the determined idle period. The PMC sub-circuit stores one or more operating parameters of the one or more USB ports in response to the suspend signal. The PMC sub-circuit also maintains the idle state on the one or more USB ports in response to the suspend signal. Thereafter, the main controller circuit is placed in a low energy state while the PMC sub-circuit maintains the idle state."
9395997,"Sequential fetch requests from a set of fetch requests are combined into longer coalesced requests that match the width of a system memory interface in order to improve memory access efficiency for reading the data specified by the fetch requests. The fetch requests may be of different classes and each data class is coalesced separately, even when intervening fetch requests are of a different class. Data read from memory is ordered according to the order of the set of fetch requests to produce an instruction stream that includes the fetch requests for the different classes."
9396117,"In one embodiment, a method for controlling an instruction cache including a least-recently-used bits array, a tag array, and a data array, includes looking up, in the least-recently-used bits array, least-recently-used bits for each of a plurality of cacheline sets in the instruction cache, determining a most-recently-used way in a designated cacheline set of the plurality of cacheline sets based on the least-recently-used bits for the designated cacheline, looking up, in the tag array, tags for one or more ways in the designated cacheline set, looking up, in the data array, data stored in the most-recently-used way in the designated cacheline set, and if there is a cache hit in the most-recently-used way, retrieving the data stored in the most-recently-used way from the data array."
9396512,"A non-transitory computer-readable storage medium having computer-executable instructions for causing a computer system to perform a method for constructing k-d trees, octrees, and quadtrees from radix trees is disclosed. The method includes assigning a Morton code for each of a plurality of primitives corresponding to leaf nodes of a binary radix tree, and sorting the plurality of Morton codes. The method includes building a radix tree requiring at most a linear amount of temporary storage with respect to the leaf nodes, wherein an internal node is built in parallel with one or more of its ancestor nodes. The method includes, partitioning the plurality of Morton codes for each node of the radix tree into categories based on a corresponding highest differing bit to build a k-d tree. A number of octree or quadtree nodes is determined for each node of the k-d tree. A total number of nodes in the octree or quadtree is determined, allocated and output."
9396515,"One embodiment sets forth a method for transforming 3-D images into 2-D rendered images using render target sample masks. A software application creates multiple render targets associated with a surface. For each render target, the software application also creates an associated render target sample mask configured to select one or more samples included in each pixel. Within the graphics pipeline, a pixel shader processes each pixel individually and outputs multiple render target-specific color values. For each render target, a ROP unit uses the associated render target sample mask to select covered samples included in the pixel. Subsequently, the ROP unit uses the render target-specific color value to update the selected samples in the render target, thereby achieving sample-level color granularity. Advantageously, by increasing the effective resolution using render target sample masks, the quality of the rendered image is improved without incurring the performance degradation associated with processing each sample individually."
9396585,"Embodiments of the present invention are directed to a novel approach for realistically modeling sub-surface scattering effects in three-dimensional objects of graphically rendered images. In an embodiment, an indirection map is generated for an image by analyzing the triangle mesh of one or more three-dimensional objects in the image and identifying pairs of edges between adjacent triangles in the mesh that have the same spatial locations in the three-dimensional representations, but which have different locations in the texture map. For each of these edges, the opposite triangle in each pair is projected into their corresponding edge's two-dimensional space. This allows samples which cross a seam in the two dimensional representation that would otherwise sample out into invalid data to be redirected to the spatially correct region of the texture and generate consistent results with non-seam areas."
9401004,"One embodiment of the present invention sets forth a technique for tracking and filtering state change methods provided to a graphics pipeline. State shadow circuitry at the start of the graphics pipeline may be configured in different modes. A track mode is used to capture the current state by storing state change methods that are transmitted to the graphics pipeline. A passthrough mode is used to provide different state data to the graphics pipeline without updating the current state stored in the state shadow circuitry. A replay mode is used to restore the current state to the graphics pipeline using the state shadow circuitry. Additionally, the state shadow circuitry may also be configured to filter the state change methods that are transmitted to graphics pipeline by removing redundant state change methods."
9405508,"This disclosure is directed to systems and methods for sorting data in which pre-sorting operations are performed on keys prior to those keys being reordered within memory. One example method includes generating, for each of a plurality of keys, an associated modified key. This operation is an example pre-sorting operation that occurs prior to any reordering of the keys. Once the modified keys are generated, the modified keys and/or associated information are processed in order to change the ordering of the keys in memory."
9405561,A system and method for implementing memory overlays for portable pointer variables. The method includes providing a program executable by a heterogeneous processing system comprising a plurality of a processors running a plurality of instruction set architectures (ISAs). The method also includes providing a plurality of processor specific functions associated with a function pointer in the program. The method includes executing the program by a first processor. The method includes dereferencing the function pointer by mapping the function pointer to a corresponding processor specific feature based on which processor in the plurality of processors is executing the program.
9406101,"A tessellation pipeline includes an alpha phase and a beta phase. The alpha phase includes pre-tessellation processing stages, while the beta phase includes post-tessellation processing stages. A processing unit configured to implement a processing stage in the alpha phase stores input graphics data within a buffer and then copies over that buffer with output graphics data, thereby conserving memory resources. The processing unit may also copy output graphics data directly to a level 2 (L2) cache for beta phase processing by other tessellation pipelines, thereby avoiding the need for fixed function copy-out hardware."
9406149,"A system and method are described for compressing image data using a combination of compression methods. Compression method combinations are provided to compress image data of a particular frame buffer format and antialiasing mode. Each method in the compression method combination is tried in turn to compress the image data in a tile. The best method that succeeded in compressing the image data is encoded in the compression bit state associated with the tile. Together, the compression bits, the compression method combination, and the frame buffer format provide sufficient information to decompress a tile."
9407427,"A first transceiver is configured to transmit a first data signal to a second transceiver across a communication link. The second transceiver maintains clock data recovery (CDR) lock with the first signal by adjusting a sampling clock configured to sample the first data signal. When the communication link reverses directions, the second transceiver is configured to transmit a second data signal to the first transceiver with the phase of that second data signal adjusted based on the adjustments made to the sampling clock."
9407814,"An approach is provided for performing back-end operations for camera control. In one example, a method includes the following: receiving a user edit via a user interface device that displays an interpretation of a scene at which a camera lens of the camera is pointing, wherein the user edit is based on user input that is associated with a selection region on the user interface device; generating an edits mask based on one or more matching image patches, which are based on the user edit and a high dynamic range (HDR) image generated by the camera; performing one or more tone mapping operations based on the edits mask and the HDR image in order to generate a tone mapped HDR image; and performing one or more metering operations based on the edits mask and the tone mapped HDR image in order to generate metering parameters for frame capturing operations."
9411390,"A programmable SoC (system on a chip) having optimized power domains and power islands. The SoC is an integrated circuit device including a plurality of power domains, each of the power domains having a respective voltage rail to supply power to the power domain. A plurality of power islands are included within the integrated circuit device, wherein each power domain includes at least one power island. A plurality of functional blocks are included within the integrated circuit device, wherein each power island includes at least one functional block. Each functional block is configured to provide a specific device functionality. The integrated circuit device adjusts power consumption in relation to a requested device functionality by individually turning on or turning off power to a selected one or more power domains, and for each turned on power domain, individually power gating one or more power islands."
9411595,"The disclosure provides systems and methods for maintaining cache coherency in a multi-threaded processing environment. For each location in a data cache, a global state is maintained specifying the coherency of the cache location relative to other data caches and/or to a shared memory resource backing the data cache. For each cache location, thread state information associated with a plurality of threads is maintained. The thread state information is specified separately and in addition to the global state, and is used to individually control read and write permissions for each thread for the cache location. The thread state information is also used, for example by a cache controller, to control whether uncommitted transactions of threads relating to the cache location are to be rolled back."
9411596,One embodiment of the present invention sets forth a graphics subsystem. The graphics subsystem includes a first tiling unit associated with a first set of raster tiles and a crossbar unit. The crossbar unit is configured to transmit a first set of primitives to the first tiling unit and to transmit a first cache invalidate command to the first tiling unit. The first tiling unit is configured to determine that a second bounding box associated with primitives included in the first set of primitives overlaps a first cache tile and that the first bounding box overlaps the first cache tile. The first tiling unit is further configured to transmit the primitives and the first cache invalidate command to a first screen-space pipeline associated with the first tiling unit for processing. The screen-space pipeline processes the cache invalidate command to invalidate cache lines specified by the cache invalidate command.
9411642,"When a computing system is running at a lower clock rate, in response to an event that triggers the computing system to increase the clock rate, a list of threads pending execution by the computing system is accessed. The list includes a thread that, when executed, causes the clock rate to increase. That thread is selected and executed before any other thread in the list is executed."
9411668,"A subsystem is configured to apply an offset voltage to a test, or canary, SRAM write driver circuit to create a condition that induces failure of the write operation. The offset voltage is incrementally increased until failure of the test write operation occurs in the canary SRAM circuit. The subsystem then calculates a probability of failure for the actual, non-test SRAM write operation, which is performed by an equivalent driver circuit with zero offset. The subsystem then compares the result to a benchmark acceptable probability figure. If the calculated probability of failure is greater than the benchmark acceptable probability figure, corrective action is initiated. In this manner, actual failures of SRAM write operations are anticipated, and corrective action reduces their occurrence and their impact on system performance."
9411715,"A system, method, and computer program product for optimizing thread stack memory allocation is disclosed. The method includes the steps of receiving source code for a program, translating the source code into an intermediate representation, analyzing the intermediate representation to identify at least two objects that could use a first allocated memory space in a thread stack memory, and modifying the intermediate representation by replacing references to a first object of the at least two objects with a reference to a second object of the at least two objects."
9412042,"A number of images of a scene are captured and stored. The images are captured over a range of values for an attribute (e.g., a camera setting). One of the images is displayed. A location of interest in the displayed image is identified. Regions that correspond to the location of interest are identified in each of the images. Those regions are evaluated to identify which of the regions is rated highest with respect to the attribute relative to the other regions. The image that includes the highest-rated region is then displayed."
9412194,"A method for sub-pixel texture mapping and filtering is provided. The method includes the steps of: dividing an area on a source image into a red (R) sub-area, a green (G) sub-area, and a blue (B) sub-area, where the area on the source image is corresponding to a pixel of a destination image presented by a display device; sampling the R sub-area to obtain a R color value, sampling the G sub-area to obtain a G color value, and sampling the B sub-area to obtain a B color value; and rendering R, G, B color components of the pixel of the destination image according to the R color value, the G color value, and the B color value."
9413518,"Systems and methods for stabilizing clock data recovery (CDR) by filtering the abrupt phase shift associated with data pattern transition in the input signal. The CDR circuit includes a data pattern detector coupled to a data pattern filter. The data pattern detector is capable of detecting the data patterns of the input signal. Accordingly, the data pattern filter can selectively generate a filter indication indicating to freeze or suppress the CDR phase caused by data pattern transition. The filter indication can be incorporated to a phase error signal, a gain function, and/or the control voltage driving the VCO."
9414052,"A system and method for correcting image data. Embodiments of the present invention provide calibration and image correction to overcome various lens effects including lens shading and lens imperfections. In one embodiment, the correction of image data is performed via utilization of a spline surface (e.g., Bezier surface). The use of spline surfaces facilitates efficient hardware implementation. The image correction may be performed on a per channel and illumination type basis. In another embodiment, the present invention provides a method for determine a spline surface to be used for calibrating an image signal processor to be used in correcting image data."
9417875,"One embodiment of the present invention sets forth a technique for performing aggregation operations across multiple threads that execute independently. Aggregation is specified as part of a barrier synchronization or barrier arrival instruction, where in addition to performing the barrier synchronization or arrival, the instruction aggregates (using reduction or scan operations) values supplied by each thread. When a thread executes the barrier aggregation instruction the thread contributes to a scan or reduction result, and waits to execute any more instructions until after all of the threads have executed the barrier aggregation instruction. A reduction result is communicated to each thread after all of the threads have executed the barrier aggregation instruction and a scan result is communicated to each thread as the barrier aggregation instruction is executed by the thread."
9417881,"One embodiment of the present invention sets forth a technique for dynamically allocating memory using one or more lock-free pop-only FIFOs. One or more lock-free FIFOs are populated with FIFO nodes, where each FIFO node represents a memory allocation of a predetermined size. Each particular lock-free FIFO includes memory allocations of a single size. Different lock-free FIFOs may include memory allocations for different sizes to service allocation requests for different size memory allocations. A lock-free mechanism is used to pop FIFO nodes from the FIFO. The use of the lock-free FIFO allows multiple consumers to simultaneously attempt to pop the head FIFO node without first obtaining a lock to ensure exclusive access of the FIFO."
9418400,"Systems and methods for rendering depth-of-field visual effect on images with high computing efficiency and performance. A diffusion blurring process and a Fast Fourier Transform (FFT)-based convolution are combined to achieve high-fidelity depth-of-field visual effect with Bokeh spots in real-time applications. The brightest regions in the background of an original image are enhanced with Bokeh effect by virtue of FFT convolution with a convolution kernel. A diffusion solver can be used to blur the background of the original image. By blending the Bokeh spots with the image with gradually blurred background, a resultant image can present an enhanced depth-of-field visual effect. The FFT-based convolution can be computed with multi-threaded parallelism."
9418437,"One embodiment of the present invention includes techniques for rasterizing primitives that include edges shared between paths. For each edge, a rasterizer unit selects and applies a sample rule from multiple sample rules. If the edge is shared, then the selected sample rule causes each group of coverage samples associated with a single color sample to be considered as either fully inside or fully outside the edge. Consequently, conflation artifacts caused when the number of coverage samples per pixel exceeds the number of color samples per pixel may be reduced. In prior-art techniques, reducing such conflation artifacts typically involves increasing the number of color samples per pixel to equal the number of coverage samples per pixel. Advantageously, the disclosed techniques enable rendering using algorithms that reduce the ratio of color to coverage samples, thereby decreasing memory consumption and memory bandwidth use, without causing conflation artifacts associated with shared edges."
9418616,"A graphics processing unit includes a set of geometry processing units each configured to process graphics primitives in parallel with one another. A given geometry processing unit generates one or more graphics primitives or geometry objects and buffers the associated vertex data locally. The geometry processing unit also buffers different sets of indices to those vertices, where each such set represents a different graphics primitive or geometry object. The geometry processing units may then stream the buffered vertices and indices to global buffers in parallel with one another. A stream output synchronization unit coordinates the parallel streaming of vertices and indices by providing each geometry processing unit with a different base address within a global vertex buffer where vertices may be written. The stream output synchronization unit also provides each geometry processing unit with a different base address within a global index buffer where indices may be written."
9418714,"One embodiment provides, in a sense amplifier for an electronic memory array in which a selected memory cell drives a developing voltage differential according to a logic state of the memory cell, a method to store the logic state. The method includes poising source voltages of first and second transistors at levels offset, respectively, by threshold voltages of the first and second transistors. The method also includes applying the voltage differential between a gate of the first transistor and a gate of the second transistor, the first and second transistors configured to oppose each other in a cross-coupled inverter stage of the sense amplifier."
9418730,"Handshaking sense amplifier. In accordance with a first embodiment, an electronic circuit includes a sense amplifier configured to differentially sense contents of a memory cell. The circuit also includes a self-timing circuit configured to detect a completion of evaluation by the sense amplifier; and to initiate a subsequent memory operation responsive to the completion. A completion of evaluation may not be aligned with a clock edge."
9419638,"A subsystem configured to implement an analog to digital converter that includes a high speed comparator with an embedded reference voltage level that functions as a calibrated threshold. A calibration element applies power to a reference voltage system. The calibration element then selects a differential analog voltage and applies the differential analog voltage to the inputs of the comparator. A digitally coded signal then configures an array of switches that connect complements of integrated resistors to each input of the comparator so that the switching point of the comparator occurs coincident with the applied differential analog reference voltage, nulling out the effect of the applied differential analog voltage and comparator errors. The calibration element then removes power from the reference voltage system. As a result, the comparator is configured with an embedded threshold that equals the differential analog reference voltage."
9420657,"Embodiments of the present invention provide a flat panel electronic device and a current control system thereof. The current control system comprises: a detecting module for detecting a current in a main circuit of the flat panel electronic device; and a control mechanism for reducing a brightness level of a backlight unit of the flat panel electronic device when the current in the main circuit is larger than or equal to a threshold so that the current in the main circuit is reduced to be less than the threshold. The current control system provided by the present invention reduces the current in the main circuit by reducing the brightness level of the backlight unit. Therefore, it is able to reduce the processing time by more than 10 ms compared with the prior art, and the fast and effective response is an important factor for extending the life of the battery."
9423825,"A mobile computing device comprising a display panel and a home button, the display panel being disposed on the exterior front surface and the home button being disposed on the exterior back surface of the mobile computing device. The front surface may be free of any additional user Input/Output devices apart from the display panel. The mobile computing device may further comprise an accelerometer and a phone circuit. Upon detection that the display panel faces away from a user during a phone call, displayed information on the display panel may be concealed automatically. The accelerometer may be also operable to detect shaking motions on the mobile computing device as a user command to turn on or turn off the display panel."
9423846,"In an integrated circuit device, a power circuit for maintaining asserted values on an input output pin of the device when a functional block of the device is placed in a sleep mode. The device includes a power circuit disposed along the periphery of the device, the power circuit configured to maintain power when the device is placed in a low-power mode. A plurality of input output blocks are included in the device and are for receiving external inputs for the integrated circuit device and for providing outputs from the integrated circuit device. The power circuit is coupled to provide power to at least one of the input output blocks to maintain state when the integrated circuit device is in the low-power mode."
9424038,"A compiler-controlled technique for scheduling threads to execute different regions of a program. A compiler analyzes program code to determine a control flow graph for the program code. The control flow graph contains regions and directed edges between regions. The regions have associated execution priorities. The directed edges indicate the direction of program control flow. Each region has a thread frontier which contains one or more regions. The compiler inserts one or more update predicate mask variable instructions at the end of a region. The compiler also inserts one or more conditional branch instructions at the end of the region. The conditional branch instructions are arranged in order of execution priority of the regions in the thread frontier of the region, to enforce execution priority of the regions at runtime."
9424138,"Various embodiments relating to saving and recovering a hardware architecture state are provided. In one embodiment, during a first mode of operation, entries in a first portion of a random-access memory (RAM) are manipulated. A current version of less than all of the entries of the first portion is saved to a checkpointed version in response to a checkpoint event that triggers operation in a second mode of operation. During the second mode of operation, entries in a second portion of the RAM are manipulated. The checkpointed version of less than all of the entries of the first portion is recovered as the current version in response to a restore event that triggers resumption of operation in the first mode."
9424201,"One embodiment of the present invention sets forth a computer-implemented method for migrating a memory page from a first memory to a second memory. The method includes determining a first page size supported by the first memory. The method also includes determining a second page size supported by the second memory. The method further includes determining a use history of the memory page based on an entry in a page state directory associated with the memory page. The method also includes migrating the memory page between the first memory and the second memory based on the first page size, the second page size, and the use history."
9424227,"Non-contiguous or tiled payload data are efficiently transferred between peers over a fabric. Specifically, a client transfers a byte enable message to a peer device via a mailbox mechanism, where the byte enable message specifies which bytes of the payload data being transferred via the data packet are to be written to the frame buffer on the peer device and which bytes are not to be written. The client transfers the non-contiguous or tiled payload payload data to the peer device. Upon receiving the payload data, the peer device writes bytes from the payload data into the target frame buffer for only those bytes enabled via the byte enable message. One advantage of the present invention is that non-contiguous or tiled data are transferred over a fabric with improved efficiency."
9424383,"An integrated circuit (IC) is designed that includes one variant having a plurality of a modular circuits communicatively coupled together and a second variant having a sub-set of the plurality of modular circuits. The modular circuits are then laid out on a wafer for fabricating each of the variants of the IC. The layout includes routing communicative couplings between the sub-set of the modular circuits of the second variant to the other modular circuits of the first variant in one or more metallization layers to be fabricated last. Fabricating the IC is then started, up to but not including the one or more metallization layers to be fabricated last. One or more of the plurality of variants of the IC is selected based upon a demand predicted during fabrication. Fabrication then continues with the last metallization layers of the IC according to the selected layout."
9424684,"A system, method, and computer program product are provided for simulating light transport. In operation, a distribution function is decomposed utilizing a technique for sampling from a probability distribution (e.g. the Alias Method, etc.). Additionally, light transport associated with at least one scene is simulated utilizing information associated with the decomposed distribution function."
9425171,"One embodiment of the present invention sets forth a technique for packaging an integrated circuit die. The technique includes bonding a first surface of the integrated circuit die to a first substrate via a first plurality of solder bump structures and bonding a second substrate to a second surface of the integrated circuit die. The technique further includes bonding the first substrate to a third substrate via a second plurality of solder bump structures and, after bonding the first substrate to the third substrate, removing the second substrate from the second surface of the integrated circuit die. The technique further includes disposing a heat sink on the second surface of the integrated circuit die."
9425772,"The described systems and methods can facilitate examination of device parameters including analysis of relatively dominant characteristic impacts on delays. In one embodiment, at least some coupling components (e.g., metal layer wires, traces, lines, etc.) have a relatively dominant impact on delays and the delay is in part a function of both capacitance and resistance of the coupling component. In one embodiment, a system comprises a plurality of dominant characteristic oscillating rings, wherein each respective one of the plurality of dominant characteristic oscillating rings includes a respective dominant characteristic. Additional analysis can be performed correlating the dominant characteristic delay impact results with device fabrication and operation."
9430242,Systems and methods for throttling GPU execution performance to avoid surges in DI/DT. A processor includes one or more execution units coupled to a scheduling unit configured to select instructions for execution by the one or more execution units. The execution units may be connected to one or more decoupling capacitors that store power for the circuits of the execution units. The scheduling unit is configured to throttle the instruction issue rate of the execution units based on a moving average issue rate over a large number of scheduling periods. The number of instructions issued during the current scheduling period is less than or equal to a throttling rate maintained by the scheduling unit that is greater than or equal to a minimum throttling issue rate. The throttling rate is set equal to the moving average plus an offset value at the end of each scheduling period.
9430400,"One embodiment of the present invention sets forth a computer-implemented method for altering migration rules for a unified virtual memory system. The method includes detecting that a migration rule trigger has been satisfied. The method also includes identifying a migration rule action that is associated with the migration rule trigger. The method further includes executing the migration rule action. Other embodiments of the present invention include a computer-readable medium, a computing device, and a unified virtual memory subsystem. One advantage of the disclosed approach is that various settings of the unified virtual memory system may be modified during program execution. This ability to alter the settings allows for an application to vary the manner in which memory pages are migrated and otherwise manipulated, which provides the application the ability to optimize the unified virtual memory system for efficient execution."
9430863,"A system, method, and computer program product are provided for constructing a hierarchical acceleration data structure that supports ray tracing of motion blur. In use, scene description data associated with an image to be generated is received. Additionally, a hierarchical acceleration data structure for performing ray tracing on the scene description data is constructed, where the hierarchical acceleration data structure supports ray tracing of motion blur."
9432590,One embodiment of the present invention sets forth a technique for reducing flicker in image frames captured with a rolling shutter. A flicker detection and correction engine selects a first channel from a first image frame for processing. The flicker detection and correction engine subtracts each pixel value in the first channel from a corresponding pixel value in a prior image frame to generate a difference image frame. The flicker detection and correction engine identifies a first alternating current (AC) component based on a discrete cosine transform (DCT) associated with the difference image frame. The flicker detection and correction engine reduces flicker that is present in the first image frame based on the first AC component. One advantage of the disclosed techniques is that the flicker resulting from fluctuating light sources is correctly detected and reduced or eliminated irrespective of the frequency of the fluctuating light source.
9432674,"Multi-level prediction mode encoding type decision methods and systems are presented. In one embodiment, an indication of a prediction mode level is received and encoding is performed in accordance with said prediction mode level. The indication of said prediction mode level is programmable and can be set at different levels. The prediction mode level can be associated with a programmable encoding type decision point (e.g., early, intermediate, late, etc.). The encoding process includes deciding upon an I-type or P-type encoding. In one embodiment, a multi-stage encoding type method is also implemented in intra-prediction related search and inter-prediction related search and respective corresponding prediction operations are performed, wherein at least a portion of the intra-prediction related search and the inter-prediction related search are performed in parallel."
9435861,"Systems and methods for latches are presented. In one embodiment a system includes scan in propagation component, data propagation component, and control component. The scan in propagation component is operable to select between a scan in value and a recirculation value. The data propagation component is operable to select between a data value and results forwarded from the scan in propagation component, wherein results of the data propagation component are forwarded as the recirculation value to the scan in propagation component. The control component is operable to control an indication of a selection by the scan in propagation component and the data propagation component."
9436235,A cooling subsystem is provided for dissipating heat from processor. The cooling subsystem includes a heat sink comprising an upper portion having a plurality of fins formed therein and a base portion fixed to the upper portion to form a vapor chamber in an enclosed volume between the upper portion and the base portion.
9436243,"A power source management system of a circuit board that comprises: a processor, comprising a core voltage input terminal; and a core voltage feedback terminal; and a voltage regulating member, comprising a setting terminal with a fixed reference voltage provided thereto; a detecting terminal connected to the core voltage feedback terminal to detect a feedback core voltage from the core voltage feedback terminal; and a core voltage output terminal connected to the core voltage input terminal to provide a core voltage thereto, wherein the core voltage is regulated by the voltage regulating member based on the feedback core voltage, such that the feedback core voltage is equal to the fixed reference voltage, wherein an offset voltage equal to a difference between a desired core voltage of the processor and the fixed reference voltage is provided between the core voltage input terminal and the core voltage feedback terminal by the processor."
9436447,"A device compiler and linker within a parallel processing unit (PPU) is configured to optimize program code of a co-processor enabled application by rematerializing a subset of live-in variables for a particular block in a control flow graph generated for that program code. The device compiler and linker identifies the block of the control flow graph that has the greatest number of live-in variables, then selects a subset of the live-in variables associated with the identified block for which rematerializing confers the greatest estimated profitability. The profitability of rematerializing a given subset of live-in variables is determined based on the number of live-in variables reduced, the cost of rematerialization, and the potential risk of rematerialization."
9436475,"A system and method for executing sequential code in the context of a single-instruction, multiple-thread (SIMT) processor. In one embodiment, the system includes: (1) a pipeline control unit operable to create a group of counterpart threads of the sequential code, one of the counterpart threads being a master thread, remaining ones of the counterpart threads being slave threads and (2) lanes operable to: (2a) execute certain instructions of the sequential code only in the master thread, corresponding instructions in the slave threads being predicated upon the certain instructions and (2b) broadcast branch conditions in the master thread to the slave threads."
9436504,"One embodiment of the present disclosure sets forth an enhanced way for GPUs to queue new computational tasks into a task metadata descriptor queue (TMDQ). Specifically, memory for context data is pre-allocated when a new TMDQ is created. A new TMDQ may be integrated with an existing TMDQ, where computational tasks within that TMDQ include task from each of the original TMDQs. A scheduling operation is executed on completion of each computational task in order to preserve sequential execution of tasks without the use of atomic locking operations. One advantage of the disclosed technique is that GPUs are enabled to queue computational tasks within TMDQs, and also create an arbitrary number of new TMDQs to any arbitrary nesting level, without intervention by the CPU. Processing efficiency is enhanced where the GPU does not wait while the CPU creates and queues tasks."
9436625,"Banks within a dynamic random access memory (DRAM) are managed with virtual bank managers. A DRAM controller receives a new memory access request to DRAM including a plurality of banks. If the request accesses a location in DRAM where no virtual bank manager includes parameters for the corresponding DRAM page, then a virtual bank manager is allocated to the physical bank associated with the DRAM page. The bank manager is initialized to include parameters needed by the DRAM controller to access the DRAM page. The memory access request is then processed using the parameters associated with the virtual bank manager. One advantage of the disclosed technique is that the banks of a DRAM module are controlled with fewer bank managers than in previous DRAM controller designs. As a result, less surface area on the DRAM controller circuit is dedicated to bank managers."
9436969,"One embodiment of the present invention sets forth a technique for redistributing geometric primitives generated by tessellation and geometry shaders for processing by multiple graphics pipelines. Geometric primitives that are generated in a first processing cycle are collected and redistributed more evenly and in smaller tasks to the multiple graphics pipelines for vertex processing in a second processing cycle. The smaller tasks do not exceed the resource limits of a graphics pipeline and the per-vertex processing workloads of the graphics pipelines in the second cycle are balanced and make full use of resources. Therefore, the performance of the tessellation and geometry shaders is improved."
9436971,"A system, method, and computer program product are provided for accessing multi-sample surfaces. A multi-sample store instruction that specifies data for a single sample of a multi-sample pixel and a sample mask is received and the data for the single sample is stored to each sample of the multi-sample pixel that is enabled according to the sample mask. A multi-sample load instruction that specifies a multi-sample pixel is received, and, in response to executing the multi-sample load instruction, data for one sample of the multi-sample pixel is received. A determination is made that the data for the one sample of the multi-sample pixel represents multi-sample pixel data for at least one additional sample of the multi-sample pixel."
9437025,"A system and method for compressing stencil data attendant to rendering an image. In one embodiment, the method includes: (1) selecting a base stencil value for a particular group, (2) selecting a single-bit delta value for each sample in the particular group and (3) storing the stencil base value and the delta values in a frame buffer."
9437031,"A large non-patterned noise texture occupies a relatively small physical memory space. Each of a small set of physical pages in physical memory includes noise texels forming part of a noise texture. A large “virtual” noise texture is created by mapping each one of a large number of pages in virtual address space to one of the small set of physical pages; multiple virtual pages may be mapped to the same physical page. The physical page that each virtual page maps to is randomly or pseudo-randomly selected such that the resulting noise texture appears to be non-repeating. When a noise texel is requested by reference to a virtual address during rendering, the virtual address of the virtual page is translated to the corresponding physical address, and the noise texel is retrieved."
9437039,"A method of generating an image. The method includes simulating a presence of at least one light source within a virtualized three dimensional space. Within the virtualized three dimensional space, a light sensing plane is defined. The light sensing plane includes a matrix of a number of pixels to be displayed on a display screen. The method further includes using a light transport procedure, computing a gradient value for each pixel of the matrix to produce a number of gradient values. The gradient computation involves selecting a plurality of light path pairs that contribute to a pixel wherein the selection is biased towards selection of more light paths that pass through pixels having larger gradient values. The plurality of gradient values are converted to a plurality of light intensity values which represent the image."
9437040,"A system, method, and computer program product are provided for implementing anti-aliasing operations using a programmable sample pattern table. The method includes the steps of receiving an instruction that causes one or more values to be stored in one or more corresponding entries of the programmable sample pattern table and performing an anti-aliasing operation based on at least one value stored in the programmable sample pattern table. At least one value is selected from the programmable sample pattern table based on, at least in part, a location of one or more corresponding pixels."
9437042,"A system, method, and computer program product are provided for performing dicing on a primitive. In use, a primitive to be rendered is identified. Additionally, preprocessing is performed on the primitive. Further, dicing is performed on the primitive, based on the preprocessing."
9437165,"A method includes scanning, through a processor of a data processing device communicatively coupled to a memory, display data to be rendered on a display unit communicatively coupled to the data processing device for boundaries of one or more virtual object(s) therein. The method also includes rendering, through the processor, a portion of the display data outside the boundaries of the one or more virtual object(s) at a reduced level compared to a portion of the display data within the boundaries on the display unit."
9438213,"A flip-flop circuit may include a master latch and a slave latch. Each latch may have a transparent mode and a storage mode. The slave latch may be in storage mode when the master latch is in transparent mode; and vice-versa. A clock signal may control the mode of each latch through a pair of clock-gated pull-up transistors and a pair clock-gated of pull-down transistors, for a total of four clock-gated transistors. The clock-gated transistors may be shared by the master latch and the slave latch. Fewer clock-gated transistors may be required when they are shared, as opposed to not being shared. Clock-gated transistors may have parasitic capacitance and consume power when subjected to a varying clock signal, due to the charging and discharging of the parasitic capacitance. Having fewer clock-gated transistors thus may reduce the power consumed by the flip-flop circuit."
9442755,"A method and a system are provided for hardware scheduling of indexed barrier instructions. Execution of a plurality of threads to process instructions of a program that includes a barrier instruction is initiated and when each thread reaches the barrier instruction, the thread pauses execution of the instructions. A first sub-group of threads in the plurality of threads is associated with a first sub-barrier index and a second sub-group of threads in the plurality of threads is associated with a second sub-barrier index. When the barrier instruction can be scheduled for execution, threads in the first sub-group are executed serially and threads in the second sub-group are executed serially and at least one thread in the first sub-group is executed in parallel with at least one thread in the second sub-group."
9442759,"A time slice group (TSG) is a grouping of different streams of work (referred to herein as “channels”) that share the same context information. The set of channels belonging to a TSG are processed in a pre-determined order. However, when a channel stalls while processing, the next channel with independent work can be switched to fully load the parallel processing unit. Importantly, because each channel in the TSG shares the same context information, a context switch operation is not needed when the processing of a particular channel in the TSG stops and the processing of a next channel in the TSG begins. Therefore, multiple independent streams of work are allowed to run concurrently within a single context increasing utilization of parallel processing units."
9445242,"A method for supporting broadcast transmission in a wireless communication system (200) that comprises a plurality of communication cells, with broadcast content being routed from a base station (210) to at least one wireless communication unit (225, 226) via at least one relay node (RN) (224) is described. The method comprises, at the base station (210) broadcasting the broadcast content from the base station (210) to at least one from a group consisting of: the at least one RN (224), the at least one wireless communication unit (226); and supplementing the broadcast transmission with at least one augmented unicast transmission associated with the broadcast content. A base station (210), an integrated circuit and a non-transitory computer program product comprising executable program code are also described. A relay node (224), an integrated circuit, a method performed at the relay node and a non-transitory computer program product comprising executable program code are also described."
9448125,"A method, in one embodiment, can include modeling and calibrating two types of sensors that are part of a semiconductor device. In addition, the method can include determining a temperature and voltage based on data received from the two sensors."
9448766,"An arithmetic logic stage in a graphics pipeline includes a number of arithmetic logic units (ALUs). The ALUs each include, for example, a multiplier and an adder. The ALUs are interconnected by circuitry that, for example, routes the output from the multiplier in one ALU to both the adder in that ALU and an adder in another ALU."
9448779,One embodiment of the present invention sets forth a technique for translating application programs written using a parallel programming model for execution on multi-core graphics processing unit (GPU) for execution by general purpose central processing unit (CPU). Portions of the application program that rely on specific features of the multi-core GPU are converted by a translator for execution by a general purpose CPU. The application program is partitioned into regions of synchronization independent instructions. The instructions are classified as convergent or divergent and divergent memory references that are shared between regions are replicated. Thread loops are inserted to ensure correct sharing of memory between various threads during execution by the general purpose CPU.
9448803,"A method and a system are provided for hardware scheduling of barrier instructions. Execution of a plurality of threads to process instructions of a program that includes a barrier instruction is initiated, and when each thread reaches the barrier instruction during execution of program, it is determined whether the thread participates in the barrier instruction. The threads that participate in the barrier instruction are then serially executed to process one or more instructions of the program that follow the barrier instruction. A method and system are also provided for impatient scheduling of barrier instructions. When a portion of the threads that is greater than a minimum number of threads and less than all of the threads in the plurality of threads reaches the barrier instruction each of the threads in the portion is serially executed to process one or more instructions of the program that follow the barrier instruction."
9448804,"One embodiment of the present invention sets forth a technique for managing buffer entries in a tile-based architecture. The technique includes receiving a first plurality of graphics primitives and a first buffer address at which attributes associated with the first plurality of graphics primitives are stored. The technique further includes, for each tile included in a plurality of tiles, transmitting the first plurality of graphics primitives and the first buffer address to a screen space pipeline and receiving an acknowledgement from the screen space pipeline indicating that processing the first plurality of graphics primitives has completed. The technique further includes determining that processing the first plurality of graphics primitives has completed for a last tile included in the plurality of tiles and that the acknowledgement has been received for each tile included in the plurality of tiles, and, in response, releasing a buffer entry associated with the first buffer address."
9448806,"A floating-point unit and a method of identifying exception cases in a floating-point unit. In one embodiment, the floating-point unit includes: (1) a floating-point computation circuit having a normal path and an exception path and operable to execute an operation on an operand and (2) a decision circuit associated with the normal path and the exception path and configured to employ a flush-to-zero mode of the floating-point unit to determine which one of the normal path and the exception path is appropriate for carrying out the operation on the operand."
9448837,"Techniques are provided for restoring thread groups in a cooperative thread array (CTA) within a processing core. Each thread group in the CTA is launched to execute a context restore routine. Each thread group, executes the context restore routine to restore from a memory a first portion of context associated with the thread group, and determines whether the thread group completed an assigned function prior to executing the context restore routine. If the thread group completed an assigned function prior to executing the context restore routine, then the thread group exits the context restore routine. If the thread group did not complete the assigned function prior to executing the context restore routine, then the thread group executes one or more operations associated with a trap handler routine. One advantage of the disclosed techniques is that the trap handling routine operates efficiently in parallel processors."
9448935,"Techniques are disclosed for performing memory access operations. A texture unit receives a memory access operation that includes a tuple associated with a first view in a plurality of views. The texture unit retrieves a first hash value associated with a first texture header in a plurality of texture headers, where the first texture header is related to the first view. The texture unit retrieves a second hash value associated with a second texture header in the plurality of texture headers, where the second texture header is related to a second view. The texture unit determines whether the first view is potentially aliased with the second view, based on the first and second hash values. If so, then the texture unit invalidates a cache entry in a cache memory associated with the second texture header. Otherwise, the texture unit maintains the cache entry."
9451187,"Embodiments of the present invention are directed to methods and systems for performing automatic lens shading correction using module-specific calibrations. According to one aspect of the invention, a method is provided that is performed over three main stages. During a first stage, radial symmetric component data is determined that is common to camera modules of the type to be calibrated. During the second stage, the actual measurement of the shading profile of one or more specific camera modules is performed. In the third and final stage is the extrapolation stage, the base measurement surfaces of a camera module type determined in the first stage are extrapolated and modified with the module-specific Bezier correction surface and calibration data of the second stage. The output surfaces of this third and final stage are used to correct for the shading profile in the camera module, depending on the light-source estimation."
9454792,"A device, system and method for transferring network data are presented. The device includes: a data processing module configured to convert a data signal in a TMDS signal output via a DVI of a graphics card to network data for being transferred via a network; and a network transmitter for receiving the network data and transferring the network data to an external device via the network. The data signal is generated by encoding texture data generated by a GPU of the graphics card by a digital video sender of the graphics card. The texture data is generated by binding a pointer to general computing data stored in a device memory of the graphics card to a texture stored in the device memory by the GPU. The general computing data is generated by general computation executed by the GPU."
9454806,"A computer implemented method of performing an approximate-nearest-neighbor search is disclosed. The method comprises dividing an image into a plurality of tiles. Further, for each of the plurality of tiles, perform the following in parallel on a processor: (a) dividing image patches into a plurality of clusters, wherein each cluster comprises similar images patches, and wherein the dividing continues recursively until a size of a cluster is below a threshold value; (b) performing a nearest-neighbor query within each of the plurality of clusters; and (c) performing collaborative filtering in parallel for each image patch, wherein the collaborative filtering aggregates and processes nearest neighbor image patches from a same cluster containing a respective image patch to form an output image."
9454843,"A system, method, and computer program product are provided for anti-aliasing. During a first processing pass of a plurality of graphics primitives, z data is computed for multiple samples of each pixel in an image to generate a multi-sample z buffer. During a second processing pass of the graphics primitives, computed color values corresponding to each pixel in a color buffer that stores one color value for each pixel are accumulated."
9454975,"Voice trigger. In accordance with a first method embodiment, a long term average audio energy is determined based on a one-bit pulse-density modulation bit stream. A short term average audio energy is determined based on the one-bit pulse-density modulation bit stream. The long term average audio energy is compared to the short term average audio energy. Responsive to the comparing, a voice trigger signal is generated if the short term average audio energy is greater than the long term average audio energy. Determining the long term average audio energy may be performed independent of any decimation of the bit stream."
9459635,"A system and method are provided for regulating a voltage at a load. A current source is configured to provide a current to a voltage control mechanism and the voltage control mechanism is configured to provide a portion of the current to the load. The current is generated based on the portion of the current that is provided to the load. A system includes the current source, an upstream controller, and the voltage control mechanism that is coupled to the load. The upstream controller is coupled to the current source and is configured to control a current that is generated by the current source based on a portion of the current that is provided to the load."
9459876,"A system, method, and computer program product for ensuring forward progress of threads that implement divergent operations in a single-instruction, multiple data (SIMD) architecture is disclosed. The method includes the steps of allocating a queue data structure to a thread block including a plurality of threads, determining that a current instruction specifies a yield operation, pushing a token onto the second side of the queue data structure, disabling any active threads in the thread block, popping a next pending token from the first side of the queue data structure, and activating one or more threads in the thread block according to a mask included in the next pending token."
9460546,"A hierarchical structure for accelerating ray tracing operations in scene rendering includes a plurality of geometry objects, and a single acceleration structure constructed over the collective plurality of geometry objects. Each geometry object includes primitives of a predefined type, whereby primitives within the plurality of geometry objects collectively define a geometry included within a region of the scene which is to be rendered. The single acceleration structure is operable for accelerating ray tracing operations for the primitives included within the plurality of geometry objects, and is constructed over the plurality of the geometry objects without an intervening bounding volume representation of the plurality of primitives included within the geometry objects."
9460776,"The disclosure provides for an SRAM array having a plurality of wordlines and a plurality of bitlines, referred to generally as SRAM lines. The array has a plurality of cells, each cell being defined by an intersection between one of the wordlines and one of the bitlines. The SRAM array further includes voltage boost circuitry operatively coupled with the cells, the voltage boost circuitry being configured to provide an amount of voltage boost that is based on an address of a cell to be accessed and/or to provide this voltage boost on an SRAM line via capacitive charge coupling."
9461428,"Embodiments of the present invention may be directed to an electronic connector. More specifically, the electronic connector may include a single connector body and a mounting end operable to couple the single connector body with an electronic board of an electronics unit. The electronic connector may also include a lower jack portion disposed in the single connector body and include multiple lower pin receptacles, where the lower jack portion is disposed adjacent to the mounting end and is operable to receive a first connector end of a first cable. The electronic connector may further include an upper jack portion disposed in the single connector body and include multiple upper pin receptacles, where the upper jack portion is disposed above the lower jack portion and is operable to receive a second connector end of a second cable."
9465575,"A fused floating-point multiply-add element includes a multiplier that generates a product, and a shifter that shifts an addend within a narrow range. Interpreting logic analyzes the magnitude of the addend relative to the product and then causes logic arrays to position the shifted addend within the left, center, or right portions of a composite register depending in the magnitude of the addend relative to the product. The interpreting logic also forces other portions of the composite register to zero. When the addend is zero, the interpreting logic forces all portions of the composite register to zero. Final combining logic then adds the contents of the composite register to the product."
9465578,"A system and method are provided for performing 32-bit or dual 16-bit floating-point arithmetic operations using logic circuitry. An operating mode that specifies an operating mode for a multiplication operation is received, where the operating mode is one of a 32-bit floating-point mode and a dual 16-bit floating-point mode. Based on the operating mode, nine recoding terms for a mantissa of at least one floating-point input operand are determined. A dual-mode multiplier array circuit that is configurable to generate partial products for either one 32-bit floating-point result or for two 16-bit floating-point results computes the partial products based on the nine recoding terms. The partial products are processed to generate an output based on the operating mode."
9465597,"A device is disclosed herein. In one embodiment; the device includes: a wireless transceiver; an interface for connecting with a terminal running one of the first and second operating systems; memory storing the driver software for installation on the terminal if running the second operating system; and processing apparatus operable to output a first definition of a configuration of the device and a second definition of a configuration of the device; wherein the first definition defines configuration of the device as a storage device for providing the driver software to the terminal; and on condition that the terminal is running the first version of the first operating system, the second definition defines configuration of the device as a modem."
9465728,"A memory controller, in one embodiment, includes a command translation data structure, a front end and a back end. The command translation data structure maps command operations to primitives, wherein the primitives are decomposed from command operations determined for one or more memory devices. The front end receives command operations from a processing unit and translates each command operation to a set of one or more corresponding primitives using the command translation data structure. The back end outputs the set of one or more corresponding primitives for each received command operation to a given memory device."
9466115,"One embodiment of the present invention includes techniques for rasterizing primitives that include edges shared between paths. For each edge, a rasterizer unit selects and applies a sample rule from multiple sample rules. If the edge is shared, then the selected sample rule causes each group of coverage samples associated with a single color sample to be considered as either fully inside or fully outside the edge. Consequently, conflation artifacts caused when the number of coverage samples per pixel exceeds the number of color samples per pixel may be reduced. In prior-art techniques, reducing such conflation artifacts typically involves increasing the number of color samples per pixel to equal the number of coverage samples per pixel. Advantageously, the disclosed techniques enable rendering using algorithms that reduce the ratio of color to coverage samples, thereby decreasing memory consumption and memory bandwidth use, without causing conflation artifacts associated with shared edges."
9470743,"Dynamic yield prediction. In accordance with a first method embodiment of the present invention, a computer-implemented method includes collecting sample test information from a plurality of test-only structures prior to completion of the first wafer, gathering finished test data from all die of the first wafer, after completion of the first wafer, constructing a yield prediction model based on the sample test information and on the finished test data, and predicting, using the model, a percentage of die of the first wafer that will meet a particular specification. The method may further include a feedback loop to dynamically update the model."
9471091,A method and a system are provided for speculative periodic synchronization. A phase value representing a measured phase of the second clock signal relative to the first clock signal measured at least one cycle earlier is received. A period value representing a period of the second clock signal relative to the first clock signal measured at least one cycle earlier is also received. A reduced timing margin is determined based on the phase value and the period value. A speculatively synchronized output signal is generated based on the reduced timing margin.
9471307,A system and apparatus are provided that include an implementation for decoupled pipelines. The apparatus includes a scheduler configured to issue instructions to one or more functional units and a functional unit coupled to a queue having a number of slots for storing instructions. The instructions issued to the functional unit are stored in the queue until the functional unit is available to process the instructions.
9471310,"A method, computer program product, and system are provided for multi-input bitwise logical operations. The method includes the steps of receiving a multi-input bitwise logical operation instruction that specifies two or more input operands and a function operand, where a first input operand of the two or more input operands comprises a number of bits, each bit having a corresponding bit in each of the additional input operands in the two or more input operands. The function operand is written to a lookup table. Then, the lookup table is accessed for each set of corresponding input operand bits in the two or more input operands to generate an output for the multi-input bitwise logical operation instruction."
9471395,"Embodiments of the present technology provide for migrating processes executing one any one of a plurality of cores in a multi-core cluster to a core of a separate cluster without first having to transfer the processes to a predetermined core of the multi-core cluster. Similarly, the processes may be transferred from the core of the separate cluster to the given core of the multi-core cluster."
9471456,"One or more embodiments of the invention are directed to a method including monitoring execution of a set of programs each including a set of instructions executing interleaved with other instructions of the set of instructions, where each of the set of instructions includes at least one operation operating on a set of threads; organizing a first set of instructions corresponding to a first program of the set of programs based on an execution order of the first set of instructions; generating a result set representing the first set of instructions organized based on the execution order; and displaying the result set."
9471952,A method and system for coordinated data execution in a computer system. The system includes a first graphics processor coupled to a first memory and a second graphics processor coupled to a second memory. A graphics bus is configured to couple the first graphics processor and the second graphics processor. The first graphics processor and the second graphics processor are configured for coordinated data execution via communication across the graphics bus.
9474022,"Saving power in a mobile terminal includes determining alignment processing moments after the mobile terminal enters a standby mode. Alignable wakeup events, which occur during alignment processing periods corresponding to each alignment processing moment, are thus controlled to commence related processing at each of the alignment processing moments. Power consumption caused by various wakeup events in a standby mode may thus be reduced and battery life of the mobile terminal may thus be improved."
9477475,"According to embodiments disclosed herein, there is disclosed a computer processor architecture; and in particular a computer processor, a method of operating the same, and a computer program product that makes use of an instruction set for the computer. In one embodiment, the computer processor includes: (1) a decode unit for decoding instruction packets fetched from a memory holding the instruction packets, (2) a control processing channel capable of performing control operations and (3) a data processing channel capable of performing data processing operations, wherein, in use the decode unit causes instructions of instruction packets comprising a plurality of only control instructions to be executed sequentially on the control processing channel, and wherein, in use the decode unit causes instructions of instruction packets comprising a plurality of instructions comprising at least one data processing instruction to be executed simultaneously on the data processing channel."
9477477,"A system, method, and computer program product are provided for executing casting-arithmetic instructions. The method comprises receiving a casting-arithmetic instruction that specifies an arithmetic operation to be performed on input data and at least one casting operation of an input casting operation and an output casting operation. Upon determining that the casting-arithmetic instruction specifies the input casting operation, the input casting operation is performed on identified terms comprising the input data. Then the arithmetic operation is performed on the input data to generate an arithmetic result. Upon determining that the casting-arithmetic instruction specifies the output casting operation, the output casting operation is performed on the arithmetic result."
9477480,"A system, method, and computer program product are provided for scheduling interruptible hatches of instructions for execution by one or more functional units of a processor. The method includes the steps of receiving a batch of instructions that includes a plurality of instructions and dispatching at least one instruction from the batch of instructions to one or more functional units for execution. The method further includes the step of receiving an interrupt request that causes an interrupt routine to be dispatched to the one or more functional units prior to all instructions in the batch of instructions being dispatched to the one or more functional units. When the interrupt request is received, the method further includes the step of storing batch-level resources in a memory to resume execution of the batch of instructions once the interrupt routine has finished execution."
9477482,"A system, method, and computer program product are provided for implementing a multi-cycle register file bypass mechanism. The method includes the steps of receiving a set of control bits, combining the set of control bits with a set of valid bits associated with previously issued instructions, and enabling a bypass path for each thread based on the set of control bits and the set of valid bits. Each valid bit in the set of valid bits indicates whether execution of an instruction of the previously issued instructions was enabled for a thread in a thread block."
9477526,"A system, method, and computer program product are provided for providing prioritized access for multithreaded processing. The method includes the steps of allocating threads to process a workload and assigning a set of priority tokens to at least a portion of the threads. Access to a resource, by each one of the threads, is based on the priority token assigned to the thread and the threads are executed by a multithreaded processor to process the workload."
9477575,"A method for debugging and includes receiving a request for capturing a frame generated by a graphics application implementing application threads executing function calls. The function calls are associated with one or more thread specific resources used at the beginning of the capturing process. For each application thread, a corresponding state is determined for each thread specific resource utilized, and a corresponding capture stream is established. For each application thread, executed function calls are captured into the corresponding capture stream. A plurality of captured function calls is arranged in the order they were executed by the graphics application. For each capture stream, a corresponding replay thread is established. Application threads, capture streams, and replay threads exist in a one-to-one-to-one relationship. Captured function calls are replayed in order, wherein each captured function call is executed in a corresponding replay thread based on which application thread executed the captured function call."
9477597,Embodiments of the present technology are directed toward techniques for enabling different memory partitions to have different memory depths.
9478066,"A system, method, and computer program product are provided for adjusting vertex positions. One or more viewport dimensions are received and a snap spacing is determined based on the one or more viewport dimensions. The vertex positions are adjusted to a grid according to the snap spacing. The precision of the vertex adjustment may increase as at least one dimension of the viewport decreases. The precision of the vertex adjustment may decrease as at least one dimension of the viewport increases."
9478482,"One embodiment of the present invention sets forth an integrated circuit package including a substrate, an integrated circuit die, and a plurality of solder bump structures. The substrate includes a first plurality of interconnects disposed on a first surface of the substrate. The integrated circuit die includes a second plurality of interconnects disposed on a first surface of the integrated circuit die. The plurality of solder bump structures couple the first plurality of interconnects to the second plurality of interconnects. The first plurality of interconnects are configured to be substantially aligned with the second plurality of interconnects when the integrated circuit package is at a first temperature within a range of about 0° C. to about −100° C. The first plurality of interconnects are configured to be offset from the second plurality of interconnects when the integrated circuit package is at a temperature above the first temperature."
9479001,"A regulator draws power from a battery or power delivery system and supplies regulated power to a load according to alternating modes of operation. In a voltage control mode, the regulator supplies power with a nominal voltage level and a fluctuating current level that is allowed to float according to the current demands of the load. When the load demands an amount of current that could potentially cause damage, the regulator transitions to a current control mode. In the current control mode, the regulator supplies power with a fluctuating voltage level and a maximum current level. The regulator transitions between voltage control mode and current control mode in order to supply a maximum power level to the load without exceeding the maximum current level. The regulator is also configured to limit the power drawn from the battery by decreasing the maximum output current, potentially avoiding voltage droop."
9479709,"A method for displaying a live preview image on a mobile device is disclosed. The method includes computing a history color value and confidence value for each pixel of a sensor of a camera. Further, it includes obtaining a new frame of pixels from the camera. Subsequently, for each pixel in the new frame, the method includes: (a) determining if a pixel color is similar to a corresponding history color value and if a confidence corresponding to a pixel is above a predetermined threshold; (b) if the pixel color is not similar to the history color value and the confidence is above the predetermined threshold, displaying the history color value on the preview when displaying the new frame; and (c) if the pixel color is similar to the history color value or the confidence is below the threshold, displaying the pixel color on the preview instead."
9483068,"One embodiment of the present invention sets for a method for monitoring the aging of a circuit. The method includes operating an aging unit included in the circuit beginning at a first time. The method also includes in response to a trigger event, operating a non-aging unit also included in the circuit beginning at a second time wherein the second time is subsequent to the first time. The method further includes detecting a frequency difference between a first frequency generated by the aging unit and a second frequency generated by the non-aging unit. The method also includes generating a modified power supply voltage based on the frequency difference. The method also includes applying the modified power supply voltage to the non-aging unit."
9483235,"Embodiments of the present invention provide a novel solution that supports the separate compilation of host code and device code used within a heterogeneous programming environment. Embodiments of the present invention are operable to link device code embedded within multiple host object files using a separate device linking operation. Embodiments of the present invention may extract device code from their respective host object files and then linked them together to form linked device code. This linked device code may then be embedded back into a host object generated by embodiments of the present invention which may then be passed to a host linker to form a host executable file. As such, device code may be split into multiple files and then linked together to form a final executable file by embodiments of the present invention."
9483270,"One embodiment of the present invention sets forth a graphics subsystem configured to implement distributed tiled caching. The graphics subsystem includes one or more world-space pipelines, one or more screen-space pipelines, one or more tiling units, and a crossbar unit. Each world-space pipeline is implemented in a different processing entity and is coupled to a different tiling unit. Each screen-space pipeline is implemented in a different processing entity and is coupled to the crossbar unit. The tiling units are configured to receive primitives from the world-space pipelines, generate cache tile batches based on the primitives, and transmit the primitives to the screen-space pipelines. One advantage of the disclosed approach is that primitives are processed in application-programming-interface order in a highly parallel tiling architecture. Another advantage is that primitives are processed in cache tile order, which reduces memory bandwidth consumption and improves cache memory utilization."
9483423,"One embodiment sets forth a method for guiding the order in which a parallel processing subsystem executes memory copies. A driver creates semaphores for all but the lowest priority included in a plurality of priorities and associates one priority with each copy hardware channel included in the parallel processing subsystem. The driver then aliases prioritized streams to the copy hardware channels based on the priorities. Upon receiving a request to execute a memory copy within one of the streams, the driver inserts commands into the aliased copy hardware channel. These commands use the semaphores to direct the parallel processing subsystem to execute the memory copy based on the priority of the copy hardware channel. Advantageously, by assigning priorities to streams and, subsequently, strategically requesting memory copies within the prioritized streams, an application developer may fine-tune their software application to increase the overall processing efficiency of the software application."
9483845,"A video frame compression system includes a rendering engine that provides a current video frame and current additional rendering information. Additionally, the video frame compression system includes a warping engine that generates a warped video frame, wherein the warped video frame is a transformation of a previous video frame that is based on the current additional rendering information. Further, the video frame compression system includes a video encoder that compresses the current video frame by using the warped video frame as a reference frame and separately compresses the current additional rendering information. Still further, the video frame compression system includes a packetizer that provides main and auxiliary data streams corresponding to the compressed current video frame and the compressed current additional rendering information, respectively. A video frame decompression system and methods of video frame compression and decompression are also provided."
9484115,"A subsystem configured to select the power supply to a static random access memory cell compares the level of a dedicated memory supply voltage to the primary system supply voltage. The subsystem then switches the primary system supply to the SRAM cell when the system voltage is higher than the memory supply voltage with some margin. When the system voltage is lower than the memory supply voltage, with margin, the subsystem switches the memory supply to the SRAM cell. When the system voltage is comparable to the memory supply, the subsystem switches the system voltage to the SRAM cell if performance is a prioritized consideration, but switches the memory supply to the SRAM cell if power reduction is a prioritized consideration. In this manner, the system achieves optimum performance without incurring steady state power losses and avoids timing issues in accessing memory."
9484815,"A system and method are provided for controlling a switching voltage regulator circuit. An energy difference between a stored energy of a switching voltage regulator and a target energy is determined. A control variable of the switching voltage regulator is computed based on the energy difference and the control variable is applied to a current control mechanism of the switching voltage regulator. In one embodiment, the control variable is pulse width of a control signal."
9489201,A system includes a processing unit and a register file. The register file includes at least a first memory structure and a second memory structure. The first memory structure has a lower access energy than the second memory structure. The processing unit is configured to address the register file using a single logical namespace for both the first memory structure and the second memory structure.
9489245,"One embodiment of the present invention enables threads executing on a processor to locally generate and execute work within that processor by way of work queues and command blocks. A device driver, as an initialization procedure for establishing memory objects that enable the threads to locally generate and execute work, generates a work queue, and sets a GP_GET pointer of the work queue to the first entry in the work queue. The device driver also, during the initialization procedure, sets a GP_PUT pointer of the work queue to the last free entry included in the work queue, thereby establishing a range of entries in the work queue into which new work generated by the threads can be loaded and subsequently executed by the processor. The threads then populate command blocks with generated work and point entries in the work queue to the command blocks to effect processor execution of the work stored in the command blocks."
9489541,"A computer system comprising a processor and a memory for storing instructions, that when executed by the processor performs a copy protection method. The copy protection method comprises executing a software loop of a first software application in a first operating system. A first call is executed in the software loop to a code portion. A decrypted code portion of the first software application is executed in a second operating system in response to the first call. The code portion is decrypted in response to a successful validation of the first software application."
9489712,"One embodiment of the present invention sets forth a system for generating multiple video output signals from a single video pipeline within a graphics processing unit. Pixel data from more than one display surface is retrieved and multiplexed before being transmitted to a video pipeline for processing. The resulting video pixel data is routed to video output encoders, which selectively accept the video pixel data for transmission to attached display devices."
9489763,"One embodiment sets forth a method for processing draw calls that includes setting up a plurality of shader input buffers in memory, receiving shader input data related to a graphics scene from a software application, storing the shader input data in the plurality of shader input buffers, computing a pointer to each shader input buffer included in the plurality of shader input buffers, and passing the pointers to the plurality of shader input buffers to the software application. By implementing the disclosed techniques, a shader program advantageously can access the shader input data associated with a graphics scene and stored in various shader input buffers without having to go through the central processing unit to have the shader input buffers binded to the shader program."
9489767,"One embodiment of the present invention sets forth a technique to perform fine-grained rendering predication using an IGPU and a DGPU. A graphics driver divides a 3D object into batches of triangles. The IGPU processes each batch of triangles through a modified rendering pipeline to determine if the batch is culled. The IGPU writes bits into a bitstream corresponding to the visibility of the batches. The DGPU reads bits from the bitstream and performs full-blown rendering, including shading, but only on the batches of triangles whose bit indicates that the batch is visible. Advantageously, this approach to rendering predication provides fine-grained culling without adding unnecessary overhead, thereby optimizing both hardware resources and performance."
9489924,"Techniques for selecting a boot display device in the multi-GPU configured computing device include a graphic initialization routine for determining a topology of a plurality of GPUs. It is then determined if a display is coupled to any of the plurality of GPUs. The determination of whether the display is coupled to a GPU is communicated to the other of the plurality of GPUs based upon the determined topology. Thereafter, selection of a given GPU as a primary boot device, by a system initialization routine, is influenced by representing each GPU not coupled to the display as a graphics device and the GPUs coupled to a given display as the primary boot device if one or more displays are coupled to GPUs, and by representing the given GPU as the primary boot device and all other GPUs as graphics devices when the display is not coupled to any of the GPUs. In addition or in the alternative selection of the given GPU as the primary boot device may be influenced by hiding the expansion ROM of GPUs not coupled to a display."
9490847,"One embodiment of the present invention sets forth a technique for protecting data with an error correction code (ECC). The data is accessed by a processing unit and stored in an external memory, such as dynamic random access memory (DRAM). Application data and related ECC data are advantageously stored in a common page within a common DRAM device. Application data and ECC data are transmitted between the processor and the external common DRAM device over a common set of input/output (I/O) pins. Eliminating I/O pins and DRAM devices conventionally associated with transmitting and storing ECC data advantageously reduces system complexity and cost."
9494641,"A degradation detector for an integrated circuit (IC), a method of detecting aging in an IC and an IC incorporating the degradation detector or the method. In one embodiment, the degradation detector includes: (1) an offline ring oscillator (RO) coupled to a power gate and a clock gate, (2) a frozen RO coupled to a clock gate, (3) an online RO and (4) an analyzer coupled to the offline RO, the frozen RO and the online RO and operable to place the degradation detector in a normal state in which the offline RO is disconnected from both the drive voltage source and the clock source, the frozen RO is connected to the drive voltage source but disconnected from the clock source and the online RO is connected to both the drive voltage source and the clock source."
9494797,"In embodiments of the invention, an apparatus may include a display comprising a plurality of pixels and a computer system coupled with the display and operable to instruct the display to display images. The apparatus may further include an SLM array located adjacent to the display and comprising a plurality of SLMs, wherein the SLM array is operable to produce a light field by altering light emitted by the display to simulate an object that is in focus to an observer while the display and the SLM array are located within a near-eye range of the observer."
9495721,"Techniques for dispatching pixel information in a graphics processing pipeline. A fragment processing unit generates a pixel that includes multiple samples based on a first portion of a graphics primitive received by a first thread. The fragment processing unit calculates a first value for the first pixel, where the first value is calculated only once for the pixel. The fragment processing unit calculates a first set of values for the samples, where each value in the first set of values corresponds to a different sample and is calculated only once for the corresponding sample. The fragment processing unit combines the first value with each value in the first set of values to create a second set of values. The fragment processing unit creates one or more dispatch messages to store the second set of values in a set of output registers."
9495723,"A device for processing graphics data includes a plurality of graphics processing units. Each graphics processing unit may correspond to a virtualized operating system. Each graphics processing unit may include a configuration register indicating a 3D class code and a command register indicating that I/O cycle decoding is disabled. The device may be configured to transmit a configuration register value to a virtualized operating system indicating a VGA-compatible class code. The device may be configured to transmit a command register value to the virtualized operating system that indicates that I/O cycle decoding is enabled. In this manner, legacy bus architecture of the device may not limit the number of graphics processing units deployed in the device."
9495781,"A technique for early sample evaluation during coarse rasterization of primitives reduces the number of pixel tiles that are processed during fine rasterization of the primitive. A primitive bounding box determines when a primitive is small and may not actually cover any samples within at least one fine raster tile. Early sample evaluation is performed for the small primitive during coarse rasterization and the small primitive is discarded when no samples are actually covered by the small primitive. When the small primitive lies on a boundary between at least two fine raster tiles, early sample evaluation is performed during coarse rasterization to correctly identify which, if any, of the at least two fine raster tiles includes samples that are actually covered by the small primitive."
9495951,"An audio enhancement system includes a display unit configured to exhibit a waveform corresponding to a microphone signal that is subject to an audio interference. The audio enhancement system also includes an interference reduction unit coupled to the microphone signal and configured to provide a reduction in the audio interference, wherein a reduced audio interference is indicated by the waveform in real time. A microphone signal enhancement method is also provided."
9496047,"In various embodiments, a memory cell and a memory are provided. The memory cell comprises a Static Random Access Memory (SRAM) cell including a reset-set (RS) flip-flop and a Read Only Memory (ROM) cell being connected (or coupled) to the SRAM cell to set logic states of internal latch nodes of the RS flip-flop when the ROM cell is triggered. The size of the memory cells proposed in an embodiment of the invention is much smaller than the sum of the size of ROM cells and the size of SRAM cells with the capacity of the memory cells same as the sum of the capacity of the ROM cells and the capacity of the SRAM cells."
9496853,"Component characteristics analysis systems and methods are described. In one embodiment, a ring oscillator comprises: at least one inversion stage operable to cause a signal transition; a target component that has an increased comparative impact or influence on a signal transition propagation in the ring oscillator; and an output component for outputting an indication of the impact the target component has on the signal transition. The target component can include a plurality of vias from one metal layer to another metal layer, which can be configured in a cell. The vias can correspond to a via layer. In one exemplary implementation, the output is coupled to an analysis component. The analysis component can include correlation of the via resistance into a wafer variations and generate a wafer map and can include correlation of the via resistance into a wafer."
9497631,"This disclosure presents a modem for use at a terminal for accessing first and second communication networks that comprises a device interface for connecting to a subscriber identity device that stores first and second subscriber identity applications, and first and second pieces of user authentication data, separate from one another, for effecting independent first and second user authentication procedures for the first and second applications, respectively. A processing unit executes the first application to provide access to the first network when the first authentication procedure has been completed, and executes the second application to provide access to the second network when the second authentication procedure has been completed. An actuation component responds to an authentication command received via a host interface to identify at least one of the first and second pieces of user authentication data to perform an authentication task in relation to the identified user authentication data."
9500706,"Various aspects described or referenced herein are directed to different methods, systems, and computer program products for implementing hybrid on-chip clock controller techniques for facilitating at-speed scan testing and scan architecture support."
9501847,"One embodiment of the present invention sets forth a technique for computing line stipple using a parallel rasterizer. Stipple phases are computed in parallel for individual line segments of a line strip during the viewport scale, cull, and clipping operations. The line segments are distributed to multiple parallel rasterizers. Each line segment may be sent to only one of the parallel rasterizers. Update phase messages that include an accumulated stipple phase for a batch of line segments are broadcast to all of the multiple parallel rasterizers. The update phase messages are used by the multiple parallel rasterizers to reconstruct the stipple phases for each line segment of a line strip in order to correctly render stippled line strips and produce a continuous stippled line."
9501865,"A system, method, and computer program product are provided for determining a quantity of light received by an element of a scene. In use, a quantity of light received by a first element of the scene is determined by averaging a quantity of light received by elements of the scene that are associated with a selected set of light paths."
9502355,"A system, method, and computer program product are provided for producing a high bandwidth bottom package of a die-on-package structure. The method includes the steps of receiving a bottom package comprising a substrate material having a top layer and an integrated circuit die that is coupled to the top layer of the substrate material. A first set of pads is formed on the top layer of the substrate material and a layer of dielectric material is applied on a top surface of the bottom package to cover the integrated circuit die and the first set of pads."
9507378,"An apparatus for dissipating heat is presented. The apparatus comprises a base provided with a recess on a top thereof for containing a portion of a flat panel electronic device. It also comprises a base heat sink disposed in the base. Finally, it comprises a heat-conducting plug with a first end thereof thermally contacting with the base heat sink, and a second end thereof extending upward from a bottom of the recess for plugging into a heat-conducting socket of the flat panel electronic device when the flat panel electronic device is placed on the base."
9507470,"Embodiments of the present invention can be configured to recognize and/or track certain types of touch input detected by a touch sensor, such as stylus input, during the performance of standard “full” touch scans in which each drive line of the touch sensor is generally scanned. Upon detection of these input types, “partial” touch scan operations can advantageously be performed which can dynamically reduce the number of lines scanned in a power-saving manner. These partial scans can be configured to intelligently initially scan the area where these input types were last detected so that there is minimal need to return to a previous “full” scan mode. If these specified touch inputs types are not detected during a “partial” scan mode, the touch sensor can be restored to a “full” scan mode until a subsequent detection of the touch input is determined, in which the touch sensor can be returned to a “partial” scan mode. Each time a partial scan is used, power is saved."
9507638,"One embodiment of the present invention sets forth a technique for managing the allocation and release of resources during multi-threaded program execution. Programmable reference counters are initialized to values that limit the amount of resources for allocation to tasks that share the same reference counter. Resource parameters are specified for each task to define the amount of resources allocated for consumption by each array of execution threads that is launched to execute the task. The resource parameters also specify the behavior of the array for acquiring and releasing resources. Finally, during execution of each thread in the array, an exit instruction may be configured to override the release of the resources that were allocated to the array. The resources may then be retained for use by a child task that is generated during execution of a thread."
9508109,An embodiment of the present invention includes a device for real-time graphics processing. The device includes an interface coupled to exterior for receiving external data. The device includes a data converter coupled to the interface for converting the external data received from the interface. The device includes a graphics processing unit coupled to the data converter to process the external data that has been converted.
9508111,"A method and system for detecting a display mode suitable for a reduced display refresh rate are disclosed. Specifically, one embodiment of the present invention sets forth a computing device, which includes a memory and a processing unit. The memory stores multiple image surface data. The processing unit is configured to compose a first display frame from a first base surface and optionally a first overlay surface, calculate a first numerical code representative of a first frame content of the first display frame, compose a second display frame from a second base surface and optionally a second overlay surface, calculate a second numerical code representative of a second frame content of the second display frame, and track the results of comparing the first numerical code with the second numerical code to determine whether a change between the first frame content and the second frame content has occurred."
9508318,Dynamic white point management techniques include determining a white point of ambient light proximate to a display. A color profile adjustment is determined based upon the determined white point and intensity of the ambient light. The image color space is transformed to a display color space for rendering on the display based on the determined adjusted to the color profile.
9509392,"Method, receiver and computer program product for processing a signal transmitted over a wireless network from a plurality of spatially separated transmit antennas of a transmitter using a Multiple-Input Multiple-Output transmission. The signal is received at a plurality of receive antennas, the signal comprising a plurality of data streams. The channel quality for each of the data streams in the received signal is determined and based on the determined channel quality of the data streams, the number of independent data streams that can be supported in the Multiple-Input Multiple-Output transmission of the signal is determined. An indication of the determined number is transmitted to the transmitter."
9510242,"In one embodiment the modem has a network interface, application interface, processor, and memory. The network interface exchanges radio data with a network. The application (or host) interface exchanges application data with an application (or host) processor. The processor converts a unit of radio data to a corresponding unit of application data. The memory stores each unit of application data received by the modem. The processor is configured to execute a selective discard function to reduce traffic by determining if a newly arrived unit of application data is a duplicate of a stored unit of application. In the case that the newly arrived unit of application data is a duplicate of the stored unit of application data, the processor is further configured to selectively discard the duplicate unit of application data in dependence on whether an acknowledgement of the data has been already recognized by the processor."
9513923,"One embodiment of the present invention sets forth a technique for associating arbitrary parallel processing unit (PPU) contexts with a given central processing unit (CPU) thread. The technique introduces two operators used to manage the PPU contexts. The first operator is a PPU context push, which causes a PPU driver to store the current PPU context of a calling thread on a PPU context stack and to associate a named PPU context with the calling thread. The second operator is a PPU context pop, which causes the PPU driver to restore the PPU context of a calling function to the PPU context at the top of the PPU context stack. By performing a PPU context push at the beginning of a function and a PPU context pop prior to returning from the function, the function may execute within a single CPU thread, but operate on a two distinct PPU contexts."
9513975,"One embodiment of the present invention sets forth a technique for performing nested kernel execution within a parallel processing subsystem. The technique involves enabling a parent thread to launch a nested child grid on the parallel processing subsystem, and enabling the parent thread to perform a thread synchronization barrier on the child grid for proper execution semantics between the parent thread and the child grid. This technique advantageously enables the parallel processing subsystem to perform a richer set of programming constructs, such as conditionally executed and nested operations and externally defined library functions without the additional complexity of CPU involvement."
9516224,"In one embodiment, a car navigation device is provided. The device comprises: at least one wide-angle camera; a video correction unit for acquiring video data from the wide-angle lens and correcting the video data; a video merging unit for acquiring corrected video data from video correction unit and merging the corrected video data; an image recognition unit for acquiring video from the video merging unit and performing image recognition to the video; and a driving assistant unit for acquiring data from the image recognition unit and assisting driving in accordance with the recognized content. The navigation device provided by various embodiments in accordance with the present invention can correct and recognize the images taken by fisheye lens in real-time so as to assist the driver for driving or drive the car automatically without a human being."
9516326,"A method for rotating macro-blocks of a frame of a video stream. A degree of rotation for the video stream is accessed. A macro-block of the video stream is accessed. The macro-block is rotated according to the degree of rotation. The macro-block is repositioned to a new position within the frame, wherein the new position is based on the degree of rotation."
9519144,"A system, method, and computer program product are provided for producing images for a near-eye light field display. Defect information for a first pixel of a microdisplay of a near-eye light field display device is received and a second pixel of the microdisplay is identified, where the first pixel and the second pixel contribute to a portion of the retinal image. Based on the defect information, a value of the second pixel within an array of elemental images is modified to produce a corrected array of elemental images for display by the microdisplay. An optical apparatus of the near-eye light field display device may, for example, be a microlens of a microlens array positioned between a viewer and an emissive microdisplay or a pinlight of a pinlight array positioned behind a transmissive microdisplay relative to the viewer."
9519568,A system and method for debugging an executing program. The method includes executing a general-purpose computing on graphics processing units (GPGPU) program. The GPGPU program comprises a first portion operable to execute on a central processing unit (CPU) and a second portion operable to execute on a graphics processing unit (GPU). The method further includes attaching a debugging program to the first portion of the GPGPU program and modifying the first portion of the GPGPU program. The attaching of the debugging program to the first portion of the GPGPU program pauses execution of the first portion of the GPGPU program. The method further includes resuming execution of the first portion of the GPGPU program and accessing a first state information corresponding to the first portion of the GPGPU program. Execution of the first portion of the GPGPU program may then be paused. The first state information may then be used to access a second state information corresponding to the second portion of the GPGPU program.
9519947,"One embodiment of the present invention sets forth a technique for a program to access multi-dimensional formatted graphics surface memory. Multi-dimensional memory objects called “surfaces” stored in a user-specified data or pixel format and arranged in a graphics optimized layout are accessed by programs using surface instructions. A set of memory access instructions e.g., load, store, reduce, and atomic, referred to as surface instructions, may be used to access the surfaces. Coordinate bounds checking is performed with configurable clamping. Caching behavior may also be specified by the surface instructions. Data format conversion and packing to a specified storage format is supported for store, reduction, and atomic surface instructions. Data format conversion and unpacking from a specified storage format is supported for loads and atomic surface instructions."
9524138,"In typical embodiments a three GPU configuration is provided comprising three discrete video cards, each connected to a standard monitor placed horizontally for a 3× horizontal resolution. In this configuration, depending on the load on each GPU, the vertical split lines are dynamically adjusted. To adjust the load balancing according to these virtual split lines, the rendering clip rectangle of each GPU is adjusted, in order to reduce the number of pixels rendered by the heavily loaded GPU. These split lines define the boundary of the scene to be rendered by each GPU, and, according to some embodiments, may be moved horizontally. Thus for example if a GPU has a more complex rendering clip polygon to render than the other GPUs, the neighboring GPUs may render the rendering clip polygon it displays plus a portion of the rendering clip polygon to be displayed by heavily loaded GPU. The assisting GPUs transmit to the heavily loaded GPU the portion of the rendering clip polygon to be displayed by GPU via the chipset with a peer-to-peer protocol or through a communication bus. The split line is dynamically adjusted after each scene."
9525401,"Low clocking power flip-flop. In accordance with a first embodiment of the present invention, a flip-flop electronic circuit includes a master latch coupled to a slave latch in a flip-flop configuration. The flip-flop electronic circuit also includes a clock control circuit for comparing an input to the master latch with an output of the slave latch, and responsive to the comparing, blocking a clock signal to the master latch and the slave latch when the flip-flop electronic circuit is in a quiescent condition."
9529525,"A method for reducing line display latency on a touchpad device is disclosed. The method comprises storing information regarding a plurality of prior touch events on a touch screen of the touchpad device into an event buffer. It further comprises determining an average speed and a predicted direction of motion of a user interaction with the touch screen using the plurality of prior touch events. Next, it comprises calculating a first prediction point using the average speed, the predicted direction, and a last known touch event on the touch screen. Subsequently, it comprises applying weighted filtering on the first prediction point using a measured line curvature to determine a second prediction point. Finally, it comprises rendering a prediction line between the last known touch event on the touch screen and the second prediction point."
9529712,Embodiments of the present technology are directed toward techniques for balancing memory accesses to different memory types.
9530189,"A method for compressing framebuffer data is presented. The method includes determining a reduction ratio for framebuffer data in a tile including multiple samples. The reduction ratio determined is independent of the sampling mode, where the sampling mode is the number of samples within each pixel in the tile. The method further includes comparing a first portion of the framebuffer data for each of the multiple samples to determine an equality comparison result and also comparing a second portion of the framebuffer data for each one of the multiple samples to compute per-channel differences for each one of the multiple samples and testing the per-channel differences against a threshold value to determine a threshold comparison result. Finally, the method comprises compressing the framebuffer data for the tile based on the reduction ratio, the equality comparison result and the threshold comparison result to produce output framebuffer data for the tile."
9530714,"An integrated circuit system includes a heat spreader that is thermally coupled to a semiconductor chip and has a cavity or opening formed in the heat spreader. The cavity or opening is positioned so that capacitors and/or other passive components mounted to the same packaging substrate as the semiconductor chip are at least partially disposed in the cavity or opening. Because the passive components are disposed in the cavity or opening, the integrated circuit system has a reduced package thickness."
9535815,"A system, method, and computer program product are provided for collecting trace information based on a computational workload. The method includes the steps of compiling source code to generate a program, launching a workload to be executed by the parallel processing unit, collecting one or more records of trace information associated with a plurality of threads configured to execute the program, and correlating the one or more records to one or more corresponding instructions included in the source code. Each record in the one or more records includes at least a value of a program counter and a scheduler state of the thread."
9536275,A system and method uses the capabilities of a geometry shader unit within the multi-threaded graphics processor to implement algorithms with variable input and output.
9536341,"One embodiment of the present invention sets forth a technique for parallel distribution of primitives to multiple rasterizers. Multiple, independent geometry units perform geometry processing concurrently on different graphics primitives. A primitive distribution scheme delivers primitives from the multiple geometry units concurrently to multiple rasterizers at rates of multiple primitives per clock. The multiple, independent rasterizer units perform rasterization concurrently on one or more graphics primitives, enabling the rendering of multiple primitives per system clock."
9538633,"A passive cooling system is provided for dissipating heat from an electronic component. The system includes a printed circuit board including a first dielectric layer and a first conductive layer, an electronic component coupled to the printed circuit board via a plurality of electrical contacts, and a cooling component thermally coupled to the electronic component through the first conductive layer by a micro via thermal array."
9542189,"One embodiment of the present invention includes a technique for processing graphics primitives in a tile-based architecture. The technique includes storing, in a buffer, a first plurality of graphics primitives and a first plurality of state bundles received from a world-space pipeline, and transmitting the first plurality of graphics primitives to a screen-space pipeline for processing while a tiling function is enabled. The technique further includes storing, in the buffer, a second plurality of graphics primitives and a second plurality of state bundles received from the world-space pipeline. The technique further includes determining, based on a first condition, that the tiling function should be disabled and that the second plurality of graphics primitives should be flushed from the buffer, and transmitting the second plurality of graphics primitives to the screen-space pipeline for processing while the tiling function is disabled."
9542192,"A method for executing an application program using streams. A device driver receives a first command within an application program and parses the first command to identify a first stream token that is associated with a first stream. The device driver checks a memory location associated with the first stream for a first semaphore, and determines whether the first semaphore has been released. Once the first semaphore has been released, a second command within the application program is executed. Advantageously, embodiments of the invention provide a technique for developers to take advantage of the parallel execution capabilities of a GPU."
9542227,"One embodiment of the present invention sets forth a technique for dynamically allocating memory using one or more lock-free FIFOs. One or more lock-free FIFOs are populated with FIFO nodes, where each FIFO node represents a memory allocation of a predetermined size. Each particular lock-free FIFO includes memory allocations of a single size. Different lock-free FIFOs may include memory allocations for different sizes to service allocation requests for different size memory allocations. A lock-free mechanism is used to pop FIFO nodes from the FIFO. The use of the lock-free FIFO allows multiple consumers to simultaneously attempt to pop the head FIFO node without first obtaining a lock to ensure exclusive access of the FIFO."
9542715,"The server based graphics processing techniques, describer herein, include loading a given instance of a guest shim layer and loading a given instance of a guest display device interface that calls back into the given instance of the guest shim layer, in response to loading the given instance of the guest shim layer, wherein the guest shim layer and the guest display device interface are executing under control of a virtual machine guest operating system. The given instance of the shim layer requests a communication channel between the given instance of the guest shim layer and a host-guest communication manager (D3D HGCM) service module from a host-guest communication manager (HGCM). In response to the request for the communication channel loading, the D3D HGCM service module is loaded and a communication channel between the given instance of the shim layer and the D3D HGCM service module is created by the HGCM. The given instance of the shim layer maps the graphics buffer memory space of a host D3D DDI binary executing under control of a host operating system. Thereafter, function calls are sent from the given instance of the guest shim layer through the communication channel to the D3D HGCM service module utilizing the graphics buffer memory space mapping."
9542992,"A static random access memory (SRAM) cell includes a storage unit configured to store a data bit in a storage node. The SRAM cell further includes an access unit coupled to the storage unit. The access unit is configured to transfer current to the storage node when a word line is asserted. The SRAM cell further includes a row header configured to provide current from a power supply when the word line is not asserted, and to not provide current from the power supply when the word line is asserted. The SRAM cell further includes a column header configured to provide current from a power supply when a write column line is not asserted, and to not provide current from the power supply when the write column line is asserted."
9547358,"In one embodiment, a microprocessor is provided. The microprocessor includes a branch prediction unit. The branch prediction unit is configured to track the presence of branches in instruction data that is fetched from an instruction memory after a redirection at a target of a predicted taken branch. The branch prediction unit is selectively powered up from a powered-down state when the fetched instruction data includes a branch instruction and is maintained in the powered-down state when the fetched instruction data does not include an instruction branch in order to reduce power consumption of the microprocessor during instruction fetch operations."
9547535,One or more embodiments of the invention set forth techniques to create a process in a graphical processing unit (GPU) that has access to memory buffers in the system memory of a computer system that are shared among a plurality of GPUs in the computer system. The GPU of the process is able to engage in Direct Memory Access (DMA) with any of the shared memory buffers thereby eliminating additional copying steps that have been needed to combine data output of the various GPUs without such shared access.
9547602,"Presented systems and methods can facilitate efficient information storage and tracking operations, including translation look aside buffer operations. In one embodiment, the systems and methods effectively allow the caching of invalid entries (with the attendant benefits e.g., regarding power, resource usage, stalls, etc), while maintaining the illusion that the TLBs do not in fact cache invalid entries (e.g., act in compliance with architectural rules). In one exemplary implementation, an “unreal” TLB entry effectively serves as a hint that the linear address in question currently has no valid mapping. In one exemplary implementation, speculative operations that hit an unreal entry are discarded; architectural operations that hit an unreal entry discard the entry and perform a normal page walk, either obtaining a valid entry, or raising an architectural fault."
9547931,"A system, method, and computer program product are provided for generating anti-aliased images. The method includes the steps of assigning one or more samples to a plurality of clusters, each cluster in the plurality of clusters corresponding to an aggregate stored in an aggregate geometry buffer, where each of the one or more samples is covered by a visible fragment and rasterizing three-dimensional geometry to generate material parameters for each sample of the one or more samples. For each cluster in the plurality of clusters, the material parameters for each sample assigned to the cluster are combined to produce the aggregate. The combined material parameters for each cluster are stored in an aggregate geometry buffer. An anti-aliased image may then be generated by shading the combined material parameters."
9547932,"A system, method, and computer program product are provided for splitting primitives. A plurality of primitives is received for a scene and a pre-determined plane that intersects the scene is identified. Bounding volumes of the plurality of primitives that are intersected by the pre-determined plane are split, where a bounding volume that encloses each intersected primitive of the plurality of primitives is split into a first bounding volume and a second bounding volume at an intersection of the bounding volume and the pre-determined plane."
9549147,"A system and method of producing a frame of a video image from an interlaced field. In one embodiment, the method includes: (1) creating an equal-intensity trace from present samples in the field, (2) recognizing an equal-intensity path in the equal-intensity trace, (3) at least partially straightening the equal-intensity path and (4) using the equal-intensity path to determine an intensity value for a missing sample in the frame."
9552032,"In one embodiment, a microprocessor is provided. The microprocessor includes instruction memory and a branch prediction unit. The branch prediction unit is configured to use information from the instruction memory to selectively power up the branch prediction unit from a powered-down state when fetched instruction data includes a branch instruction and maintain the branch prediction unit in the powered-down state when the fetched instruction data does not include a branch instruction in order to reduce power consumption of the microprocessor during instruction fetch operations."
9552208,"A system, method, and computer program product are provided for remapping registers based on a change in execution mode. A sequence of instructions is received for execution by a processor and a change in an execution mode from a first execution mode to a second execution mode within the sequence of instructions is identified, where a first register mapping is associated with the first execution mode and a second register mapping is associated with the second execution mode. Data stored in a set of registers within a processor is reorganized based on the first register mapping and the second register mapping in response to the change in the execution mode."
9552664,"A system, method, and computer program product for implementing a tree traversal operation for a tree data structure is disclosed. The method includes the steps of receiving at least a portion of a tree data structure that represents a tree having a plurality of nodes and processing, via a tree traversal operation algorithm executed by a processor, one or more nodes of the tree data structure by intersecting the one or more nodes of the tree data structure with a query data structure. A first node of the tree data structure is associated with a first local coordinate system and a second node of the tree data structure is associated with a second local coordinate system, the first node being an ancestor of the second node, and the first local coordinate system and the second local coordinate system are both specified relative to a global coordinate system."
9552667,"One embodiment of the present invention includes a parallel processing unit (PPU) that performs pixel shading at variable granularities. For effects that vary at a low frequency across a pixel block, a coarse shading unit performs the associated shading operations on a subset of the pixels in the pixel block. By contrast, for effects that vary at a high frequency across the pixel block, fine shading units perform the associated shading operations on each pixel in the pixel block. Because the PPU implements coarse shading units and fine shading units, the PPU may tune the shading rate per-effect based on the frequency of variation across each pixel group. By contrast, conventional PPUs typically compute all effects per-pixel, performing redundant shading operations for low frequency effects. Consequently, to produce similar image quality, the PPU consumes less power and increases the rendering frame rate compared to a conventional PPU."
9554287,"A mobile communications system comprises a first group of one or more base stations which are arranged to communicate signals with mobile units via a wireless access interface by transmitting and/or receiving radio signals within a first frequency band; a second group of one or more base stations which are arranged to communicate signals with mobile units via a wireless access interface by transmitting and/or receiving radio signals within a second frequency band; and a controller. The controller is arranged in operation to determine an amount of interference in the first frequency band to radio signals for a first type of traffic where the interference is caused by radio signals for a second type of traffic in the second frequency band, wherein: the radio signals for the first type of traffic are to and/or from a first base station of the first group; and the radio signals for the second type of traffic are to and/or from to a second base station of the second group; and to, in response to the determined interference, generate instructions to influence the second group in respect of the transmission of the radio signals for the second type of traffic in the second frequency band, wherein the instructions are generated based on at least a priority for the first type of traffic and a priority for the second type of traffic. In one example, the first group of one or more base stations may be providing communications services to human to human communications (H2H), whereas the second group of one or more base stations may be providing communications services supporting machine type communications (MTC), where H2H communications are prioritizes over machine type communications. The second group of one or more base stations is therefore instructed to take action to reduce the interference caused by the mobile unit."
9557565,"In embodiments of the invention, an apparatus may include a display comprising a plurality of pixels. The apparatus may further include a computer system coupled with the display and operable to instruct the display to display a deconvolved image corresponding to a target image, wherein when the display displays the deconvolved image while located within a near-eye range of an observer, the target image may be perceived in focus by the observer."
9558573,"A technique for efficiently rendering path images tessellates path contours into triangle tans comprising a set of representative triangles. Topology of the set of representative triangles is then optimized for greater rasterization efficiency by applying a flip operator to selected triangle pairs within the set of representative triangles. The optimized triangle pairs are then rendered using a path rendering technique, such as stencil and cover."
9558712,"A computer implemented method of determining a latent image from an observed image is disclosed. The method comprises implementing a plurality of image processing operations within a single optimization framework, wherein the single optimization framework comprises solving a linear minimization expression. The method further comprises mapping the linear minimization expression onto at least one non-linear solver. Further, the method comprises using the non-linear solver, iteratively solving the linear minimization expression in order to extract the latent image from the observed image, wherein the linear minimization expression comprises: a data term, and a regularization term, and wherein the regularization term comprises a plurality of non-linear image priors."
9563227,"A modulated clock device is provided that includes an update device for updating a phase of the modulated clock device. In one example, the update device includes an update phase multiplexer coupled to an output phase multiplexer of an output clock generator and configured to receive an input clock signal and one or more phases of the input clock signal; an output phase fractional counter coupled to the update phase multiplexer and configured to receive an update clock signal and to generate an output phase; and an update phase device coupled to the output phase fractional counter and to the update phase multiplexer. The output phase fractional counter is further configured to send the output phase to the output phase multiplexer and to the update phase device. The update phase device is configured to generate an update phase and to send the update phase to the update phase multiplexer."
9563432,"Various embodiments relating to executing different types of instruction code in a micro-processing system are provided. In one embodiment, a micro-processing system includes a memory/storage subsystem configured to store non-native instruction set architecture (ISA) code and native ISA code in a common address space, fetch logic configured to retrieve the non-native ISA code and native ISA code from the common address space, instruction type determining logic configured to determine, at runtime, whether fetched instruction code is non-native ISA code or native ISA code, and processing logic configured to execute the fetched instruction code via a first pipeline configuration in response to the instruction type determining logic determining that the fetched instruction code is non-native ISA code, and via a second pipeline configuration which is different than the first pipeline configuration, in response to the instruction type determining logic determining that the fetched instruction code is native ISA code."
9563562,"Prefetching is permitted to cross from one physical memory page to another. More specifically, if a stream of access requests contains virtual addresses that map to more than one physical memory page, then prefetching can continue from a first physical memory page to a second physical memory page. The prefetching advantageously continues to the second physical memory page based on the confidence level and prefetch distance established while the first physical memory page was the target of the access requests."
9563933,"Various disclosed embodiments are directed to methods and systems for reducing memory space in sequential computer-implemented operations. The method includes generating a directed acyclic graph (DAG) having a plurality of vertices and directed edges, wherein each edge connects a predecessor vertex to a successor vertex. Each vertex represents one of the computer-implemented operations and each directed edge represents output data generated by the operations. The method includes merging one of the predecessor vertex with one of the successor vertex by combining the operations of the predecessor vertex and the successor vertex if the predecessor and successor vertices are connected by a directed edge and there is only one directed edge originating from the predecessor vertex. The merger of the predecessor and the successor vertices reduces the number of directed edges in the DAG, resulting in a reduction of intermediate buffer memory required to store the output data."
9569197,"Disclosed herein are mobile computing devices that employ compatible updated drivers. In one embodiment, the mobile computing device includes: (1) a processor, (2) a driver library configured to store original drivers and updated drivers for applications on the mobile computing device, and (3) a driver selector configured to determine at least one driver from the original drivers or the updated drivers to use for running one of the applications."
9569214,"In one embodiment, in an execution pipeline having a plurality of execution subunits, a method of using a bypass network to directly forward data from a producing execution subunit to a consuming execution subunit is provided. The method includes producing output data with the producing execution subunit, consuming input data with the consuming execution subunit, for one or more intervening operations whose input is the output data from the producing execution subunit and whose output is the input data to the consuming execution subunit, evaluating those one or more intervening operations to determine whether their execution would compose an identify function, and if the one or more intervening operations would compose such an identity function, controlling the bypass network to forward the producing execution subunit's output data directly to the consuming execution subunit."
9569279,"A technique for managing processor cores within a multi-core central processing unit (CPU) provides efficient power and resource utilization over a wide workload range. The CPU comprises at least one core designed for low power operation and at least one core designed for high performance operation. For low workloads, the low power core executes the workload. For certain higher workloads, the high performance core executes the workload. For certain other workloads, the low power core and the high performance core both share execution of the workload. This technique advantageously enables efficient processing over a wider range of workloads than conventional systems."
9569348,One embodiment of the present invention sets forth a technique for performing a method for compressing page table entries (PTEs) prior to storing the PTEs in a translation look-aside buffer (TLB). A page table entry (PTE) request is received for a PTE that is not stored in the TLB. The PTE as well as a plurality of PTEs that are adjacent to the PTE are retrieved from a memory. The PTE and the plurality of PTEs are compressed and then stored in the TLB.
9569385,"Embodiments are disclosed relating to methods of ordering transactions across a bus of a computing device. One embodiment of a method includes determining a current target memory channel for an incoming transaction request, and passing the incoming transaction request downstream if the current target memory channel matches an outstanding target memory channel indicated by a direction bit of a counter or the counter equals zero. The method further includes holding the incoming transaction request if the counter is greater than zero and the current target memory channel does not match the outstanding target memory channel."
9569559,"An apparatus, computer readable medium, and method are disclosed for performing an intersection query between a query beam and a target bounding volume. The target bounding volume may comprise an axis-aligned bounding box (AABB) associated with a bounding volume hierarchy (BVH) tree. An intersection query comprising beam information associated with the query beam and slab boundary information for a first dimension of a target bounding volume is received. Intersection parameter values are calculated for the first dimension based on the beam information and the slab boundary information and a slab intersection case is determined for the first dimension based on the beam information. A parametric variable range for the first dimension is assigned based on the slab intersection case and the intersection parameter values and it is determined whether the query beam intersects the target bounding volume based on at least the parametric variable range for the first dimension."
9569885,"One embodiment of the present invention includes techniques for pre-computing ambient shadowing parameters for a computer-generated scene. A processing unit retrieves a reference object associated with the computer-generated scene and comprising a plurality of vertices. For each vertex in the plurality of vertices, the processing unit computes a local ambient shadowing parameter, and stores the local ambient shadowing parameter in a memory. For each instance of the reference object included in the computer-generated scene, the processing unit computes a first global ambient shadowing parameter based on the position of the instance within the computer-generated scene, and stores the first global ambient shadowing parameter in the memory. One advantage of the disclosed embodiments is that ambient obscurance is applied to instance objects in a scene in real time while reducing memory space dedicated to storing the AO parameters."
9570284,A method for controlling a semiconductor fabrication process includes the steps of analyzing process-data related to an intermediate-process-step in the fabrication process and adjusting a metal-layer-parameter corresponding to the metal layer based on the process-data.
9570907,"A dynamic multiple input rail switching unit includes a plurality of DC input voltage rails and a rail switching section coupled to the plurality of DC input voltage rails that is configured to individually connect selected ones of the plurality of DC input voltage rails to a switched rail output. The dynamic multiple input rail switching unit also includes a rail selection section that is coupled to the rail switching section and configured to dynamically choose the selected ones by balancing rail supply currents from the plurality of DC input voltage rails based on rail supply current capacity margins and a switched rail output current. A dynamic multiple input rail switching unit operating method, and a dynamic multiple input rail power converter are also provided."
9571818,"Techniques for generating robust depth maps from stereo images are described. A robust depth map is generated from a set of stereo images captured with and without flash illumination. The depth map is more robust than depth maps generated using conventional techniques because a pixel-matching algorithm is implemented that weights pixels in a matching window according to the ratio of light intensity captured using different flash illumination levels. The ratio map provides a rough estimate of depth relative to neighboring pixels that enables the flash/no-flash pixel-matching algorithm to devalue pixels that appear to be located at different depths than the central pixel in the matching window. In addition, the ratio map may be used to filter the generated depth map to generate a smooth estimate for the depth of objects within the stereo image."
9575760,"One embodiment sets forth a method for assigning priorities to kernels launched by a software application and executed within a stream of work on a parallel processing subsystem that supports dynamic parallelism. First, the software application assigns a maximum nesting depth for dynamic parallelism. The software application then assigns a stream priority to a stream. These assignments cause a driver to map the stream priority to a device priority and, subsequently, associate the device priority with the stream. As part of the mapping, the driver ensures that each device priority is at least the maximum nesting depth higher than the device priorities associated with any lower priority streams. Subsequently, the driver launches any kernel included in the stream with the device priority associated with the stream. Advantageously, by strategically assigning the maximum nesting depth and prioritizing streams, an application developer may increase the overall processing efficiency of the software application."
9575892,"One embodiment of the present invention is a parallel processing unit (PPU) that includes one or more streaming multiprocessors (SMs) and implements a replay unit per SM. Upon detecting a page fault associated with a memory transaction issued by a particular SM, the corresponding replay unit causes the SM, but not any unaffected SMs, to cease issuing new memory transactions. The replay unit then stores the faulting memory transaction and any faulting in-flight memory transaction in a replay buffer. As page faults are resolved, the replay unit replays the memory transactions in the replay buffer—removing successful memory transactions from the replay buffer—until all of the stored memory transactions have successfully executed. Advantageously, the overall performance of the PPU is improved compared to conventional PPUs that, upon detecting a page fault, stop performing memory transactions across all SMs included in the PPU until the fault is resolved."
9576340,"A technique for efficiently compressing rendered three-dimensional images in a remote rendering system adds a novel render-assisted prediction function to an existing video compression framework, such as the standard H.264/5 framework. Auxiliary rendering information is separated from rendering information used to describe a reference image by a server system. A client system may alter the auxiliary data and generate a new image based on the reference image and rendered scene information from the auxiliary data without creating additional network bandwidth or server workload."
9578224,"A system and method for enhanced automatic monoimaging. Embodiments of the present invention are operable for configuring a first camera based on a configuration determination by a second camera. The method includes capturing a first image with the first camera and determining an optical configuration based on an optical measurement performed by a second camera. In one embodiment, the second camera comprises a lower resolution sensor than a sensor of the first camera. The method further includes sending the optical configuration from the second camera to the first camera and adjusting a configuration of the first camera based on the optical configuration. The method further includes capturing a second image with the first camera. The first image and the second image may be preview images."
9582065,"Various embodiments relating to reducing memory bandwidth consumed by a continuous scan display screen are provided. In one embodiment, an indication of a static image period of a continuous scan display screen is determined. A reference image of a first image format having a first bit depth is converted into a modified image of a second image format having a second bit depth that is less than the first bit depth. During the static image period, the modified image is scanned onto the continuous scan display screen."
9582075,"A method to drive a pixelated display of an electronic device arranged in sight of a user of the device. The method includes receiving a signal that encodes a display image, and controlling the pixelated display based on the signal to form the display image in addition to a latent image, the latent image being configured to illuminate an eye of the user with light of such characteristics as to be unnoticed by the user, but to reveal an orientation of the eye on reflection into a machine-vision system."
9582280,"The description covers a system and method for operating a micro-processing system having a runahead mode of operation. In one implementation, the method includes providing, for a first portion of code, a runahead correlate. When the first portion of code is encountered by the micro-processing system, a determination is made as to whether the system is operating in the runahead mode. If so, the system branches to the runahead correlate, which is specifically configured to identify and resolve latency events likely to occur when the first portion of code is encountered outside of runahead. Branching out of the first portion of code may also be performed based on a determination that a register is poisoned."
9582922,"A system, method, and computer program product are provided for producing images for a near-eye light field display. A ray defined by a pixel of a microdisplay and an optical apparatus of a near-eye light field display device is identified and the ray is intersected with a two-dimensional virtual display plane to generate map coordinates corresponding to the pixel. A color for the pixel is computed based on the map coordinates. The optical apparatus of the near-eye light field display device may, for example, be a microlens of a microlens array positioned between a viewer and an emissive microdisplay or a pinlight of a pinlight array positioned behind a transmissive microdisplay relative to the viewer."
9588903,"One embodiment of the present invention includes a microcontroller coupled to a memory management unit (MMU). The MMU is coupled to a page table included in a physical memory, and the microcontroller is configured to perform one or more virtual memory operations associated with the physical memory and the page table. In operation, the microcontroller receives a page fault generated by the MMU in response to an invalid memory access via a virtual memory address. To remedy such a page fault, the microcontroller performs actions to map the virtual memory address to an appropriate location in the physical memory. By contrast, in prior-art systems, a fault handler would typically remedy the page fault. Advantageously, because the microcontroller executes these tasks locally with respect to the MMU and the physical memory, latency associated with remedying page faults may be decreased. Consequently, overall system performance may be increased."
9589310,"One embodiment of the present invention sets forth a technique for splitting a set of vertices into a plurality of batches for processing. The method includes receiving one or more primitives each containing an associated set of vertices. For each of the one or more primitives, one or more vertices are gathered from the set of vertices, the vertices are arranged into one or more batches, the batch is routed to a processing pipeline line to process each batch as a separate primitive, and the one or more batches are processed to produce results identical to those of processing the entire primitive as a single entity."
9589383,"A method for simulating visual effects is disclosed. The method comprises modeling each visual effect within a simulation as a set of associated particles with associated constraints applicable thereto. It also comprises predicting first velocities and first positions of a plurality of particles being used to simulate a visual effect based on an external force applied to the plurality of particles. Next, it comprises identifying a set of neighboring particles for each of the plurality of particles. The method also comprises solving a plurality of constraints related to the visual effect, wherein each of the plurality of constraints is solved for the plurality of particles in parallel. Lastly, responsive to the solving, the method comprises determining second velocities and second positions for the plurality of particles."
9590806,"One embodiment of the present invention includes a boot read only memory (ROM) with an embedded, private key provision key (KPK) set that enables secure provisioning of chips. As part of taping-out a chip, the chip provider establishes the KPK set and provides the boot ROM exclusive access to the KPK. For each Original Equipment Manufacturer (OEM), the chip provider assigns and discloses an OEM-specific KPK that is included in the KPK set at a particular KPK index. Upon receiving a secured provisioning image and the associated KPK index, the boot ROM accesses the KPK set to reconstruct the KPK and then decrypts and executes the secured provisioning image. Advantageously, this enables the manufacturing factory to provision the chip without the security risks attributable to conventional provisioning approaches that require disclosing security keys to the manufacturing factory."
9591309,"A method, in one embodiment, can include performing difference transformation of image samples. In addition, the method can also include performing length selection. The method can also include performing a prioritized ordering of difference data. Furthermore, the method can include performing packing that includes utilizing varying sized bit fields to produce a lossy compressed representation."
9594247,"A system, method, and computer program product are provided for implementing a pinlight see-through near-eye display. Light cones configured to substantially fill a field-of-view corresponding to a pupil are generated by an array of pinlights positioned between a near focus plane and the pupil. Overlap regions where two of more light cones intersect at a display layer positioned between the array of pinlights and the pupil are determined. The two or more light cones are modulated based on the overlap regions to produce a target image at or beyond the near focus plane."
9594599,"A work distribution unit distributes work batches to general processing clusters (GPCs) based on the number of streaming multiprocessors included in each GPC. Advantageously, each GPC receives an amount of work that is proportional to the amount of processing power afforded by the GPC. Embodiments include a method for distributing batches of processing tasks to two or more general processing clusters (GPCs), including the steps of updating a counter value for each of the two or more GPCs based on the number of enabled parallel processing units within each of the two or more GPCs, and distributing a batch of processing tasks to a first GPC of the two or more GPCs based on a counter value associated with the first GPC and based on a load signal received from the first GPC."
9594675,Virtual chip enable techniques perform memory access operations on virtual chip enables rather than physical chip enables. Each virtual chip enable is a construct that includes attributes that correspond to a unique physical or logical memory device.
9594700,A method and a system are provided for controlling memory accesses. Memory access requests including at least a first speculative memory access request and a first non-speculative memory access request are received and a memory access request is selected from the memory access requests. A memory access command is generated to process the selected memory access request.
9595075,"Approaches are disclosed for performing memory access operations in a texture processing pipeline having a first portion configured to process texture memory access operations and a second portion configured to process non-texture memory access operations. A texture unit receives a memory access request. The texture unit determines whether the memory access request includes a texture memory access operation. If the memory access request includes a texture memory access operation, then the texture unit processes the memory access request via at least the first portion of the texture processing pipeline, otherwise, the texture unit processes the memory access request via at least the second portion of the texture processing pipeline. One advantage of the disclosed approach is that the same processing and cache memory may be used for both texture operations and load/store operations to various other address spaces, leading to reduced surface area and power consumption."
9595759,"Provided is an antenna. The antenna, in this aspect, includes an inverted-F GPS antenna structure, the inverted-F GPS antenna structure embodying a GPS feed element, a GPS extending arm, and a ground element. The antenna, in this aspect, further includes a loop WiFi antenna structure, the loop WiFi antenna structure embodying a WiFi feed element, the ground element, and a WiFi connecting arm coupling the WiFi feed element to the ground element. In this particular aspect, the ground element is located between the GPS feed element and the WiFi feed element."
9595827,"A subsystem is configured to apply a voltage source to a gated circuit domain in a manner that limits in-rush current and affords minimal time delay. A control signal turns on a wake-up switch that connects the voltage source to the domain. The equivalent series resistance of the wake-up switch has a magnitude that limits the transient charge current to the gated domain. A digital control circuit monitors the resulting rising domain voltage and determines when the domain voltage reaches operating level, at which point additional transient current will be minimal. The control circuit then activates a primary switch that connects the voltage source to the domain through a series resistance of negligible magnitude. An adjustment element provides the option to permanently set a control signal that marginally reduces the time at which the control circuit activates the primary switch to compensate for variations in circuit parameters."
9600235,"One embodiment of the present invention includes a method for performing arithmetic operations on arbitrary width integers using fixed width elements. The method includes receiving a plurality of input operands, segmenting each input operand into multiple sectors, performing a plurality of multiply-add operations based on the multiple sectors to generate a plurality of multiply-add operation results, and combining the multiply-add operation results to generate a final result. One advantage of the disclosed embodiments is that, by using a common fused floating point multiply-add unit to perform arithmetic operations on integers of arbitrary width, the method avoids the area and power penalty of having additional dedicated integer units."
9600446,"A preconditioner processor and a method of computing a preconditioning matrix. In one embodiment, the preconditioner processor has parallel computing pipelines including: (1) a graph coloring circuit operable to identify parallelisms in a sparse linear system, (2) an incomplete lower triangle, upper triangle factorization (ILU) computer configured to employ the parallel computing pipelines according to the parallelisms to: (2a) determine a sparsity pattern for an ILU preconditioning matrix, and (2b) compute non-zero elements of the ILU preconditioning matrix according to the sparsity pattern, and (3) a memory communicably couplable to the parallel computing pipelines and configured to store the ILU preconditioning matrix."
9600852,"A graphical processing unit having an implementation of a hierarchical hash table thereon, a method of establishing a hierarchical hash table in a graphics processing unit and GPU computing system are disclosed herein. In one embodiment, the graphics processing unit includes: (1) a plurality of parallel processors, wherein each of the plurality of parallel processors includes parallel processing cores, a shared memory coupled to each of the parallel processing cores, and registers, wherein each one of the registers is uniquely associated with one of the parallel processing cores and (2) a controller configured to employ at least one of the registers to establish a hierarchical hash table for a key-value pair of a thread processing on one of the parallel processing cores."
9602083,"Clock generation circuit that track critical path across process, voltage and temperature variation. In accordance with a first embodiment of the present invention, an integrated circuit device includes an oscillator electronic circuit on the integrated circuit device configured to produce an oscillating signal and a receiving electronic circuit configured to use the oscillating signal as a system clock. The oscillating signal tracks a frequency-voltage characteristic of the receiving electronic circuit across process, voltage and temperature variations. The oscillating signal may be independent of any off-chip oscillating reference signal."
9602230,"Disclosed is a method of providing channel state information for a desired downlink channel of a wireless communication system. In a configuration phase, the method comprises receiving on a signaling channel configuration information comprising an identifier of an interference source and an association which associates the identifier with at least one resource element not used for transmission on the desired downlink channel. In an estimation phase, the method comprises estimating channel state information for an expected transmission on the desired downlink channel accounting for an incoming interference transmission from the identified interference source as observed from the at least one resource element. In a reporting phase, the method comprises reporting the channel state information."
9602821,"For encoding, a frame of video data can be segregated into macroblocks, which can be segregated into slices, which in turn can be segregated into slice groups. A macroblock identifier (ID) can be associated with each of the macroblocks. When at least one slice from each of the slice groups has been encoded, the macroblock IDs associated with the encoded slices can be compared to determine an order in which the encoded slices are to be placed in an access unit for the frame. Of the encoded slices, the slice that includes the macroblock with the lowest macroblock ID will be placed in the access unit before the other encoded slices."
9606808,"A computing device detects divergences between threads in a thread group executing on a parallel processing unit. The computing device includes an address divergence unit that identifies a subset of non-divergent threads included in the thread group. The address divergence unit stores instructions related to the subset of non-divergent threads in a multi-issue queue. The address divergence unit causes the instructions related to the subset of non-divergent threads to be retrieved from the multi-issue queue when the parallel processing unit is available. The address divergence unit causes the subset of non-divergent threads to be issued for execution on the parallel processing unit. The address divergence unit repeats the identifying, storing, and causing steps for the remaining threads in the thread group that are not included in the subset of non-divergent threads."
9607133,"A method and apparatus for inserting a watermark into a compiled computer program. A location process specifies an insertion point in the compiled program and a watermark generating process inserts a watermark, based on data to be encoded, into the program at the insertion point. The location process is also utilized to specify the location of watermark data to be decoded."
9607407,"A method, in one embodiment, can include performing difference transformation of image samples. In addition, the method can also include performing length selection. Furthermore; the method can include performing packing that includes utilizing varying sized bit fields to produce a compressed representation."
9607714,A method of training a command signal for a memory module. The method includes programming a memory controller into a mode where a single bit of an address signal is active for a single clock cycle. The method then programs a programmable delay line of the address signal with a delay value and performs initialization of the memory module. The memory module is then placed in a write leveling mode. A write leveling procedure is then performed and a response to the write leveling procedure is determined from the memory module. A determination is made whether the memory module is in a pass state or an error state based on the response.
9612801,"A true random number generator, a method of generating a true random number and a system incorporating the generator or the method. In one embodiment, the generator includes: (1) a ring oscillator including inverting gates having power inputs and (2) a time-varying power supply coupled to the power inputs to provide power thereto and including power perturbation circuitry operable to perturb the power provided to at least one of the power inputs."
9612811,One embodiment of the present invention sets forth a method for causing thread convergence. The method includes determining that a control flow graph representing a first section of a program includes at least two non-overlapping paths that extend from a first divergent node to a candidate node. The method also includes determining that the first divergent node is not a dominator of the candidate node or that the candidate node is not a post-dominator of the first divergent node. The method further includes identifying an external node and inserting a first instruction configured to cause a predicate variable to be set to true for a first set of threads that is to execute the external node. The method additionally includes inserting into the program a second divergent node configured to cause various threads to execute or not execute a first control flow path associated with the external node.
9612836,"A system, method, and computer program product are provided for implementing a software-based scoreboarding mechanism. The method includes the steps of receiving a dependency barrier instruction that includes an immediate value and an identifier corresponding to a first register and, based on a comparison of the immediate value to the value stored in the first register, dispatching a subsequent instruction to at least a first processing unit of two or more processing units."
9612839,A graphics processing pipeline configured for z-cull operations. The graphics processing pipeline comprising a screen-space pipeline and a tiling unit. The screen-space pipeline includes a z-cull unit configured to perform z-culling operations. The tiling unit is configured to determine that a first set of primitives overlaps a first cache tile. The tiling unit is also configured to transmit the first set of primitives to the screen-space pipeline for processing. The tiling unit is further configured to select between processing the first set of primitives in a full-surface z-cull mode or processing the first set of primitives in a partial-surface z-cull mode. The tiling unit is also configured to cause the z-cull unit to process the first set of primitives in the full-surface z-cull mode or to process the first set of primitives in the partial-surface z-cull mode.
9612994,Systems and devices configured to implement techniques for ensuring the completion of transactions while minimizing latency and power consumption are described. A device may be operably coupled to a bidirectional communications bus. A bidirectional communications bus may include a clock line and a data line. The device may be configured to determine if an initiated transaction corresponds to a device in a low power state. The device may pause the transaction. The device may replay portions of the transaction when the device is in an appropriate power state. The device may replay portions of the transaction using an override interface.
9613215,"A method, an integrated circuit and a system for implementing a secure chain of trust is disclosed. While executing secure boot code in a secure boot mode, less-secure boot code may be authenticated using a secret key. A secure key may also be calculated or generated during the secure boot mode. After control is turned over to the authenticated less-secure boot code, at least one application may be authenticated using the secure key. Once authenticated in the less-secure boot mode, the application may be executed by the programmable integrated circuit. In this manner, a secure chain of trust may be implemented for the programmable integrated circuit."
9613390,"The server based graphics processing techniques, describer herein, include receiving function calls by a three dimension graphics application programming interface host-guest communication manager (D3D HGCM) service module from one or more given instances of a guest shin layer through a communication channel of a host-guest communication manager (HGCM). The one or more given instances of the guest shim layer are executing under control of a respective given instance of a guest operating system. The HGCM and D3D HGCM service module are executing under control of a host operating system. The rendering context for each function call received from the each instance of the guest shim layer is determined by the D3D HGCM service module. Each function call of a given rendering context is sent by the D3D HGCM service module to a corresponding device specific kernel mode driver of a given graphics processing unit for scheduling execution with the given graphics processing unit of the given rendering context."
9613449,"A computer implemented method of simulating a stack of objects represented as data within memory of a computer system is disclosed. The method comprises modeling the stack within a computer simulation as a set of associated primitives with associated constraints thereto in the memory, wherein the stack comprises a plurality of layers and wherein each layer comprises at least one primitive. The method further comprises estimating a height for each of the primitives in the stack and determining a respective scaling factor for each of the primitives in parallel, wherein each scaling factor is operable to adjust a mass value of each of the primitives. Also, the method comprises scaling a mass value of each of the primitives in accordance with a respective scaling factor in parallel. Finally, the method comprises solving over a plurality of constraints iteratively using a scaled mass value for each of the primitives."
9613451,"One embodiment of the present invention sets forth a technique for rendering anti-aliased paths by first generating an alpha buffer representing coverage data. To generate the alpha buffer, jittered versions of the rendered path are rendered and corresponding stencil buffers indicating sub-pixel samples of the path that should be covered are generated. After each stencil buffer is generated, the jittered path is rasterized to convert the sub-pixel coverage into coverage weights that are stored in the alpha component of a frame buffer. As each jittered path is rasterized, the coverage weights are accumulated. Finally, geometry representing the union of the jittered versions of the path is rendered to shade pixels based on the accumulated coverage weights. The anti-aliased rendered paths may be filled or stroked without tessellating the paths."
9615176,"A portable electronic device is provided having an audio subsystem with a plurality of audio devices, each of which is coupled to a logic subsystem via its own audio path. The portable electronic device may also include a display configured to present visual content, with the display being fixed in position relative to the plurality of audio devices. The portable electronic device further includes an orientation sensor electronically coupled to the logic subsystem, the logic subsystem being configured, using data received from the orientation sensor, (i) to determine whether the portable electronic device has been reoriented; and (ii) in response to such determination, vary operation of one or more of the audio paths."
9619004,"Circuits, methods, and apparatus that reduce the power consumed by data transfers initiated by a USB host controller. Peripheral devices on a USB network are accessed with a reduced frequency in order to save power dissipated by a CPU and other circuits when reading data needed by the host controller. Instead of possibly accessing devices each frame, peripheral devices are accessed during some frames, and not accessed during others. A USB host controller may have two or more modes, such as a low power mode and a regular mode. In the low power mode, USB devices are accessed during fewer than all frames, in the regular mode, USB devices are possibly accessed each frame. Mode selection may depend on whether battery power is used."
9619204,"A system and method for performing sorting. The method includes partitioning a plurality of keys needing sorting into a first plurality of bins, wherein the bins are sequentially sorted. The plurality of keys is capable of being sorted into a sequence of keys using a corresponding ordering system. The method includes coalescing a first pair of consecutive bins, such that when coalesced the first pair of bins falls below a threshold. The method also includes ordering keys in the first coalesced pair to generate a first sub-sequence of keys in the sequence of keys."
9619364,"A method for analyzing race conditions between multiple threads of an application is disclosed. The method comprises accessing hazard records for an application under test. It further comprises creating a graph comprising a plurality of vertices and a plurality of edges using the hazard records, wherein each vertex of the graph comprises information about a code location of a hazard and wherein each edge of the graph comprises hazard information between one or more vertices. Additionally, it comprises assigning each edge with a weight, wherein the weight depends on a number and relative priority of hazards associated with a respective edge. Finally, it comprises traversing the graph to report an analysis record for each hazard represented in the graph."
9619930,"A light transport simulator and a method of constructing and classifying light transport paths. One embodiment of the light transport simulator includes a light transport simulator operable to construct and classify a light transport path between two points in a scene, including: (1) a memory configured to store dual deterministic finite automata (DFA) based on an LPE that defines criteria for accepting the light transport path, and (2) a processor configured to employ the dual DFA to construct opposing light subpaths originating from the two points, and employ a correspondence among states of the dual DFA to unite the opposing light subpaths to form the light transport path."
9621780,"An efficient method and system for estimating an optimal focus position for capturing an image are presented. Embodiments of the present invention initially determine an initial lens position dataset. Then, scores are calculated for each value of the initial lens position dataset producing a plurality of scores. Embodiments of the present invention then determine an optimum focus position through interpolation and extrapolation by relating the initial lens position dataset to the score dataset, in which the score dataset comprises of the plurality of scores."
9626191,"One embodiment of the present invention sets forth a technique for performing a shaped access of a register file that includes a set of N registers, wherein N is greater than or equal to two. The technique involves, for at least one thread included in a group of threads, receiving a request to access a first amount of data from each register in the set of N registers, and configuring a crossbar to allow the at least one thread to access the first amount of data from each register in the set of N registers."
9626216,"A technique for executing a plurality of applications on a GPU. The technique involves establishing a first connection to a first application and a second connection to a second application, establishing a universal processing context that is shared by the first application and the second application, transmitting a first workload pointer to a first queue allocated to the first application, the first workload pointer pointing to a first workload generated by the first application, transmitting a second workload pointer to a second queue allocated to the second application, the second workload pointer pointing to a second workload generated by the second application, transmitting the first workload pointer to a first GPU queue in the GPU, and transmitting the second workload pointer to a second GPU queue in the GPU, wherein the GPU is configured to execute the first workload and the second workload in accordance with the universal processing context."
9626320,"A transmitter is configured to scale up a low bandwidth delivered by a first processing element to match a higher bandwidth associated with an interconnect. A receiver is configured to scale down the high bandwidth delivered by the interconnect to match the lower bandwidth associated with a second processing element. The first processing element and the second processing element may thus communicate with one another across the interconnect via the transmitter and the receiver, respectively, despite the bandwidth mismatch between those processing elements and the interconnect."
9627021,"An 8-transistor SRAM (static random access memory) storage cell provides differential read bit lines that are precharged to a low voltage level for read operations. The 8-transistor storage cell provides separate ports for read and write operations, including differential read bit lines. Prior to each read operation, the differential read bit lines are precharged to the low voltage level. During read operations, one of the two differential read bit lines is pulled high towards a high voltage level while the complementary bit line remains at the low voltage level resulting from the precharge. The difference in voltage between the differential read bit lines is sensed to determine the value stored in each 8-transistor SRAM storage cell and complete the read operation."
9628705,"In one embodiment, a car navigation device is provided. The device comprises: at least one wide-angle camera; a video correction unit for acquiring video data from the wide-angle lens and correcting the video data; a video merging unit for acquiring corrected video data from video correction unit and merging the corrected video data; an image recognition unit for acquiring video from the video merging unit and performing image recognition to the video; and a driving assistant unit for acquiring data from the image recognition unit and assisting driving in accordance with the recognized content. The navigation device provided by various embodiments in accordance with the present invention can correct and recognize the images taken by fisheye lens in real-time so as to assist the driver for driving or drive the car automatically without a human being."
9632834,"One embodiment sets forth a method for assigning priorities to kernels launched by a software application and executed within a stream of work on a parallel processing subsystem. First, the software application assigns a desired priority to a stream using a call included in the API. The API receives this call and passes it to a driver. The driver maps the desired priority to an appropriate device priority associated with the parallel processing subsystem. Subsequently, if the software application launches a particular kernel within the stream, then the driver assigns the device priority associated with the stream to the kernel before adding the kernel to the stream for execution on the parallel processing subsystem. Advantageously, by assigning priorities to streams and, subsequently, strategically launching kernels within the prioritized streams, an application developer may fine-tune the software application to increase the overall processing efficiency of the software application."
9632976,"Embodiments related to managing lazy runahead operations at a microprocessor are disclosed. For example, an embodiment of a method for operating a microprocessor described herein includes identifying a primary condition that triggers an unresolved state of the microprocessor. The example method also includes identifying a forcing condition that compels resolution of the unresolved state. The example method also includes, in response to identification of the forcing condition, causing the microprocessor to enter a runahead mode."
9633458,"In a graphics processing pipeline, a processing unit establishes a bounding box around a polygon in order to identify sample points that are covered by the polygon. For a given sample point included within the bounding box, the processing unit constructs a set of lines that intersect at the sample point, where each line in the set of lines is parallel to at least one side of the polygon. When all vertices of the polygon reside on one side of at least one line in the set of lines, the processing unit may reduce the size of the bounding box to exclude the sample point."
9633469,"A system, method, and computer program product are provided for conservative rasterization of primitives using an error term. In use, an edge equation is determined for each edge of a primitive, the edge equation having coefficients defining the edge of the primitive. Each edge of the primitive is shifted to enlarge the primitive by modifying coefficients of the edge equation defining the edge by an error term that is a predetermined amount. Pixels that intersect the primitive are then determined using the enlarged primitive."
9639102,A system and method are provided for estimating current. A current source is configured to generate a current and a pulsed sense enable signal is generated. An estimate of the current is generated and the estimate of the current is updated based on a first signal that is configured to couple the current source to an electric power supply and a second signal that is configured to couple the current source to aloud. A system includes the current source and a current prediction unit. The current source is configured to generate a current. The current prediction unit is coupled the current source and is configured to generate the estimate of the current and update the estimate of the current based on the first signal and the second signal.
9639327,"A circuit for multiplying a digital signal by a variable gain, controlled in dependence on a digital gain control value. The circuit comprises: a multiplier input for receiving the digital signal; a multiplier output for outputting the digital signal multiplied by the gain; a plurality of multiplier stages each arranged to multiply by a respective predetermined multiplication factor; and switching circuitry arranged so as to apply selected ones of the multiplier stages in a multiplication path between the input and output, in dependence on the digital gain control value. The multiplication factors are arranged such that binary steps in the digital gain control value result in logarithmic steps in said gain."
9639336,"One embodiment of the present invention sets forth a technique for reducing the number of assembly instructions included in a computer program. The technique involves receiving a directed acyclic graph (DAG) that includes a plurality of nodes, where each node includes an assembly instruction of the computer program, hierarchically parsing the plurality of nodes to identify at least two assembly instructions that are vectorizable and can be replaced by a single vectorized assembly instruction, and replacing the at least two assembly instructions with the single vectorized assembly instruction."
9639365,"An indirect branch instruction takes an address register as an argument in order to provide indirect function call capability for single-instruction multiple-thread (SIMT) processor architectures. The indirect branch instruction is used to implement indirect function calls, virtual function calls, and switch statements to improve processing performance compared with using sequential chains of tests and branches."
9639366,"One embodiment of the present invention sets forth a technique for managing buffer table entries in a tile-based architecture. The technique includes binding a plurality of shader registers to a buffer table entry. The technique further includes processing at least one tile by reading a buffer table index stored in the shader register to access the buffer table entry, reading a buffer address stored in the buffer table entry, accessing data associated with the buffer address, and unbinding the shader register from the buffer table entry. The technique further includes determining that none of the shader registers is still bound to the buffer table entry and, in response, causing a release packet to be inserted into an instruction stream. The technique further includes determining that a last tile has been processed and, in response, transmitting the release packet to cause the buffer table entry to be released."
9639367,"One embodiment of the present invention sets forth a graphics processing system configured to track event counts in a tile-based architecture. The graphics processing system includes a screen-space pipeline and a tiling unit. The screen-space pipeline includes a first unit, a count memory associated with the first unit, and an accumulating memory associated with the first unit. The first unit is configured to detect an event type and increment the count memory. The tiling unit is configured to cause the screen-space pipeline to update an external memory address to reflect a first value stored in the count memory when the first unit completes processing of a first set of primitives. The tiling unit is also configured to cause the screen-space pipeline to update the accumulating memory to reflect a second value stored in the count memory when the first unit completes processing of a second set of primitives."
9639466,"One embodiment of the present invention sets forth a technique for processing commands received by an intermediary cache from one or more clients. The technique involves receiving a first write command from an arbiter unit, where the first write command specifies a first memory address, determining that a first cache line related to a set of cache lines included in the intermediary cache is associated with the first memory address, causing data associated with the first write command to be written into the first cache line, and marking the first cache line as dirty. The technique further involves determining whether a total number of cache lines marked as dirty in the set of cache lines is less than, equal to, or greater than a first threshold value, and: not transmitting a dirty data notification to the frame buffer logic when the total number is less than the threshold value, or transmitting a dirty data notification to the frame buffer logic when the total number is equal to or greater than the first threshold value."
9639471,"Attributes of access requests can be used to distinguish one set of access requests from another set of access requests. The prefetcher can determine a pattern for each set of access requests and then prefetch cache lines accordingly. In an embodiment in which there are multiple caches, a prefetcher can determine a destination for prefetched cache lines associated with a respective set of access requests. For example, the prefetcher can prefetch one set of cache lines into one cache, and another set of cache lines into another cache. Also, the prefetcher can determine a prefetch distance for each set of access requests. For example, the prefetch distances for the sets of access requests can be different."
9639474,"Techniques are provided by which memory pages may be migrated among PPU memories in a multi-PPU system. According to the techniques, a UVM driver determines that a particular memory page should change ownership state and/or be migrated between one PPU memory and another PPU memory. In response to this determination, the UVM driver initiates a peer transition sequence to cause the ownership state and/or location of the memory page to change. Various peer transition sequences involve modifying mappings for one or more PPU, and copying a memory page from one PPU memory to another PPU memory. Several steps in peer transition sequences may be performed in parallel for increased processing speed."
9639479,"A method for managing a parallel cache hierarchy in a processing unit. The method includes receiving an instruction from a scheduler unit, where the instruction comprises a load instruction or a store instruction; determining that the instruction includes a cache operations modifier that identifies a policy for caching data associated with the instruction at one or more levels of the parallel cache hierarchy; and executing the instruction and caching the data associated with the instruction based on the cache operations modifier."
9639494,"One embodiment of the present invention includes a hard-coded first device ID. The embodiment also includes a set of fuses that represents a second device ID. The hard-coded device ID and the set of fuses each designate a separate device ID for the device, and each device ID corresponds to a specific operating configuration of the device. The embodiment also includes selection logic to select between the hardcoded device ID and the set of fuses to set the device ID for the device. One advantage of the disclosed embodiments is providing flexibility for engineers who develop the devices while also reducing the likelihood that a third party can counterfeit the device."
9640249,"A write-assist memory includes a memory supply voltage and a column of SRAM cells that is controlled by a pair of bit lines, during a write operation. Additionally, the write-assist memory includes a write-assist unit that is coupled to the memory supply voltage and the column of SRAM cells and has a separable conductive line located between the pair of bit lines that provides a collapsible SRAM supply voltage to the column of SRAM cells based on a capacitive coupling of a control signal in the pair of bit lines, during the write operation. A method of operating a write-assist memory is also provided."
9641182,"A digital phase-and-frequency controller. In one embodiment, the controller includes: (1) a first segment accumulator operable to accumulate errors while an accumulation-selection signal has a first value and (2) a second segment accumulator operable to accumulate errors while said accumulation-selection signal has a second value, and (3) circuitry operable to produce the control signal using the errors accumulated in the first segment accumulator while a use-selection signal has a first value and the errors accumulated in the second segment accumulator while the use-selection signal has a second value."
9645635,"A power-gating array configured to power gate a logic block includes multiple zones of sleep field-effect transistors (FETs). A zone controller coupled to the power-gating array selectively enables a certain number of zones within the array depending on the voltage drawn by the logic block. When the logic block draws a lower voltage, the zone controller enables a lower number of zones. When the logic block draws a higher voltage, the zone controller enables a greater number of zones. One advantage of the disclosed technique is that sleep FET usage is reduced, thereby countering the effects of FET deterioration due to BTI and TDDB. Accordingly, the lifetime of sleep FETs configured to perform power gating for logic blocks may be extended."
9645802,"A device compiler and linker is configured to group instructions into different strands for execution by different threads based on the dependence of those instructions on other, long-latency instructions. A thread may execute a strand that includes long-latency instructions, and then hardware resources previously allocated for the execution of that thread may be de-allocated from the thread and re-allocated to another thread. The other thread may then execute another strand while the long-latency instructions are in flight. With this approach, the other thread is not required to wait for the long-latency instructions to complete before acquiring hardware resources and initiating execution of the other strand, thereby eliminating at least a portion of the time that the other thread would otherwise spend waiting."
9645929,"In a processor, a method for speculative permission acquisition for access to a shared memory. The method includes receiving a store from a processor core to modify a shared cache line, and in response to receiving the store, marking the cache line as speculative. The cache line is then modified in accordance with the store. Upon receiving a modification permission, the modified cache line is subsequently committed."
9646656,One embodiment sets forth a technique for time-multiplexed communication for transmitting command and address information between a controller and a multi-port memory device over a single connection. Command and address information for each port of the multi-port memory device is time-multiplexed within the controller to produce a single stream of commands and addresses for different memory requests. The single stream of commands and addresses is transmitted by the controller to the multi-port memory device where the single stream is demultiplexed to generate separate streams of commands and addresses for each port of the multi-port memory device.
9652016,Techniques for degrading rendering performance to extend operating time of a computing platform includes determining a source and a level of power for the computing platform during receipt of the graphics data and rendering of the graphics data. Graphics data is rendered using settings received from the application if the computing platform is not operating from a limited power supply. The graphics data is rendered using one or more sets of graphics processing power conservation rendering settings if the computing platform is operating from a limited power supply and the remaining energy capacity of the limited power supply is less than one or more predetermined levels.
9652282,One embodiment of the present invention sets forth a technique for instruction level execution preemption. Preempting at the instruction level does not require any draining of the processing pipeline. No new instructions are issued and the context state is unloaded from the processing pipeline. Any in-flight instructions that follow the preemption command in the processing pipeline are captured and stored in a processing task buffer to be reissued when the preempted program is resumed. The processing task buffer is designated as a high priority task to ensure the preempted instructions are reissued before any new instructions for the preempted context when execution of the preempted context is restored.
9652815,"A graphics processing subsystem and a method of shading are provided. In one embodiment, the subsystem includes: (1) a memory configured to contain a texel data structure according to which multiple primitive texels corresponding to a particular composite texel are contained in a single page of the memory and (2) a graphics processing unit configured to communicate with the memory via a data bus and execute a shader to fetch the multiple primitive texels contained in the single page to create the particular composite texel."
9659139,"One embodiment of the present invention includes a method for updating timing parameters after a circuit design change. The method includes, prior to the circuit design change, deriving a value for a first timing parameter based on a signoff timing analysis of a timing arc, and a value for a second timing parameter based on a quick timing analysis of the timing arc; and obtaining a first transition time based on the quick timing analysis. The method further includes, after the circuit design change, deriving a value for a third timing parameter based on the quick timing analysis, obtaining a second transition time based on the quick timing analysis, and deriving a fourth value for a fourth parameter based on the quick timing analysis, wherein the fourth parameter is based on the first, second, and third parameters and on the first and second transition times."
9659339,"A processing unit includes multiple execution pipelines, each of which is coupled to a first input section for receiving input data for pixel processing and a second input section for receiving input data for vertex processing and to a first output section for storing processed pixel data and a second output section for storing processed vertex data. The processed vertex data is rasterized and scan converted into pixel data that is used as the input data for pixel processing. The processed pixel data is output to a raster analyzer."
9659399,"A system, method, and computer program product are provided for passing attribute structures between shader stages of a processing pipeline. The method includes the steps of receiving data represented at a first level by a processing pipeline including an upstream shader unit, a downstream shader unit, and a processing unit. The upstream shader unit processes the data to generate a first set of attributes corresponding to the data represented at a second level. The upstream shader unit also stores the first set of the attributes in a first portion of a memory system that can be read by the downstream shader unit and any shader units that are downstream in the processing pipeline relative to the upstream shader unit. In one embodiment, the processing unit is coupled between the upstream shader unit and the downstream shader unit."
9659815,"A system, method, and computer program product are provided for producing a cavity bottom package of a package-on-package structure. The method includes the steps of receiving a bottom package comprising a substrate material having a top layer including a first set of pads configured to be electrically coupled to a second set of pads of an integrated circuit die. A layer of non-conductive material is applied to the top layer of the bottom package and a cavity is formed in the layer of non-conductive material to expose the first set of pads, where the cavity is configured to contain the integrated circuit die oriented such that the second set of pads face the first set of pads."
9660599,"A system and method are provided for controlling a radio frequency (RF) power amplifier. A magnitude input and a phase input are received for transmission of a RF signal by the RF power amplifier. A digital pulse, having a center position relative to an edge of a reference clock based on the phase input and having a width based on the magnitude input, is generated. The digital pulse is filtered with a resonant matching network to produce the RF signal corresponding to the magnitude input and the phase input."
9665920,"One embodiment of the present invention sets forth a technique for distributing graphics commands and atomic commands to a color processing unit (CROP) in an efficient manner. The interleaving mechanism determines, at each clock cycle, which graphics command(s) or atomic command(s) is transmitted to the CROP based on different factors. First, the interleaving mechanism ensures that atomic commands or graphics commands associated with a multi-transaction command stream are processed together. Second, the interleaving mechanism selects consecutive graphics commands for transmission to the CROP that optimize the use of different memory caches. Third, the interleaving mechanism prioritizes atomic commands over graphics commands. At each clock cycle, the graphics command(s) or the atomic command(s) selected by the interleaving mechanism are transmitted to the CROP for processing."
9665958,"A system, method, and computer program product are provided for redistributing multi-sample processing workloads between threads. A workload for a plurality of multi-sample pixels is received and each thread in a parallel thread group is associated with a corresponding multi-sample pixel of the plurality of pixels. The workload is redistributed between the threads in the parallel thread group based on a characteristic of the workload and the workload is processed by the parallel thread group. In one embodiment, the characteristic is rasterized coverage information for the plurality of multi-sample pixels."
9665969,"One embodiment of the present invention discloses a method for processing video data within a video data processing path of a processing unit. The video data processing path includes three stages. In the first stage, source operands are extracted from a local register file and are ordered to map efficiently onto the downstream data path. In the second stage, arithmetic operations are performed on the source operands based on video processing instructions to generate intermediate results. In the third stage, additional operations are performed on the intermediate results based on the video processing instructions. In some embodiment, the intermediate results are combined with additional operands retrieved from the local register file."
9667068,"A system, method, and computer program product are provided for merging two or more supply rails into a merged supply rail. The method comprises receiving two or more current measurement signals associated with two or more supply rails, selecting one supply rail from the two or more supply rails, based on the current measurement signals, and enabling the selected supply rail to source current into a merged supply rail."
9667230,"A method for operating a latch and a latch circuit are disclosed. The latch circuit comprises a storage sub-circuit, a propagation sub-circuit, and a shared clock-enabled transistor. The storage sub-circuit is configured to capture a level of an input signal when a clock signal transitions from first level to a second level and hold the captured level to generate an output signal while the clock signal is at the second level. The propagation sub-circuit is configured to enable a path through a blocking transistor to the shared clock-enabled supply node to propagate the captured level of the input signal to the storage sub-circuit. The shared clock-enabled transistor is configured to couple the shared clock-enabled supply node to a power supply while the clock signal is at the first level and decouple the shared clock-enabled supply node from the power supply while the clock signal is at the second level."
9667668,"One aspect provides a method of handling a proactive indication received from a subscriber identity module at a modem, the modem being connected to a terminal equipment via a command interface. The method comprises receiving, at a modem processor, the proactive indication from the subscriber identity module. The method further comprises determining that the indication is to be handled by the modem processor. The method further comprises a modem processor transmitting a display command via the command interface to the terminal equipment and the modem processor awaiting a user response command, and continuing or aborting an action indicated in the proactive indication depending on the user response in the user response command received from the terminal equipment."
9668284,One aspect provides a method of operating a modem at a terminal. The modem is arranged to store one or more message identifier. Each of the one or more message identifier identifies a type of message that the modem is arranged to act upon when received on a broadcast channel from a communications network. The method comprises detecting a country that the terminal is located in. The method further comprises determining if the detected country is a country in which a public warning system is implemented. The method further comprises determining if the one or more message identifier includes only public warning message identifiers. The method further comprises disabling monitoring of the broadcast channel if the detected country is not a country in which a public warning system is implemented and the one or more message identifier includes only public warning message identifiers.
9671877,"A passive stylus with a deformable tip is described herein. In one embodiment, a thin annular body configured to be hand-held with a chisel shaped tip disposed at the first end of the body is provided. The chisel shaped tip includes a deformable material such that the chisel shaped tip is operable to interface with a touch a sensitive surface with a detectable surface area when a first pressure is exerted on the body and translated to the chisel shaped tip. The chisel shaped tip is operable to interface with the touch sensitive surface with a second detectable surface area, this one different from the first detectable surface area, when a second pressure is exerted on the body and translated to the chisel shaped tip. The stylus may include a second tip on the back end for providing an erase function."
9672008,"A system, method, and computer program product are provided for a pausible bisynchronous FIFO. Data is written synchronously with a first clock signal of a first clock domain to an entry of a dual-port memory array and an increment signal is generated in the first clock domain. The increment signal is determined to transition near an edge of a second dock signal, where the second clock signal is a pausible clock signal. A next edge of the second clock signal of the second clock domain is delayed and the increment signal to the second clock domain and is transmitted."
9672653,"A stereo viewpoint graphics processing subsystem and a method of sharing geometry data between stereo images in screen-space processing. One embodiment of the stereo viewpoint graphics processing subsystem configured to render a scene includes: (1) stereo frame buffers configured to contain respective pixel-wise rendered scene data for stereo images, and (2) a sharing decision circuit operable to determine when to share geometric data between the stereo frame buffers for carrying out screen-space effect processes to render the scene in the stereo images."
9678529,"One aspect of the disclosure provides a computer system. In one embodiment, the computer system comprises a clock generator, at least one processor, and a clock frequency controller. The clock generator is configured to provide a clock signal at a clock frequency. The at least one processor is configured to receive the clock signal and to operate at a speed dependent on the clock frequency. The clock frequency controller is configured to receive efficiency information indicating a current efficiency of the at least one processor. The clock frequency controller is further configured to receive a request from the processor for a target number of processor instructions to be handled in a particular time period. The clock frequency controller is further configured to output a frequency control signal to the clock generator for controlling the clock frequency in dependence thereon."
9678775,Computer code written to execute on a multi-threaded computing environment is transformed into code designed to execute on a single-threaded computing environment and simulate concurrent executing threads. Optimization techniques during the transformation process are utilized to identify local variables for scalar expansion. A first set of local variables is defined that includes those local variables in the code identified as “Downward exposed Defined” (DD). A second set of local variables is defined that includes those local variables in the code identified as “Upward exposed Use” (UU). The intersection of the first set and the second set identifies local variables for scalar expansion.
9678897,"A streaming multiprocessor in a parallel processing subsystem processes atomic operations for multiple threads in a multi-threaded architecture. The streaming multiprocessor receives a request from a thread in a thread group to acquire access to a memory location in a lock-protected shared memory, and determines whether a address lock in a plurality of address locks is asserted, where the address lock is associated the memory location. If the address lock is asserted, then the streaming multiprocessor refuses the request. Otherwise, the streaming multiprocessor asserts the address lock, asserts a thread group lock in a plurality of thread group locks, where the thread group lock is associated with the thread group, and grants the request. One advantage of the disclosed techniques is that acquired locks are released when a thread is preempted. As a result, a preempted thread that has previously acquired a lock does not retain the lock indefinitely."
9679530,"One embodiment of the present invention sets forth a method for compressing via a pixel shader color information associated with a line of pixels. An intermediary representation of an uncompressed stream of color information is first generated that indicates, for each pixel, whether a previous adjacent pixel shares color information with the pixel. A set of cascading buffers is then generated based on intermediary representation, where each cascading buffer represents a number of unique color codes across different groups of pixels. Finally, a compressed output stream that specifies the unique color codes as well as the number of pixels that share each unique color code is generated based on the set of cascading buffers."
9684581,"One embodiment of the present invention includes a dependency extractor and a dependency investigator that, together, facilitate performance analysis of computer systems. In operation, the dependency extractor instruments a software application to generate run-time execution data for each work task. This execution data includes per-task performance data and dependency data reflecting linkages between tasks. After the instrumented software application finishes executing, the dependency investigator evaluates the captured execution data and identifies the critical path of tasks that establishes the overall run-time of the software application. Advantageously, since the execution data includes both task-level performance data and dependencies between tasks, the dependency investigator enables the developer to effectively optimize software and hardware in computer systems that are capable of concurrently executing tasks. By contrast, conventional performance analysis may not correctly identify critical paths in software applications that execute tasks in parallel across multiple processing units and, consequently, may misdirect optimization efforts."
9684998,"One embodiment includes determining a first z-range for a first portion of a coarse raster tile, where the first portion includes a plurality of pixels having a first set of pixel locations, retrieving from a memory a corresponding z-range related to a second set of pixel locations associated with the coarse raster tile, where the first set of pixel locations comprises a subset of the second set of pixel locations, and comparing the first z-range to the corresponding z-range to determine whether the plurality of pixels is occluded. If the plurality of pixels determined to be occluded, then the plurality of pixels is culled. If the plurality of pixels is determined to not be occluded, then the plurality of pixels is transmitted to a fine raster unit for further processing. The coarse raster tile comprises a plurality of portions, including the first portion, and those portions are processed serially."
9685207,"A synchronous sequential latch array generated by an automated system for generating master-slave latch structures is disclosed. A master-slave latch structure includes N/2 rows of master-slave latch pairs, an N/2-to-1 multiplexer and control logic. N is equal to the number of latches that are included in the latch array."
9690715,"One embodiment of the present invention includes a hash selector that facilitates performing effective hashing operations. In operation, the hash selector creates a transformation matrix that reflects specific optimization criteria. For each hash value, the hash selector generates a potential hash value and then computes the rank of a submatrix included in the transformation matrix. Based on this rank in conjunction with the optimization criteria, the hash selector either re-generates the potential hash value or accepts the potential hash value. Advantageously, the optimization criteria may be tailored to create desired correlations between input patterns and the results of performing hashing operations based on the transformation matrix. Notably, the hash selector may be configured to efficiently and reliably incrementally generate a transformation matrix that, when applied to certain strides of memory addresses, produces a more uniform distribution of accesses across caches lines than previous approaches to memory addressing."
9690736,"A microprocessor within a processing unit is configured to manage to operation of a finite state machine (FSM) that, in turn, manages the operation of a data connector. The FSM may be a hardwired chip component that adheres to a communication protocol associated with the data connector. The microprocessor is configured to execute a software application in order to (i) apply configuration changes to the processing unit during state transitions initiated by the FSM and (ii) cause the FSM to initiate specific state transitions."
9697006,"A texture processing pipeline can be configured to service memory access requests that represent texture data access operations or generic data access operations. When the texture processing pipeline receives a memory access request that represents a texture data access operation, the texture processing pipeline may retrieve texture data based on texture coordinates. When the memory access request represents a generic data access operation, the texture pipeline extracts a virtual address from the memory access request and then retrieves data based on the virtual address. The texture processing pipeline is also configured to cache generic data retrieved on behalf of a group of threads and to then invalidate that generic data when the group of threads exits."
9697044,"An application programming interface (API) provides various software constructs that allow a developer to assemble a processing pipeline having arbitrary structure and complexity. Once assembled, the processing pipeline is configured to include a set of interconnected pipestages. Those pipestages are associated with one or more different CTAs that may execute in parallel with one another on a parallel processing unit. The developer specifies the configuration of the pipestages, including the configuration of the different CTAs across all pipestages, as well as the different processing operations performed by each different CTA."
9697641,"One embodiment of the present invention sets forth a technique for converting alpha values into pixel coverage masks. Geometric coverage is sampled at a number of “real” sample positions within each pixel. Color and depth values are computed for each of these real samples. Fragment alpha values are used to determine an alpha coverage mask for the real samples and additional “virtual” samples, in which the number of bits set in the mask bits is proportional to the alpha value. An alpha-to-coverage mode uses the virtual samples to increase the number of transparency levels for each pixel compared with using only real samples. The alpha-to-coverage mode may be used in conjunction with virtual coverage anti-aliasing to provide higher-quality transparency for rendering anti-aliased images."
9704212,"A system and method for image processing are provided. The system comprises a main computing device and a secondary computing device. The main computing device comprises a main graphics card and a main central processing unit, and the secondary computing device comprises a secondary graphics card and a secondary central processing unit. The main computing device is configured to detect the secondary computing device. The main central processing unit is configured to send a request to process raw image data together to the secondary central processing unit and allocate the raw image data to the main graphics card and the secondary graphics card after receiving a response from the secondary central processing unit. The main graphics card and the secondary graphics card are configured to process images based on the allocation of the main central processing unit. The system and method for image processing provided by the present invention can take full advantage of graphics cards located in different computing devices and enable these graphics cards to work together to accelerate image processing."
9710275,"A system and method for allocating shared memory of differing properties to shared data objects and a hybrid stack data structure. In one embodiment, the system includes: (1) a hybrid stack creator configured to create, in the shared memory, a hybrid stack data structure having a lower portion having a more favorable property and a higher portion having a less favorable property and (2) a data object allocator associated with the hybrid stack creator and configured to allocate storage for shared data object in the lower portion if the lower portion has a sufficient remaining capacity to contain the shared data object and alternatively allocate storage for the shared data object in the higher portion if the lower portion has an insufficient remaining capacity to contain the shared data object."
9710306,Systems and methods for auto-throttling encapsulated compute tasks. A device driver may configure a parallel processor to execute compute tasks in a number of discrete throttled modes. The device driver may also allocate memory to a plurality of different processing units in a non-throttled mode. The device driver may also allocate memory to a subset of the plurality of processing units in each of the throttling modes. Data structures defined for each task include a flag that instructs the processing unit whether the task may be executed in the non-throttled mode or in the throttled mode. A work distribution unit monitors each of the tasks scheduled to run on the plurality of processing units and determines whether the processor should be configured to run in the throttled mode or in the non-throttled mode.
9710874,"One embodiment of the present invention sets forth a technique for mid-primitive execution preemption. When preemption is initiated no new instructions are issued, in-flight instructions progress to an execution unit boundary, and the execution state is unloaded from the processing pipeline. The execution units within the processing pipeline, including the coarse rasterization unit complete execution of in-flight instructions and become idle. However, rasterization of a triangle may be preempted at a coarse raster region boundary. The amount of context state to be stored is reduced because the execution units are idle. Preempting at the mid-primitive level during rasterization reduces the time from when preemption is initiated to when another process can execute because the entire triangle is not rasterized."
9710894,"A system and method for enhanced multi-sample anti-aliasing. The method includes determining a sampling pattern corresponding to a pixel and adjusting the sampling pattern based on a visual effect (e.g., post-processing visual effect). The method further includes accessing a first plurality of samples based on the sampling pattern. The first plurality of samples may comprise a second plurality of samples within the pixel and a third plurality of pixels outside of the pixel. The method further includes performing anti-aliasing filtering of the pixel based on the first plurality of samples and the sampling pattern."
9711099,"A method for driving a display panel having a variable refresh rate is disclosed. The method comprises receiving a current input frame from an image source. Next, it comprises determining a number of re-scanned frames to insert between the current input frame and a subsequent input frame, wherein the re-scanned frames repeat the input frame, and wherein the number of re-scanned frames depends on the minimum refresh interval (MRI) of the display panel. Further, it comprises calculating respective intervals at which to insert the re-scanned frames between the current input frame and the subsequent input frame. Subsequently, it comprises determining if a charge accumulation in pixels of the display panel has crossed over a predetermined threshold value. Finally, responsive to a determination that the charge accumulation has crossed over a predetermined threshold value, it comprises performing a counter-measure to remediate the charge accumulation."
9715413,"One embodiment of the present invention sets forth a technique for selecting a first processor included in a plurality of processors to receive work related to a compute task. The technique involves analyzing state data of each processor in the plurality of processors to identify one or more processors that have already been assigned one compute task and are eligible to receive work related to the one compute task, receiving, from each of the one or more processors identified as eligible, an availability value that indicates the capacity of the processor to receive new work, selecting a first processor to receive work related to the one compute task based on the availability values received from the one or more processors, and issuing, to the first processor via a cooperative thread array (CTA), the work related to the one compute task."
9716051,"A packaging substrate, a packaged semiconductor device, a computing device and methods for forming the same are provided. In one embodiment, a packaging substrate is provided that includes a packaging structure having a chip mounting surface and a bottom surface. The packaging structure has at a plurality of conductive paths formed between the chip mounting surface and the bottom surface. The conductive paths are configured to provide electrical connection between an integrated circuit chip disposed on the chip mounting surface and the bottom surface of the packaging structure. The packaging structure has an opening formed in the chip mounting surface proximate a perimeter of the packaging structure. A stiffening microstructure is disposed in the opening and is coupled to the packaging structure."
9720768,"A receiver, transmitter and method for early packet header verification are provided. In one embodiment, the method includes: (1) receiving a payload flit of a preceding packet and a header flit of a current packet; and (2) using a Cyclic Redundancy Check (CRC) in the header flit to verify the payload flit of the preceding packet and the header flit of the current packet."
9720842,"A device driver calculates a tile size for a plurality of cache memories in a cache hierarchy. The device driver calculates a storage capacity of a first cache memory. The device driver calculates a first tile size based on the storage capacity of the first cache memory and one or more additional characteristics. The device driver calculates a storage capacity of a second cache memory. The device driver calculates a second tile size based on the storage capacity of the second cache memory and one or more additional characteristics, where the second tile size is different than the first tile size. The device driver transmits the second tile size to a second coalescing binning unit. One advantage of the disclosed techniques is that data locality and cache memory hit rates are improved where tile size is optimized for each cache level in the cache hierarchy."
9720858,"A texture processing pipeline can be configured to service memory access requests that represent texture data access operations or generic data access operations. When the texture processing pipeline receives a memory access request that represents a texture data access operation, the texture processing pipeline may retrieve texture data based on texture coordinates. When the memory access request represents a generic data access operation, the texture pipeline extracts a virtual address from the memory access request and then retrieves data based on the virtual address. The texture processing pipeline is also configured to cache generic data retrieved on behalf of a group of threads and to then invalidate that generic data when the group of threads exits."
9721187,"A system, method, and computer program product for providing a lasso selection tool for a stereoscopic image is disclosed. The method includes the steps of obtaining a lasso region of a stereoscopic image pair based on a path defined by a user using a lasso selection tool. An object in a first image of the stereoscopic image pair is identified, where the object is at least partially included within the lasso region and the object is identified in a second image of the stereoscopic image pair."
9721320,"A non-transitory computer-readable storage medium having computer-executable instructions for causing a computer system to perform a method for constructing bounding volume hierarchies from binary trees is disclosed. The method includes providing a binary tree including a plurality of leaf nodes and a plurality of internal nodes. Each of the plurality of internal nodes is uniquely associated with two child nodes, wherein each child node comprises either an internal node or leaf node. The method also includes determining a plurality of bounding volumes for nodes in the binary tree by traversing the binary tree from the plurality of leaf nodes upwards toward a root node, wherein each parent node is processed once by a later arriving corresponding child node."
9721381,"A system, method, and computer program product are provided for discarding pixel samples. The method includes the steps of completing shading operations for a pixel set including one or more pixels to generate per-sample shaded attributes according to a shader program executed by a processing pipeline. Discard information for the pixel set is evaluated and one or more per-sample shaded attributes for at least one pixel in the pixel set are discarded based on the evaluated discard information."
9723216,"A method for generating images. The method includes capturing first image data representing a first scene taken optically at a first magnification index, wherein the first image data comprises a first region of an image. The method includes capturing second image data representing a second scene taken optically at a second magnification index that is less than the first magnification index, wherein the second image data comprises a second region of the image. The method includes digitally zooming the second image data in the second region to the first magnification index. The method includes digitally stitching the second image data in the second region to the first image data in the first region."
9727338,"A system and method of translating functions of a program. In one embodiment, the system includes: (1) a local-scope variable identifier operable to identify local-scope variables employed in the at least some of the functions as being either thread-shared local-scope variables or thread-private local-scope variables and (2) a function translator associated with the local-scope variable identifier and operable to translate the at least some of the functions to cause thread-shared memory to be employed to store the thread-shared local-scope variables and thread-private memory to be employed to store the thread-private local-scope variables."
9727339,"Embodiments of the present invention are operable to communicate a list of important shaders and their current best-known compilations to remote client devices over a communications network. Client devices are allowed to produce modified shader compilations by varying optimizations. If a client device produces a modified compilation that beats an important shader's current best-known compilation, embodiments of the present invention can communicate this new best-known shader compilation back to a host computer system. Furthermore, embodiments of the present invention may periodically broadcast the new best-known shader compilation back to client devices for possible further optimization or for efficient rendering operations using the best-known shader compilation."
9727392,"Techniques for passing dependencies in an application programming interface API includes identifying a plurality of passes of execution commands. For each set of passes, wherein one pass is a destination pass and the other pass is a source pass to each other, one or more dependencies, of one or more dependency types, are determined between the execution commands of the destination pass and the source pass. Pass objects are then created for each identified pass, wherein each pass object records the execution commands and dependencies between the corresponding destination and source passes."
9727463,"A method of caching data in the memory of electronic processor units including compiling, in a first processor configured to perform data-parallel computation, a set of asymmetric coherent caching rules. The set of rules configure the first processor to be: inoperable to cache, in a second level memory cache of the first electronic processor unit, data whose home location is in a final memory store of a second electronic processor unit; operable to cache, in the second level memory cache of the first electronic processor unit, the data whose home location is in a final memory store of the first electronic processor unit; and operable to cache, in a first level memory cache of the first electronic processor unit, the data, regardless of a home location of the data."
9727521,"Techniques are disclosed for peer-to-peer data transfers where a source device receives a request to read data words from a target device. The source device creates a first and second read command for reading a first portion and a second portion of a plurality of data words from the target device, respectively. The source device transmits the first read command to the target device, and, before a first read operation associated with the first read command is complete, transmits the second read command to the target device. The first and second portions of the plurality of data words are stored in a first and second portion a buffer memory, respectively. Advantageously, an arbitrary number of multiple read operations may be in progress at a given time without using multiple peer-to-peer memory buffers. Performance for large data block transfers is improved without consuming peer-to-peer memory buffers needed by other peer GPUs."
9728481,"An IC system includes low-power chips, e.g., memory chips, located proximate one or more higher power chips, e.g., logic chips, without suffering the effects of overheating. The IC system may include a high-power chip disposed on a packaging substrate and a low-power chip embedded in the packaging substrate to form a stack. Because portions of the packaging substrate thermally insulate the low-power chip from the high-power chip, the low-power chip can be embedded in the IC system in close proximity to the high-power chip without being over heated by the high-power chip. Such close proximity between the low-power chip and the high-power chip advantageously shortens the path length of interconnects therebetween, which improves device performance and reduces interconnect parasitics in the IC system."
9734545,"One embodiment of the present invention sets forth a technique for executing a software method within a graphics processing unit (GPU) that minimizes the number of clock cycles during which the graphics engine is idled. The function of the software method is performed by a firmware method that is executed by a processor within the GPU. The firmware method is executed to access and optionally update the state stored in the GPU. Unlike execution of a conventional software method, execution of the firmware method does not require an exchange of information between a CPU and the GPU. Therefore, the CPU is not interrupted and throughput of the CPU is not reduced."
9734546,"A computer system includes an operating system having a kernel and configured to launch a plurality of computing processes. The system also includes a plurality of graphics processing units (GPUs), a front-end driver module, and a plurality of back-end driver modules. The GPUs are configured to execute instructions on behalf of the computing processes subject to a GPU service request. The front-end driver module is loaded into the kernel and configured to receive the GPU service request from one of the computing processes. Each back-end driver module is associated with one or more of the GPUs and configured to receive the GPU service request from the front-end driver module and pass the GPU service request to an associated GPU."
9734548,"One embodiment of the present invention includes techniques for adaptively sizing cache tiles in a graphics system. A device driver associated with a graphics system sets a cache tile size associated with a cache tile to a first size. The detects a change from a first render target configuration that includes a first set of render targets to a second render target configuration that includes a second set of render targets. The device driver sets the cache tile size to a second size based on the second render target configuration. One advantage of the disclosed approach is that the cache tile size is adaptively sized, resulting in fewer cache tiles for less complex render target configurations. Adaptively sizing cache tiles leads to more efficient processor utilization and reduced power requirements. In addition, a unified L2 cache tile allows dynamic partitioning of cache memory between cache tile data and other data."
9740046,"A system and method are provided for displaying a lower power user interface on an liquid crystal display (LCD) panel using localized backlight control. The method includes the step of identifying a subset of light emitting elements included in a backlight for the LCD panel, where the backlight includes a plurality of light emitting elements. The subset of light emitting elements consumes less power when operated individually or in combination with other subsets of light emitting elements than the total backlight with all light emitting elements simultaneously active. The method also includes the steps of activating the subset of light emitting elements to at least partially illuminate the LCD panel while at least one light emitting element is not activated, adjusting an image for a user interface based on a compensation map corresponding to the subset of light emitting elements, and displaying the adjusted image on the LCD panel."
9740553,"Embodiments related to managing potentially invalid results generated/obtained by a microprocessor during runahead are provided. In one example, a method for operating a microprocessor includes causing the microprocessor to enter runahead upon detection of a runahead event. The example method also includes, during runahead, determining that an operation associated with an instruction referencing a storage location would produce a potentially invalid result based on a value of an architectural poison bit associated with the storage location and performing a different operation in response."
9741098,A digital camera includes an image optimization engine configured to generate an optimized image based on a raw image captured by the digital camera. The image optimization engine implements one or more machine learning engines in order to select rendering algorithms and rendering algorithm arguments that may then be used to render the raw image.
9742396,"Presented systems and methods facilitate efficient reset operation. In one embodiment, a system comprises a core domain portion an I/O domain portion and a core reset I/O by-pass component. The core domain portion is configured to operate at a nominal core domain voltage level. The I/O domain portion configured to operate at a nominal I/O domain voltage level. The core reset I/O by-pass component configured to forward a reset indication to the core domain independent of the I/O domain. In one exemplary implementation the core reset I/O by-pass component is operable to receive an input reset indication at a high domain voltage level and to convert the input reset indication to a core reset signal that is less than or substantially equal to the nominal core domain voltage, wherein the high domain is voltage higher than the core domain voltage level."
9742869,"A request management subsystem is configured to establish service classes for clients that issue requests for a shared resource on a computer system. The subsystem also is configured to determine the state of the system with respect to bandwidth, current latency, frequency and voltage levels, among other characteristics. Further, the subsystem is configured to evaluate the requirements of each client with respect to latency sensitivity and required bandwidth, among other characteristics. Finally, the subsystem is configured to schedule access to shared resources, based on the priority class of each client, the demands of the application, and the state of the system. With this approach, the subsystem may enable all clients to perform optimally or, alternatively, may cause all clients to experience an equal reduction in performance."
9746954,"A touch-screen input/output device including a touch sensor, a display, a display control module, a touch sensor control module and a synchronizer module. The touch sensor is overlaid on a display. The display control module is communicatively coupled to the display and converts video data into a serial bit stream video display signal include one or more blanking intervals. The touch sensor control module is communicatively coupled to the touch sensor and determines touch events and location of the touch event on the touch sensor during one or more touch sensor scan cycles. The synchronizer module is communicatively coupled between the display control module and the touch sensor control module, and interleaves the one or more touch sensor scan cycles with the one or more blanking intervals of the video display signal."
9746969,"A flat panel electronic device is presented. The flat panel electronic device comprises an actuating apparatus, a supporting apparatus and a control apparatus. The actuating apparatus is configured to generate a first actuating signal. The supporting apparatus has an extending position and an initial position, wherein the supporting apparatus is configured to support at least a portion of the flat panel electronic device to a predetermined height when the supporting apparatus is in the extending position. The control apparatus is configured to control the movement of the supporting apparatus in response to the first actuating signal. In addition, the supporting apparatus can also have an additional function for adjusting the angle of the display panel of the flat panel electronic device with respect to the user, so as to improve the comfort level for watching."
9747107,"A system and method for compiling or runtime executing a fork-join data parallel program with function calls. In one embodiment, the system includes: (1) a partitioner operable to partition groups into a master group and at least one worker group and (2) a thread designator associated with the partitioner and operable to designate only one thread from the master group for execution and all threads in the at least one worker group for execution."
9747527,"In one embodiment of the present invention, a graphics processing unit (GPU) is configured to detect an object in an image using a random forest classifier that includes multiple, identically structured decision trees. Notably, the application of each of the decision trees is independent of the application of the other decision trees. In operation, the GPU partitions the image into subsets of pixels, and associates an execution thread with each of the pixels in the subset of pixels. The GPU then causes each of the execution threads to apply the random forest classifier to the associated pixel, thereby determining a likelihood that the pixel corresponds to the object. Advantageously, such a distributed approach to object detection more fully leverages the parallel architecture of the PPU than conventional approaches. In particular, the PPU performs object detection more efficiently using the random forest classifier than using a cascaded classifier."
9747661,"A system, method, and computer program product are provided for adjusting vertex positions. One or more viewport dimensions are received and a snap spacing is determined based on the one or more viewport dimensions. The vertex positions are adjusted to a grid according to the snap spacing. The precision of the vertex adjustment may increase as at least one dimension of the viewport decreases. The precision of the vertex adjustment may decrease as at least one dimension of the viewport increases."
9747718,"A system, method, and computer program product are provided for performing object-space shading. A primitive defined by vertices in three-dimensional (3D) space that is specific to an object defined by at least the primitive is received and a shading sample rate is computed for the primitive based on a screen-space derivative of coordinates of a pixel fragment transformed into the 3D space. A shader program is executed by a processing pipeline to compute shaded attributes for the primitive according to the computed shading sample rate."
9754407,"A system, method, and computer program product are provided for shading using a dynamic object-space grid. An object defined by triangle primitives in a three-dimensional (3D) space that is specific to the object is received and an object-space shading grid is defined for a first triangle primitive of the triangle primitives based on coordinates of the first triangle primitive in the 3D space. A shader program is executed by a processing pipeline to compute a shaded value at a point on the object-space shading grid for the first triangle primitive."
9754561,"One embodiment of the present invention includes a memory management unit (MMU) that is configured to manage sparse mappings. The MMU processes requests to translate virtual addresses to physical addresses based on page table entries (PTEs) that indicate a sparse status. If the MMU determines that the PTE does not include a mapping from a virtual address to a physical address, then the MMU responds to the request based on the sparse status. If the sparse status is active, then the MMU determines the physical address based on whether the type of the request is a write operation and, subsequently, generates an acknowledgement of the request. By contrast, if the sparse status is not active, then the MMU generates a page fault. Advantageously, the disclosed embodiments enable the computer system to manage sparse mappings without incurring the performance degradation associated with both page faults and conventional software-based sparse mapping management."
9755994,"One embodiment of the present disclosure sets forth an effective way to maintain fairness and order in the scheduling of common resource access requests related to replay operations. Specifically, a streaming multiprocessor (SM) includes a total order queue (TOQ) configured to schedule the access requests over one or more execution cycles. Access requests are allowed to make forward progress when needed common resources have been allocated to the request. Where multiple access requests require the same common resource, priority is given to the older access request. Access requests may be placed in a sleep state pending availability of certain common resources. Deadlock may be avoided by allowing an older access request to steal resources from a younger resource request. One advantage of the disclosed technique is that older common resource access requests are not repeatedly blocked from making forward progress by newer access requests."
9756222,"Embodiments of the present invention are operable to perform automatic white balancing operations on images captured by a camera system through the use of weights derived through crowdsourcing procedures. Embodiments of the present invention use crowdsourced weight data resident on the camera system in combination with sampled image data of a captured image to determine a likely illuminant source. When performing automatic white balancing operations on the captured image, embodiments of the present invention may also compute a confidence score which may present the user with a choice to either use the likely illuminant determined using the crowdsourced weights or the camera system's default or normal automatic white balancing correction algorithm."
9760132,"Stiffening is provided for an electronic package assembly having a substrate. A first electronic package, having a first function, is electromechanically fastened to a first surface of the substrate with a first array of electrically conductive interconnects, which is disposed over a central area of the substrate first surface. A second electronic package, having a second function, is fastened to the first substrate surface with a second conductive interconnect array. At least a pair of the first array conductors is electrically coupled to at least a pair of the second array conductors for data/signal exchange and at least a component of the first electronic package interacts with at least a component of the second package. A metallic stiffener ring is disposed about an outer periphery of at least the central area of the substrate."
9760150,"A method of entering a power conservation state comprises selecting and entering one of a plurality of low power states for the computer system in response to a detected system idle event. The plurality of low power states comprise a first low power state and a second low power state for the computer system. A memory of the computer system is self refreshed during the first low power state. A baseband module of the computer system remains powered, and the memory is accessible to the baseband module during the second low power state. The one low power state is selected depending upon baseband module activity. The method also includes exiting from the one of a plurality of low power states when a wake event is detected."
9760525,"A clock generator chip, a PCI Express port and a computing device control board are provided herein. In one embodiment the clock generator chip includes: (1) a clock generator configured to generate a reference clock signal for a component in response to a clock request from the component, (2) a reference clock pin configured to provide the reference clock signal and (3) a pair of sideband signal pins configured to receive and transmit sideband packets between the component and the clock generator chip."
9760966,"A system and method for performing computer algorithms. The system includes a graphics pipeline operable to perform graphics processing and an engine operable to perform at least one of a correlation determination and a convolution determination for the graphics pipeline. The graphics pipeline is further operable to execute general computing tasks. The engine comprises a plurality of functional units operable to be configured to perform at least one of the correlation determination and the convolution determination. In one embodiment, the engine is coupled to the graphics pipeline. The system further includes a configuration module operable to configure the engine to perform at least one of the correlation determination and the convolution determination."
9761037,"A graphics processing subsystem and method for updating a voxel representation of a scene. One embodiment of the graphics processing subsystem includes: (1) a memory configured to store a voxel representation of a scene having first and second regions to be updated, and (2) a graphics processing unit (GPU) operable to: (2a) unify the first and second regions into a bounding region if a volume thereof does not exceed summed volumes of the first and second regions by more than a tolerance, and (2b) generate voxels for the bounding region and cause the voxels to be stored in the voxel representation."
9762381,"A method comprises receiving an input signal at an input of a receiver and retrieving a data sample signal and an error sample signal from the input signal. The method also comprises applying an adaptive procedure to generate a feedback code using the data sample signal and the error sample signal for feeding back into a decision feedback equalization (DFE) module. Further, it comprises converting the feedback code into a corresponding voltage value and assigning the corresponding voltage value as a tap weight for the DFE module. Finally, it comprises generating an edge sample signal by applying DFE to the input signal using the DFE module, wherein the DFE is based on the tap weight."
9766649,"A system is based on an IC. A first component of the IC generates a signal that clocks the IC at a target operating frequency. A period corresponding to the target clock frequency exceeds a duration of a longest critical path associated with the IC. The first component and synchronous logic of the IC clocked therewith, each functions with the core supply voltage, which may be supplied to each via the same power supply rail. A second IC component detects errors that relate to an operation of the IC at the target clock frequency and determines a level for adjusting the core supply voltage. The Vdd adjustment ameliorates the frequency error. The voltage determination uses closed loop dynamic voltage and frequency scaling."
9766734,"Embodiments are disclosed for a touch-based device and methods for operation thereof. One embodiment provides a touch-based device having a display with a plurality of pixels and a touch input sensor overlying the display. The touch input sensor has a plurality of touch regions, each of which overlie an associated set of the pixels. The touch-based device further comprises a display controller configured to update the pixels according to a schema during which pixels are updated during update periods. The touch-based device yet further comprises a touch controller configured to recognize selectively applied touch inputs at the plurality of touch regions. The touch controller and the display controller are synchronized such that, for a given touch region, touch input recognition is modified while the display controller is updating the set of pixels associated with that touch region."
9766866,"One embodiment sets forth a method for efficiently determining memory resource dependencies between instructions included in a software application. For each instruction, a dependency analyzer uses overlapping search techniques to identify one or more overlaps between the memory elements included in the current instruction and the memory elements included in previous instructions. The dependency analyzer then maps objects included in the instructions to a set of partition elements wherein each partition element represents a set of memory elements that are functionally equivalent for dependency analysis. Subsequently, the dependency analyzer uses the set of partition elements to determine memory dependencies between the instructions at the memory element level. Advantageously, the disclosed techniques enable the compiler to retain an acceptable compilation speed while tuning the instruction ordering at a fine-grained memory element level, thereby increasing the speed at which the processor may execute the software application."
9767036,A system for managing virtual memory. The system includes a first processing unit configured to execute a first operation that references a first virtual memory address. The system also includes a first memory management unit (MMU) associated with the first processing unit and configured to generate a first page fault upon determining that a first page table that is stored in a first memory unit associated with the first processing unit does not include a mapping corresponding to the first virtual memory address. The system further includes a first copy engine associated with the first processing unit. The first copy engine is configured to read a first command queue to determine a first mapping that corresponds to the first virtual memory address and is included in a first page state directory. The first copy engine is also configured to update the first page table to include the first mapping.
9767538,"An image capture application captures a sequence of images via a digital camera. The sequence of images may have undesirable levels of blurriness due to the motion of objects in the field of view of the digital camera or due to movement of the digital camera itself. A deblur engine within the image capture application generates image segments within one of the captured images, where a given image segment includes pixel values that move coherently between different images in the sequence. The deblur engine then deblurs each image segment based on the coherent motion of each different image segment and combines the resultant, deblurred image segments into a deblurred image. Advantageously, blurriness caused by the combined effects of moving objects and camera motion may be reduced, thereby improving the ability of a digital camera to provide high-quality images. As such, the user experience of digital photography may be enhanced."
9767600,"A graphics processing pipeline within a parallel processing unit (PPU) is configured to perform path rendering by generating a collection of graphics primitives that represent each path to be rendered. The graphics processing pipeline determines the coverage of each primitive at a number of stencil sample locations within each different pixel. Then, the graphics processing pipeline reduces the number of stencil samples down to a smaller number of color samples, for each pixel. The graphics processing pipeline is configured to modulate a given color sample associated with a given pixel based on the color values of any graphics primitives that cover the stencil samples from which the color sample was reduced. The final color of the pixel is determined by downsampling the color samples associated with the pixel."
9769550,A method for processing a bitstream starts by shifting a bitstream of a first sample of a signal into a buffer. The buffer also holds bits of one or more additional bitstreams for one or more additional samples of the signal. Bits of a first half of the buffer are incrementally compared to corresponding bits of a second half of the buffer. Each bit of the first half of the buffer is compared to a corresponding bit of the second half of the buffer. A computation is performed on each bit of the first half of the buffer that is equal to a corresponding bit of the second half of the buffer. The results of the computations are summed to determine an output value for the first sample of the signal.
9772827,"One embodiment sets forth a method for efficiently determining memory resource dependencies between instructions included in a software application. For each instruction, a dependency analyzer uses overlapping search techniques to identify one or more overlaps between the memory elements included in the current instruction and the memory elements included in previous instructions. The dependency analyzer then maps objects included in the instructions to a set of partition elements wherein each partition element represents a set of memory elements that are functionally equivalent for dependency analysis. Subsequently, the dependency analyzer uses the set of partition elements to determine memory dependencies between the instructions at the memory element level. Advantageously, the disclosed techniques enable the compiler to retain an acceptable compilation speed while tuning the instruction ordering at a fine-grained memory element level, thereby increasing the speed at which the processor may execute the software application."
9773341,"One embodiment of the present invention includes techniques for rasterizing geometries. First, a processing unit defines a bounding primitive that covers the geometry and does not include any internal edges. If the bounding primitive intersects any enabled clip plane, then the processing unit generates fragments to fill a current viewport. Alternatively, the processing unit generates fragments to fill the bounding primitive. Because the rasterized region includes no internal edges, conflation artifacts caused when the number of coverage samples per pixel exceeds the number of color samples per pixel may be reduced. In prior-art techniques, reducing such conflation artifacts typically involves increasing the number of color samples per pixel to equal the number of coverage samples per pixel. Consequently, the disclosed techniques enable rendering using algorithms that reduce the ratio of color to coverage samples, thereby decreasing memory consumption and memory bandwidth use, without causing conflation artifacts associated with cover geometries."
9773342,"The disclosure provides a method of determining reflected irradiance for a surface point on a surface whose reflectance properties are represented by a measured BSDF. Additionally, the disclosure provides a renderer and a computer program product. In one embodiment, the method includes: (1) determining u, v and w coordinates in the measured BSDF for the surface point based on an incoming and an outgoing ray direction, (2) selecting a triangle for barycentric interpolation based on values of the v and the w coordinates at the surface point and (3) performing the barycentric interpolation for evaluating the measured BSDF for the surface point."
9773344,"A method for graphics processor clock scaling comprises the following steps. A percentage of idle-time is calculated, based upon an elapsed idle-time and an elapsed active time. A graphics processor clock rate is reduced if the percentage of idle time is higher than a high limit threshold. The graphics processor clock rate is increased if the percentage of idle time is lower than a low limit threshold."
9773460,"A system, method, and computer program product are provided for combining low motion blur and variable refresh rate in a display. In one embodiment, a hold-type display is operated in a first mode of operation where the hold-type display is dynamically refreshed such that the hold type display handles updates to image frames at unpredictable times and where for each of the image frames a backlight of the hold-type display is activated for an entire duration of display of the image frame. Additionally, it is determined that at least one predefined condition has been met. Further, in response to the determination, the hold-type display is operated in a second mode of operation where the hold-type display is statically refreshed such that the hold-type display handles updates to image frames at regular intervals and where for each of the image frames the backlight of the hold-type display is flashed."
9773473,"A system, computer-readable medium, and method are provided for generating images based on adaptations of the human visual system. An input image is received, an effect provoking change is received, and an afterimage resulting from a cumulative effect of human visual adaptation is computed based on the effect provoking change and a per-photoreceptor type physiological adaptation of the human visual system. The computed afterimage may include a bleaching afterimage effect and/or a local adaptation afterimage effect. The computed afterimage is then accumulated into an output image for display."
9775229,"This disclosure describes an electronics device that effectively removes heat from the SoC, which increases its efficiency and extends its useful life by spreading heat in the thermally conductive plate before transferring it across the interface. Surface area is a significant factor in TIM thermal performance, so this increases the performance substantially when using the same type of TIM pad. This device allows the use of lower performance TIM pads that resolve the issues of high die pressure and non-resilient behavior of high thermal conductivity TIMs. Additionally, the device mechanically isolates the SoC from the heatsink, which reduces stress and provides improved thermal performance."
9779533,One embodiment of the present invention includes a method for processing graphics objects. The method includes receiving a first draw-call and a second draw-call. The method also includes dividing the first draw-call into a first set of sub-draw-calls and the second draw-call into a second set of sub-draw-calls. The method further includes identifying a first screen tile. The method also includes identifying a first group of sub-draw-calls included in the first set of sub-draw-calls that overlap the first screen tile and a second group of sub-draw-calls included in the second set of sub-draw-calls that overlap the second screen tile. The method further includes causing the first group of sub-draw-calls and the second group of sub-draw-calls to be processed together.
9785729,"A simulation engine is configured to generate a physical simulation of a chain of particles by implementing a physics-based algorithm. The simulation engine is configured to generate a predicted position for each particle and to then adjust the predicted position of each particle based on a set of constraints associated with the physics-based algorithm. The simulation engine may then generate a predicted velocity for a given particle based on the adjusted, predicted position of that particle and based on the adjusted, predicted position of an adjacent particle."
9786255,"A method, computer program product, and system for adjusting a dynamic refresh frequency of a display device are disclosed. The method includes the steps of obtaining a current frame duration associated with a first image, computing, based on the current frame duration, a repetition value for a second image, and repeating presentation of the second image on a display device based on the repetition value. The logic for implementing the method may be included in a graphics processing unit or within the display device itself."
9787509,"An apparatus including a receiver coupled to receive an input signal from a communication link and operable to employ decision feedback equalization to the input signal of the communication link and generate an edge sample signal. The apparatus also includes a timing recovery module coupled to the receiver and operable to receive the edge sample signal and use the edge sample signal to generate a data sampling phase signal, wherein the edge sample signal influences a settling point of the data sampling phase signal."
9788347,"Provided is a recursive method and apparatus for processing a signal for determining a plurality of frequency components of the signal, the signal being a chirp-like polyphase sequence. In one embodiment, the method includes: (1) determining a first frequency component of the plurality of frequency components, (2) determining a component factor by accessing a factor table, (3) determining the second frequency component using the determined first frequency component and the determined component factor. If there is at least one further frequency component of the signal, the method further comprising for each of the further frequency components: (4) determining a respective further component factor by accessing the factor table, and (5) determining the further frequency component using a previously determined frequency component and the determined further component factor, wherein the previously determined frequency component is the frequency component determined most recently prior to determining each respective further frequency component."
9792122,"One embodiment of the present invention includes a technique for processing graphics primitives in a tile-based architecture. The technique includes storing, in a buffer, a first plurality of graphics primitives and a first plurality of state bundles received from the world-space pipeline. The technique further includes determining, based on a first condition, that the first plurality of graphics primitives should be replayed from the buffer, and, in response, replaying the first plurality of graphics primitives against a first tile included in a first plurality of tiles. Replaying the first plurality of graphics primitives includes comparing each graphics primitive against the first tile to determine whether the graphics primitive intersects the first tile, determining that one or more graphics primitives intersects the first tile, and transmitting the one or more graphics primitives and one or more associated state bundles to a screen-space pipeline for processing."
9792220,"One embodiment of the present invention includes a microcontroller coupled to a memory management unit (MMU). The MMU is coupled to a page table included in a physical memory, and the microcontroller is configured to perform one or more virtual memory operations associated with the physical memory and the page table. In operation, the microcontroller receives a page fault generated by the MMU in response to an invalid memory access via a virtual memory address. To remedy such a page fault, the microcontroller performs actions to map the virtual memory address to an appropriate location in the physical memory. By contrast, in prior-art systems, a fault handler would typically remedy the page fault. Advantageously, because the microcontroller executes these tasks locally with respect to the MMU and the physical memory, latency associated with remedying page faults may be decreased. Consequently, overall system performance may be increased."
9794593,"A video decoder architecture for processing out-of-order macro-blocks of a video stream. A microcode engine receives compressed data representing macro-blocks of a frame of a video stream, wherein at least one macro-block is received out-of-order. The microcode engine is for buffering the compressed data and for ordering the macro-blocks of the frame in raster scan order. A digital video decoder receives the macro-blocks in raster scan order and is for decoding the macro-blocks."
9798487,"One embodiment of the present invention sets forth a computer-implemented method for migrating a memory page from a first memory to a second memory. The method includes determining a first page size supported by the first memory. The method also includes determining a second page size supported by the second memory. The method further includes determining a use history of the memory page based on an entry in a page state directory associated with the memory page. The method also includes migrating the memory page between the first memory and the second memory based on the first page size, the second page size, and the use history."
9798543,"One embodiment of the present invention sets forth a technique for allocating register file entries included in a register file to a thread group. A request to allocate a number of register file entries to the thread group is received. A required number of mapping table entries included in a register file mapping table (RFMT) is determined based on the request, where each mapping table entry included in the RFMT is associated with a different plurality of register file entries included in the register file. The RFMT is parsed to locate an available mapping table entry in the RFMT for each of the required mapping table entries. For each available mapping table entry, a register file pointer is associated with an address that corresponds to a first register file entry in the plurality of register file entries associated with the available mapping table entry."
9798544,"Systems and methods for scheduling instructions for execution on a multi-core processor reorder the execution of different threads to ensure that instructions specified as having localized memory access behavior are executed over one or more sequential clock cycles to benefit from memory access locality. At compile time, code sequences including memory access instructions that may be localized are delineated into separate batches. A scheduling unit ensures that multiple parallel threads are processed over one or more sequential scheduling cycles to execute the batched instructions. The scheduling unit waits to schedule execution of instructions that are not included in the particular batch until execution of the batched instructions is done so that memory access locality is maintained for the particular batch. In between the separate batches, instructions that are not included in a batch are scheduled so that threads executing non-batched instructions are also processed and not starved."
9798548,"Systems and methods for scheduling instructions using pre-decode data corresponding to each instruction. In one embodiment, a multi-core processor includes a scheduling unit in each core for selecting instructions from two or more threads each scheduling cycle for execution on that particular core. As threads are scheduled for execution on the core, instructions from the threads are fetched into a buffer without being decoded. The pre-decode data is determined by a compiler and is extracted by the scheduling unit during runtime and used to control selection of threads for execution. The pre-decode data may specify a number of scheduling cycles to wait before scheduling the instruction. The pre-decode data may also specify a scheduling priority for the instruction. Once the scheduling unit selects an instruction to issue for execution, a decode unit fully decodes the instruction."
9798569,"A system for and method of retrieving values of captured local variables for a lambda function in Java. In one embodiment, the system includes: (1) a Java virtual machine and (2) a captured variable retriever that interacts with the Java virtual machine and configured to retrieve a signature of the lambda function from a classfile of a Java class containing the lambda function, compare the signature with a declaration of the lambda function to identify arguments corresponding to the captured local variables, modify the lambda function and cause the Java virtual machine to execute the modified lambda function."
9798698,"A system and method for preconditioning or smoothing (e.g., multi-color DILU preconditioning) for iterative solving of a system of equations. The method includes accessing a matrix comprising a plurality of coefficients of a system of equations and accessing coloring information corresponding to the matrix. The method further includes determining a diagonal matrix based on the matrix and the coloring information corresponding to the matrix. The determining of the diagonal matrix may be determined in parallel on a per color basis. The method may further include determining an updated solution to the system of equations where the updated solution is determined in parallel on a per color basis using the diagonal matrix."
9800158,"A system and method are provided for regulating a voltage level at a load. A current source generates a current and a voltage control mechanism provides a portion of the current to regulate the voltage level at the load. When the voltage level at the load is greater than a maximum voltage level, the current source is decoupled from the load and the current source is coupled to a current sink to reduce the voltage level at the load. An electric power conversion comprises the current source and the voltage control mechanism. A downstream controller is configured to control the voltage control mechanism to decouple the current source from the load and couple the current source to a current sink to reduce the voltage level at the load when the voltage level at the load is greater than a maximum voltage level."
9804621,"A system and method are provided for generating non-overlapping enable signals. A peak voltage level is measured at an output of a current source that is configured to provide current to a voltage control mechanism. The non-overlapping enable signals are generated for the voltage control mechanism based on the peak voltage level. A system includes the current source, a downstream controller, and the voltage control mechanism that is coupled to the load. The current source is configured to provide current to the voltage control mechanism. The controller is configured to measure the peak voltage level at the output of the current source and generate the non-overlapping enable signals based on the peak voltage level. The non-overlapping enable signals provide a portion of the current to the load."
9804826,"System and method for pseudo-random number generation based on a recursion with significantly increased multithreaded parallelism. A single pseudo-random generator program is assigned with multiple threads to process in parallel. N state elements indexed incrementally are arranged into a matrix comprising x rows, where a respective adjacent pair of state elements in a same column are related by g=(M+j)mod N, wherein j and g represent indexes of the pair of state elements. x can be determined through an modular manipulative inverse of M and N. The matrix can be divided into sections with each section having a number of columns, and each thread is assigned with a section. In this manner, the majority of the requisite interactions among the state elements occur without expensive inter-thread communications, and further each thread may only need to communicate with a single other thread for a small number of times."
9804854,"The description covers a system and method for operating a micro-processing system having a runahead mode of operation. In one implementation, the method includes providing, for a first portion of code, a runahead correlate. When the first portion of code is encountered by the micro-processing system, a determination is made as to whether the system is operating in the runahead mode. If so, the system branches to the runahead correlate, which is specifically configured to identify and resolve latency events likely to occur when the first portion of code is encountered outside of runahead. Branching out of the first portion of code may also be performed based on a determination that a register is poisoned."
9804885,"Techniques are provided for restoring threads within a processing core. The techniques include, for a first thread group included in a plurality of thread groups, executing a context restore routine to restore from a memory a first portion of a context associated with the first thread group, determining whether the first thread group completed an assigned function, and, if the first thread group completed the assigned function, then exiting the context restore routine, or if the first thread group did not complete the assigned function, then executing one or more operations associated with a trap handler routine."
9805439,"The server based graphics processing techniques, describer herein, include loading a given instance of a guest shim layer and loading a given instance of a guest display device interface that calls back into the given instance of the guest shim layer, in response to loading the given instance of the guest shim layer, wherein the guest shim layer and the guest display device interface are executing under control of a virtual machine guest operating system. The given instance of the shim layer requests a communication channel between the given instance of the guest shim layer and a host-guest communication manager (D3D HGCM) service module from a host-guest communication manager (HGCM). In response to the request for the communication channel loading, the D3D HGCM service module is loaded and a communication channel between the given instance of the shim layer and the D3D HGCM service module is created by the HGCM. The given instance of the shim layer maps the graphics buffer memory space of a host D3D DDI binary executing under control of a host operating system. Thereafter, function calls are sent from the given instance of the guest shim layer through the communication channel to the D3D HGCM service module utilizing the graphics buffer memory space mapping."
9811874,"System and method of dynamically adjusting a frame buffer resolution. An average frame rate is dynamically computed based on the frame rates with respect to rendering a sequence of previous frames to a frame buffer. The frame rates may vary with the processing load of an associated graphics processor. A target scaling factor for frame buffer resolution is computed based upon the dynamic average frame rate and a desired frame rate. The current scaling factor of frame buffer resolution for rendering a respective frame data of a sequence of frame data to the frame buffer is adjusted incrementally to reach the target scaling factor. Accordingly, frame resolutions for rendering the sequence of frame data to the frame buffer are incrementally adjusted based on corresponding current scaling factors."
9812770,"One aspect provides an antenna. The antenna, in this aspect, includes a grounded segment extending from a metal chassis of an electronic device, and a feed portion coplanar with the grounded segment, the grounded segment and feed portion jointly tuned to cause the antenna to communicate in selected bands of frequencies."
9813254,"A system and method for providing real-time assistance regarding a cloud-based application and an application server incorporating the system or the method. In one embodiment, the system includes: (1) an assistance request receiver operable to receive from a user requesting assistance an assistance request regarding the cloud-based application, (2) a rendered video stream diverter associated with the assistance request receiver and operable to reroute an original rendered video stream associated with the user requesting assistance to a user providing assistance and (3) a modification receiver associated with the assistance request receiver and operable to receive from the user providing assistance at least one modification regarding the original rendered video stream, a stream transmitter associated with the modification receiver operable to transmit a modified rendered video stream toward the user requesting assistance that has been modified based on the at least one modification."
9817455,"The present invention provides a processor and a circuit board including the processor. The processor includes a data processing unit, and an external power supply component that is coupled to the data processing unit; wherein the data processing unit includes a power management unit that is integrated into the data processing unit, and the power management unit is used for performing power management for the data processing unit; and the power management unit further includes a pulse signal output terminal which is used for outputting a pulse-width modulation signal, and the pulse-width modulation signal controls the external power supply component to supply a stable operating voltage to the data processing unit. The present invention provides a processor with the improved performance, the improved stability and the simplified structure."
9817668,"One embodiment of the present invention sets forth an approach for executing replay operations for divergent operations in a parallel processing subsystem. Specifically, the streaming multiprocessor (SM) includes a multistage pipeline configured to batch two or more replay operations for processing via replay loop. A logic element within the multistage pipeline detects whether the current pipeline stage is accessing a shared resource, such as loading data from a shared memory. If the threads are accessing data which are distributed across multiple cache lines, then the multistage pipeline batches two or more replay operations, where the replay operations are inserted into the pipeline back-to-back."
9817919,"A system, method, and computer program product are provided for modifying a hierarchical tree data structure. An initial hierarchical tree data structure is received, and treelets of node neighborhoods are formed. A processor restructures the treelets using agglomerative clustering to produce an optimized hierarchical tree data structure that includes at least one restructured treelet, where each restructured treelet includes at least one internal node."
9818379,"Embodiments are disclosed relating to a method of driving a display panel. In one embodiment, the method includes sending a stream of pixels from a display engine to a first pixel interface and a second pixel interface, transmitting a first subset of the stream of pixels from the first pixel interface to the display panel, and transmitting a second subset of the stream of pixels from the second pixel interface to the display panel."
9819604,"Systems and methods for multiplexing audio/video data and generating transport streams for WiFi network with reduced latency for real time playback at a remote device. A virtual presentation clock reference (PCR) representing a scheduled transmission time of a transport stream packet at a transport stream multiplexer is calculated based on the network transmission rate and generation of the data packets. The virtual PCR is compared with the corresponding system PCR to derive a time difference. Based on the time difference, the transport stream multiplexer is configured to adaptively drop packets or throttle packet generation so as to synchronize the playback of audio/video data on a sink device with the generation of interleaved audio/video packets."
9819969,"A method for encoding at least one extra bit in an image compression and decompression system. The method includes accessing an input image, and compressing the input image into a compressed image using an encoder system, wherein said encoding system implements an algorithm for encoding at least one extra bit. The method further includes communicatively transferring the compressed image to a decoding system, and decompressing the compressed image into a resulting uncompressed image that is unaltered from said input image, wherein the algorithm for encoding enables the recovery of the at least one extra bit."
9823728,"Embodiments of the present invention are capable of lowering touch scan rates in a manner that conserves power resources without compromising performance or user experience thereby promoting battery life. Embodiments of the present invention perform touch scan operations using a touch sensitive panel at a first scan rate. In response to certain events automatically detected within the mobile device (e.g., when a full-screen video is being displayed), embodiments of the present invention may then perform touch scan operations at a second scan rate that is slower than the first scan rate that also consumes less power compared to the first scan rate. As such, for events or use cases in which limited user interaction with the touch sensitive panel is typical, embodiments of the present invention may lower touch scan rates in a manner that still enables users to interact with applications (e.g., interaction with playback controls during video playback) and promotes efficient power usage and extends battery life."
9823758,"A computer system has a touch sensitive display screen within a housing and a touch sensor, which is coupled to a bus. A processor and a memory are coupled to the bus. The housing has a channel for receiving and storing a stylus. A sensor is disposed adjacent to the channel. The sensor interacts with the stylus through the Hall effect caused by a magnet within the stylus and is thus operable for detecting a presence or absence of the stylus without physical contact therewith. The memory has an application which, when executed on the processor, automatically performs one or more stylus related software functions upon a reported absence of the stylus from the channel. One of the software functions includes palm detection rejection with respect to data from the touch sensor. Another function includes display of a GUI displaying a listing of applications that are based on stylus data entry modes. Another function includes setting up OS modes designed for accurate operation of stylus data entry."
9823869,"Embodiments of the claimed subject matter provide systems and methods for protecting data in dynamically allocated regions of memory. The method can include receiving the read request where the read request comprises a virtual address associated with a memory and determining a physical address associated with the virtual address. The further includes determining whether the physical address associated with the virtual address is read protected and determining whether the read request is from a component allowed to access read protected memory. The read protected memory was dynamically allocated on a per page basis. The method further includes in response to determining that the read request is to a read protected physical address and determining that the component is allowed to access read protected memory, sending the data from the physical address in the memory."
9823931,"Various embodiments of microprocessors and methods of operating a microprocessor during runahead operation are disclosed herein. One example method of operating a microprocessor includes identifying a runahead-triggering event associated with a runahead-triggering instruction and, responsive to identification of the runahead-triggering event, entering runahead operation and inserting the runahead-triggering instruction along with one or more additional instructions in a queue. The example method also includes resuming non-runahead operation of the microprocessor in response to resolution of the runahead-triggering event and re-dispatching the runahead-triggering instruction along with the one or more additional instructions from the queue to the execution logic."
9823935,"A system including one or more input interface drivers, an input dispatcher, one or more applications, a system compositor and one or more output interface drivers. The input interface driver receives input events. The input dispatcher is modified to dispatch a current input event to a corresponding application after receiving an indication that a display image based upon a previous input event has been posted to an output interface driver. The corresponding application renders a new display image based upon the current input event. The system compositor posts the new display image to the output interface driver. The system compositor is also modified to send an indication to the input dispatcher that the new display image has been posted to the output interface driver. The system iteratively performs the process to latch the dispatching of input events to the display flip."
9823964,A method for updating a DRAM memory array is disclosed. The method comprises: a) receiving a command from a memory controller to initiate an active cycle for activating a memory row in a DRAM memory array; b) performing an Error Correction Code (ECC) scrub on the memory row prior to reading data from the memory row into sense amplifiers in the DRAM memory array in accordance with the command to activate; c) activating the memory row; and d) writing corrected data following the ECC scrub back into memory from the sense amplifiers during a pre-charge cycle of the DRAM memory array.
9823990,"Embodiments of the claimed subject matter are directed to methods and systems that allow tracking and accounting of wear and other aging effects in integrated circuits and products which include integrated circuits over time, and the dynamic adjustment of operating conditions to increase or decrease wear in response to the accumulated wear relative to the expected wear during the lifetime of the circuit and/or product."
9824009,"Systems and methods for coherency maintenance are presented. The systems and methods include utilization of multiple information state tracking approaches or protocols at different memory or storage levels. In one embodiment, a first coherency maintenance approach (e.g., similar to a MESI protocol, etc.) can be implemented at one storage level while a second coherency maintenance approach (e.g., similar to a MOESI protocol, etc.) can be implemented at another storage level. Information at a particular storage level or tier can be tracked by a set of local state indications and a set of essence state indications. The essence state indication can be tracked “externally” from a storage layer or tier directory (e.g., in a directory of another cache level, in a hub between cache levels, etc.). One storage level can control operations based upon the local state indications and another storage level can control operations based in least in part upon an essence state indication."
9824772,A method of training chip select for a memory module. The method includes programming a memory controller into a mode wherein a command signal is active for a programmable time period. The method then programs a programmable delay line of the chip select with a delay value and performs initialization of the memory module. A read command is then sent to the memory module to toggle a state of the chip select. A number of data strobe signals sent by the memory module in response to the read command are counted. A determination is made whether the memory module is in a pass state or an error state based on a result of the counting.
9825642,"A subsystem configured to implement an analog to digital converter that includes a high speed comparator with an embedded reference voltage level that functions as a calibrated threshold. A calibration element applies power to a reference voltage system. The calibration element then selects a differential analog voltage and applies the differential analog voltage to the inputs of the comparator. A digitally coded signal then configures an array of switches that connect complements of integrated resistors to each input of the comparator so that the switching point of the comparator occurs coincident with the applied differential analog reference voltage, nulling out the effect of the applied differential analog voltage and comparator errors. The calibration element then removes power from the reference voltage system. As a result, the comparator is configured with an embedded threshold that equals the differential analog reference voltage."
9826208,"Embodiments of the present invention are operable to generate a set of weights derived through crowdsourcing procedures for use in automatically performing white balancing operations on images captured by a digital camera system. Embodiments of the present invention are operable to generate a set of images which are illuminated with known and different illuminants. Using crowdsourcing procedures, embodiments of the present invention gather user feedback concerning which images from the set of images adjusted by the known illuminants are considered to be the most aesthetically pleasing. Images selected by the users are then stored within a database of selected images. Using a learning engine, embodiments of the present invention may then produce a set of weights based on the user selected images for use in determining a likely illuminant when performing automatic white balancing operations performed on the camera system."
9829536,"In one embodiment, a multiple input signature register (MISR) shadow works with a MISR to compress test responses of a layout partition in a functional region of an integrated circuit. In operation, for each test pattern in a test pattern split, the MISR generates a MISR signature based on the responses of the layout partition. As the test patterns in the test pattern split execute, the MISR shadow accumulates the MISR signatures and stores the result as MISR shadow data. After the final test pattern included in the test pattern split executes, the MISR shadow combines the bits in the MISR shadow data to form a single bit MISR shadow status that indicates whether the layout partition, and therefore the functional region, responds properly to the test pattern split. By efficiently summarizing the test responses, the MISR shadow optimizes the resources required to identify defective functional regions."
9829715,"The invention provides an eyewear device for transmitting a signal and a communication method thereof. The eyewear device comprises a receiving unit, a shutter and a transmitting unit. For example, the receiving unit is capable of receiving a synchronization signal, and the shutter performs an operation in response to the synchronization signal. Meanwhile, the transmitting unit transmits the synchronization signal to another eyewear device. By this way, each eyewear device is capable of receiving the synchronization signal, and re-transmits the synchronization signal to another eyewear device."
9829956,"An approach is provided for enabling power reduction in floating-point operations. In one example, a system receives floating-point numbers of a fused multiply-add instruction. The system determines the fused multiply-add instruction does not require compliance with a standard of precision for floating-point numbers. The system generates gating signals for an integrated circuit that is configured to perform operations of the fused multiply-add instruction. The system then sends the gating signals to the integrated circuit to turn off a plurality of logic gates included in the integrated circuit."
9829967,"A power subsystem is configured to manage the maximum power usage of a computer subsystem. A power detector determines when power usage approaches the maximum capability of the power supply. The power detector generates a signal that corresponds to power usage. A controller then applies the signal to the system voltage regulator as a secondary regulation function such that the output voltage is reduced in a manner that supports maximum operating voltage while limiting power usage to within the capability of the power supply. The controller may configure the signal to implement the secondary regulation function as a modification of the feedback voltage, the reference voltage, or the current feedback of the regulator. As a result the subsystem causes the computer subsystem to operate at an optimum point on the voltage-current curve of the power supply."
9830156,"One embodiment of the present invention sets forth a technique for optimizing parallel thread execution in a temporal single-instruction multiple thread (SIMT) architecture. When the threads in a parallel thread group execute temporally on a common processing pipeline rather than spatially on parallel processing pipelines, execution cycles may be reduced when some threads in the parallel thread group are inactive due to divergence. Similarly, an instruction can be dispatched for execution by only one thread in the parallel thread group when the threads in the parallel thread group are executing a scalar instruction. Reducing the number of threads that execute an instruction removes unnecessary or redundant operations for execution by the processing pipelines. Information about scalar operands and operations and divergence of the threads is used in the instruction dispatch logic to eliminate unnecessary or redundant activity in the processing pipelines."
9830158,"One embodiment of the present invention sets forth a technique for speculatively issuing instructions to allow a processing pipeline to continue to process some instructions during rollback of other instructions. A scheduler circuit issues instructions for execution assuming that, several cycles later, when the instructions reach multithreaded execution units, that dependencies between the instructions will be resolved, resources will be available, operand data will be available, and other conditions will not prevent execution of the instructions. When a rollback condition exists at the point of execution for an instruction for a particular thread group, the instruction is not dispatched to the multithreaded execution units. However, other instructions issued by the scheduler circuit for execution by different thread groups, and for which a rollback condition does not exist, are executed by the multithreaded execution units. The instruction incurring the rollback condition is reissued after the rollback condition no longer exists."
9830161,"In one embodiment of the present invention, a streaming multiprocessor (SM) uses a tree of nodes to manage threads. Each node specifies a set of active threads and a program counter. Upon encountering a conditional instruction that causes an execution path to diverge, the SM creates child nodes corresponding to each of the divergent execution paths. Based on the conditional instruction, the SM assigns each active thread included in the parent node to at most one child node, and the SM temporarily discontinues executing instructions specified by the parent node. Instead, the SM concurrently executes instructions specified by the child nodes. After all the divergent paths reconverge to the parent path, the SM resumes executing instructions specified by the parent node. Advantageously, the disclosed techniques enable the SM to execute divergent paths in parallel, thereby reducing undesirable program behavior associated with conventional techniques that serialize divergent paths across thread groups."
9830197,"One embodiment of the present invention sets forth a technique for performing aggregation operations across multiple threads that execute independently. Aggregation is specified as part of a barrier synchronization or barrier arrival instruction, where in addition to performing the barrier synchronization or arrival, the instruction aggregates (using reduction or scan operations) values supplied by each thread. When a thread executes the barrier aggregation instruction the thread contributes to a scan or reduction result, and waits to execute any more instructions until after all of the threads have executed the barrier aggregation instruction. A reduction result is communicated to each thread after all of the threads have executed the barrier aggregation instruction and a scan result is communicated to each thread as the barrier aggregation instruction is executed by the thread."
9830210,"One embodiment of the present invention includes techniques for a first processing unit to perform an atomic operation on a memory page shared with a second processing unit. The memory page is associated with a page table entry corresponding to the first processing unit. Before executing the atomic operation, an MMU included in the first processing unit evaluates an atomic permission bit that is included in the page table entry. If the MMU determines that the atomic permission bit is inactive, then the two processing units coordinate to change the permission status of the memory page. As part of the status change, the atomic permission bit in the page table entry is activated. Subsequently, the first processing unit performs the atomic operation uninterrupted by the second processing unit. Advantageously, coordinating the processing unit via the atomic permission bit ensures the proper and efficient execution of the atomic operation."
9830224,"One embodiment of the present invention is a parallel processing unit (PPU) that includes one or more streaming multiprocessors (SMs) and implements a selective fault-stalling pipeline. Upon detecting a memory access fault associated with an operation executing on a particular SM, a replay unit in the selective fault-stalling pipeline considers the operation as a faulting operation. Subsequently, instead of notifying the SM of the memory access fault, the replay unit recirculates the operation—reinserting the operation into the selective fault-stalling pipeline. Recirculating faulting operations in such a fashion enables the SM to execute other operation while the replay unit stalls the faulting request until the associated access fault is resolved. Advantageously, the overall performance of the PPU is improved compared to conventional PPUs that, upon detecting a memory access fault, cancel the associated operation and subsequent operations."
9830262,"Embodiments of the approaches disclosed herein include a subsystem that includes an access tracking mechanism configured to monitor access operations directed to a first memory and a second memory. The access tracking mechanism detects an access operation generated by a processor for accessing a first memory page residing on the second memory. The access tracking mechanism further determines that the first memory page is included in a first subset of memory pages residing on the second memory. The access tracking mechanism further locates, within a reference vector, a reference bit that corresponds to the first memory page, and sets the reference bit. One advantage of the present invention is that memory pages in a hybrid system migrate as needed to increase overall memory performance."
9830276,"One embodiment of the present invention is a parallel processing unit (PPU) that includes one or more streaming multiprocessors (SMs) and implements a replay unit per SM. Upon detecting a page fault associated with a memory transaction issued by a particular SM, the corresponding replay unit causes the SM, but not any unaffected SMs, to cease issuing new memory transactions. The replay unit then stores the faulting memory transaction and any faulting in-flight memory transaction in a replay buffer. As page faults are resolved, the replay unit replays the memory transactions in the replay buffer—removing successful memory transactions from the replay buffer—until all of the stored memory transactions have successfully executed. Advantageously, the overall performance of the PPU is improved compared to conventional PPUs that, upon detecting a page fault, stop performing memory transactions across all SMs included in the PPU until the fault is resolved."
9830288,"One embodiment of the present invention sets forth a method for transmitting data rendered on a primary computer to a secondary computer. The method includes transmitting to GPU graphics processing commands received from a graphics application, where the graphics processing commands are configured to cause the GPU to render a first set of graphics data, determining that graphics data should be collected for transmission to the secondary computer, conveying to the GPU that the first set of graphics data should be stored in a first buffer within a frame buffer memory, transmitting to the GPU graphics processing commands received from a process application executing on the primary computer, where the graphics processing commands are configured to cause the GPU to perform operations on the first set of graphics data to generate a second set of graphics data, and transmitting the second set of graphics data to the secondary computer."
9830419,"A computer-implemented method for designing an integrated circuit includes determining a timing slack associated with a first cell of the integrated circuit that is physically adjacent to a second cell of the integrated circuit, the second cell including an implant region that is in violation of an implant width design rule associated with the integrated circuit, determining that the timing slack is greater than a change in timing slack associated with expanding the implant region into the first cell, and, in response, expanding the implant region from first cell into the second cell to form a larger implant region."
9830703,One embodiment of the present invention sets forth a technique for estimating a head pose of a user. The technique includes acquiring depth data associated with a head of the user and initializing each particle included in a set of particles with a different candidate head pose. The technique further includes performing one or more optimization passes that include performing at least one iterative closest point (ICP) iteration for each particle and performing at least one particle swarm optimization (PSO) iteration. Each ICP iteration includes rendering the three-dimensional reference model based on the candidate head pose associated with the particle and comparing the three-dimensional reference model to the depth data. Each PSO iteration comprises updating a global best head pose associated with the set of particles and modifying at least one candidate head pose. The technique further includes modifying a shape of the three-dimensional reference model based on depth data.
9830741,"Techniques are disclosed for processing graphics objects in a stage of a graphics processing pipeline. The techniques include receiving a graphics primitive associated with the graphics object, and determining a plurality of attributes corresponding to one or more vertices associated with the graphics primitive. The techniques further include determining values for one or more state parameters associated with a downstream stage of the graphics processing pipeline based on a visual effect associated with the graphics primitive. The techniques further include transmitting the state parameter values to the downstream stage of the graphics processing pipeline. One advantage of the disclosed techniques is that visual effects are flexibly and efficiently performed."
9830865,"A solution is proposed that performs global histogramming of pre-regionally-enhanced pixel values accounting for inter-regional illumination contributions to verify that over-saturation of an image is prevented. According to an embodiment, pixel values that have been regionally enhanced—that is, with applied gains calculated for the respective regions—are further added to illumination values corresponding to the pixel values, with the resultant summed pixel values being histogrammed again to determine the amount of over-saturated pixels. An over-abundance of over-saturated pixels results in a calculation of a global modifier applied to each pixel to reduce the number of over-saturated pixels below an acceptable threshold."
9830871,"A method for driving a display panel having a variable refresh rate is disclosed. The method comprises detecting a condition that results in a charge accumulation in the display panel using an accumulated difference in time duration between frames of positive polarity and frames of negative polarity received from an image source. The DC imbalance is a result of a frame pattern comprising alternating frames of differing polarities, wherein frames of positive polarity within the frame pattern are of a different time duration than frames of negative polarity, and wherein the frame pattern results in an accumulation of charge in pixels of the display panel. The method also comprises correcting for the charge accumulation by disrupting the frame pattern."
9830880,"One embodiment of the invention sets forth a technique for determining the frame rate of video content and modifying the refresh rate of a display device to be a multiple of the determined frame rate. A video player application accesses video content and transmits video content frames associated with the video content to a driver. Based on the received video content frames, the driver generates display frames for display on a display device. The driver also determines a frame rate associated with the video content and then modifies the refresh rate of the display device to be a multiple of the video content frame rate."
9830889,"Embodiments of the present invention are directed to provide a method and system for automatically applying artificial limits to display resolutions in a computing system to improve performance. Embodiments are described herein that automatically limits the display resolution of an application executing in a discrete graphics processing unit operating from configurations with limited means of data transfer to the system memory. By automatically limiting the resolution in certain detected circumstances, the rate of generated graphics data may be dramatically increased. Another embodiment is also provided which allows for the automatic detection of an application's initialization and pro-actively limiting the user-selectable resolutions in which the output of the application may be displayed in to a maximum resolution calculated for optimal performance. The application's termination is also detected, whereupon a comprehensive list of supported resolutions becomes available."
9830958,One embodiment sets forth a technique for time-multiplexed communication for transmitting command and address information between a controller and a multi-port memory device over a single connection. Command and address information for each port of the multi-port memory device is time-multiplexed within the controller to produce a single stream of commands and addresses for different memory requests. The single stream of commands and addresses is transmitted by the controller to the multi-port memory device where the single stream is demultiplexed to generate separate streams of commands and addresses for each port of the multi-port memory device.
9831184,"An interposer having decaps formed in blind-vias, a packaged semiconductor structure having decaps formed in blind-vias, and methods for forming the same are provided. In one embodiment, an interposer is provided that includes an interconnect layer disposed on a substrate. A plurality of through-vias are formed through the substrate in an isolated region of the substrate. At least one of the plurality of conductive vias are electrically coupled to at least one of a plurality of top wires formed in the interconnect layer. A plurality of blind-vias are formed through the substrate in a dense region of the substrate during a common etching step with the through-vias. At least one blind-via includes (a) a dielectric material lining the blind-vias, and (b) a conductive material filling the lined blind-vias and forming a decoupling capacitor."
9831189,"An integrated circuit package includes a packaging substrate, which has an electrically conductive grid formed on a dielectric layer, and an integrated circuit die electrically coupled to the electrically conductive grid at one or more locations. In this embodiment, the electrically conductive grid includes a plurality of electrically conductive portions, wherein each portion is electrically coupled to at least one other portion, and a plurality of void regions that are electrically non-contiguous and substantially free of electrically conductive material. One advantage of the integrated circuit package is that a packaging substrate that is reduced in thickness, and therefore rigidity, can still maintain planarity during operation. The electrically conductive grid formed on a dielectric layer in the packaging substrate can replace a power plane or a ground plane in the packaging substrate, thereby reducing stressed produced as a result of thermal expansion mismatch between materials in the packaging substrate."
9831198,"An active component of an integrated voltage regulator (IVR) circuit is deployed within an IC device for regulating an operating voltage thereof. An interposer interconnects the IC device with a power source. A passive inductive component of the IVR circuit is deployed upon a surface of the IC device or the interposer. The inductive component has a magnetic core and a winding (e.g., wire-bond), wound about the magnetic core."
9831225,"A system includes a semiconductor die mounted on a packaging substrate, a signal redistribution layer that is formed within the packaging substrate, a power plane that is formed on a surface of the packaging substrate, and a ground plane that is formed within the packaging substrate. The power plane couples the semiconductor die to a capacitor disposed on the packaging substrate and the ground plane is disposed between the power plane and the signal redistribution layer. An advantage of the disclosed system is that loop inductance between power and ground paths to a packaged semiconductor die is reduced, thereby lowering the impedance of the packaged semiconductor die system and signal noise associated with the packaged semiconductor system."
9831838,"A low noise amplifier includes a first input transistor coupled to an input signal and a second input transistor coupled to the input signal. The low noise amplifier also includes a first output transistor, coupled between the first input transistor and a first carrier aggregation load, configured to connect the first input transistor to the first carrier aggregation load. Additionally, the low noise amplifier includes a second output transistor, coupled between the first input transistor and a second carrier aggregation load, configured to connect the first input transistor to the second carrier aggregation load. Further, the low noise amplifier includes a third output transistor, coupled between the second input transistor and the second carrier aggregation load, configured to connect the second input transistor to the second carrier aggregation load. Also included are a method of operating a low noise amplifier and an extended carrier low noise amplifier."
9831999,Methods for operating a small cell in a discontinued reception (DRX) mode include maintaining the small cell in a discontinuous transmission (DTX) mode during a first time period having a plurality of first time slots. The methods include transmitting common reference signals in a predetermined number of second time slots prior to the first time slots and in a predetermined number of third time slots following commencement of the first time slots. The methods include discontinuing transmission of the common reference signals and common channel signals if mobile devices are in a discontinuous reception mode during the first time period. The methods include discontinuing transmission of the common reference signals during a predetermined number of fourth time slots following commencement of the first time period if there is no dedicated common transmission to the mobile devices.
9832388,Systems and methods for generating high dynamic images from interleaved Bayer array data with high spatial resolution and reduced sampling artifacts. Bayer array data are demosaiced into components of the YUV color space before deinterleaving. The Y component and the UV components can be derived from the Bayer array data through demosiac convolution processes. A respective convolution is performed between a convolution kernel and a set of adjacent pixels of the Bayer array that are in the same color channel. A convolution kernel is selected based the mosaic pattern of the Bayer array and the color channels of the set of adjacent pixels. The Y data and UV data are deinterleaved and interpolated into frames of short exposure and long exposures in the second color space. The short exposure and long exposure frames are then blended and converted back to a RGB frame representing a high dynamic range image.
9835684,"A printed circuit board, an in-circuit test structure and a method for producing the in-circuit test structure thereof are disclosed. The in-circuit test structure comprises a via and a test pad. The via passes through the printed circuit board for communicating with an electrical device to be tested on the printed circuit board. The test pad is formed on an upper surface of the printed circuit board and covering the via, wherein a center of the via deviates from a center of the test pad. In the in-circuit test, the accuracy of the test data can be improved by means of the in-circuit test structure provided by the present invention, and thus the reliability of the test result is ensured. Also, the test efficiency of the in-circuit test is improved."
9836325,"One embodiment of the present disclosure sets forth an effective way to maintain fairness and order in the scheduling of common resource access requests related to replay operations. Specifically, a streaming multiprocessor (SM) includes a total order queue (TOQ) configured to schedule the access requests over one or more execution cycles. Access requests are allowed to make forward progress when needed common resources have been allocated to the request. Where multiple access requests require the same common resource, priority is given to the older access request. Access requests may be placed in a sleep state pending availability of certain common resources. Deadlock may be avoided by allowing an older access request to steal resources from a younger resource request. One advantage of the disclosed technique is that older common resource access requests are not repeatedly blocked from making forward progress by newer access requests."
9836878,"A system, method, and computer program product are provided for processing primitive-specific attributes. A portion of a graphics processor is determined to operate in a fast geometry shader mode and a vertex associated with a set of per-vertex attributes is determined to be a shared vertex. The shared vertex is determined to be a non-provoking vertex corresponding to a first primitive that is associated with a first set of per-primitive attributes and the shared vertex is determined to be a provoking vertex corresponding to a second primitive that is associated with a second set of per-primitive attributes. Only one set of the per-vertex attributes associated with the shared vertex is stored and only one of the second set of per-primitive attributes associated with the second primitive is stored."
9837030,"A method, computer program product, and system for selectively disabling temporal dithering is disclosed. The method includes the steps of configuring a display device to refresh utilizing a dynamic refresh rate to display images and selectively disabling temporal dithering of the images based on the dynamic refresh rate. Selectively disabling temporal dithering may comprise determining a dynamic refresh rate associated with a current frame of image data and disabling temporal dithering for the current frame of image data when the dynamic refresh rate is less than a first threshold value, or enabling temporal dithering for the current frame of image data when the dynamic refresh rate is greater than or equal to a second threshold value."
9839854,"Methods of providing in-game virtual split screens with peer-to-peer video conferencing are described for use in online gaming, for instance. In one approach, a live video stream, a live audio stream, and a player viewpoint are sent from a first computer system for receipt by a second computer system. The first and second computer systems concurrently execute the online game. The live video stream, the in-game video stream, and locally rendered in-game content are combined to create a composite video stream, and the live audio stream, the in-game audio stream, and locally generated in-game audio are combined to create a composite audio stream. The composite video stream and the composite audio stream are operable to be presented at the second computer system in real-time."
9841537,"In embodiments of the invention, an apparatus may include a display comprising a plurality of pixels and a computer system coupled with the display and operable to instruct the display to display images. The apparatus may further include a microlens array located adjacent to the display and comprising a plurality of microlenses, wherein the microlens array is operable to produce a light field by altering light emitted by the display to simulate an object that is in focus to an observer while the display and the microlens array are located within a near-eye range of the observer."
9841938,A monitor display system includes a computing device that is coupled to a collection of dissimilar monitors and a display manager that is coupled to the computing device. The display manager has an image generator that generates an image for the collection of dissimilar monitors and also has a pixel density normalizer that is coupled to the image generator and provides an alignment of the image across the collection of dissimilar monitors. A method of managing a display image is also included.
9842532,"An image is remotely processed over a network. An electronic device is characterized based on a unique identifier associated therewith and properties data, which relate to display related properties of the device. Local data is collected from the device in relation to real-time conditions and control data and, which correspond to the device in relation to the characterizing. The image is remotely generated for download to the device and includes processing data. The processing data are based on the properties data and the local data."
9842631,"Mitigating external influences on long signal lines. In accordance with an embodiment of the present invention, a column of a memory array includes first and second transistors configured to pull up the bit line of the column. The column includes a third transistor configured to selectively pull up the bit line of the column responsive to a level of the inverted bit line of the column and a fourth transistor configured to selectively pull up the inverted bit line of the column responsive to a level of the bit line of the column. The column further includes fifth and sixth transistors configured to selectively pull up the bit line and inverted bit line of the column responsive to the clamp signal and a seventh transistor configured to selectively couple the bit line of the column and the inverted bit line of the column responsive to the clamp signal."
9843811,"A method for rotating macro-blocks of a frame of a video stream. A degree of rotation for the video stream is accessed. A macro-block of the video stream is accessed. The macro-block is rotated according to the degree of rotation. The macro-block is repositioned to a new position within the frame, wherein the new position is based on the degree of rotation."
9846607,"A method for linking information related to a computer crash. The method includes establishing a network of computing resources communicatively coupled to a network, wherein each computing resource is associated with a corresponding hardware configuration capable of executing and displaying at least one application, wherein each of the network of computing resources is associated with a globally unique identifier (GUID). The method includes receiving configuration information relating to the network of computing resources. The method includes receiving a crash report of a crash occurring on a crashed computing system within the network of computing resources. The method includes extracting a GUID from the crash report, wherein the GUID identifies said crashed computing resource. The method includes determining configuration information for the crashed computing resource, and correlating the configuration information with the crash information."
9847891,"In a system according to one embodiment of the present disclosure, the system comprises a first device, a second device, a communications link, and a memory. The memory stores instructions that when executed by the system perform a method of communications link training. This method comprises requesting a speed change to a second speed for the first device communicating with the second device at a first speed via the communications link. A saved set of parameters are accessed for at least one of the first device and the second device. A first training cycle is performed for the first device and the second device at the second speed using the saved set of parameters for the at least one of the first device and second device. The reuse of parameters from a previous successful equalization training cycle reduces the time required to perform equalization training."
9852497,"An aspect of the present invention proposes a solution to allow low-cost flat panel displays without light guides to maintain a high quality image display via enhancement of pixel data to account for non uniform brightness. According to one embodiment, each pixel of a display is mapped to the brightness (intensity) of illumination that reaches the pixel. Regional pixel gains are calculated and applied on a per pixel basis to compensate for the non-uniform brightness across the screen. According to such an embodiment, even low cost flat panel displays experiencing non-uniform brightness can be used to render high quality images."
9858221,"Remotely synchronizing data communicated in an electronic computing system. Ordered writing of a data set of discrete data packets (data) and a following associated semaphore packet (semaphore) from a source electronic device (source) to a bridge interface device (bridge). Relaxed writing of the data set from the bridge to discrete target memory addresses (targets) of a data-consuming electronic device (consumer), wherein the order of the data and the semaphore written to the targets is different than the order of the data and semaphore written with the ordered writing. Monitoring, by the consumer, the relaxed writing of the semaphore to one of the targets. Issuing a synchronization command to the bridge upon detection of the semaphore having been written to the one target. Sending a synchronization confirmation reply from the bridge after all of the data has been written to the targets."
9865035,"Image scaling techniques, in accordance with embodiments of the present technology, include directionally interpolating blocks of pixel data of an image, sharpening the directional interpolated blocks of pixel data, and optionally clamping the sharpened, directional interpolated blocks of pixel data."
9870375,"Various embodiments relating to reducing memory bandwidth consumed by a continuous scan display screen are provided. In one embodiment, scoring criteria are applied to a reference image of a first image format having a first bit depth to generate an image conversion score. The scoring criteria are based on a histogram of one or more characteristics of the reference image. If the image conversion score is greater than a threshold value, then the reference image is converted to a modified image of a second image format having a second bit depth less than the first bit depth, and the modified image is scanned onto the continuous scan display screen. If the image conversion score is less than the threshold value, then the reference image is scanned onto the continuous scan display screen."
9870598,"A method of noise filter parameter adaptation, the method comprising receiving a current video frame comprising a plurality of pixels. A table lookup is performed, using current statistical values associated with the current video frame. Noise filter parameters are adapted, based on current lighting conditions as determined from the performed table lookup. The current lighting conditions correspond to the current statistical values. The current video frame is noise filtered as defined by the adapted noise filter parameters."
9871448,"A power supply system. The power system includes a power supply controller for supplying a control signal. The power system also includes a plurality of MOSFET drivers controlled by the control signal. The power system also includes a plurality of power channels. Each of the power channels includes a plurality of MOSFETs that is controlled by a corresponding MOSFET driver. The plurality of power channels is configured to generate a plurality of power signals, wherein the control signal controls delivery of the plurality of power signals through each of the power channels."
9875105,"Embodiments related to re-dispatching an instruction selected for re-execution from a buffer upon a microprocessor re-entering a particular execution location after runahead are provided. In one example, a microprocessor is provided. The example microprocessor includes fetch logic, one or more execution mechanisms for executing a retrieved instruction provided by the fetch logic, and scheduler logic for scheduling the retrieved instruction for execution. The example scheduler logic includes a buffer for storing the retrieved instruction and one or more additional instructions, the scheduler logic being configured, upon the microprocessor re-entering at a particular execution location after runahead, to re-dispatch, from the buffer, an instruction that has been previously dispatched to one of the execution mechanisms."
9875568,"A graphics effect data structure and method of use thereof. One embodiment of the graphics effect data structure is embodied in an effect processing system, including: (1) a memory configured to store an effect data structure that describes a graphics effect implemented by a plurality of passes and shader code modules contained in the effect data structure, (2) a graphics processing unit (GPU) operable to render the graphics effect according to a shader program based on the shader code modules, assembled according to the plurality of passes, and (3) a central processing unit (CPU) configured to execute an application that employs the graphics effect and to gain access to the effect data structure during run time, at which time the shader program is passed to the GPU for processing."
9876875,"Optimizing computing device application profiles. Receiving, from power-user computing devices, a set of user-based application profiles, each application profile including one or more device parameter settings associated with an application operable to run on the devices. Evaluating the set on an optimization server computer with an electronic processor operable to: calculate if a count of the profiles of the set exceeds a predefined minimum threshold count; calculate a variance for one of the device parameter settings of the set, if the count exceeds the minimum threshold count; calculate if the variance is below a predefined maximum threshold variance; calculate an optimal value for the one of the device parameter settings, if the variance is below the maximum threshold variance; and storing, in computer-readable storage media of the optimization server computer, the optimal value in a recommended set. Publishing the recommended set towards end-user computing devices configured to run the application."
9880325,"A method for displaying a near-eye light field display (NELD) image is disclosed. The method comprises determining a pre-filtered image to be displayed, wherein the pre-filtered image corresponds to a target image. It further comprises displaying the pre-filtered image on a display. Subsequently, it comprises producing a near-eye light field after the pre-filtered image travels through a microlens array adjacent to the display, wherein the near-eye light field is operable to simulate a light field corresponding to the target image. Finally, it comprises altering the near-eye light field using at least one converging lens, wherein the altering allows a user to focus on the target image at an increased depth of field at an increased distance from an eye of the user and wherein the altering increases spatial resolution of said target image."
9880846,"In one embodiment, a micro-processing system includes a hardware structure disposed on a processor core. The hardware structure includes a plurality of entries, each of which are associated with portion of code and a translation of that code which can be executed to achieve substantially equivalent functionality. The hardware structure includes a redirection array that enables, when referenced, execution to be redirected from a portion of code to its counterpart translation. The entries enabling such redirection are maintained within or evicted from the hardware structure based on usage information for the entries."
9880851,"A system, method, and computer program product for generating executable code for performing large integer operations on a parallel processing unit is disclosed. The method includes the steps of compiling a source code linked to a large integer library to generate an executable file and executing the executable file to perform a large integer operation using a parallel processing unit. The large integer library includes functions for processing large integers that are optimized for the parallel processing unit."
9880900,"In one embodiment, a method for updating a DRAM memory array is disclosed. The method comprises: a) transitioning the DRAM memory array from an idle state to a self-refresh state after a period of inactivity; b) initiating a refresh on the DRAM memory array using DRAM internal control circuitry; and c) during the refresh, performing an Error Correction Code (ECC) scrub operation of selected bits in an activated row of the DRAM memory array."
9881592,"An aspect of the present invention proposes a novel approach that can reduce the total number of the overlays to be composited during the display of graphical output in a mobile computing device. As a result, the total number of memory bandwidth and the usage of a graphics processing unit by a pre-compositor can be decreased significantly. According to one embodiment, this new approach is implemented with a display panel with embedded memory which supports a partial update, or refresh feature. Which such a feature, the layer compositor (typically either the display controller or GPU) is able to keep track of actively updating regions of a display panel by checking if each layer has new content to be displayed."
9882605,"A method for transmitting data advantageously reduces cross-talk in high-speed data transmission. The method comprises receiving an input data word, encoding the input data word into a code word, and driving the code word on to an interconnect for transmission. The code word is generating using a balanced coding scheme, and the interconnect is a single-ended, twisted-wire interposer interconnect. A receiver circuit decodes the code word to generate an output data word."
9885753,Efficient scan system presented can comprise: an array including a plurality of array non scannable components and a plurality of array quasi-scannable components wherein each column of the array includes at least one of the plurality of array quasi-scannable components; and an input interface configured to receive and selectively forward data and scan information to at least a portion of the array. At least a portion of the plurality of array quasi-scannable components can form a diagonal pattern in the array. The input interface can include: an input interface selection component wherein an output of the input interface selection component is communicatively coupled to an input of the input interface quasi-scannable component associated with one row and an input of the input interface selection component is communicatively coupled to an output of one of the plurality of array quasi-scannable components associated with another row.
9886402,"A method comprises selecting a starting point on a map of equalization coefficients and measuring an eye height of a signal transmitted using the set of equalization coefficients associated with the starting point and an eye height associated with each adjacent point on the map relative to the starting point. The eye height associated with an adjacent point is based on a signal transmitted using the set of equalization coefficients associated with the adjacent point. The method also comprises walking on the map in a first direction from the starting point to the adjacent point associated with the greatest eye height, wherein the eye height associated with the adjacent point is greater than or equal to the eye height associated with the starting point."
9886409,"An integrated circuit device comprises pin resources, a memory controller circuit, a network interface controller circuit, and transmitter circuitry. The pin resources comprise pads coupled to off-chip pins of the integrated circuit device. The memory controller circuit comprises a first interface and the network interface controller circuit comprises a second interface. The transmitter circuitry is configurable to selectively couple either a first signal of the first interface or a second signal of the second interface to a first pad of the pin resources based on a pin distribution between the first interface and the second interface."
9886736,"A method for handling parallel processing clients associated with a server in a GPU, the method comprising: receiving a failure indication for at least client running a thread in the GPU; determining threads in the GPU associated with the failing client; exiting threads in the GPU associated with the failing client; and continuing to execute remaining threads in the GPU for other clients running threads in the GPU."
9887751,"A communications system has a cellular structure and the communications system includes a base station that is located within a cell of the cellular structure and employs a Kronecker product of azimuth and elevation precoding vectors for beamforming. Additionally, the communications system includes user equipment that is located within the cell and coupled to the base station to receive a reference channel state information process employing a reference precoding vector for use in a non-reference channel state information process to derive a compensated channel quality indication. A method of operating a communications system is also included."
9888074,"A method, web browser, and system for co-browsing online content is disclosed. Embodiments enable a co-browsing session between web browsers running on different computer systems using a respective peer proxy server on each computer system. A primary peer proxy server running on a first computer system communicates directly with a web server, while communications from other peer proxy servers running on other computer systems are directed through the primary peer proxy server. The primary peer proxy server accesses online content from the web server for presentation using a web browser running on the first computer system, where the online content is presented simultaneously with modified online content presented using web browsers running on the other computer systems. The online content and the modified online content may be synchronized based upon a web server response associated with a browser event communicated to the web server."
9891949,A method for scheduling work for processing by a GPU is disclosed. The method includes accessing a work completion data structure and accessing a work tracking data structure. Dependency logic analysis is then performed using work completion data and work tracking data. Work items that have dependencies are then launched into the GPU by using a software work item launch interface.
9891972,"Embodiments related to managing lazy runahead operations at a microprocessor are disclosed. For example, an embodiment of a method for operating a microprocessor described herein includes identifying a primary condition that triggers an unresolved state of the microprocessor. The example method also includes identifying a forcing condition that compels resolution of the unresolved state. The example method also includes, in response to identification of the forcing condition, causing the microprocessor to enter a runahead mode."
9892548,"A method, system, and computer program product for performing a lighting simulation are disclosed. The method includes the steps of receiving a three-dimensional (3D) model, receiving a set of probes, where each probe specifies a location within the 3D model and an orientation of the probe, and performing, via a processor, a lighting simulation based on the 3D model, the set of probes, and one or more light path expressions. The light path expressions are regular expressions that represent a series of events, each event representing an interaction of a ray at a location in the 3D model."
9892669,"System and method of displaying images in spatial/temporal superresolution by multiplicative superposition of cascaded display layers integrated in a display device. Using an original image with a target spatial/temporal resolution as a priori, a factorization process is performed to derive respective image data for presentation on each display layer. The cascaded display layers may be progressive and laterally shifted with each other, resulting in an effective spatial resolution exceeding the native display resolutions of the display layers. Factorized images may be refreshed on respective display layers in synchronization or out of synchronization."
9900185,"A wireless communications receiver includes a receiving unit configured to receive a radio transmission having Doppler distortion and channel noise. Also included is an estimating unit coupled to the receiving unit and configured to determine a noise-abated maximum Doppler frequency estimate for the Doppler distortion. Additionally, the estimating unit is further configured to determine a signal-to-noise ratio (SNR) estimate based on the noise-abated maximum Doppler frequency estimate. In another aspect, a method of operating a wireless communications receiver is provided."
9904459,"System and method of controlling an object via control device having integrated touch and displacement control. An embodiment includes an input device having a control stick with an integrated touch sensor, where the control stick may be displaced to provide control of a first functionality of an object, and a user touch sensed by the integrated touch sensor provides control of a second functionality of the object. Additionally, a method is described for controlling an object using a control device integrating displacement and touch control modes. A motion of the object may be controlled, such that inputs from the control device control a relative movement, an absolute movement, and/or a combination of relative and absolute movement for the object. An embodiment includes a game controller having a control device according to the present disclosure."
9904653,"The disclosure provides a PCI Express Scaled Port, a computing device and a method of communicating between PCI Express components. In one embodiment, the PCI Express Scaled Port includes: (1) an interface configured to communicate flow control negotiating packets with another PCI Express Port and (2) a FCC Controller configured to generate the flow control negotiating packets, wherein the flow control negotiating packets include a flow control credit for PCI Express packets and a scaling factor for the flow control credit."
9905037,"A system, method, and computer program product are provided for rejecting small primitives. A three-dimensional (3D) primitive is received and a position within the primitive is identified. The primitive has a size that is less than a threshold value. Sub-pixel coverage information is read from a pixel sample map using the position. If the position coincides with a sub-pixel sample according to the sub-pixel coverage information, then the 3D primitive is processed. Otherwise, the 3D primitive is rejected."
9905038,"A computing system, driver and method for inserting an extra visual effect into a rendering pipeline of an application are provided. In one embodiment, the method includes: 1) loading into a driver a state machine that is customized for a particular application being rendered at a rendering pipeline; 2) identifying a point in the rendering pipeline to insert an extra visual effect using the state machine; and 3) inserting the extra visual effect into the rendering pipeline at the point."
9905196,"A computer implemented method of determining a latent image from an observed image is disclosed. The method comprises implementing a plurality of image processing operations within a single optimization framework, wherein the single optimization framework comprises solving a linear minimization expression. The method further comprises mapping the linear minimization expression onto at least one non-linear solver. Further, the method comprises using the non-linear solver, iteratively solving the linear minimization expression in order to extract the latent image from the observed image, wherein the linear minimization expression comprises: a data term, and a regularization term, and wherein the regularization term comprises a plurality of non-linear image priors."
9906981,"A method for discovering wireless access. The method includes launching an application in association with a first device. A Wi-Fi scan policy is accessed, wherein the scan policy is associated with the application. The method includes setting parameters for implementing a plurality of Wi-Fi scans from the first device based on said Wi-Fi scan policy."
9910589,"A virtual keyboard with dynamically adjusted recognition zones for predicted user-intended characters. When a user interaction with the virtual keyboard is received on the virtual keyboard, a character in a recognition zone encompassing the detected interaction location is selected as the current input character. Characters likely to be the next input character are predicted based on the current input character. The recognition zones of the predicted next input characters are adjusted to be larger than their original sizes."
9910760,"An aspect of the present invention proposes a solution for correctly intercepting, capturing, and replaying tasks (such as functions and methods) in an interception layer operating between an application programming interface (API) and the driver of a processor by using synchronization objects such as fences. According to one or more embodiments of the present invention, the application will use what appears to the application to be a single synchronization object to signal (from a processor) and to wait (on a processor), but will actually be two separate synchronization objects in the interception layer. According to one or more embodiments, the solution proposed herein may be implemented as part of an module or tool that works as an interception layer between an application and an API exposed by a device driver of a resource, and allows for an efficient and effective approach to frame-debugging and live capture and replay of function bundles."
9910865,"A method for storing digital images is presented. The method includes capturing an image using a digital camera system. It also comprises capturing metadata associated with the image or a moment of capture of the image. Further, it comprises storing the metadata in at least one field within a file format, wherein the file format defines a structure for the image, and wherein the at least one field is located within an extensible segment of the file format. In one embodiment, the metadata is selected from a group that comprises audio data, GPS data, time data, related image information, heat sensor data, gyroscope data, annotated text, and annotated audio."
9911470,"A memory circuit that presents input data at a data output promptly on receiving a clock pulse includes upstream and downstream memory logic and selection logic. The upstream memory logic is configured to latch the input data on receiving the clock pulse. The downstream memory logic is configured to store the latched input data. The selection logic is configured to expose a logic level dependent on whether the upstream memory logic has latched the input data, the exposed logic level derived from the input data before the input data is latched, and from the latched input data after the input data is latched."
9912322,"Clock generation circuit that track critical path across process, voltage and temperature variation. In accordance with a first embodiment of the present invention, an integrated circuit device includes an oscillator electronic circuit on the integrated circuit device configured to produce an oscillating signal and a receiving electronic circuit configured to use the oscillating signal as a system clock. The oscillating signal tracks a frequency-voltage characteristic of the receiving electronic circuit across process, voltage and temperature variations. The oscillating signal may be independent of any off-chip oscillating reference signal."
9916674,One embodiment of the present invention sets forth a technique for improving path rendering on computer systems with an available graphics processing unit. The technique involves reducing complex path objects to simpler geometric objects suitable for rendering on a graphics processing unit. The process involves a central processing unit “baking” a set of complex path rendering objects to generate a set of simpler graphics objects. A graphics processing unit then renders the simpler graphics objects. This division of processing load can advantageously yield higher overall rendering performance.
9916680,"Techniques are disclosed for suppressing access to a depth processing unit associated with a graphics processing pipeline. The method includes receiving a graphics primitive from a first pipeline stage associated with the graphics processing pipeline. The method further includes determining that the graphics primitive is visible over one or more graphics primitives previously rendered to a frame buffer, and determining that the depth buffer is in a read-only mode. The method further includes suppressing an operation to transmit the graphics primitive to the depth processing unit. One advantage of the disclosed technique is that power consumption is reduced within the GPU by avoiding unnecessary accesses to the depth processing unit."
9918098,"In the claimed approach, a high efficiency video coding codec optimizes the memory resources used during motion vector (MV) prediction. As the codec processes block of pixels, known as coding units (CUs), the codec performs read and write operations on a fixed-sized neighbor union buffer representing the MVs associated with processed CUs. In operation, for each CU, the codec determines the indices at which proximally-located “neighbor” MVs are stored within the neighbor union buffer. The codec then uses these neighbor MVs to compute new MVs. Subsequently, the codec deterministically updates the neighbor union buffer—replacing irrelevant MVs with those new MVs that are useful for computing the MVs of unprocessed CUs. By contrast, many conventional codecs not only redundantly store MVs, but also retain irrelevant MVs. Consequently, the codec reduces memory usage and memory operations compared to conventional codecs, thereby decreasing power consumption and improving codec efficiency."
9921847,"In one embodiment of the present invention, a streaming multiprocessor (SM) uses a tree of nodes to manage threads. Each node specifies a set of active threads and a program counter. Upon encountering a conditional instruction that causes an execution path to diverge, the SM creates child nodes corresponding to each of the divergent execution paths. Based on the conditional instruction, the SM assigns each active thread included in the parent node to at most one child node, and the SM temporarily discontinues executing instructions specified by the parent node. Instead, the SM concurrently executes instructions specified by the child nodes. After all the divergent paths reconverge to the parent path, the SM resumes executing instructions specified by the parent node. Advantageously, the disclosed techniques enable the SM to execute divergent paths in parallel, thereby reducing undesirable program behavior associated with conventional techniques that serialize divergent paths across thread groups."
9921873,"A technique for controlling the distribution of compute task processing in a multi-threaded system encodes each processing task as task metadata (TMD) stored in memory. The TMD includes work distribution parameters specifying how the processing task should be distributed for processing. Scheduling circuitry selects a task for execution when entries of a work queue for the task have been written. The work distribution parameters may define a number of work queue entries needed before a cooperative thread array” (“CTA”) may be launched to process the work queue entries according to the compute task. The work distribution parameters may define a number of CTAs that are launched to process the same work queue entries. Finally, the work distribution parameters may define a step size that is used to update pointers to the work queue entries."
9922457,"A system and method for performing tessellation of three-dimensional surface patches performs some tessellation operations using programmable processing units and other tessellation operations using fixed function units with limited precision. (u,v) parameter coordinates for each vertex are computed using fixed function units to offload programmable processing engines. The (u,v) computation is a symmetric operation and is based on integer coordinates of the vertex, tessellation level of detail values, and a spacing mode."
9928033,"One embodiment of the present invention performs a parallel prefix scan in a single pass that incorporates variable look-back. A parallel processing unit (PPU) subdivides a list of inputs into sequentially-ordered segments and assigns each segment to a streaming multiprocessor (SM) included in the PPU. Notably, the SMs may operate in parallel. Each SM executes write operations on a segment descriptor that includes the status, aggregate, and inclusive-prefix associated with the assigned segment. Further, each SM may execute read operations on segment descriptors associated with other segments. In operation, each SM may perform reduction operations to determine a segment-wide aggregate, may perform look-back operations across multiple preceding segments to determine an exclusive-prefix, and may perform a scan seeded with the exclusive prefix to generate output data. Advantageously, the PPU performs one read operation per input, thereby reducing the time required to execute the prefix scan relative to prior-art parallel implementations."
9928034,"A method, computer readable medium, and system are disclosed for processing a segmented data set. The method includes the steps of receiving a data structure storing a plurality of values segmented into a plurality of sequences; assigning a plurality of processing elements to process the plurality of values; and processing the plurality of values by the plurality of processing elements according to a merge-based algorithm. Each processing element in the plurality of processing elements identifies a portion of values in the plurality of values allocated to the processing element based on the merge-based algorithm. In one embodiment, the processing elements are threads executed in parallel by a parallel processing unit."
9928104,"A system, method, and computer program product are provided for accessing a queue. The method includes receiving a first request to reserve a data record entry in a queue, updating a queue state block based on the first request, and returning a response to the request. A second request is received to commit the data record entry and the queue state block is updated based on the second request."
9928109,"One embodiment of the present disclosure sets forth a technique for enforcing cross stream dependencies in a parallel processing subsystem such as a graphics processing unit. The technique involves queuing waiting events to create cross stream dependencies and signaling events to indicated completion to the waiting events. A scheduler kernel examines a task status data structure from a corresponding stream and updates dependency counts for tasks and events within the stream. When each task dependency for a waiting event is satisfied, an associated task may execute."
9928639,"A system and method for facilitating increased graphics processing without deadlock. Embodiments of the present invention provide storage for execution unit pipeline results (e.g., texture pipeline results). The storage allows increased processing of multiple threads as a texture unit may be used to store information while corresponding locations of the register file are available for reallocation to other threads. Embodiments further provide for preventing deadlock by limiting the number of requests and ensuring that a set of requests is not issued unless there are resources available to complete each request of the set of requests. Embodiments of the present invention thus provide for deadlock free increased performance."
9928642,A system and method uses the capabilities of a geometry shader unit within the multi-threaded graphics processor to implement algorithms with variable input and output.
9928644,"A solution is proposed for efficiently determining whether or not a set of elements (such as convex shapes) in a multi-dimensional space mutually intersects. The solution may be applied to elements in any closed subset of real numbers for any number of spatial dimensions of the multi-dimensional space. The solutions provided herein include iterative processes for calculating the point displacement from boundaries of the elements (shapes), and devices for implementing the iterative process(es). The processes and devices herein may be extended to abstract (functional) definitions of convex shapes, allowing for simple and economical representations. As an embodiment of the present invention, an object called a “void simplex” may be determined, allowing the process to terminate even earlier when found, thereby avoiding unnecessary computation without excess memory requirements."
9930082,"A system and method for network driven automatic adaptive rendering impedance are presented. Embodiments of the present invention are operable to dynamically throttle the frame rate associated with an application using a server based graphics processor based on determined communication network conditions between a server based application and a remote server. Embodiments of the present invention are operable to monitor network conditions between the server and the client using a network monitoring module and correspondingly adjust the frame rate for a graphics processor used by an application through the use of a throttling signal in response to the determined network conditions. By throttling the application in the manner described by embodiments of the present invention, power resources of the server may be conserved, computational efficiency of the server may be promoted and user density of the server may be increased."
9934145,"In one embodiment of the present invention a cache unit organizes data stored in an attached memory to optimize accesses to compressed data. In operation, the cache unit introduces a layer of indirection between a physical address associated with a memory access request and groups of blocks in the attached memory. The layer of indirection—virtual tiles—enables the cache unit to selectively store compressed data that would conventionally be stored in separate physical tiles included in a group of blocks in a single physical tile. Because the cache unit stores compressed data associated with multiple physical tiles in a single physical tile and, more specifically, in adjacent locations within the single physical tile, the cache unit coalesces the compressed data into contiguous blocks. Subsequently, upon performing a read operation, the cache unit may retrieve the compressed data conventionally associated with separate physical tiles in a single read operation."
9934153,"A patch memory system for accessing patches from a memory is disclosed. A patch is an abstraction that refers to a contiguous, array of data that is a subset of an N-dimensional array of data. The patch memory system includes a tile cache, and is configured to fetch data associated with a patch by determining one or more tiles associated with an N-dimensional array of data corresponding to the patch, and loading data for the one or more tiles from the memory into the tile cache. The N-dimensional array of data may be a two-dimensional (2D) digital image comprising a plurality of pixels. A patch of the 2D digital image may refer to a 2D subset of the image."
9934714,"System and method of displaying images in temporal superresolution by multiplicative superposition of cascaded display layers integrated in a display device. Using an original video with a target temporal resolution as a priori, a factorization process is performed to derive respective image data for presentation on each display layer. The multiple layers are refreshed in staggered intervals to synthesize a video with an effective refresh rate exceeding that of each individual display layer, e.g., by a factor equal to the number of layers. Further optically averaging neighboring pixels can minimize artifacts."
9935584,"A self-biased gyrator-based input receiver amplifies and equalizes single-ended signals. The input receiver implements inductive impedance useful for high-frequency peaking circuits using an active gyrator-C circuit comprising only resistive, capacitive, and transistor elements, which are easily and efficiently fabricated on a conventional integrated circuit. Transistors comprising the input receiver, along with resistive elements and capacitive elements may be implemented as digitally adjustable circuit elements, providing for adjustment of at least peak frequency, low-frequency gain, and termination impedance."
9939883,"One embodiment provides a method for reducing leakage current in device logic having an operational supply-voltage threshold, a nonzero data-retention supply-voltage threshold, and two or more on-die transistor switches to switchably connect a voltage source to the device logic. After the logic enters an idle period, one or more of the switches are opened to lower a supply voltage of the logic below the operational supply-voltage threshold but above the data-retention supply-voltage threshold. When the logic exits the idle period, one or more of the switches are closed to raise the supply voltage of the logic above the operational supply-voltage threshold."
9940286,"Techniques are disclosed for tracking memory page accesses in a unified virtual memory system. An access tracking unit detects a memory page access generated by a first processor for accessing a memory page in a memory system of a second processor. The access tracking unit determines whether a cache memory includes an entry for the memory page. If so, then the access tracking unit increments an associated access counter. Otherwise, the access tracking unit attempts to find an unused entry in the cache memory that is available for allocation. If so, then the access tracking unit associates the second entry with the memory page, and sets an access counter associated with the second entry to an initial value. Otherwise, the access tracking unit selects a valid entry in the cache memory; clears an associated valid bit; associates the entry with the memory page; and initializes an associated access counter."
9940689,"A Central Processing Unit (CPU), system and method of performing a Graphics Processing Unit (GPU) simulation of a fluid-like object in a grid-based simulation space are provided. In one embodiment, the method includes: (1) determining, by a CPU, a list of bricks in the simulation space that the fluid-like object would occupy in a future frame based on simulation data of a current frame and (2) updating, based on the list, a virtual table that maps portions of a GPU memory to tiled resources corresponding to the bricks before a simulation of said future frame."
9940898,"A method for displaying video. The method includes executing an application at a processor. As instructed by the processor when executing the application, the method includes rendering a plurality of image frames at a plurality of graphics processing units (GPUs). The method includes determining information related to relative timing between renderings of the plurality of image frames. The method includes encoding the plurality of image frames into a video file. The method includes encoding the information into the video file."
9940901,"Systems and methods for performing optical image processing via a transparent display are disclosed. In one example approach, a method comprises determining a position of incident light on a see-through display device, determining a direction of the incident light relative to the see-through display device, and modulating, with the see-through display device, a transmission of the incident light through the see-through display device based on the determined position and determined direction of the incident light."
9946658,"An improved memory interface design is provided. In some implementations, an integrated circuit includes a first cache memory unit, a second cache memory unit located in parallel with the first cache memory unit, and a floorsweeping module configured to be able to select between the first cache memory unit and the second cache memory unit for cache requests, wherein the selection is based at least partially on the presence or absence of one or more manufacturing defects in the first cache memory unit or the second cache memory unit."
9946666,"A system, method, and computer program product are provided for coalescing memory access requests. A plurality of memory access requests is received in a thread execution order and a portion of the memory access requests are coalesced into memory order, where memory access requests included in the portion are generated by threads in a thread block. A memory operation is generated that is transmitted to a memory system, where the memory operation represents the coalesced portion of memory access requests."
9947084,"A technique for multiresolution consistent rasterization in which a setup unit calculates universal edge equations for a universal resolution. A rasterizer evaluates coverage data for two different resolutions based on the edge equations. The rasterizer evaluates coverage data for different effective pixel sizes—a large pixel size and a small pixel size. Optionally, the rasterizer may determine a first set of coverage data by performing conservative rasterization to determine coverage data for large pixels. Optionally, the rasterizer may then determine a second set of coverage data by performing standard rasterization for small pixels. Optionally, for the second set of coverage data, the rasterizer may evaluate only the small pixels that are within large pixels in the first set of coverage data that evaluate as covered."
9947132,"A material representation data structure and a method of representing a material for digital image synthesis. The data structure may be embodied in a graphics processing subsystem, including: (1) a memory configured to store a material representation data structure according to which a material is declaratively represented by a property indicative of an interaction between the material and light, and (2) a processor operable to gain access to the memory and employ the property in a rendering procedure defined independent of the material representation data structure and designed to effect the interaction."
9952281,"Disclosed are a method, system, and/or apparatus to perform clock jitter and power supply noise analysis. In one embodiment, a method may include receiving a first signal, which may be a clock signal, then generating a second signal based on the first signal. The method may further include delaying the second signal by a base delay and/or a series of fine delays. The method may also include taking measurements of the delayed second signal and comparing those measurements to theoretical measurements of the second signal that would occur if the first signal were noise-free. The method may further include determining, based on the measurements and the comparison thereof, whether noise is present, whether the noise is high frequency or low frequency noise, and whether the noise is due to clock jitter and/or power supply deviations."
9952843,"A solution is proposed for implementing staging in computer programs and code specialization at runtime. Even when values are not known at compile time, many of the values used as parameters for a code section or a function are constant, and are known prior to starting the computation of the algorithm. Embodiments of the claimed subject matter propagate these values just before execution in the same way a compiler would if they were compile time constant, resulting in improved control flow and significant simplification in the computation involved."
9952868,"One embodiment of the present invention sets forth a graphics processing system. The graphics processing system includes a screen-space pipeline and a tiling unit. The screen-space pipeline is configured to perform visibility testing and fragment shading. The tiling unit is configured to determine that a first set of primitives overlaps a first cache tile. The tiling unit is also configured to first transmit the first set of primitives to the screen-space pipeline with a command configured to cause the screen-space pipeline to process the first set of primitives in a z-only mode, and then transmit the first set of primitives to the screen-space pipeline with a command configured to cause the screen-space pipeline to process the first set of primitives in a normal mode. In the z-only mode, at least some fragment shading operations are disabled in the screen-space pipeline. In the normal mode, fragment shading operations are enabled."
9952977,A method for managing a parallel cache hierarchy in a processing unit. The method including receiving an instruction that includes a cache operations modifier that identifies a level of the parallel cache hierarchy in which to cache data associated with the instruction; and implementing a cache replacement policy based on the cache operations modifier.
9953455,"Techniques are disclosed for storing post-z coverage data in a render target. A color raster operations (CROP) unit receives a coverage mask associated with a portion of a graphics primitive, where the graphics primitive intersects a pixel that includes a multiple samples, and the portion covers at least one sample. The CROP unit stores the coverage mask in a data field in the render target at a location associated with the pixel. One advantage of the disclosed techniques is that the GPU computes color and other pixel information only for visible fragments as determined by post-z coverage data. The GPU does not compute color and other pixel information for obscured fragments, thereby reducing overall power consumption and improving overall render performance."
9953457,"A system, method, and computer program product are provided for performing path space filtering. In use, a set of light transport paths associated with a scene is sampled. Additionally, a plurality of vertices associated with the sampled set of light transport paths is selected, where each selected vertex has an associated throughput and light contribution. Further, an averaged light contribution of each of the selected plurality of vertices is determined, utilizing one or more weights. Further still, the averaged light contribution of each of the selected plurality of vertices is combined after multiplying the averaged light contribution of each of the selected vertices by the associated throughput of the vertex."
9954527,"A balanced, charge-recycling repeater link is disclosed. The link includes a first set of segments operating in a first voltage domain and a second set of segments operating in a second voltage domain. The link is configured to transmit a first signal over at least one segment in the first set of segments and at least one other segment in the second set of segments. Each segment of the link includes at least one active circuit element configured to charge or discharge one or more corresponding interconnects within the link and a level shifter configured to shift the level of a signal on a last interconnect of the segment from the first voltage domain to the second voltage domain or the second voltage domain to the first voltage domain."
9954984,"A receiver, transmitter and method for enabling a replay using a packetized link protocol are provided. In one embodiment, the method includes: (1) transmitting a stream of packets including an untagged packet and (2) using synchronized counters to determine a sequence ID of the untagged packet, which is a corrupt/lost packet that needs to be retransmitted."
9961412,"A cellular communication system is described for supporting broadcast transmission in at least one of a plurality of communication cells. The cellular communication system comprises at least one base station (210) capable of broadcasting content to at least one wireless communication unit (226) via at least one relay node (RN) (224), wherein the at least one base station (210) is arranged to supplement the broadcast transmission with at least one augmented unicast transmission associated with the broadcast content."
9965321,"One embodiment of the present invention sets forth a technique for error-checking a compute task. The technique involves receiving a pointer to a compute task, storing the pointer in a scheduling queue, determining that the compute task should be executed, retrieving the pointer from the scheduling queue, determining via an error-check procedure that the compute task is eligible for execution, and executing the compute task."
9965821,"A system and method for constructing binary radix trees in parallel, which are used for as a building block for constructing secondary trees. A non-transitory computer-readable storage medium having computer-executable instructions for causing a computer system to perform a method is disclosed. The method includes determining a plurality of primitives comprising a total number of primitive nodes that are indexed, wherein the plurality of primitives correspond to leaf nodes of a hierarchical tree. The method includes sorting the plurality of primitives. The method includes building the hierarchical tree in a manner requiring at most a linear amount of temporary storage with respect to the total number of primitive nodes. The method includes building an internal node of the hierarchical tree in parallel with one or more of its ancestor nodes."
9966755,"A shut-off circuit interrupts the flow of power to the system circuit of a portable device, when liquids are detected within the portable device. Liquid sensors are placed proximate to the ports of the portable device. The ports may admit the flow of liquids, so the liquid sensors may detect the passage of liquids into the portable device. If the liquid sensors detect liquids entering the portable device, a shut-off circuit interrupts the flow of power from the battery to the system circuit."
9971576,"A software development environment (SDE) and a method of compiling integrated source code. One embodiment of the SDE includes: (1) a parser configured to partition an integrated source code into a host code partition and a device code partition, the host code partition including a reference to a device variable, (2) a translator configured to: (2a) embed device machine code, compiled based on the device code partition, into a modified host code, (2b) define a pointer in the modified host code configured to be initialized, upon execution of the integrated source code, to a memory address allocated to the device variable, and (2c) replace the reference with a dereference to the pointer, and (3) a host compiler configured to employ a host library to compile the modified host code."
9971699,"A method, computer readable medium, and system are disclosed for decoupling data pre-fetch from demand loads. The method includes the steps of receiving, by a processor, a set of instructions that includes a load instruction; and executing, by the processor, the load instruction to perform a load operation. The load operation loads data from a cache unit into a register file. The load instruction includes a no-update operator that prevents the cache unit from updating the cache state information in response to the load operation. The result is that the eviction policy for the cache unit responds to the order of pre-fetch memory access requests rather than the demand load operations."
9971959,"In one embodiment of the present invention, a graphics processing unit (GPU) is configured to detect an object in an image using a random forest classifier that includes multiple, identically structured decision trees. Notably, the application of each of the decision trees is independent of the application of the other decision trees. In operation, the GPU partitions the image into subsets of pixels, and associates an execution thread with each of the pixels in the subset of pixels. The GPU then causes each of the execution threads to apply the random forest classifier to the associated pixel, thereby determining a likelihood that the pixel corresponds to the object. Advantageously, such a distributed approach to object detection more fully leverages the parallel architecture of the parallel processing unit (PPU) than conventional approaches. In particular, the PPU performs object detection more efficiently using the random forest classifier than using a cascaded classifier."
9973921,"A terminal for communication with a communication network and a method of configuring a subscriber identity device are disclosed. In one embodiment, the terminal includes computer storage configured to store a subscriber identity application, a processing unit operable to provide access to the communication network by executing an instance of the subscriber identity application, and a toolkit file assigning a modem of the terminal to handle at least one communication procedure for effecting said communication with the communication network, wherein the transferred terminal profile information assigns a host processor of the terminal to handle at least one communication procedure for effecting said communication with the communication network."
9978171,"A method, system, and computer program product for controlling a sample mask from a fragment shader are disclosed. The method includes the steps of generating a fragment for each pixel that is covered, at least in part, by a primitive and determining coverage information for each fragment corresponding to the primitive. Then, for each fragment, the method includes the steps of generating a sample mask by a fragment shader, replacing the coverage information for the fragment with the sample mask, and writing, based on the sample mask, a result generated by the fragment shader to a memory. The method may be implemented on a parallel processing unit configured to implement, at least in part, a graphics processing pipeline."
9983602,"Presented systems and methods can facilitate efficient voltage sensing and regulation. In one embodiment, a presented multiple point voltage sensing system includes Multiple point voltage sensing. Multi-point sensing is the scheme where voltage feedback from Silicon to the voltage regulator is an average from multiple points on the die. In one embodiment, multi-point sensing is done by placing multiple sense points across the partition/silicon and merging the sense traces from each sense point with balanced routing. In one embodiment, a presented multiple point voltage sensing system includes Virtual VDD Sensing with guaranteed non-floating feedback. In one exemplary implementation, Virtual VDD Sensing with guaranteed non-floating feedback allows more accurate sensing when a component is power gated off by removing the sensing results associated with the component."
9984504,"A system and method are provided for improving video encoding using content information. A three-dimensional (3D) modeling system produces an encoded video stream. The system includes a content engine, a renderer, and a video encoder. The renderer receives 3D model information from the content engine relating and to produces corresponding two-dimensional (2D) images. The video encoder receives the 2D images and produce a corresponding encoded video stream. The video encoder receives content information from the content engine, transforms the content information into encoder control information, and controls the video encoder using the encoder control information."
9986159,"Raw video data is captured, processed, and then stored within a set of buffers. An encoder engine is configured to encode the video data for storage. A feedback controller dynamically adjusts the clock frequency of the encoder engine based on the number of buffers currently occupied by the video data. The feedback controller is tuned so that the clock frequency of the encoder engine will be increased when the number of buffers occupied by video data increases, and the clock frequency of the encoder engine will be decreased when the number of buffers occupied by the video data decreases."
9987561,"A system for multi-client control of a common avatar is provided herein. The system includes, for example, a cloud game engine and a cooperative play engine associated with the cloud game engine and configured to multicast a video stream from the cloud game engine to multiple players, combine separate response streams from the multiple players into a joint response stream based on avatar functions contained therein and provide the joint response stream to the cloud game engine."
9996189,"Detecting a tool used on a touch screen. In accordance with a method embodiment of the present invention, a cell value is accessed for each cell of a touch sensing device. The cell value indicates a force applied to the cell. A touch area sample count is determined as a count of how many of the cells have a cell value above a noise floor. A touch area weight is determined as a sum of all cell values for the cells having a cell value above the noise floor. An object touching the touch sensing device is identified based on the touch area sample count and the touch area weight. The object's touch indication may be rejected if the object is not identified. The identity of the object may be reported to a software application."
9996490,"A transmitter is configured to scale up a low bandwidth delivered by a first processing element to match a higher bandwidth associated with an interconnect. A receiver is configured to scale down the high bandwidth delivered by the interconnect to match the lower bandwidth associated with a second processing element. The first processing element and the second processing element may thus communicate with one another across the interconnect via the transmitter and the receiver, respectively, despite the bandwidth mismatch between those processing elements and the interconnect."
9996771,"A system and method for procedurally synthesizing a training dataset for training a machine-learning model. In one embodiment, the system includes: (1) a training designer configured to describe variations in content of training images to be included in the training dataset and (2) an image definer coupled to the training designer, configured to generate training image definitions in accordance with the variations and transmit the training image definitions: to a 3D graphics engine for rendering into corresponding training images, and further to a ground truth generator for generating associated ground truth corresponding to the training images, the training images and the associated ground truth comprising the training dataset."
D1078812,
D515086,
D600738,
D702684,
D704271,
D707679,
D713844,
D892084,
D902882,
D932484,
D958860,
D978078,
RE39501,"A multiple network protocol encoder/decoder comprising a network protocol layer, data handler, O.S. State machine, and memory manager state machines implemented at a hardware gate level. Network packets are received from a physical transport level mechanism by the network protocol layer state machine which decodes network protocols such as TCP, IP, User Datagram Protocol (UDP), PPP, and Raw Socket concurrently as each byte is received. Each protocol handler parses and strips header information immediately from the packet, requiring no intermediate memory. The resulting data are passed to the data handler which consists of data state machines that decode data formats such as email, graphics, Hypertext Transfer Protocol (HTTP), Java, and Hypertext Markup Language (HTML). Each data state machine reacts accordingly to the pertinent data, and any data that are required by more than one data state machine is provided to each state machine concurrently, and any data required more than once by a specific data state machine, are placed in a specific memory location with a pointer designating such data (thereby ensuring minimal memory usage). Resulting display data are immediately passed to a display controller. Any outgoing network packets are created by the data state machines and passed through the network protocol state machine which adds header information and forwards the resulting network packet via a transport level mechanism."
RE39898,"A graphics and video controller 105 is provided which includes a dual aperture interface 206 for receiving words of graphics and video pixel data, each word of such data associated with an address directing that word to be processed as either graphics or video data. Circuitry 200, 201, 202, 207, 208 is provided for writing a word of the pixel data received from the interface 206 to a one of the on- and off-screen memory areas corresponding to the address associated with the received word. Circuitry 201, 202 is provided for selectively retrieving graphics and video data from the on-screen and off-screen memory areas. A first pipeline 205 is provided for processing data received from the on-screen area of frame buffer 107 while a second pipeline 204 is provided for processing data retrieved from the off-screen area of the frame buffer."
RE45757,"A cellular wireless internet access system which operates in the 2.5 to 2.68 GHz band and which must comply with complex government regulations on power levels, subscriber equipment and interference levels yet which provides high data rates to users and cell sizes of 1½ miles radius or more from base stations with subscriber equipment and antennas mounted indoors. Such base stations are mounted low and use spread-spectrum transmission to comply with interference rules with respect to adjacent license areas. An unidirectional tear-drop coverage pattern is used at multiple cells to further reduce interference when required. Time division duplex is used to allow the system to operate on any single channel of varying bandwidth within the 2.5 to 2.68 GHz band. Backhaul transmission from base stations to the Internet is provided using base station radio equipment, operating either on a different frequency in the band or on the same frequency using a time-division peer-to-peer technique. Different effective data-rates are provided by a prioritization tiering technique."
RE47772,"The present invention facilitates convenient and secure distribution of proprietary content. A present secure content enabled drive system and method permits flexible use of storage medium for both protected distribution of information and user definable storage use. In one embodiment, a computer readable storage medium includes an unprotected information portion, a protected information portion and a protection interface. The unprotected portion stores unprotected information. The protected content portion stores protected information. The protection interface protects information in the protected content portion from unauthorized access."
RE47984,"In embodiments of the invention, an apparatus may include a display comprising a plurality of pixels. The apparatus may further include a computer system coupled with the display and operable to instruct the display to display a deconvolved image corresponding to a target image, wherein when the display displays the deconvolved image while located within a near-eye range of an observer, the target image may be perceived in focus by the observer."
RE48876,"In embodiments of the invention, an apparatus may include a display comprising a plurality of pixels and a computer system coupled with the display and operable to instruct the display to display images. The apparatus may further include an SLM array located adjacent to the display and comprising a plurality of SLMs, wherein the SLM array is operable to produce a light field by altering light emitted by the display to simulate an object that is in focus to an observer while the display and the SLM array are located within a near-eye range of the observer."
RE49711,"Digital low-dropout micro voltage regulator configured to accept an external voltage and produce a regulated voltage. All active devices of the voltage regulator are digital devices. All signals of the voltage regulator, except the first voltage and the regulated voltage, may be characterized as digital signals. Some active devices of the voltage regulator may be physically separated from other active devices of the voltage regulator by active devices of non-voltage regulator circuitry."
